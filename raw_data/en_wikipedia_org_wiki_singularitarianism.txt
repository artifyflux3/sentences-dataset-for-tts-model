Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 History 3 Reception 4 See also 5 References 6 External links Toggle the table of contents Singularitarianism 12 languages Ελληνικά Español فارسی Français 한국어 Italiano Lietuvių 日本語 Português Русский Türkçe Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Belief in an incipient technological singularity Transhumanism Issues Accelerating change Eradication of suffering Fourth Industrial Revolution Human enhancement Genetic Moral Neuro- Cognitive liberty New eugenics Eugenics Human nature Meliorism Post-politics Post-scarcity People Andrews Bostrom Church Cordeiro de Chardin Drexler Fahy FM-2030 Freitas Fyodorov Fuller de Garis Gasson Goertzel de Grey Haldane Hanson Harari Harbisson Harris Huxley Hughes Istvan Johnson Kurzweil Land Moen Moravec More Musk Pearce Rothblatt Sandberg Savulescu Sorgner Spencer Stock Stolyarov Thiel Vinge Vita-More Walker Warwick Wiener Yudkowsky Influential works Oration on the Dignity of Man (1486) Thus Spoke Zarathustra (1883) Looking Backward (1888) The Will to Power (~1901) Daedalus (1924) La raza cósmica (1925) The Phenomenon of Man (1955) The Dialectic of Sex (1970) Metaman (1993) The Hedonistic Imperative (1995) Regeln für den Menschenpark (1997) The Age of Spiritual Machines (1999) Citizen Cyborg (2004) The Singularity Is Near (2005) Human Enhancement (2009) Fanged Noumena (2011) The Transhumanist Wager (2013) Sapiens (2014) Homo Deus (2015) The Transhumanist Bill of Rights (2015) The Age of Em (2016) The Precipice (2020) What We Owe the Future (2022) " Techno-Optimist Manifesto " (2023) Variants Accelerationism Effective Cypherpunk Dataism Extropianism Immortalism Longtermism Postgenderism Posthumanism Russian Cosmism Singularitarianism Technogaianism Technolibertarianism Technological utopianism Techno-progressivism Related topics Dyson sphere Technologies Emerging Disruptive Hypothetical v t e Singularitarianism is a movement defined by the belief that a technological singularity —the creation of superintelligence —will likely happen in the medium future, and that deliberate action ought to be taken to ensure that the singularity benefits humans .

[ 1 ] Singularitarians are distinguished from other futurists who speculate on a technological singularity by their belief that the singularity is not only possible, but desirable if guided prudently. Accordingly, they may sometimes dedicate their lives to acting in ways they believe will contribute to its rapid yet safe realization.

[ 2 ] American news magazine Time describes the worldview of Singularitarians by saying "even though it sounds like science fiction, it isn't, no more than a weather forecast is science fiction. It's not a fringe idea; it's a serious hypothesis about the future of life on Earth. There's an intellectual gag reflex that kicks in anytime you try to swallow an idea that involves super-intelligent immortal cyborgs, but... while the Singularity appears to be, on the face of it, preposterous, it's an idea that rewards sober, careful evaluation".

[ 1 ] Definition [ edit ] The term "Singularitarian" was originally defined by Extropian thinker Mark Plus (Mark Potts) in 1991 to mean "one who believes the concept of a Singularity".

[ 3 ] This term has since been redefined to mean "Singularity activist" or "friend of the Singularity"; that is, one who acts so as to bring about the singularity.

[ 4 ] Singularitarianism can also be thought of as an orientation or an outlook that prefers the enhancement of human intelligence as a specific transhumanist goal instead of focusing on specific technologies such as A.I.

[ 5 ] There are also definitions that identify a singularitarian as an activist or a friend of the concept of singularity, that is, one who acts so as to bring about a singularity.

[ 6 ] Some sources described it as a moral philosophy that advocates deliberate action to bring about and steer the development of a superintelligence that will lead to a theoretical future point that emerges during a time of accelerated change.

[ 7 ] Inventor and futurist Ray Kurzweil , author of the 2005 book The Singularity Is Near: When Humans Transcend Biology , defines a Singularitarian as someone "who understands the Singularity and who has reflected on its implications for his or her own life" [ 2 ] and estimates the singularity will occur around 2045 .

[ 2 ] History [ edit ] An early singularitarian articulation that history is making progress toward a point of superhuman intelligence is found in Hegel 's work The Phenomenology of Spirit .

[ 8 ] In 1993, mathematician , computer scientist , and science fiction author Vernor Vinge hypothesized that the moment might come when technology will allow "creation of entities with greater than human intelligence" [ 9 ] and used the term "the Singularity" to describe this moment.

[ 10 ] He suggested that the singularity may pose an existential risk for humanity, and that it could happen through one of four means: The development of computers that are "awake" and superhumanly intelligent.

Large computer networks (and their associated users) may "wake up" as a superhumanly intelligent entity.

Computer/human interfaces may become so intimate that users may reasonably be considered superhumanly intelligent.

Biological science may find ways to improve upon the natural human intellect.

[ 11 ] Singularitarianism coalesced into a coherent ideology in 2000, when artificial intelligence (AI) researcher Eliezer Yudkowsky wrote The Singularitarian Principles , [ 2 ] [ 12 ] in which he states that a Singularitarian believes that the singularity is a secular, non-mystical event that is possible, beneficial to the world, and worked toward by its adherents.

[ 12 ] Yudkowsky's definition is inclusive of various interpretations.

[ 5 ] Theorists such as Michael Anissimov argue for a strict definition that refers only to the advocacy of the development of superintelligence .

[ 5 ] In June 2000, Yudkowsky, with the support of Internet entrepreneurs Brian Atkins and Sabine Atkins, founded the Machine Intelligence Research Institute to work toward the creation of self-improving Friendly AI . MIRI's writings that an AI with the ability to improve upon its own design ( Seed AI ) would rapidly lead to superintelligence. These Singularitarians believe that reaching the singularity swiftly and safely is the best possible way to minimize net existential risk .

[ citation needed ] Many people believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy. Although the exact numbers are hard to quantify, Singularitarianism is a small movement, which includes transhumanist philosopher Nick Bostrom . Inventor and futurist Ray Kurzweil , who predicts that the Singularity will occur circa 2045 , greatly contributed to popularizing Singularitarianism with his 2005 book The Singularity Is Near: When Humans Transcend Biology .

[ 2 ] What, then, is the Singularity? It's a future period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed. Although neither utopian or dystopian, this epoch will transform the concepts we rely on to give meaning to our lives, from our business models to the cycle of human life, including death itself. Understanding the Singularity will alter our perspective on the significance of our past and the ramifications for our future. To truly understand it inherently changes one's view of life in general and one's particular life. I regard someone who understands the Singularity and who has reflected on its implications for his or her own life as a "singularitarian." [ 2 ] With the support of NASA , Google , and a broad range of technology forecasters and technocapitalists , the Singularity University opened in 2009 at the NASA Research Park in Silicon Valley with the goal of preparing the next generation of leaders to address the challenges of accelerating change .

[ citation needed ] In July 2009, many prominent Singularitarians participated in a conference organized by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss the potential impact of robots and computers and the possibility that they may become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire autonomy, and to what degree they could use such abilities to pose a threat or hazard (i.e., cybernetic revolt ). They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and independently choose targets to attack with weapons. They warned that some computer viruses can evade elimination and have achieved "cockroach intelligence". They asserted that self-awareness as depicted in science fiction is probably unlikely, but that there are other potential hazards and pitfalls.

[ 10 ] Some experts and academics have questioned the use of robots for military combat , especially when such robots are given some degree of autonomous functions.

[ 13 ] The President of the AAAI has commissioned a study of this issue.

[ 14 ] Reception [ edit ] There are several objections to Kurzweil's singularitarianism, even from optimists in the A.I. field. For instance, Pulitzer Prize -winning author Douglas Hofstadter argued that Kurzweil's predicted achievement of human-level A.I. by 2045 is not viable.

[ 15 ] Even Gordon Moore , the namesake of Moore's Law that predicated [ 16 ] the notion of singularity, maintained that it will never occur.

[ 17 ] According to some observers, these criticisms do not diminish enthusiasm for singularity because it has assumed a quasi-religious response to the fear of death, allowing its adherents to enjoy the benefits of religion without its ontological burdens.

[ 15 ] Science journalist John Horgan wrote: Let's face it. The singularity is a religious rather than a scientific vision. The science-fiction writer Ken MacLeod has dubbed it "the rapture for nerds," an allusion to the end-time, when Jesus whisks the faithful to heaven and leaves us sinners behind. Such yearning for transcendence, whether spiritual or technological, is all too understandable. Both as individuals and as a species, we face deadly serious problems, including terrorism , nuclear proliferation , overpopulation , poverty , famine , environmental degradation , climate change , resource depletion , and AIDS . Engineers and scientists should be helping us face the world's problems and find solutions to them, rather than indulging in escapist, pseudoscientific fantasies like the singularity.

[ 18 ] Kurzweil rejects this assessment, saying that his predictions about the singularity are driven by the data that increases in computational technology have long been exponential.

[ 19 ] He says that his critics mistakenly take an intuitive, linear view of technological advancement rather than accounting for that exponential growth.

[ 20 ] See also [ edit ] AI mysticism Artificial general intelligence Eschatology Existential risk from artificial general intelligence Global brain Intelligence explosion Outline of transhumanism Post-scarcity economy Technological utopianism References [ edit ] ^ a b Grossman, Lev (10 February 2011).

"2045: The Year Man Becomes Immortal" .

Time .

ISSN 0040-781X .

Archived from the original on 21 December 2023 . Retrieved 3 December 2023 .

^ a b c d e f Kurzweil, Raymond (2005).

The Singularity Is Near: When Humans Transcend Biology . Viking Adult.

ISBN 0-670-03384-7 .

OCLC 224517172 .

^ Keats, Jonathon (11 November 2010), "Singularity" , Virtual Words , Oxford University Press, doi : 10.1093/oso/9780195398540.003.0033 , ISBN 978-0-19-539854-0 , retrieved 20 February 2025 ^ Extropy Institute.

"Neologisms of Extropy" . Extropy.org.

Archived from the original on 15 January 2014 . Retrieved 30 March 2011 .

^ a b c Thweatt-Bates, Jeanine (2016).

Cyborg Selves: A Theological Anthropology of the Posthuman . Oxon: Routledge. p. 52.

ISBN 978-1-4094-2141-2 .

^ Kurzweil, Ray (2010).

The Singularity is Near . London: Gerald Duckworth & Co.

ISBN 978-0-7156-4015-9 .

^ "Singularitarianism | Technoprogressive Wiki" .

ieet.org .

Archived from the original on 26 October 2018 . Retrieved 26 October 2018 .

^ Eden, A.H.; Moor, J.H.; Soraker, J.H.; Steinhart, E. (2013).

Singularity Hypotheses: A Scientific and Philosophical Assessment . The Frontiers Collection. Springer Berlin Heidelberg. p. 6.

ISBN 978-3-642-32560-1 .

Archived from the original on 5 May 2023 . Retrieved 5 May 2023 .

^ The Coming Technological Singularity: How to Survive in the Post-Human Era Archived 1 January 2007 at the Wayback Machine , by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.

^ a b Markoff, John (26 July 2009).

"Scientists Worry Machines May Outsmart Man" .

New York Times .

Archived from the original on 25 February 2017 . Retrieved 25 February 2017 .

^ The Coming Technological Singularity: How to Survive in the Post-Human Era Archived 1 January 2007 at the Wayback Machine , by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.

^ a b Singularitarian Principles Archived 28 January 2016 at the Wayback Machine " ^ Palmer, Jason (3 August 2009).

"Call for debate on killer robots" .

BBC News .

Archived from the original on 7 August 2009 . Retrieved 3 August 2009 .

^ AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study Archived 28 August 2009 at the Wayback Machine , Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.

^ a b Margolis, Eric; Samuels, Richard; Stitch, Stephen (2012).

The Oxford Handbook of Philosophy of Cognitive Science . Oxford: Oxford University Press. p. 169.

ISBN 978-0-19-530979-9 .

^ Lazar, Zohar (7 April 2016).

"When Is the Singularity? Probably Not in Your Lifetime" .

The New York Times . Retrieved 26 October 2018 .

^ "Tech Luminaries Address Singularity" .

IEEE Spectrum . 1 June 2008.

Archived from the original on 26 June 2024 . Retrieved 26 October 2018 .

^ Horgan, John (2008).

"The Consciousness Conundrum" .

IEEE Spectrum .

Archived from the original on 30 June 2022 . Retrieved 11 June 2022 .

^ W. Jenkins, Jr., Holman (12 April 2013).

"Will Google's Ray Kurzweil Live Forever?" .

Wall Street Journal .

Archived from the original on 18 April 2014 . Retrieved 14 March 2017 .

^ Barfield, Woodrow (2015).

Cyber-Humans: Our Future with Machines . Cham, Switzerland: Springer. p. 40.

ISBN 978-3-319-25048-9 .

External links [ edit ] Ethical Issues in Advanced Artificial Intelligence by Nick Bostrom , 2003 "The Consciousness Conundrum" , a criticism of singularitarians by John Horgan NewPP limit report
Parsed by mw‐web.codfw.main‐597b4b5bbd‐nsv4b
Cached time: 20250814222818
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.471 seconds
Real time usage: 0.546 seconds
Preprocessor visited node count: 2756/1000000
Revision size: 17820/2097152 bytes
Post‐expand include size: 65727/2097152 bytes
Template argument size: 5644/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 73412/5000000 bytes
Lua time usage: 0.323/10.000 seconds
Lua memory usage: 15260343/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  487.346      1 -total
 40.63%  198.013      1 Template:Transhumanism
 40.33%  196.554      1 Template:Sidebar_with_collapsible_lists
 36.33%  177.072      1 Template:Reflist
 17.19%   83.797      1 Template:Lang
 13.90%   67.718      2 Template:Cite_magazine
 10.66%   51.969      1 Template:Short_description
  6.68%   32.560      6 Template:Cite_book
  6.30%   30.709      2 Template:Citation_needed
  5.82%   28.364      2 Template:Pagetype Saved in parser cache with key enwiki:pcache:516138:|#|:idhash:canonical and timestamp 20250814222818 and revision id 1300178780. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Singularitarianism&oldid=1300178780 " Categories : Singularitarianism Philosophy of artificial intelligence Systems thinking Technology forecasting Technology neologisms Transhumanism Hidden categories: Webarchive template wayback links Articles with short description Short description matches Wikidata Use dmy dates from December 2023 Articles containing German-language text All articles with unsourced statements Articles with unsourced statements from July 2025 This page was last edited on 12 July 2025, at 18:44 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Singularitarianism 12 languages Add topic

