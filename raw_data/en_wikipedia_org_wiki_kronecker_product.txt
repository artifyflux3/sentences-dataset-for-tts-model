Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition Toggle Definition subsection 1.1 Examples 2 Properties Toggle Properties subsection 2.1 Relations to other matrix operations 2.2 Abstract properties 3 Matrix equations Toggle Matrix equations subsection 3.1 Applications 4 Related matrix operations Toggle Related matrix operations subsection 4.1 Tracy–Singh product 4.2 Khatri–Rao product 4.3 Face-splitting product 5 See also 6 Notes 7 References 8 External links Toggle the table of contents Kronecker product 24 languages العربية Català Чӑвашла Čeština Deutsch Español Français Galego 한국어 Հայերեն Italiano Latviešu Magyar Nederlands 日本語 Polski Română Русский Slovenčina Slovenščina Suomi Svenska Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Mathematical operation on matrices For the Kronecker product of representations of symmetric groups, see Kronecker coefficient .

In mathematics , the Kronecker product , sometimes denoted by ⊗, is an operation on two matrices of arbitrary size resulting in a block matrix . It is a specialization of the tensor product (which is denoted by the same symbol) from vectors to matrices and gives the matrix of the tensor product linear map with respect to a standard choice of basis . The Kronecker product is to be distinguished from the usual matrix multiplication , which is an entirely different operation. The Kronecker product is also sometimes called matrix direct product .

[ 1 ] The Kronecker product is named after the German mathematician Leopold Kronecker (1823–1891), even though there is little evidence that he was the first to define and use it. The Kronecker product has also been called the Zehfuss matrix , and the Zehfuss product , after Johann Georg Zehfuss [ de ] , who in 1858 described this matrix operation, but Kronecker product is currently the most widely used term.

[ 2 ] [ 3 ] The misattribution to Kronecker rather than Zehfuss was due to Kurt Hensel .

[ 4 ] Definition [ edit ] If A is an m × n matrix and B is a p × q matrix, then the Kronecker product A ⊗ B is the pm × qn block matrix: A ⊗ ⊗ B = [ a 11 B ⋯ ⋯ a 1 n B ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ a m 1 B ⋯ ⋯ a m n B ] , {\displaystyle \mathbf {A} \otimes \mathbf {B} ={\begin{bmatrix}a_{11}\mathbf {B} &\cdots &a_{1n}\mathbf {B} \\\vdots &\ddots &\vdots \\a_{m1}\mathbf {B} &\cdots &a_{mn}\mathbf {B} \end{bmatrix}},} more explicitly: A ⊗ ⊗ B = [ a 11 b 11 a 11 b 12 ⋯ ⋯ a 11 b 1 q ⋯ ⋯ ⋯ ⋯ a 1 n b 11 a 1 n b 12 ⋯ ⋯ a 1 n b 1 q a 11 b 21 a 11 b 22 ⋯ ⋯ a 11 b 2 q ⋯ ⋯ ⋯ ⋯ a 1 n b 21 a 1 n b 22 ⋯ ⋯ a 1 n b 2 q ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ a 11 b p 1 a 11 b p 2 ⋯ ⋯ a 11 b p q ⋯ ⋯ ⋯ ⋯ a 1 n b p 1 a 1 n b p 2 ⋯ ⋯ a 1 n b p q ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ a m 1 b 11 a m 1 b 12 ⋯ ⋯ a m 1 b 1 q ⋯ ⋯ ⋯ ⋯ a m n b 11 a m n b 12 ⋯ ⋯ a m n b 1 q a m 1 b 21 a m 1 b 22 ⋯ ⋯ a m 1 b 2 q ⋯ ⋯ ⋯ ⋯ a m n b 21 a m n b 22 ⋯ ⋯ a m n b 2 q ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ a m 1 b p 1 a m 1 b p 2 ⋯ ⋯ a m 1 b p q ⋯ ⋯ ⋯ ⋯ a m n b p 1 a m n b p 2 ⋯ ⋯ a m n b p q ] .

{\displaystyle {\mathbf {A} \otimes \mathbf {B} }={\begin{bmatrix}a_{11}b_{11}&a_{11}b_{12}&\cdots &a_{11}b_{1q}&\cdots &\cdots &a_{1n}b_{11}&a_{1n}b_{12}&\cdots &a_{1n}b_{1q}\\a_{11}b_{21}&a_{11}b_{22}&\cdots &a_{11}b_{2q}&\cdots &\cdots &a_{1n}b_{21}&a_{1n}b_{22}&\cdots &a_{1n}b_{2q}\\\vdots &\vdots &\ddots &\vdots &&&\vdots &\vdots &\ddots &\vdots \\a_{11}b_{p1}&a_{11}b_{p2}&\cdots &a_{11}b_{pq}&\cdots &\cdots &a_{1n}b_{p1}&a_{1n}b_{p2}&\cdots &a_{1n}b_{pq}\\\vdots &\vdots &&\vdots &\ddots &&\vdots &\vdots &&\vdots \\\vdots &\vdots &&\vdots &&\ddots &\vdots &\vdots &&\vdots \\a_{m1}b_{11}&a_{m1}b_{12}&\cdots &a_{m1}b_{1q}&\cdots &\cdots &a_{mn}b_{11}&a_{mn}b_{12}&\cdots &a_{mn}b_{1q}\\a_{m1}b_{21}&a_{m1}b_{22}&\cdots &a_{m1}b_{2q}&\cdots &\cdots &a_{mn}b_{21}&a_{mn}b_{22}&\cdots &a_{mn}b_{2q}\\\vdots &\vdots &\ddots &\vdots &&&\vdots &\vdots &\ddots &\vdots \\a_{m1}b_{p1}&a_{m1}b_{p2}&\cdots &a_{m1}b_{pq}&\cdots &\cdots &a_{mn}b_{p1}&a_{mn}b_{p2}&\cdots &a_{mn}b_{pq}\end{bmatrix}}.} Using / / {\displaystyle /\!/} and % % {\displaystyle \%} to denote truncating integer division and remainder , respectively, and numbering the matrix elements starting from 0, one obtains ( A ⊗ ⊗ B ) p r + v , q s + w = a r s b v w {\displaystyle (A\otimes B)_{pr+v,qs+w}=a_{rs}b_{vw}} ( A ⊗ ⊗ B ) i , j = a i / / p , j / / q b i % % p , j % % q .

{\displaystyle (A\otimes B)_{i,j}=a_{i/\!/p,j/\!/q}b_{i\%p,j\%q}.} For the usual numbering starting from 1, one obtains ( A ⊗ ⊗ B ) p ( r − − 1 ) + v , q ( s − − 1 ) + w = a r s b v w {\displaystyle (A\otimes B)_{p(r-1)+v,q(s-1)+w}=a_{rs}b_{vw}} ( A ⊗ ⊗ B ) i , j = a ⌈ ⌈ i / p ⌉ ⌉ , ⌈ ⌈ j / q ⌉ ⌉ b ( i − − 1 ) % % p + 1 , ( j − − 1 ) % % q + 1 .

{\displaystyle (A\otimes B)_{i,j}=a_{\lceil i/p\rceil ,\lceil j/q\rceil }b_{(i-1)\%p+1,(j-1)\%q+1}.} If A and B represent linear transformations V 1 → W 1 and V 2 → W 2 , respectively, then the tensor product of the two maps is a map V 1 ⊗ V 2 → W 1 ⊗ W 2 represented by A ⊗ B .

Examples [ edit ] [ 1 2 3 4 ] ⊗ ⊗ [ 0 5 6 7 ] = [ 1 [ 0 5 6 7 ] 2 [ 0 5 6 7 ] 3 [ 0 5 6 7 ] 4 [ 0 5 6 7 ] ] = [ 1 × × 0 1 × × 5 2 × × 0 2 × × 5 1 × × 6 1 × × 7 2 × × 6 2 × × 7 3 × × 0 3 × × 5 4 × × 0 4 × × 5 3 × × 6 3 × × 7 4 × × 6 4 × × 7 ] = [ 0 5 0 10 6 7 12 14 0 15 0 20 18 21 24 28 ] .

{\displaystyle {\begin{bmatrix}1&2\\3&4\\\end{bmatrix}}\otimes {\begin{bmatrix}0&5\\6&7\\\end{bmatrix}}={\begin{bmatrix}1{\begin{bmatrix}0&5\\6&7\\\end{bmatrix}}&2{\begin{bmatrix}0&5\\6&7\\\end{bmatrix}}\\3{\begin{bmatrix}0&5\\6&7\\\end{bmatrix}}&4{\begin{bmatrix}0&5\\6&7\\\end{bmatrix}}\\\end{bmatrix}}=\left[{\begin{array}{cc|cc}1\times 0&1\times 5&2\times 0&2\times 5\\1\times 6&1\times 7&2\times 6&2\times 7\\\hline 3\times 0&3\times 5&4\times 0&4\times 5\\3\times 6&3\times 7&4\times 6&4\times 7\\\end{array}}\right]=\left[{\begin{array}{cc|cc}0&5&0&10\\6&7&12&14\\\hline 0&15&0&20\\18&21&24&28\end{array}}\right].} Similarly: [ 1 − − 4 7 − − 2 3 3 ] ⊗ ⊗ [ 8 − − 9 − − 6 5 1 − − 3 − − 4 7 2 8 − − 8 − − 3 1 2 − − 5 − − 1 ] = [ 8 − − 9 − − 6 5 − − 32 36 24 − − 20 56 − − 63 − − 42 35 1 − − 3 − − 4 7 − − 4 12 16 − − 28 7 − − 21 − − 28 49 2 8 − − 8 − − 3 − − 8 − − 32 32 12 14 56 − − 56 − − 21 1 2 − − 5 − − 1 − − 4 − − 8 20 4 7 14 − − 35 − − 7 − − 16 18 12 − − 10 24 − − 27 − − 18 15 24 − − 27 − − 18 15 − − 2 6 8 − − 14 3 − − 9 − − 12 21 3 − − 9 − − 12 21 − − 4 − − 16 16 6 6 24 − − 24 − − 9 6 24 − − 24 − − 9 − − 2 − − 4 10 2 3 6 − − 15 − − 3 3 6 − − 15 − − 3 ] {\displaystyle {\begin{bmatrix}1&-4&7\\-2&3&3\end{bmatrix}}\otimes {\begin{bmatrix}8&-9&-6&5\\1&-3&-4&7\\2&8&-8&-3\\1&2&-5&-1\end{bmatrix}}=\left[{\begin{array}{cccc|cccc|cccc}8&-9&-6&5&-32&36&24&-20&56&-63&-42&35\\1&-3&-4&7&-4&12&16&-28&7&-21&-28&49\\2&8&-8&-3&-8&-32&32&12&14&56&-56&-21\\1&2&-5&-1&-4&-8&20&4&7&14&-35&-7\\\hline -16&18&12&-10&24&-27&-18&15&24&-27&-18&15\\-2&6&8&-14&3&-9&-12&21&3&-9&-12&21\\-4&-16&16&6&6&24&-24&-9&6&24&-24&-9\\-2&-4&10&2&3&6&-15&-3&3&6&-15&-3\end{array}}\right]} Properties [ edit ] Relations to other matrix operations [ edit ] Bilinearity and associativity : The Kronecker product is a special case of the tensor product , so it is bilinear and associative : A ⊗ ⊗ ( B + C ) = A ⊗ ⊗ B + A ⊗ ⊗ C , ( B + C ) ⊗ ⊗ A = B ⊗ ⊗ A + C ⊗ ⊗ A , ( k A ) ⊗ ⊗ B = A ⊗ ⊗ ( k B ) = k ( A ⊗ ⊗ B ) , ( A ⊗ ⊗ B ) ⊗ ⊗ C = A ⊗ ⊗ ( B ⊗ ⊗ C ) , A ⊗ ⊗ 0 = 0 ⊗ ⊗ A = 0 , {\displaystyle {\begin{aligned}\mathbf {A} \otimes (\mathbf {B} +\mathbf {C} )&=\mathbf {A} \otimes \mathbf {B} +\mathbf {A} \otimes \mathbf {C} ,\\(\mathbf {B} +\mathbf {C} )\otimes \mathbf {A} &=\mathbf {B} \otimes \mathbf {A} +\mathbf {C} \otimes \mathbf {A} ,\\(k\mathbf {A} )\otimes \mathbf {B} &=\mathbf {A} \otimes (k\mathbf {B} )=k(\mathbf {A} \otimes \mathbf {B} ),\\(\mathbf {A} \otimes \mathbf {B} )\otimes \mathbf {C} &=\mathbf {A} \otimes (\mathbf {B} \otimes \mathbf {C} ),\\\mathbf {A} \otimes \mathbf {0} &=\mathbf {0} \otimes \mathbf {A} =\mathbf {0} ,\end{aligned}}} where A , B and C are matrices, 0 is a zero matrix, and k is a scalar.

Non- commutative : In general, A ⊗ B and B ⊗ A are different matrices. However, A ⊗ B and B ⊗ A are permutation equivalent, meaning that there exist permutation matrices P and Q such that [ 5 ] B ⊗ ⊗ A = P ( A ⊗ ⊗ B ) Q .

{\displaystyle \mathbf {B} \otimes \mathbf {A} =\mathbf {P} \,(\mathbf {A} \otimes \mathbf {B} )\,\mathbf {Q} .} If A and B are square matrices, then A ⊗ B and B ⊗ A are even permutation similar , meaning that we can take P = Q T .

The matrices P and Q are perfect shuffle matrices, called the "commutation" matrix.

[ 6 ] The Commutation matrix S p , q can be constructed by taking slices of the I r identity matrix, where r = p q {\displaystyle r=pq} .

S p , q = [ I r ( 1 : q : r , : ) I r ( 2 : q : r , : ) ⋮ ⋮ I r ( q : q : r , : ) ] {\displaystyle \mathbf {S} _{p,q}={\begin{bmatrix}\mathbf {I} _{r}(1:q:r,:)\\\mathbf {I} _{r}(2:q:r,:)\\\vdots \\\mathbf {I} _{r}(q:q:r,:)\end{bmatrix}}} MATLAB colon notation is used here to indicate submatrices, and I r is the r × r identity matrix. If A ∈ ∈ R m 1 × × n 1 {\displaystyle \mathbf {A} \in \mathbb {R} ^{m_{1}\times n_{1}}} and B ∈ ∈ R m 2 × × n 2 {\displaystyle \mathbf {B} \in \mathbb {R} ^{m_{2}\times n_{2}}} , then B ⊗ ⊗ A = S m 1 , m 2 ( A ⊗ ⊗ B ) S n 1 , n 2 T {\displaystyle \mathbf {B} \otimes \mathbf {A} =\mathbf {S} _{m_{1},m_{2}}(\mathbf {A} \otimes \mathbf {B} )\mathbf {S} _{n_{1},n_{2}}^{\textsf {T}}} The mixed-product property: If A , B , C and D are matrices of such size that one can form the matrix products AC and BD , then [ 7 ] ( A ⊗ ⊗ B ) ( C ⊗ ⊗ D ) = ( A C ) ⊗ ⊗ ( B D ) .

{\displaystyle (\mathbf {A} \otimes \mathbf {B} )(\mathbf {C} \otimes \mathbf {D} )=(\mathbf {AC} )\otimes (\mathbf {BD} ).} This is called the mixed-product property , because it mixes the ordinary matrix product and the Kronecker product.

As an immediate consequence (again, taking A ∈ ∈ R m 1 × × n 1 {\displaystyle \mathbf {A} \in \mathbb {R} ^{m_{1}\times n_{1}}} and B ∈ ∈ R m 2 × × n 2 {\displaystyle \mathbf {B} \in \mathbb {R} ^{m_{2}\times n_{2}}} ), A ⊗ ⊗ B = ( I m 1 ⊗ ⊗ B ) ( A ⊗ ⊗ I n 2 ) = ( A ⊗ ⊗ I m 2 ) ( I n 1 ⊗ ⊗ B ) .

{\displaystyle \mathbf {A} \otimes \mathbf {B} =(\mathbf {I} _{m_{1}}\otimes \mathbf {B} )(\mathbf {A} \otimes \mathbf {I} _{n_{2}})=(\mathbf {A} \otimes \mathbf {I} _{m_{2}})(\mathbf {I} _{n_{1}}\otimes \mathbf {B} ).} In particular, using the transpose property from below, this means that if A = Q ⊗ ⊗ U {\displaystyle \mathbf {A} =\mathbf {Q} \otimes \mathbf {U} } and Q and U are orthogonal (or unitary ), then A is also orthogonal (resp., unitary).

The mixed Kronecker matrix-vector product can be written as: ( A ⊗ ⊗ B ) vec ⁡ ⁡ ( V ) = vec ⁡ ⁡ ( B V A T ) {\displaystyle \left(\mathbf {A} \otimes \mathbf {B} \right)\operatorname {vec} \left(\mathbf {V} \right)=\operatorname {vec} (\mathbf {B} \mathbf {V} \mathbf {A} ^{T})} where vec ⁡ ⁡ ( V ) {\displaystyle \operatorname {vec} (\mathbf {V} )} is the vectorization operator applied on V {\displaystyle \mathbf {V} } (formed by reshaping the matrix).

Commutator property : If A {\displaystyle \mathbf {A} } and C {\displaystyle \mathbf {C} } are square matrices of the dimension m {\displaystyle m} , and B {\displaystyle \mathbf {B} } and D {\displaystyle \mathbf {D} } are square matrices of the dimension n {\displaystyle n} , then the commutator [ A ⊗ ⊗ B , C ⊗ ⊗ D ] = [ A , C ] ⊗ ⊗ ( B D ) + ( C A ) ⊗ ⊗ [ B , D ] {\displaystyle [\mathbf {A} \otimes \mathbf {B} ,\mathbf {C} \otimes \mathbf {D} ]=[\mathbf {A} ,\mathbf {C} ]\otimes (\mathbf {B} \mathbf {D} )+(\mathbf {C} \mathbf {A} )\otimes [\mathbf {B} ,\mathbf {D} ]} , or [ A ⊗ ⊗ B , C ⊗ ⊗ D ] = [ A , C ] ⊗ ⊗ ( D B ) + ( A C ) ⊗ ⊗ [ B , D ] {\displaystyle [\mathbf {A} \otimes \mathbf {B} ,\mathbf {C} \otimes \mathbf {D} ]=[\mathbf {A} ,\mathbf {C} ]\otimes (\mathbf {D} \mathbf {B} )+(\mathbf {A} \mathbf {C} )\otimes [\mathbf {B} ,\mathbf {D} ]} .

Hadamard product (element-wise multiplication): The mixed-product property also works for the element-wise product. If A and C are matrices of the same size, B and D are matrices of the same size, then [ 7 ] ( A ⊗ ⊗ B ) ∘ ∘ ( C ⊗ ⊗ D ) = ( A ∘ ∘ C ) ⊗ ⊗ ( B ∘ ∘ D ) .

{\displaystyle (\mathbf {A} \otimes \mathbf {B} )\circ (\mathbf {C} \otimes \mathbf {D} )=(\mathbf {A} \circ \mathbf {C} )\otimes (\mathbf {B} \circ \mathbf {D} ).} The inverse of a Kronecker product: It follows that A ⊗ B is invertible if and only if both A and B are invertible, in which case the inverse is given by ( A ⊗ ⊗ B ) − − 1 = A − − 1 ⊗ ⊗ B − − 1 .

{\displaystyle (\mathbf {A} \otimes \mathbf {B} )^{-1}=\mathbf {A} ^{-1}\otimes \mathbf {B} ^{-1}.} The invertible product property holds for the Moore–Penrose pseudoinverse as well, [ 7 ] [ 8 ] that is ( A ⊗ ⊗ B ) + = A + ⊗ ⊗ B + .

{\displaystyle (\mathbf {A} \otimes \mathbf {B} )^{+}=\mathbf {A} ^{+}\otimes \mathbf {B} ^{+}.} In the language of Category theory , the mixed-product property of the Kronecker product (and more general tensor product) shows that the category Mat F of matrices over a field F , is in fact a monoidal category , with objects natural numbers n , morphisms n → m are n × m matrices with entries in F , composition is given by matrix multiplication, identity arrows are simply n × n identity matrices I n , and the tensor product is given by the Kronecker product.

[ 9 ] Mat F is a concrete skeleton category for the equivalent category FinVect F of finite dimensional vector spaces over F , whose objects are such finite dimensional vector spaces V , arrows are F -linear maps L : V → W , and identity arrows are the identity maps of the spaces. The equivalence of categories amounts to simultaneously choosing a basis in every finite-dimensional vector space V over F ; matrices' elements represent these mappings with respect to the chosen bases; and likewise the Kronecker product is the representation of the tensor product in the chosen bases.

Transpose : Transposition and conjugate transposition are distributive over the Kronecker product: ( A ⊗ ⊗ B ) T = A T ⊗ ⊗ B T {\displaystyle (\mathbf {A} \otimes \mathbf {B} )^{\textsf {T}}=\mathbf {A} ^{\textsf {T}}\otimes \mathbf {B} ^{\textsf {T}}} and ( A ⊗ ⊗ B ) ∗ ∗ = A ∗ ∗ ⊗ ⊗ B ∗ ∗ .

{\displaystyle (\mathbf {A} \otimes \mathbf {B} )^{*}=\mathbf {A} ^{*}\otimes \mathbf {B} ^{*}.} Determinant : Let A be an n × n matrix and let B be an m × m matrix. Then | A ⊗ ⊗ B | = | A | m | B | n .

{\displaystyle \left|\mathbf {A} \otimes \mathbf {B} \right|=\left|\mathbf {A} \right|^{m}\left|\mathbf {B} \right|^{n}.} The exponent in | A | is the order of B and the exponent in | B | is the order of A .

Kronecker sum and exponentiation : If A is n × n , B is m × m and I k denotes the k × k identity matrix then we can define what is sometimes called the Kronecker sum , ⊕, by A ⊕ ⊕ B = A ⊗ ⊗ I m + I n ⊗ ⊗ B .

{\displaystyle \mathbf {A} \oplus \mathbf {B} =\mathbf {A} \otimes \mathbf {I} _{m}+\mathbf {I} _{n}\otimes \mathbf {B} .} This is different from the direct sum of two matrices. This operation is related to the tensor product on Lie algebras , as detailed below ( #Abstract properties ) in the point "Relation to the abstract tensor product ".

We have the following formula for the matrix exponential , which is useful in some numerical evaluations.

[ 10 ] exp ⁡ ⁡ ( N ⊕ ⊕ M ) = exp ⁡ ⁡ ( N ) ⊗ ⊗ exp ⁡ ⁡ ( M ) {\displaystyle \exp({\mathbf {N} \oplus \mathbf {M} })=\exp(\mathbf {N} )\otimes \exp(\mathbf {M} )} Kronecker sums appear naturally in physics when considering ensembles of non-interacting systems .

[ citation needed ] Let H k be the Hamiltonian of the k th such system. Then the total Hamiltonian of the ensemble is H Tot = ⨁ ⨁ k H k .

{\displaystyle H_{\operatorname {Tot} }=\bigoplus _{k}H^{k}.} Vectorization of a Kronecker product: Let A {\displaystyle A} be an m × × n {\displaystyle m\times n} matrix and B {\displaystyle B} a p × × q {\displaystyle p\times q} matrix. When the order of the Kronecker product and vectorization is interchanged, the two operations can be linked linearly through a function that involves the commutation matrix , K q m {\displaystyle K_{qm}} . That is, vec ⁡ ⁡ ( Kron ⁡ ⁡ ( A , B ) ) {\displaystyle \operatorname {vec} (\operatorname {Kron} (A,B))} and Kron ⁡ ⁡ ( vec ⁡ ⁡ A , vec ⁡ ⁡ B ) {\displaystyle \operatorname {Kron} (\operatorname {vec} A,\operatorname {vec} B)} have the following relationship: vec ⁡ ⁡ ( A ⊗ ⊗ B ) = ( I n ⊗ ⊗ K q m ⊗ ⊗ I p ) ( vec ⁡ ⁡ A ⊗ ⊗ vec ⁡ ⁡ B ) .

{\displaystyle \operatorname {vec} (A\otimes B)=(I_{n}\otimes K_{qm}\otimes I_{p})(\operatorname {vec} A\otimes \operatorname {vec} B).} Furthermore, the above relation can be rearranged in terms of either vec ⁡ ⁡ A {\displaystyle \operatorname {vec} A} or vec ⁡ ⁡ B {\displaystyle \operatorname {vec} B} as follows: vec ⁡ ⁡ ( A ⊗ ⊗ B ) = ( I n ⊗ ⊗ G ) vec ⁡ ⁡ A = ( H ⊗ ⊗ I p ) vec ⁡ ⁡ B , {\displaystyle \operatorname {vec} (A\otimes B)=(I_{n}\otimes G)\operatorname {vec} A=(H\otimes I_{p})\operatorname {vec} B,} where G = ( K q m ⊗ ⊗ I p ) ( I m ⊗ ⊗ vec ⁡ ⁡ B ) and H = ( I n ⊗ ⊗ K q m ) ( vec ⁡ ⁡ A ⊗ ⊗ I q ) .

{\displaystyle G=(K_{qm}\otimes I_{p})(I_{m}\otimes \operatorname {vec} B){\text{ and }}H=(I_{n}\otimes K_{qm})(\operatorname {vec} A\otimes I_{q}).} Outer Product : If x ∈ ∈ R n {\displaystyle x\in \mathbb {R} ^{n}} and y ∈ ∈ R m {\displaystyle y\in \mathbb {R} ^{m}} are arbitrary vectors, then the outer product between x {\displaystyle x} and y {\displaystyle y} is defined as x y T {\displaystyle xy^{T}} . The Kronecker product is related to the outer product by: y ⊗ ⊗ x = vec ⁡ ⁡ ( x y T ) {\displaystyle y\otimes x=\operatorname {vec} (xy^{T})} .

Abstract properties [ edit ] Spectrum : Suppose that A and B are square matrices of size n and m respectively. Let λ 1 , ..., λ n be the eigenvalues of A and μ 1 , ..., μ m be those of B (listed according to multiplicity ). Then the eigenvalues of A ⊗ B are λ λ i μ μ j , i = 1 , … … , n , j = 1 , … … , m .

{\displaystyle \lambda _{i}\mu _{j},\qquad i=1,\ldots ,n,\,j=1,\ldots ,m.} It follows that the trace and determinant of a Kronecker product are given by tr ⁡ ⁡ ( A ⊗ ⊗ B ) = tr ⁡ ⁡ A tr ⁡ ⁡ B and det ( A ⊗ ⊗ B ) = ( det A ) m ( det B ) n .

{\displaystyle \operatorname {tr} (\mathbf {A} \otimes \mathbf {B} )=\operatorname {tr} \mathbf {A} \,\operatorname {tr} \mathbf {B} \quad {\text{and}}\quad \det(\mathbf {A} \otimes \mathbf {B} )=(\det \mathbf {A} )^{m}(\det \mathbf {B} )^{n}.} Singular values : If A and B are rectangular matrices, then one can consider their singular values . Suppose that A has r A nonzero singular values, namely σ σ A , i , i = 1 , … … , r A .

{\displaystyle \sigma _{\mathbf {A} ,i},\qquad i=1,\ldots ,r_{\mathbf {A} }.} Similarly, denote the nonzero singular values of B by σ σ B , i , i = 1 , … … , r B .

{\displaystyle \sigma _{\mathbf {B} ,i},\qquad i=1,\ldots ,r_{\mathbf {B} }.} Then the Kronecker product A ⊗ B has r A r B nonzero singular values, namely σ σ A , i σ σ B , j , i = 1 , … … , r A , j = 1 , … … , r B .

{\displaystyle \sigma _{\mathbf {A} ,i}\sigma _{\mathbf {B} ,j},\qquad i=1,\ldots ,r_{\mathbf {A} },\,j=1,\ldots ,r_{\mathbf {B} }.} Since the rank of a matrix equals the number of nonzero singular values, we find that rank ⁡ ⁡ ( A ⊗ ⊗ B ) = rank ⁡ ⁡ A rank ⁡ ⁡ B .

{\displaystyle \operatorname {rank} (\mathbf {A} \otimes \mathbf {B} )=\operatorname {rank} \mathbf {A} \,\operatorname {rank} \mathbf {B} .} Relation to the abstract tensor product : The Kronecker product of matrices corresponds to the abstract tensor product of linear maps. Specifically, if the vector spaces V , W , X , and Y have bases { v 1 , ..., v m }, { w 1 , ..., w n }, { x 1 , ..., x d }, and { y 1 , ..., y e }, respectively, and if the matrices A and B represent the linear transformations S : V → X and T : W → Y , respectively in the appropriate bases, then the matrix A ⊗ B represents the tensor product of the two maps, S ⊗ T : V ⊗ W → X ⊗ Y with respect to the basis { v 1 ⊗ w 1 , v 1 ⊗ w 2 , ..., v 2 ⊗ w 1 , ..., v m ⊗ w n } of V ⊗ W and the similarly defined basis of X ⊗ Y with the property that A ⊗ B ( v i ⊗ w j ) = ( Av i ) ⊗ ( Bw j ) , where i and j are integers in the proper range.

[ 11 ] When V and W are Lie algebras , and S : V → V and T : W → W are Lie algebra homomorphisms , the Kronecker sum of A and B represents the induced Lie algebra homomorphisms V ⊗ W → V ⊗ W .

[ citation needed ] Relation to products of graphs : The Kronecker product of the adjacency matrices of two graphs is the adjacency matrix of the tensor product graph . The Kronecker sum of the adjacency matrices of two graphs is the adjacency matrix of the Cartesian product graph .

[ 12 ] Matrix equations [ edit ] The Kronecker product can be used to get a convenient representation for some matrix equations. Consider for instance the equation AXB = C , where A , B and C are given matrices and the matrix X is the unknown. We can use the "vec trick" to rewrite this equation as ( B T ⊗ ⊗ A ) vec ⁡ ⁡ ( X ) = vec ⁡ ⁡ ( A X B ) = vec ⁡ ⁡ ( C ) .

{\displaystyle \left(\mathbf {B} ^{\textsf {T}}\otimes \mathbf {A} \right)\,\operatorname {vec} (\mathbf {X} )=\operatorname {vec} (\mathbf {AXB} )=\operatorname {vec} (\mathbf {C} ).} Here, vec( X ) denotes the vectorization of the matrix X , formed by stacking the columns of X into a single column vector .

It now follows from the properties of the Kronecker product that the equation AXB = C has a unique solution, if and only if A and B are invertible ( Horn & Johnson 1991 , Lemma 4.3.1).

If X and C are row-ordered into the column vectors u and v , respectively, then ( Jain 1989 , 2.8 Block Matrices and Kronecker Products) v = ( A ⊗ ⊗ B T ) u .

{\displaystyle \mathbf {v} =\left(\mathbf {A} \otimes \mathbf {B} ^{\textsf {T}}\right)\mathbf {u} .} The reason is that v = vec ⁡ ⁡ ( ( A X B ) T ) = vec ⁡ ⁡ ( B T X T A T ) = ( A ⊗ ⊗ B T ) vec ⁡ ⁡ ( X T ) = ( A ⊗ ⊗ B T ) u .

{\displaystyle \mathbf {v} =\operatorname {vec} \left((\mathbf {AXB} )^{\textsf {T}}\right)=\operatorname {vec} \left(\mathbf {B} ^{\textsf {T}}\mathbf {X} ^{\textsf {T}}\mathbf {A} ^{\textsf {T}}\right)=\left(\mathbf {A} \otimes \mathbf {B} ^{\textsf {T}}\right)\operatorname {vec} \left(\mathbf {X^{\textsf {T}}} \right)=\left(\mathbf {A} \otimes \mathbf {B} ^{\textsf {T}}\right)\mathbf {u} .} Applications [ edit ] For an example of the application of this formula, see the article on the Lyapunov equation . This formula also comes in handy in showing that the matrix normal distribution is a special case of the multivariate normal distribution . This formula is also useful for representing 2D image processing operations in matrix-vector form.

Another example is when a matrix can be factored as a Kronecker product, then matrix multiplication can be performed faster by using the above formula. This can be applied recursively, as done in the radix-2 FFT and the Fast Walsh–Hadamard transform . Splitting a known matrix into the Kronecker product of two smaller matrices is known as the "nearest Kronecker product" problem, and can be solved exactly [ 13 ] by using the SVD . To split a matrix into the Kronecker product of more than two matrices, in an optimal fashion, is a difficult problem and the subject of ongoing research; some authors cast it as a tensor decomposition problem.

[ 14 ] [ 15 ] In conjunction with the least squares method , the Kronecker product can be used as an accurate solution to the hand–eye calibration problem .

[ 16 ] Related matrix operations [ edit ] Two related matrix operations are the Tracy–Singh and Khatri–Rao products , which operate on partitioned matrices .  Let the m × n matrix A be partitioned into the m i × n j blocks A ij and p × q matrix B into the p k × q ℓ blocks B kl , with of course Σ i m i = m , Σ j n j = n , Σ k p k = p and Σ ℓ q ℓ = q .

Tracy–Singh product [ edit ] The Tracy–Singh product is defined as [ 17 ] [ 18 ] [ 19 ] A ∘ ∘ B = ( A i j ∘ ∘ B ) i j = ( ( A i j ⊗ ⊗ B k l ) k l ) i j {\displaystyle \mathbf {A} \circ \mathbf {B} =\left(\mathbf {A} _{ij}\circ \mathbf {B} \right)_{ij}=\left(\left(\mathbf {A} _{ij}\otimes \mathbf {B} _{kl}\right)_{kl}\right)_{ij}} which means that the ( ij )-th subblock of the mp × nq product A ∘ ∘ {\displaystyle \circ } B is the m i p × n j q matrix A ij ∘ ∘ {\displaystyle \circ } B , of which the ( kℓ )-th subblock equals the m i p k × n j q ℓ matrix A ij ⊗ B kℓ . Essentially the Tracy–Singh product is the pairwise Kronecker product for each pair of partitions in the two matrices.

For example, if A and B both are 2 × 2 partitioned matrices e.g.: A = [ A 11 A 12 A 21 A 22 ] = [ 1 2 3 4 5 6 7 8 9 ] , B = [ B 11 B 12 B 21 B 22 ] = [ 1 4 7 2 5 8 3 6 9 ] , {\displaystyle \mathbf {A} =\left[{\begin{array}{c | c}\mathbf {A} _{11}&\mathbf {A} _{12}\\\hline \mathbf {A} _{21}&\mathbf {A} _{22}\end{array}}\right]=\left[{\begin{array}{c c | c}1&2&3\\4&5&6\\\hline 7&8&9\end{array}}\right],\quad \mathbf {B} =\left[{\begin{array}{c | c}\mathbf {B} _{11}&\mathbf {B} _{12}\\\hline \mathbf {B} _{21}&\mathbf {B} _{22}\end{array}}\right]=\left[{\begin{array}{c | c c}1&4&7\\\hline 2&5&8\\3&6&9\end{array}}\right],} we get: A ∘ ∘ B = [ A 11 ∘ ∘ B A 12 ∘ ∘ B A 21 ∘ ∘ B A 22 ∘ ∘ B ] = [ A 11 ⊗ ⊗ B 11 A 11 ⊗ ⊗ B 12 A 12 ⊗ ⊗ B 11 A 12 ⊗ ⊗ B 12 A 11 ⊗ ⊗ B 21 A 11 ⊗ ⊗ B 22 A 12 ⊗ ⊗ B 21 A 12 ⊗ ⊗ B 22 A 21 ⊗ ⊗ B 11 A 21 ⊗ ⊗ B 12 A 22 ⊗ ⊗ B 11 A 22 ⊗ ⊗ B 12 A 21 ⊗ ⊗ B 21 A 21 ⊗ ⊗ B 22 A 22 ⊗ ⊗ B 21 A 22 ⊗ ⊗ B 22 ] = [ 1 2 4 7 8 14 3 12 21 4 5 16 28 20 35 6 24 42 2 4 5 8 10 16 6 15 24 3 6 6 9 12 18 9 18 27 8 10 20 32 25 40 12 30 48 12 15 24 36 30 45 18 36 54 7 8 28 49 32 56 9 36 63 14 16 35 56 40 64 18 45 72 21 24 42 63 48 72 27 54 81 ] .

{\displaystyle {\begin{aligned}\mathbf {A} \circ \mathbf {B} ={}&\left[{\begin{array}{c | c}\mathbf {A} _{11}\circ \mathbf {B} &\mathbf {A} _{12}\circ \mathbf {B} \\\hline \mathbf {A} _{21}\circ \mathbf {B} &\mathbf {A} _{22}\circ \mathbf {B} \end{array}}\right]\\={}&\left[{\begin{array}{c | c | c | c}\mathbf {A} _{11}\otimes \mathbf {B} _{11}&\mathbf {A} _{11}\otimes \mathbf {B} _{12}&\mathbf {A} _{12}\otimes \mathbf {B} _{11}&\mathbf {A} _{12}\otimes \mathbf {B} _{12}\\\hline \mathbf {A} _{11}\otimes \mathbf {B} _{21}&\mathbf {A} _{11}\otimes \mathbf {B} _{22}&\mathbf {A} _{12}\otimes \mathbf {B} _{21}&\mathbf {A} _{12}\otimes \mathbf {B} _{22}\\\hline \mathbf {A} _{21}\otimes \mathbf {B} _{11}&\mathbf {A} _{21}\otimes \mathbf {B} _{12}&\mathbf {A} _{22}\otimes \mathbf {B} _{11}&\mathbf {A} _{22}\otimes \mathbf {B} _{12}\\\hline \mathbf {A} _{21}\otimes \mathbf {B} _{21}&\mathbf {A} _{21}\otimes \mathbf {B} _{22}&\mathbf {A} _{22}\otimes \mathbf {B} _{21}&\mathbf {A} _{22}\otimes \mathbf {B} _{22}\end{array}}\right]\\={}&\left[{\begin{array}{c c | c c c c | c | c c}1&2&4&7&8&14&3&12&21\\4&5&16&28&20&35&6&24&42\\\hline 2&4&5&8&10&16&6&15&24\\3&6&6&9&12&18&9&18&27\\8&10&20&32&25&40&12&30&48\\12&15&24&36&30&45&18&36&54\\\hline 7&8&28&49&32&56&9&36&63\\\hline 14&16&35&56&40&64&18&45&72\\21&24&42&63&48&72&27&54&81\end{array}}\right].\end{aligned}}} Khatri–Rao product [ edit ] Main article: Khatri–Rao product Block Kronecker product Column-wise Khatri–Rao product Face-splitting product [ edit ] Main article: Khatri–Rao product Mixed-products properties [ 20 ] A ⊗ ⊗ ( B ∙ ∙ C ) = ( A ⊗ ⊗ B ) ∙ ∙ C , {\displaystyle \mathbf {A} \otimes (\mathbf {B} \bullet \mathbf {C} )=(\mathbf {A} \otimes \mathbf {B} )\bullet \mathbf {C} ,} where ∙ ∙ {\displaystyle \bullet } denotes the Face-splitting product .

[ 21 ] [ 22 ] ( A ∙ ∙ B ) ( C ⊗ ⊗ D ) = ( A C ) ∙ ∙ ( B D ) , {\displaystyle (\mathbf {A} \bullet \mathbf {B} )(\mathbf {C} \otimes \mathbf {D} )=(\mathbf {A} \mathbf {C} )\bullet (\mathbf {B} \mathbf {D} ),} Similarly: [ 23 ] ( A ∙ ∙ L ) ( B ⊗ ⊗ M ) ⋯ ⋯ ( C ⊗ ⊗ S ) = ( A B ⋯ ⋯ C ) ∙ ∙ ( L M ⋯ ⋯ S ) , {\displaystyle (\mathbf {A} \bullet \mathbf {L} )(\mathbf {B} \otimes \mathbf {M} )\cdots (\mathbf {C} \otimes \mathbf {S} )=(\mathbf {A} \mathbf {B} \cdots \mathbf {C} )\bullet (\mathbf {L} \mathbf {M} \cdots \mathbf {S} ),} c T ∙ ∙ d T = c T ⊗ ⊗ d T , {\displaystyle \mathbf {c} ^{\textsf {T}}\bullet \mathbf {d} ^{\textsf {T}}=\mathbf {c} ^{\textsf {T}}\otimes \mathbf {d} ^{\textsf {T}},} where c {\displaystyle \mathbf {c} } and d {\displaystyle \mathbf {d} } are vectors , [ 24 ] ( A ∙ ∙ B ) ( c ⊗ ⊗ d ) = ( A c ) ∘ ∘ ( B d ) , {\displaystyle (\mathbf {A} \bullet \mathbf {B} )(\mathbf {c} \otimes \mathbf {d} )=(\mathbf {A} \mathbf {c} )\circ (\mathbf {B} \mathbf {d} ),} where c {\displaystyle \mathbf {c} } and d {\displaystyle \mathbf {d} } are vectors , and ∘ ∘ {\displaystyle \circ } denotes the Hadamard product .

Similarly: ( A ∙ ∙ B ) ( M N c ⊗ ⊗ Q P d ) = ( A M N c ) ∘ ∘ ( B Q P d ) , {\displaystyle (\mathbf {A} \bullet \mathbf {B} )(\mathbf {M} \mathbf {N} \mathbf {c} \otimes \mathbf {Q} \mathbf {P} \mathbf {d} )=(\mathbf {A} \mathbf {M} \mathbf {N} \mathbf {c} )\circ (\mathbf {B} \mathbf {Q} \mathbf {P} \mathbf {d} ),} F ( C ( 1 ) x ⋆ ⋆ C ( 2 ) y ) = ( F C ( 1 ) ∙ ∙ F C ( 2 ) ) ( x ⊗ ⊗ y ) = F C ( 1 ) x ∘ ∘ F C ( 2 ) y , {\displaystyle {\mathcal {F}}(C^{(1)}x\star C^{(2)}y)=({\mathcal {F}}C^{(1)}\bullet {\mathcal {F}}C^{(2)})(x\otimes y)={\mathcal {F}}C^{(1)}x\circ {\mathcal {F}}C^{(2)}y,} where ⋆ ⋆ {\displaystyle \star } is vector convolution and F {\displaystyle {\mathcal {F}}} is the Fourier transform matrix (this result is an evolving of count sketch properties [ 25 ] ), [ 21 ] [ 22 ] ( A ∙ ∙ L ) ( B ⊗ ⊗ M ) ⋯ ⋯ ( C ⊗ ⊗ S ) ( K ∗ ∗ T ) = ( A B ⋅ ⋅ C K ) ∘ ∘ ( L M ⋯ ⋯ S T ) , {\displaystyle (\mathbf {A} \bullet \mathbf {L} )(\mathbf {B} \otimes \mathbf {M} )\cdots (\mathbf {C} \otimes \mathbf {S} )(\mathbf {K} \ast \mathbf {T} )=(\mathbf {A} \mathbf {B} \cdot \mathbf {C} \mathbf {K} )\circ (\mathbf {L} \mathbf {M} \cdots \mathbf {S} \mathbf {T} ),} where ∗ ∗ {\displaystyle \ast } denotes the column-wise Khatri–Rao product .

Similarly: ( A ∙ ∙ L ) ( B ⊗ ⊗ M ) ⋯ ⋯ ( C ⊗ ⊗ S ) ( c ⊗ ⊗ d ) = ( A B ⋯ ⋯ C c ) ∘ ∘ ( L M ⋯ ⋯ S d ) , {\displaystyle (\mathbf {A} \bullet \mathbf {L} )(\mathbf {B} \otimes \mathbf {M} )\cdots (\mathbf {C} \otimes \mathbf {S} )(c\otimes d)=(\mathbf {A} \mathbf {B} \cdots \mathbf {C} \mathbf {c} )\circ (\mathbf {L} \mathbf {M} \cdots \mathbf {S} \mathbf {d} ),} ( A ∙ ∙ L ) ( B ⊗ ⊗ M ) ⋯ ⋯ ( C ⊗ ⊗ S ) ( P c ⊗ ⊗ Q d ) = ( A B ⋯ ⋯ C P c ) ∘ ∘ ( L M ⋯ ⋯ S Q d ) , {\displaystyle (\mathbf {A} \bullet \mathbf {L} )(\mathbf {B} \otimes \mathbf {M} )\cdots (\mathbf {C} \otimes \mathbf {S} )(\mathbf {P} \mathbf {c} \otimes \mathbf {Q} \mathbf {d} )=(\mathbf {A} \mathbf {B} \cdots \mathbf {C} \mathbf {P} \mathbf {c} )\circ (\mathbf {L} \mathbf {M} \cdots \mathbf {S} \mathbf {Q} \mathbf {d} ),} where c {\displaystyle \mathbf {c} } and d {\displaystyle \mathbf {d} } are vectors .

See also [ edit ] Generalized linear array model Hadamard product (matrices) Kronecker coefficient Notes [ edit ] ^ Weisstein, Eric W.

"Kronecker product" .

mathworld.wolfram.com . Retrieved 2020-09-06 .

^ Zehfuss, G. (1858).

"Ueber eine gewisse Determinante" .

Zeitschrift für Mathematik und Physik .

3 : 298– 301.

^ Henderson, Harold V.; Pukelsheim, Friedrich; Searle, Shayle R. (1983).

"On the history of the kronecker product" .

Linear and Multilinear Algebra .

14 (2): 113– 120.

doi : 10.1080/03081088308817548 .

hdl : 1813/32834 .

ISSN 0308-1087 .

^ Sayed, Ali H. (2022-12-22).

Inference and Learning from Data: Foundations . Cambridge University Press.

ISBN 978-1-009-21812-2 .

^ Henderson, H.V.; Searle, S.R. (1980).

"The vec-permutation matrix, the vec operator and Kronecker products: A review" (PDF) .

Linear and Multilinear Algebra .

9 (4): 271– 288.

doi : 10.1080/03081088108817379 .

hdl : 1813/32747 .

^ Van Loan, Charles F. (2000).

"The ubiquitous Kronecker product" .

Journal of Computational and Applied Mathematics .

123 ( 1– 2): 85– 100.

Bibcode : 2000JCoAM.123...85L .

doi : 10.1016/s0377-0427(00)00393-9 .

^ a b c Liu, Shuangzhe; Trenkler, Götz; Kollo, Tõnu; von Rosen, Dietrich; Baksalary, Oskar Maria (2023). "Professor Heinz Neudecker and matrix differential calculus".

Statistical Papers .

65 (4): 2605– 2639.

doi : 10.1007/s00362-023-01499-w .

^ Langville, Amy N.

; Stewart, William J. (1 June 2004).

"The Kronecker product and stochastic automata networks" .

Journal of Computational and Applied Mathematics .

167 (2): 429– 447.

Bibcode : 2004JCoAM.167..429L .

doi : 10.1016/j.cam.2003.10.010 .

^ Macedo, Hugo Daniel; Oliveira, José Nuno (2013). "Typing linear algebra: A biproduct-oriented approach".

Science of Computer Programming .

78 (11): 2160– 2191.

arXiv : 1312.4818 .

Bibcode : 2013arXiv1312.4818M .

CiteSeerX 10.1.1.747.2083 .

doi : 10.1016/j.scico.2012.07.012 .

S2CID 9846072 .

^ Brewer, J.W. (1969). "A note on Kronecker matrix products and matrix equation systems".

SIAM Journal on Applied Mathematics .

17 (3): 603– 606.

doi : 10.1137/0117057 .

^ Dummit, David S.; Foote, Richard M. (1999).

Abstract Algebra (2 ed.). New York: John Wiley and Sons. pp.

401– 402.

ISBN 978-0-471-36857-1 .

^ See Knuth, D.E.

"Pre-Fascicle 0a: Introduction to Combinatorial Algorithms" (zeroth printing, revision 2 ed.). answer to Exercise 96. Archived from the original on 2019-05-13 . Retrieved 2007-10-24 , to appear as part of Knuth, D.E.

The Art of Computer Programming . Vol. 4A.

^ Van Loan, C.; Pitsianis, N. (1992).

Approximation with Kronecker Products . Ithaca, NY: Cornell University Press.

^ King Keung Wu; Yam, Yeung; Meng, Helen; Mesbahi, Mehran (2016). "Kronecker product approximation with multiple factor matrices via the tensor product algorithm".

2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC) . pp.

004277– 004282.

doi : 10.1109/SMC.2016.7844903 .

ISBN 978-1-5090-1897-0 .

S2CID 30695585 .

^ Dantas, Cássio F.; Cohen, Jérémy E.; Gribonval, Rémi (2018).

"Learning Fast Dictionaries for Sparse Representations Using Low-Rank Tensor Decompositions" .

Latent Variable Analysis and Signal Separation (PDF) . Lecture Notes in Computer Science. Vol. 10891. pp.

456– 466.

doi : 10.1007/978-3-319-93764-9_42 .

ISBN 978-3-319-93763-2 .

S2CID 46963798 .

^ Li, Algo; et al. (4 September 2010).

"Simultaneous robot-world and hand-eye calibration using dual-quaternions and Kronecker product" (PDF) .

International Journal of the Physical Sciences .

5 (10): 1530– 1536.

S2CID 7446157 . Archived from the original (PDF) on 9 February 2020.

^ Tracy, D.S.; Singh, R.P. (1972). "A new matrix product and its applications in matrix differentiation".

Statistica Neerlandica .

26 (4): 143– 157.

doi : 10.1111/j.1467-9574.1972.tb00199.x .

^ Liu, Shuangzhe (1999).

"Matrix Results on the Khatri–Rao and Tracy–Singh Products" .

Linear Algebra and Its Applications .

289 ( 1– 3): 267– 277.

doi : 10.1016/S0024-3795(98)10209-4 .

^ Liu, Shuangzhe; Trenkler, Götz (2008). "Hadamard, Khatri-Rao, Kronecker and other matrix products".

International Journal of Information and Systems Sciences .

4 (1): 160– 177.

^ Slyusar, V.I. (1998) [27 December 1996].

"End products in matrices in radar applications" (PDF) .

Radioelectronics and Communications Systems .

41 (3): 50– 53.

^ a b Slyusar, Vadym (1999).

"New matrix operations for DSP" (self-published lecture).

doi : 10.13140/RG.2.2.31620.76164/1 – via ResearchGate .

^ a b Slyusar, V.I. (March 13, 1998).

"A Family of Face Products of Matrices and its Properties" (PDF) .

Cybernetics and Systems Analysis C/C of Kibernetika I Sistemnyi Analiz. 1999 .

35 (3): 379– 384.

doi : 10.1007/BF02733426 .

S2CID 119661450 .

^ Slyusar, V.I. (1997-09-15).

New operations of matrices product for applications of radars (PDF) . Direct and Inverse Problems of Electromagnetic and Acoustic Wave Theory (DIPED-97), Lviv. pp.

73– 74.

^ Ahle, Thomas Dybdahl; Knudsen, Jakob Bæk Tejs (2019-09-03). "Almost optimal tensor sketch".

arXiv : 1909.01821 [ cs.DS ].

^ Ninh, Pham; Pagh, Rasmus (2013).

Fast and scalable polynomial kernels via explicit feature maps . SIGKDD international conference on Knowledge discovery and data mining. Association for Computing Machinery.

CiteSeerX 10.1.1.718.2766 .

doi : 10.1145/2487575.2487591 .

References [ edit ] Horn, Roger A.

; Johnson, Charles R.

(1991).

Topics in Matrix Analysis . Cambridge University Press.

ISBN 978-0-521-46713-1 .

Jain, Anil K. (1989).

Fundamentals of Digital Image Processing . Prentice Hall.

Bibcode : 1989fdip.book.....J .

ISBN 978-0-13-336165-0 .

Steeb, Willi-Hans (1997).

Matrix Calculus and Kronecker Product with Applications and C++ Programs . World Scientific Publishing.

ISBN 978-981-02-3241-2 .

Steeb, Willi-Hans (2006).

Problems and Solutions in Introductory and Advanced Matrix Calculus . World Scientific Publishing.

ISBN 978-981-256-916-5 .

Liu, Shuangzhe; Trenkler, Götz (2008). "Hadamard, Khatri-Rao, Kronecker and other matrix products".

International Journal of Information and Systems Sciences .

4 : 160– 177.

External links [ edit ] "Tensor product" .

Encyclopedia of Mathematics .

EMS Press . 2001 [1994].

"Kronecker product" .

PlanetMath .

"Kronecker product" .

MathWorld .

"New Kronecker product problems" (PDF) . Archived from the original (PDF) on 2021-11-04 . Retrieved 2009-08-19 .

"Earliest uses" .

The entry on the Kronecker, Zehfuss, or Direct Product of matrices has historical information.

calculate Kronecker product of two matrices .

SourceForge (generic C++ and Fortran 90 source code). 2015-06-27.

"Kronecker product" .

RosettaCode.org . 31 December 2020 . Retrieved 2021-01-13 .

Software source in more than 40 languages.

v t e Linear algebra Outline Glossary Basic concepts Scalar Vector Vector space Scalar multiplication Vector projection Linear span Linear map Linear projection Linear independence Linear combination Multilinear map Basis Change of basis Row and column vectors Row and column spaces Kernel Eigenvalues and eigenvectors Transpose Linear equations Matrices Block Decomposition Invertible Minor Multiplication Rank Transformation Cramer's rule Gaussian elimination Productive matrix Gram matrix Bilinear Orthogonality Dot product Hadamard product Inner product space Outer product Kronecker product Gram–Schmidt process Multilinear algebra Determinant Cross product Triple product Seven-dimensional cross product Geometric algebra Exterior algebra Bivector Multivector Tensor Outermorphism Vector space constructions Dual Direct sum Function space Quotient Subspace Tensor product Numerical Floating-point Numerical stability Basic Linear Algebra Subprograms Sparse matrix Comparison of linear algebra libraries Category NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐hl48r
Cached time: 20250811235941
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.639 seconds
Real time usage: 1.090 seconds
Preprocessor visited node count: 3509/1000000
Revision size: 42007/2097152 bytes
Post‐expand include size: 125976/2097152 bytes
Template argument size: 4121/2097152 bytes
Highest expansion depth: 14/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 135908/5000000 bytes
Lua time usage: 0.370/10.000 seconds
Lua memory usage: 8173963/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  574.935      1 -total
 40.28%  231.581      1 Template:Reflist
 16.08%   92.443      8 Template:Cite_web
 14.48%   83.273      1 Template:Short_description
 13.98%   80.398     14 Template:Cite_journal
 11.51%   66.161      1 Template:Linear_algebra
 11.28%   64.841      1 Template:Navbox
  9.86%   56.702      2 Template:Pagetype
  9.56%   54.967      2 Template:Ordered_list
  8.38%   48.163     10 Template:Cite_book Saved in parser cache with key enwiki:pcache:712430:|#|:idhash:canonical and timestamp 20250811235941 and revision id 1298640396. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Kronecker_product&oldid=1298640396 " Category : Matrix theory Hidden categories: Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from October 2014 Articles with unsourced statements from July 2023 Pages that use a deprecated format of the math tags This page was last edited on 3 July 2025, at 19:03 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Kronecker product 24 languages Add topic

