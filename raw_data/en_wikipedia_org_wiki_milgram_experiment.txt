Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Procedure 2 Predictions 3 Results 4 Critical reception Toggle Critical reception subsection 4.1 Ethics 4.2 Applicability to the Holocaust 4.3 Validity 5 Interpretations Toggle Interpretations subsection 5.1 Alternative interpretations 6 Replications and variations Toggle Replications and variations subsection 6.1 Milgram's variations 6.2 Replications 6.3 Other variations 7 Media depictions 8 See also 9 Citations 10 General and cited references 11 Further reading 12 External links Toggle the table of contents Milgram experiment 52 languages العربية Azərbaycanca বাংলা Беларуская Беларуская (тарашкевіца) Български Català Чӑвашла Čeština Cymraeg Dansk Deutsch Español Esperanto Euskara فارسی Français Galego 한국어 Հայերեն Hrvatski Bahasa Indonesia Íslenska Italiano עברית Kabɩyɛ Кыргызча Lietuvių Magyar Bahasa Melayu Nederlands 日本語 Norsk bokmål Norsk nynorsk پښتو Polski Português Română Rumantsch Русский Simple English Slovenčina Slovenščina Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska ไทย Türkçe Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Series of social psychology experiments For Milgram's other well-known experiment, see Small-world experiment .

"Obedience to Authority" redirects here. For the book, see Obedience to Authority: An Experimental View .

The experimenter (E) orders the teacher (T), the subject of the experiment, to give what the teacher (T) believes are painful electric shocks to a learner (L), who is actually an actor and confederate . The subject is led to believe that for each wrong answer, the learner was receiving actual electric shocks, though in reality there were no such punishments. Being separated from the subject, the confederate set up a tape recorder integrated with the electro-shock generator, which played pre-recorded sounds for each shock level.

[ 1 ] In the early 1960s, a series of social psychology experiments were conducted by Yale University psychologist Stanley Milgram , who intended to measure the willingness of study participants to obey an authority figure who instructed them to perform acts conflicting with their personal conscience . Participants were led to believe that they were assisting a fictitious experiment, in which they had to administer electric shocks to a "learner". These fake electric shocks gradually increased to levels that would have been fatal had they been real.

[ 2 ] The experiments unexpectedly found that a very high proportion of subjects would fully obey the instructions, with every participant going up to 300 volts, and 65% going up to the full 450 volts. Milgram first described his research in a 1963 article in the Journal of Abnormal and Social Psychology [ 1 ] and later discussed his findings in greater depth in his 1974 book, Obedience to Authority: An Experimental View .

[ 3 ] [ page needed ] The experiments began on August 7, 1961 (after a grant proposal was approved in July), in the basement of Linsly-Chittenden Hall at Yale University, three months after the start of the trial of German Nazi war criminal Adolf Eichmann in Jerusalem .

[ 4 ] [ 5 ] Milgram devised his psychological study to explain the psychology of genocide and answer the popular contemporary question: "Could it be that Eichmann and his million accomplices in the Holocaust were just following orders ? Could we call them all accomplices?" [ 6 ] While the experiment was repeated many times around the globe, with fairly consistent results, both its interpretations as well as its applicability to the Holocaust are disputed.

[ 7 ] [ dubious – discuss ] [ 8 ] Procedure [ edit ] Milgram experiment advertisement, 1961. The US $4 advertised is equivalent to $42 in 2024.

Three individuals took part in each session of the experiment: The "experimenter", who was in charge of the session.

The "teacher", who was a volunteer for a single session. The "teachers" were led to believe that they were merely assisting, whereas they were actually the subjects of the experiment.

The "learner", an actor and confederate of the experimenter, who pretended to be a volunteer.

The subject and the actor arrived at the session together. The experimenter told them that they were taking part in "a scientific study of memory and learning", to see what the effect of punishment is on a subject's ability to memorize content. Also, he always clarified that the payment for their participation in the experiment was secured regardless of its development. The subject and actor drew slips of paper to determine their roles. Unknown to the subject, both slips said "teacher". The actor would always claim to have drawn the slip that read "learner", thus guaranteeing that the subject would always be the "teacher".

Next, the teacher and learner were taken into an adjacent room where the learner was strapped into what appeared to be an electric chair. The experimenter, dressed in a lab coat in order to appear to have more authority, told the participants this was to ensure that the learner would not escape.

[ 1 ] In a later variation of the experiment, the confederate would eventually plead for mercy and yell that he had a heart condition .

[ 9 ] At some point prior to the actual test, the teacher was given a sample electric shock from the electroshock generator in order to experience firsthand what the shock that the learner would supposedly receive during the experiment would feel like.

The teacher and learner were then separated so that they could communicate, but not see each other. The teacher was then given a list of word pairs that he was to teach the learner. The teacher began by reading the list of word pairs to the learner. The teacher would then read the first word of each pair and read four possible answers. The learner would press a button to indicate his response. If the answer was incorrect, the teacher would administer a shock to the learner, with the voltage increasing in 15- volt increments for each wrong answer (if correct, the teacher would read the next word pair).

[ 1 ] The volts ranged from 15 to 450. The shock generator included verbal markings that vary from "Slight Shock" to "Danger: Severe Shock".

The subjects believed that for each wrong answer the learner was receiving actual shocks. In reality, there were no shocks. After the learner was separated from the teacher, the learner set up a tape recorder integrated with the electroshock generator, which played previously recorded sounds for each shock level. As the voltage of the fake shocks increased, the learner began making audible protests, such as banging repeatedly on the wall that separated him from the teacher. In every condition the learner makes/says a predetermined sound or word. When the highest voltages were reached, the learner fell silent.

[ 1 ] If at any time the teacher indicated a desire to halt the experiment, the experimenter was instructed to give specific verbal prods. The prods were, in this order: [ 1 ] Please continue or Please go on.

The experiment requires that you continue.

It is absolutely essential that you continue.

You have no other choice; you must go on.

Prod 2 could only be used if prod 1 was unsuccessful. If the subject still wished to stop after all four successive verbal prods, the experiment was halted. Otherwise, the experiment was halted after the subject had elicited the maximum 450-volt shock three times in succession.

[ 1 ] The experimenter also had prods to use if the teacher made specific comments. If the teacher asked whether the learner might suffer permanent physical harm, the experimenter replied, "Although the shocks may be painful, there is no permanent tissue damage, so please go on." If the teacher said that the learner clearly wants to stop, the experimenter replied, "Whether the learner likes it or not, you must go on until he has learned all the word pairs correctly, so please go on." [ 1 ] Predictions [ edit ] Before conducting the experiment, Milgram polled fourteen Yale University senior-year psychology majors to predict the behavior of 100 hypothetical teachers. All of the poll respondents believed that only a very small fraction of teachers (the range was from zero to 3 out of 100, with an average of 1.2) would be prepared to inflict the maximum voltage. Milgram also informally polled his colleagues and found that they, too, believed very few subjects would progress beyond a very strong shock.

[ 1 ] He also reached out to honorary Harvard University graduate Chaim Homnick, who noted that this experiment would not be concrete evidence of the Nazis' innocence, due to the fact that "poor people are more likely to cooperate". Milgram also polled forty psychiatrists from a medical school, and they believed that by the tenth shock, when the victim demands to be free, most subjects would stop the experiment. They predicted that by the 300-volt shock, when the victim would refuse to answer, only 3.73 percent of the subjects would still continue, and they believed that "only a little over one-tenth of one percent of the subjects would administer the highest shock on the board." [ 10 ] Milgram suspected before the experiment that the obedience exhibited by Nazis reflected of a distinct German character, and planned to use the American participants as a control group before using German participants, expected to behave closer to the Nazis. However, the unexpected results stopped him from conducting the same experiment on German participants.

[ 11 ] Results [ edit ] Subjects were uncomfortable administering the shocks, and displayed varying degrees of tension and stress. These signs included sweating, trembling, stuttering, biting their lips, groaning, and digging their fingernails into their skin, and some were even having nervous laughing fits or seizures.

[ 1 ] 14 of the 40 subjects showed definite signs of nervous laughing or smiling. Every participant paused the experiment at least once to question it. Most continued after being assured by the experimenter. Some said they would refund the money they were paid for participating.

Milgram summarized the experiment in his 1974 article "The Perils of Obedience", writing: The legal and philosophic aspects of obedience are of enormous importance, but they say very little about how most people behave in concrete situations. I set up a simple experiment at Yale University to test how much pain an ordinary citizen would inflict on another person simply because he was ordered to by an experimental scientist. Stark authority was pitted against the subjects' [participants'] strongest moral imperatives against hurting others, and, with the subjects' [participants'] ears ringing with the screams of the victims, authority won more often than not. The extreme willingness of adults to go to almost any lengths on the command of an authority constitutes the chief finding of the study and the fact most urgently demanding explanation.
Ordinary people, simply doing their jobs, and without any particular hostility on their part, can become agents in a terrible destructive process. Moreover, even when the destructive effects of their work become patently clear, and they are asked to carry out actions incompatible with fundamental standards of morality, relatively few people have the resources needed to resist authority.

[ 12 ] The original Simulated Shock Generator and Event Recorder, or shock box , is located in the Archives of the History of American Psychology .

Milgram, and other psychologists, subsequently later performed variations of the experiment throughout the world, with similar results.

[ 3 ] [ page needed ] Milgram later investigated the effect of the experiment's locale on obedience levels by using an unregistered, backstreet office in a bustling city, in contrast to the respectable environment of Yale University. The level of obedience dropped from 65% to 47%, [ 13 ] suggesting that scientific credibility could very well play a larger role than just authority. A more telling variable was the proximity of the learner to the teacher: when they were together in the same room, obedience level dropped to 40%.

[ 14 ] Another variation tested the subjects' willingness to cooperate when part of a larger group.

[ 15 ] Thomas Blass of the University of Maryland, Baltimore County performed a meta-analysis on the results of repeated performances of the experiment. He found that while the percentage of participants who are prepared to inflict fatal voltages ranged from 28% to 91%, there was no significant trend over time and the average percentage for US studies (61%) was close to the one for non-US studies (66%).

[ 2 ] [ 16 ] The participants who refused to administer the final shocks neither insisted that the experiment be terminated, nor left the room to check the health of the victim as per Milgram's notes.

[ 17 ] Milgram created a documentary film titled Obedience showing the experiment and its results. He also produced a series of five social psychology films, some of which dealt with his experiments.

[ 18 ] Critical reception [ edit ] Ethics [ edit ] Milgram’s experiment raised immediate controversy about the research ethics of scientific experimentation because of the extreme emotional stress and inflicted insight suffered by the participants. On June 10, 1964, the American Psychologist published a brief but influential article by Diana Baumrind titled "Some Thoughts on Ethics of Research: After Reading Milgram's 'Behavioral Study of Obedience.

' " She argued that even though Milgram had obtained informed consent, he was still ethically responsible to ensure their well-being. When participants displayed signs of distress such as sweating and trembling, the experimenter should have stepped in and halted the experiment. Baumrind's criticisms of the treatment of human participants in Milgram's studies stimulated a thorough revision of the ethical standards of psychological research.

[ 19 ] Milgram vigorously defended the experiment. He conducted a survey of former participants in which 84% said they were "glad" or "very glad" to have participated; 15% chose neutral responses (92% of all former participants responding).

[ 20 ] In his 1974 book Obedience to Authority , Milgram described receiving offers of assistance, requests to join his staff, and letters of thanks from former participants. Six years later (at the height of the Vietnam War ), one of the participants in the experiment wrote to Milgram, explaining why he was glad to have participated despite the stress: While I was a subject in 1964, though I believed that I was hurting someone, I was totally unaware of why I was doing so. Few people ever realize when they are acting according to their own beliefs and when they are meekly submitting to authority ... To permit myself to be drafted with the understanding that I am submitting to authority's demand to do something very wrong would make me frightened of myself ... I am fully prepared to go to jail if I am not granted Conscientious Objector status. Indeed, it is the only course I could take to be faithful to what I believe. My only hope is that members of my board act equally according to their conscience ...

[ 21 ] [ 22 ] In contrast, critics such as Gina Perry argued that participants were not properly debriefed, leading to lasting emotional harm, and that many participants in fact criticized the ethics of the study in their responses to the questionnaire.

[ 23 ] Applicability to the Holocaust [ edit ] Milgram sparked direct critical response in the scientific community by claiming in his book that "a common psychological process is centrally involved in both [his laboratory experiments and Nazi Germany] events." [ 24 ] James Waller , chair of Holocaust and Genocide Studies at Keene State College , formerly chair of Whitworth College Psychology Department, argued that Milgram experiments “do not correspond well” to the Holocaust events: [ 25 ] His points were as follows: The subjects of Milgram experiments were assured in advance that no permanent physical damage would result from their actions. However, the Holocaust perpetrators were fully aware of their hands-on killing and maiming of the victims.

The laboratory subjects themselves did not know their victims and were not motivated by racism or other biases. On the other hand, the Holocaust perpetrators displayed an intense devaluation of the victims through a lifetime of personal development.

Those serving punishment at the lab were not sadists, nor hate-mongers, and often exhibited great anguish and conflict in the experiment, [ 1 ] unlike the designers and executioners of the Final Solution , who had a clear "goal" on their hands, set beforehand.

The experiment lasted for an hour, with no time for the subjects to contemplate the implications of their behavior. Meanwhile, the Holocaust lasted for years with ample time for a moral assessment of all individuals and organizations involved.

[ 25 ] In the opinion of Thomas Blass—who is the author of a scholarly monograph on the experiment ( The Man Who Shocked The World ) published in 2004—the historical evidence pertaining to actions of the Holocaust perpetrators speaks louder than words: My own view is that Milgram's approach does not provide a fully adequate explanation of the Holocaust. While it may well account for the dutiful destructiveness of the dispassionate bureaucrat who may have shipped Jews to Auschwitz with the same degree of routinization as potatoes to Bremerhaven, it falls short when one tries to apply it to the more zealous, inventive, and hate-driven atrocities that also characterized the Holocaust.

[ 26 ] Validity [ edit ] In a 2004 issue of the journal Jewish Currents , Joseph Dimow, a participant in the 1961 experiment at Yale University, wrote about his early withdrawal as a "teacher", suspicious "that the whole experiment was designed to see if ordinary Americans would obey immoral orders, as many Germans had done during the Nazi period." [ 27 ] In 2012, Australian psychologist Gina Perry investigated Milgram's data and writings and concluded that Milgram had manipulated the results, and that there was a "troubling mismatch between (published) descriptions of the experiment and evidence of what actually transpired." She wrote that "only half of the people who undertook the experiment fully believed it was real and of those, 66% disobeyed the experimenter".

[ 28 ] [ 29 ] She described her findings as "an unexpected outcome" that "leaves social psychology in a difficult situation." [ 30 ] In a book review critical of Gina Perry's findings, Nestar Russell and John Picard take issue with Perry for not mentioning that "there have been well over a score, not just several, replications or slight variations on Milgram's basic experimental procedure, and these have been performed in many different countries, several different settings and using different types of victims. And most, although certainly not all of these experiments have tended to lend weight to Milgram's original findings." [ 31 ] Interpretations [ edit ] Milgram elaborated two theories: The first is the theory of conformism , based on Solomon Asch conformity experiments , describing the fundamental relationship between the group of reference and the individual person. A subject who has neither ability nor expertise to make decisions, especially in a crisis, will leave decision making to the group and its hierarchy. The group is the person's behavioral model.

[ 3 ] [ page needed ] The second is the agentic state theory , wherein, per Milgram, "the essence of obedience consists in the fact that a person comes to view themselves as the instrument for carrying out another person's wishes, and they therefore no longer see themselves as responsible for their actions. Once this critical shift of viewpoint has occurred in the person, all of the essential features of obedience follow".

[ 32 ] Alternative interpretations [ edit ] In his book Irrational Exuberance , Yale finance professor Robert J. Shiller argues that other factors might be partially able to explain the Milgram experiments: [People] have learned that when experts tell them something is all right, it probably is, even if it does not seem so.  (In fact, the experimenter was indeed correct: it was all right to continue giving the "shocks"—even though most of the subjects did not suspect the reason.) [ 33 ] In a 2006 experiment, a computerized avatar was used in place of the learner receiving electrical shocks.  Although the participants administering the shocks were aware that the learner was unreal, the experimenters reported that participants responded to the situation physiologically "as if it were real".

[ 34 ] Another explanation of Milgram's results invokes belief perseverance as the underlying cause.

[ 32 ] What "people cannot be counted on is to realize that a seemingly benevolent authority is in fact malevolent, even when they are faced with overwhelming evidence which suggests that this authority is indeed malevolent. Hence, the underlying cause for the subjects' striking conduct could well be conceptual, and not the alleged 'capacity of man to abandon his humanity ... as he merges his unique personality into larger institutional structures."' This last explanation receives some support from a 2009 episode of the BBC science documentary series Horizon , which involved replication of the Milgram experiment. Of the twelve participants, only three refused to continue to the end of the experiment. Speaking during the episode, social psychologist Clifford Stott discussed the influence that the idealism of scientific inquiry had on the volunteers. He remarked: "The influence is ideological. It's about what they believe science to be, that science is a positive product, it produces beneficial findings and knowledge to society that are helpful for society. So there's that sense of science is providing some kind of system for good." [ 35 ] Building on the importance of idealism, some recent researchers suggest the "engaged followership " perspective. Based on an examination of Milgram's archive, in a recent study, social psychologists Alexander Haslam , Stephen Reicher and Megan Birney, at the University of Queensland , discovered that people are less likely to follow the prods of an experimental leader when the prod resembles an order. However, when the prod stresses the importance of the experiment for science (i.e. "The experiment requires you to continue"), people are more likely to obey.

[ 36 ] The researchers suggest the perspective of "engaged followership": that people are not simply obeying the orders of a leader, but instead are willing to continue the experiment because of their desire to support the scientific goals of the leader and because of a lack of identification with the learner.

[ 37 ] [ 38 ] A neuroscientific study found that with a virtual "learner", with subjects informed beforehand that the image they would see receiving shocks was not a real person, watching this virtual learner receive electric shocks did not activate the areas typically activated with empathic response.

[ 39 ] Replications and variations [ edit ] Milgram's variations [ edit ] In Obedience to Authority: An Experimental View (1974), Milgram describes 19 variations of his experiment, some of which had not been previously reported.

Several experiments varied the distance between the participant (teacher) and the learner. Generally, when the participant was physically closer to the learner, the participant's compliance decreased. In the variation where the learner's physical immediacy was closest—where the participant had to hold the learner's arm onto a shock plate—30 percent of participants completed the experiment. The participant's compliance also decreased if the experimenter was physically farther away (Experiments 1–4). For example, in Experiment 2, where participants received telephonic instructions from the experimenter, compliance decreased to 21 percent. Some participants deceived the experimenter by pretending to continue the experiment.

In Experiment 8, an all-female contingent was used; previously, all participants had been men. Obedience did not significantly differ, though the women communicated experiencing higher levels of stress.

Experiment 10 took place in a modest office in Bridgeport , Connecticut , purporting to be the commercial entity "Research Associates of Bridgeport" without apparent connection to Yale University, to eliminate the university's prestige as a possible factor influencing the participants' behavior. In those conditions, obedience dropped to 47.5 percent, though the difference was not statistically significant.

Milgram also combined the effect of authority with that of conformity . In those experiments, the participant was joined by one or two additional "teachers" (also actors, like the "learner"). The behavior of the participants' peers strongly affected the results. In Experiment 17, when two additional teachers refused to comply, only four of 40 participants continued in the experiment. In Experiment 18, the participant performed a subsidiary task (reading the questions via microphone or recording the learner's answers) with another "teacher" who complied fully. In that variation, 37 of 40 continued with the experiment.

In addition to these procedural variations, Milgram’s work also illuminates the psychological processes highlighting obedience. Participants were observed frequently entering an “agentic state,” considering themselves as mere instruments executing the experimenter’s will and therefore weakening personal responsibility.
This shift was coupled with marked psychological evidence by nervous laughter, sweating, and internal conflict—which emphasizes the tension between hierarchical compliance and individual ethical standards. Such theoretical insights laid the basement for contemporary models of destructive obedience by revealing how authoritative contexts can reshape perceptions of agency and culpability.

[ 40 ] Replications [ edit ] A virtual replication of the experiment, with an avatar serving as the learner Around the time of the release of Obedience to Authority in 1973–1974, a version of the experiment was conducted at La Trobe University in Australia. As reported by Perry in her 2012 book Behind the Shock Machine , some of the participants experienced long-lasting psychological effects, possibly due to the lack of proper debriefing by the experimenter.

[ 41 ] In 2002, the British artist Rod Dickinson created The Milgram Re-enactment , an exact reconstruction of parts of the original experiment, including the uniforms, lighting, and rooms used. An audience watched the four-hour performance through one-way glass windows.

[ 42 ] [ 43 ] A video of this performance was first shown at the CCA Gallery in Glasgow in 2002.

A partial replication of the experiment was staged by British illusionist Derren Brown and broadcast on UK's Channel 4 in The Heist (2006).

[ 44 ] Another partial replication of the experiment was conducted by Jerry M. Burger in 2006 and broadcast on the Primetime series Basic Instincts . Burger noted that "current standards for the ethical treatment of participants clearly place Milgram's studies out of bounds." In 2009, Burger was able to receive approval from the institutional review board by modifying several of the experimental protocols, including halting the experiment after the 150-volt switch and having the learner directly tell the participant within a few seconds of the end of the experiment that they had not received any shocks.

[ 45 ] Burger found obedience rates virtually identical to those reported by Milgram in 1961–62, even while meeting current ethical regulations of informing participants. In addition, half the replication participants were female, and their rate of obedience was virtually identical to that of the male participants. Burger also included a condition in which participants first saw another participant refuse to continue. However, participants in this condition obeyed at the same rate as participants in the base condition.

[ 46 ] In the 2010 French documentary Le Jeu de la Mort ( The Game of Death ), researchers recreated the Milgram experiment with an added critique of reality television by presenting the scenario as a game show pilot. Volunteers were given €40 and told that they would not win any money from the game, as this was only a trial. Only 16 of 80 "contestants" (teachers) chose to end the game before delivering the highest-voltage punishment.

[ 47 ] [ 48 ] The experiment was performed on Dateline NBC on an episode airing April 25, 2010.

The Discovery Channel aired the "How Evil are You?" segment of Curiosity on October 30, 2011.  The episode was hosted by Eli Roth , who produced results similar to the original Milgram experiment, though the highest-voltage punishment used was 165 volts, rather than 450 volts. Roth added a segment in which a second person (an actor) in the room would defy the authority ordering the shocks, finding more often than not, the subjects would stand up to the authority figure in this case.

[ 49 ] Other variations [ edit ] Charles Sheridan at the University of Missouri and Richard King at the University of California, Berkeley hypothesized that some of Milgram's subjects may have suspected that the victim was faking, so they repeated the experiment with a real victim: a "cute, fluffy puppy" that was given real, albeit apparently harmless, electric shocks. Their findings were similar to those of Milgram: Seven out of 13 of the male subjects and all 13 of the female subjects obeyed throughout. Many subjects showed high levels of distress during the experiment and some openly wept. In addition, Sheridan and King found that the duration for which the shock button was pressed decreased as the shocks got higher, meaning that for higher shock levels, subjects were more hesitant.

[ 50 ] [ 51 ] Another variation by psychologist Don Mixon in the early 1970s tested his theory that vagueness played a key role in the initial Milgram results. The maximum shock in the original experiment and all subsequent replications are simply labeled "XXX" as opposed to "lethal". He designed a replication of the experiment where it was implied that the shocks could be dangerous and cause harm to the learner saying, "The learner's health is irrelevant." Mixon found that obedience rates fell to a very low percentage.

[ 52 ] Media depictions [ edit ] This section needs additional citations for verification .

Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.

( August 2017 ) ( Learn how and when to remove this message ) Obedience to Authority ( ISBN 978-0061765216 ) is Milgram's own account of the experiment, written for a mass audience.

Obedience is a black-and-white film of the experiment, shot by Milgram himself. It is distributed by Alexander Street Press .

[ 53 ] : 81 The Tenth Level was a fictionalized 1975 CBS television drama about the experiment, featuring William Shatner and Ossie Davis .

[ 54 ] : 198 Henri Verneuil 's I as in Icarus (1979) has a lengthy 15-min scene replicating Milgram's experiment [ 55 ] Peter Gabriel 's 1986 album So features the song " We Do What We're Told (Milgram's 37) " based on the experiment and its results.

Batch '81 is a 1982 Filipino film that features a scene based on the Milgram experiment.

[ 56 ] Atrocity is a 2005 film re-enactment of the Milgram Experiment.

[ 57 ] The Heist , a 2006 TV special by Derren Brown , features a reenactment of the Milgram experiment.

Dar Williams wrote the song "Buzzer" about the experiment for her 2008 album Promised Land .

[ 58 ] Fallout: New Vegas , a 2010 video game published by Bethesda Softworks plays verbal prods told by the experimenter inside a death chamber in Vault 11.

" Authority " is an episode of Law & Order: Special Victims Unit inspired by the Milgram experiment.

[ 59 ] Experimenter , a 2015 film about Milgram, by Michael Almereyda , was screened to favorable reactions at the 2015 Sundance Film Festival .

[ 60 ] Ted satirically depicts and cites the Milgram Experiment in one episode as Ted prods drunk partygoers to celebrate the invasion of Poland .

The Milgram Project is a Japanese interactive music project from Deco*27 and Yamanaka Takuya. As the name implies, it is directly inspired by the real-life experiment.

The experiments play prominently in the novel "The Learners" (2008) by Chip Kidd .

See also [ edit ] Psychology portal Argument from authority Authority bias Acali Experiment Banality of evil Belief perseverance Graduated electronic decelerator Hofling hospital experiment Law of Due Obedience Little Eichmanns Moral disengagement My Lai massacre Ordinary Men Social influence Stanford prison experiment Superior orders The Third Wave (experiment) The Tenth Level (1976 video starring William Shatner) Unethical human experimentation in the United States Citations [ edit ] ^ a b c d e f g h i j k Milgram, Stanley (1963).

"Behavioral Study of Obedience" .

Journal of Abnormal and Social Psychology .

67 (4): 371– 8.

CiteSeerX 10.1.1.599.92 .

doi : 10.1037/h0040525 .

PMID 14049516 .

S2CID 18309531 .

Archived from the original on July 17, 2012 . Retrieved November 20, 2006 .

as PDF.

Archived April 4, 2015, at the Wayback Machine ^ a b Blass, Thomas (1999).

"The Milgram paradigm after 35 years: Some things we now know about obedience to authority" (PDF) .

Journal of Applied Social Psychology .

29 (5): 955– 978.

doi : 10.1111/j.1559-1816.1999.tb00134.x . Archived from the original (PDF) on March 31, 2012.

^ a b c Milgram 1974 .

^ Thomas Blass , The Man Who Shocked the World: The Life and Legacy of Stanley Milgram (Basic Books, 2009) p. 75 ^ Zimbardo, Philip.

"When Good People Do Evil" .

Yale Alumni Magazine . Yale Alumni Publications, Inc.

Archived from the original on May 2, 2015 . Retrieved April 24, 2015 .

^ Milgram 1974 , p. 123.

^ Blass, Thomas (1991).

"Understanding behavior in the Milgram obedience experiment: The role of personality, situations, and their interactions" (PDF) .

Journal of Personality and Social Psychology .

60 (3): 398– 413.

doi : 10.1037/0022-3514.60.3.398 . Archived from the original (PDF) on March 7, 2016.

^ Rutger, Bregman (2020).

Humankind . Bloomsbury. pp.

161– 180.

ISBN 978-1-4088-9894-9 .

^ Romm, Cari (January 28, 2015).

"Rethinking One of Psychology's Most Infamous Experiments" .

theatlantic.com . The Atlantic.

Archived from the original on October 14, 2019 . Retrieved October 14, 2019 .

In the 1960s, Stanley Milgram's electric-shock studies showed that people will obey even the most abhorrent of orders. But recently, researchers have begun to question his conclusions—and offer some of their own.

^ Milgram, Stanley (1965). "Some Conditions of Obedience and Disobedience to Authority".

Human Relations .

18 (1): 57– 76.

doi : 10.1177/001872676501800105 .

S2CID 37505499 .

^ Abelson, Robert P.; Frey, Kurt P.; Gregg, Aiden P. (April 4, 2014).

"Chapter 4. Demonstration of Obedience to Authority" .

Experiments With People: Revelations From Social Psychology . Psychology Press.

ISBN 9781135680145 .

Archived from the original on October 9, 2021 . Retrieved August 22, 2021 .

^ Milgram, Stanley (1974).

"The Perils of Obedience" .

Harper's Magazine . Archived from the original on December 16, 2010.

Abridged and adapted from Obedience to Authority .

^ "Explanations for Obedience -Variations of Milgram (1963)" .

www.tutor2u.net . Retrieved February 4, 2025 .

^ "Explanations for Obedience -Variations of Milgram (1963)" .

www.tutor2u.net . Retrieved July 15, 2025 .

^ "Obedience | Milgram's Experiments | Factors Affecting Obedience" . June 6, 2022 . Retrieved July 15, 2025 .

^ Blass, Thomas (March–April 2002).

"The Man Who Shocked the World" .

Psychology Today .

35 (2).

^ Discovering Psychology with Philip Zimbardo Ph.D. Updated Edition, "Power of the Situation," http://video.google.com/videoplay?docid=-6059627757980071729 Archived March 16, 2008, at the Wayback Machine , reference starts at 10min 59 seconds into video.

^ Milgram films.

Archived September 5, 2009, at the Wayback Machine Accessed October 4, 2006.

^ "Today in the History of Psychology [licensed for non-commercial use only] / June 10" .

Archived from the original on January 28, 2019 . Retrieved January 27, 2019 .

^ Milgram 1974 , p. 195.

^ Raiten-D'Antonio, Toni (September 1, 2010).

Ugly as Sin: The Truth about How We Look and Finding Freedom from Self-Hatred . HCI. p. 89.

ISBN 978-0-7573-1465-0 .

^ Milgram 1974 , p. 200.

^ Perry, Gina (2013).

"Deception and Illusion in Milgram's Accounts of the Obedience Experiments" .

Theoretical & Applied Ethics, University of Nebraska Press .

2 (2): 79– 92 . Retrieved October 25, 2016 .

^ Milgram 1974 , p. 175.

^ a b James Waller (February 22, 2007).

"What Can the Milgram Studies Teach Us about Perpetrators of Extraordinary Evil?" (Google Books) .

Becoming Evil: How Ordinary People Commit Genocide and Mass Killing .

Oxford University Press . pp.

111– 113.

ISBN 978-0199774852 . Retrieved June 9, 2013 .

^ Blass, Thomas (2013).

"The Roots of Stanley Milgram's Obedience Experiments and Their Relevance to the Holocaust" (PDF) . Analyse und Kritik.net. p. 51. Archived from the original (PDF file, direct download 733 KB) on October 29, 2013 . Retrieved July 20, 2013 .

^ Dimow, Joseph (January 2004).

"Resisting Authority: A Personal Account of the Milgram Obedience Experiments" .

Jewish Currents . Archived from the original on February 2, 2004.

^ Perry, Gina (April 26, 2012).

Behind the Shock Machine: the untold story of the notorious Milgram psychology experiments .

The New Press .

ISBN 978-1921844553 .

^ Perry, Gina (2013).

"Deception and Illusion in Milgram's Accounts of the Obedience Experiments" .

Theoretical & Applied Ethics .

2 (2): 79– 92.

ISSN 2156-7174 . Retrieved August 29, 2019 .

^ Perry, Gina (August 28, 2013).

"Taking A Closer Look At Milgram's Shocking Obedience Study" .

All Things Considered (Interview). Interviewed by NPR Staff.

NPR .

Archived from the original on October 22, 2018 . Retrieved October 22, 2018 .

^ Russell, Nestar; Picard, John (2013). "Gina Perry.

Behind the Shock Machine: The Untold Story of the Notorious Milgram Psychology Experiments ". Book Reviews.

Journal of the History of the Behavioral Sciences .

49 (2): 221– 223.

doi : 10.1002/jhbs.21599 .

^ a b Nissani, Moti (1990).

"A Cognitive Reinterpretation of Stanley Milgram's Observations on Obedience to Authority" .

American Psychologist .

45 (12): 1384– 1385.

doi : 10.1037/0003-066x.45.12.1384 . Archived from the original on February 5, 2013.

^ Shiller, Robert (2005).

Irrational Exuberance (2nd ed.). Princeton NJ: Princeton University Press. p. 158.

^ Slater M, Antley A, Davison A, et al. (2006). Rustichini A (ed.).

"A virtual reprise of the Stanley Milgram obedience experiments" .

PLOS ONE .

1 (1): e39.

Bibcode : 2006PLoSO...1...39S .

doi : 10.1371/journal.pone.0000039 .

PMC 1762398 .

PMID 17183667 .

^ Presenter: Michael Portillo . Producer: Diene Petterle. (May 12, 2009).

"How Violent Are You?" .

Horizon . Series 45. Episode 18.

BBC .

BBC Two .

Archived from the original on September 24, 2017 . Retrieved May 8, 2013 .

^ Haslam, S. Alexander; Reicher, Stephen D.; Birney, Megan E. (September 1, 2014). "Nothing by Mere Authority: Evidence that in an Experimental Analogue of the Milgram Paradigm Participants are Motivated not by Orders but by Appeals to Science".

Journal of Social Issues .

70 (3): 473– 488.

doi : 10.1111/josi.12072 .

hdl : 10034/604991 .

ISSN 1540-4560 .

^ Haslam, S Alexander; Reicher, Stephen D; Birney, Megan E (October 1, 2016).

"Questioning authority: new perspectives on Milgram's 'obedience' research and its implications for intergroup relations" (PDF) .

Current Opinion in Psychology .

11 : 6– 9.

doi : 10.1016/j.copsyc.2016.03.007 .

hdl : 10023/10645 .

^ Haslam, S. Alexander; Reicher, Stephen D. (October 13, 2017).

"50 Years of "Obedience to Authority": From Blind Conformity to Engaged Followership" .

Annual Review of Law and Social Science .

13 (1): 59– 78.

doi : 10.1146/annurev-lawsocsci-110316-113710 .

^ Cheetham, Marcus; Pedroni, Andreas; Antley, Angus; Slater, Mel; Jäncke, Lutz; Cheetham, Marcus; Pedroni, Andreas F.; Antley, Angus; Slater, Mel (January 1, 2009).

"Virtual milgram: empathic concern or personal distress? Evidence from functional MRI and dispositional measures" .

Frontiers in Human Neuroscience .

3 : 29.

doi : 10.3389/neuro.09.029.2009 .

PMC 2769551 .

PMID 19876407 .

^ Milgram, old answers.

Accessed October 4, 2006.

Archived April 30, 2009, at the Wayback Machine ^ Elliott, Tim (April 26, 2012).

"Dark legacy left by shock tactics" .

Sydney Morning Herald . Archived from the original on March 4, 2016.

^ History Will Repeat Itself: Strategies of Re-enactment in Contemporary (Media) Art and Performance , ed. Inke Arns, Gabriele Horn, Frankfurt: Verlag, 2007 ^ "The Milgram Re-enactment" .

Archived from the original on November 21, 2018 . Retrieved June 10, 2008 .

^ "The Milgram Experiment on YouTube" .

YouTube . July 15, 2007. Archived from the original on October 30, 2021 . Retrieved December 21, 2008 .

^ Burger, Jerry M. (2008).

"Replicating Milgram: Would People Still Obey Today?" (PDF) .

American Psychologist .

64 (1): 1– 11.

CiteSeerX 10.1.1.631.5598 .

doi : 10.1037/a0010932 .

hdl : 10822/952419 .

PMID 19209958 .

S2CID 207550934 .

Archived (PDF) from the original on March 27, 2019 . Retrieved October 22, 2018 .

^ "The Science of Evil" .

ABC News . January 3, 2007.

Archived from the original on January 4, 2007 . Retrieved January 4, 2007 .

^ "Fake TV Game Show 'Tortures' Man, Shocks France" .

NPR .

Archived from the original on October 24, 2010 . Retrieved October 19, 2010 .

^ "Fake torture TV 'game show' reveals willingness to obey" . March 17, 2010. Archived from the original on March 23, 2010 . Retrieved March 18, 2010 .

^ "Curiosity: How evil are you?" . Archived from the original on February 1, 2014 . Retrieved April 17, 2014 .

^ "Sheridan & King (1972) – Obedience to authority with an authentic victim, Proceedings of the 80th Annual Convention of the American Psychological Association 7: 165–6" (PDF) . Archived from the original (PDF) on January 27, 2018 . Retrieved March 3, 2013 .

^ Blass 1999 , p. 968 ^ Russell, Nestar (June 2014).

"Stanley Milgram's Obedience to Authority "Relationship" Condition: Some Methodological and Theoretical Implications" .

Social Sciences .

3 (2): 194– 214.

doi : 10.3390/socsci3020194 .

ISSN 2076-0760 .

^ Malin, Cameron H.; Gudaitis, Terry; Holt, Thomas; Kilger, Max (2017).

Deception in the Digital Age . Elsevier.

ISBN 9780124116399 .

^ Riggio, Ronald E.; Chaleff, Ira; Lipman-Blumen, Jean, eds. (2008).

The Art of Followership: How Great Followers Create Great Leaders and Organizations . J-B Warren Bennis Series. John Wiley & Sons.

ISBN 9780470186411 .

^ I as in Icarus : the film excerpt replicating Milgram's experiment (subtitled in English), duration: 7min 44s.

Retrieved 17 December 2024 .

^ Gomez, Jerome (2017).

Batch '81: The Making of a Mike de Leon Film . Singapore: Asian Film Archive . p. 42.

^ "Atrocity" . Archived from the original on April 27, 2007 . Retrieved March 20, 2007 .

^ Parker, Chris (August 12, 2009).

"Dar Williams' 'Buzzer' " .

INDY Week .

Archived from the original on June 1, 2024 . Retrieved June 1, 2024 .

^ "Mayor of Television Blog" . Archived from the original on March 5, 2016.

^ " 'Experimenter': Sundance Review" .

The Hollywood Reporter . January 28, 2015.

Archived from the original on February 1, 2015 . Retrieved January 30, 2015 .

General and cited references [ edit ] Blass, Thomas (2004).

The Man Who Shocked the World: The Life and Legacy of Stanley Milgram .

Basic Books .

ISBN 978-0-7382-0399-7 .

Levine, Robert V. (July–August 2004).

"Milgram's Progress" .

American Scientist . Archived from the original on February 26, 2015.

Book review of The Man Who Shocked the World Milgram, Stanley (1974).

Obedience to Authority; An Experimental View .

Harper & Row .

ISBN 978-0-06-131983-9 .

Miller, Arthur G. (1986).

The obedience experiments: A case study of controversy in social science . New York: Praeger .

Ofgang, Erik (May 22, 2018).

"Revisiting the Milgram Obedience Experiment conducted at Yale" .

New Haven Register .

Archived from the original on July 14, 2019 . Retrieved 2019-07-04 .

Parker, Ian (Autumn 2000).

"Obedience" .

Granta (71). Archived from the original on December 7, 2008.

Includes an interview with one of Milgram's volunteers, and discusses modern interest in, and scepticism about, the experiment.

Tarnow, Eugen (October 2000).

"Towards the Zero Accident Goal: Assisting the First Officer Monitor and Challenge Captain Errors" .

Journal of Aviation/Aerospace Education & Research .

10 (1).

Archived from the original on January 13, 2012 . Retrieved May 28, 2006 .

Wu, William (June 2003).

"Compliance: The Milgram Experiment" .

Practical Psychology .

Archived from the original on April 21, 2007 . Retrieved September 18, 2004 .

Further reading [ edit ] Perry, Gina (2013).

Behind the shock machine : the untold story of the notorious Milgram psychology experiments (Rev. ed.). New York [etc.]: The New Press.

ISBN 978-1-59558-921-7 .

Saul McLeod (2017).

"The Milgram Shock Experiment" .

Simply Psychology .

Archived from the original on July 9, 2018 . Retrieved December 6, 2019 .

"The Bad Show" (Audio Podcast with transcript) .

Radiolab .

WNYC . January 9, 2012.

Archived from the original on November 17, 2019 . Retrieved December 6, 2019 .

External links [ edit ] Wikiquote has quotations related to Milgram experiment .

Wikimedia Commons has media related to Milgram experiment .

Milgram S. The Milgram Experiment ( full documentary film on YouTube Archived January 27, 2020, at the Wayback Machine ) Stanley Milgram Redux, TBIYTB — Description of a 2007 iteration of Milgram's experiment at Yale University, published in The Yale Hippolytic , January 22, 2007. ( Internet Archive ) MILGRAM, S. Dynamics of obedience. Washington: National Science Foundation, 25 January 1961. (Mimeo) A Powerpoint presentation describing Milgram's experiment Synthesis of book Archived October 12, 2018, at the Wayback Machine A faithful synthesis of Obedience to Authority – Stanley Milgram Obedience To Authority — A commentary extracted from 50 Psychology Classics (2007) A personal account of a participant in the Milgram obedience experiments Summary and evaluation of the 1963 obedience experiment Archived January 22, 2018, at the Wayback Machine The Science of Evil Archived June 24, 2020, at the Wayback Machine from ABC News Primetime The Lucifer Effect: How Good People Turn Evil — Video lecture of Philip Zimbardo talking about the Milgram Experiment.

Zimbardo, Philip (2007).

"When Good People Do Evil" .

Yale Alumni Magazine .

Archived from the original on May 2, 2015 . Retrieved October 22, 2018 .

— Article on the 45th anniversary of the Milgram experiment.

Riggenbach, Jeff (August 3, 2010).

"The Milgram Experiment" .

Mises Daily .

Archived from the original on December 24, 2013 . Retrieved October 22, 2018 .

"Stanley Milgram, Obedience to Authority (1974)" .

www.panarchy.org . Retrieved August 2, 2025 .

People 'still willing to torture' Archived December 19, 2008, at the Wayback Machine — BBC News Beyond the Shock Machine Archived January 9, 2010, at the Wayback Machine , a radio documentary with the people who took part in the experiment. Includes original audio recordings of the experiment v t e Conformity Enforcement Proscription Damnatio memoriae Dissident / Dissenter Exile Émigré Homo sacer Ostracism Blacklisting Cancel culture Censorship Deplatforming Outcast Outlaw Civil death Vogelfrei Persona non grata Public enemy Enemy of the people Enemy of the state Scapegoating Shunning Governmental pressure Authoritarianism Harmonisation of law Nationalism Left-wing nationalism National conservatism Totalitarianism Tyranny of the majority Group pressure Bandwagon effect Brainwashing Closure (sociology) Collectivism Consensus reality Culture shock Dogma Echo chamber False consensus effect Fear of missing out Groupthink Hazing Herd mentality Identification (psychology) Indoctrination Invented tradition Memory conformity Mere-exposure effect Milieu control Mobbing Normalization Normative social influence Passing (sociology) Patriotism Peer pressure Pluralistic ignorance Propaganda Psychosocial issue Purity spiral Operant conditioning Rally 'round the flag effect Social construction of gender Social contagion Addiction Behavioral Crime Hysterical Suicide Emotional Social influence Social integration Socialization Spiral of silence Teasing Toxic positivity Untouchability Individual pressure Authoritarian personality Authoritarian leadership style Right-wing authoritarianism Control freak Obsessive–compulsive personality disorder Conformity Compliance Communal reinforcement Countersignaling Creeping normality Herd behavior Internalization Normalization of deviance Obedience Preference falsification Social proof Social reality Experiments Asch conformity experiments Breaching experiment Milgram experiment Stanford prison experiment Anticonformity Alternative media Anti-authoritarianism Anti-social behaviour Self-segregation Civil disobedience Cosmopolitanism Counterculture Culture jamming Deviance Devil's advocate Dissent / Defection Political Eccentricity Eclecticism Hermit Idiosyncrasy Individualism Insubordination Pueblo clown Rebellion Red team Satire Shock value v t e Social psychology Interpersonal relationships Attachment theory Falling in love Mere-exposure effect Similarity Physical attractiveness Triangular theory of love Parenting style Divorce Adoption Conflict Prejudice Stereotype Outgroup homogeneity Stereotype threat Implicit association test Minimal group paradigm Realistic conflict theory Discrimination Social dominance orientation Social influence Authority Stanford prison experiment Honesty Compliance Foot-in-the-door technique Door-in-the-face technique Conformity Autokinetic effect Asch conformity experiments Passing Persuasion Elaboration likelihood model Pluralistic ignorance Obedience Milgram experiment Reciprocity Self-concealment Social anxiety Social determinants of mental health Social proof Social stress Group dynamics Belongingness Social identity theory Social facilitation Social loafing Social cohesion Group development Group polarization Groupthink In-group favoritism False-consensus effect Diffusion of responsibility Social comparison theory Social determinants of mental health Self-enhancement Frog pond effect Aggression Violence Deindividuation Anonymity Frustration–aggression hypothesis Altruism Bystander effect Prosocial behavior Reciprocal altruism Negative-state relief model Empathy-altruism Cooperation Prisoner's dilemma Culture Enculturation Culture shock Cultural relativism Individualism Collectivism Self-concept Spotlight effect Cognitive dissonance Choice-supportive bias Attribution Explanatory style Counterfactual thinking Framing effect Confirmation bias Observer-expectancy effect Heuristic Representative heuristic Availability heuristic Fundamental attribution error Self-serving bias Authority control databases : National Germany NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐5rs4q
Cached time: 20250812014024
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.006 seconds
Real time usage: 1.190 seconds
Preprocessor visited node count: 7577/1000000
Revision size: 62655/2097152 bytes
Post‐expand include size: 201017/2097152 bytes
Template argument size: 9191/2097152 bytes
Highest expansion depth: 21/100
Expensive parser function count: 10/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 251039/5000000 bytes
Lua time usage: 0.638/10.000 seconds
Lua memory usage: 10575410/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00% 1039.161      1 -total
 36.44%  378.708      1 Template:Reflist
 15.92%  165.392     22 Template:Cite_journal
  8.72%   90.566     18 Template:Cite_web
  7.74%   80.447     13 Template:Cite_book
  7.10%   73.784      3 Template:Navbox
  7.03%   73.027      1 Template:Short_description
  6.85%   71.219      7 Template:Sfn
  6.43%   66.842      1 Template:Conformity
  5.62%   58.393      3 Template:Pn Saved in parser cache with key enwiki:pcache:19009:|#|:idhash:canonical and timestamp 20250812014024 and revision id 1303919653. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Milgram_experiment&oldid=1303919653 " Categories : Conformity Group processes History of psychology Human subject research in the United States Psychology experiments Research ethics Social influence Hidden categories: Webarchive template wayback links Articles with short description Short description is different from Wikidata Use mdy dates from February 2018 Wikipedia articles needing page number citations from August 2025 All accuracy disputes Articles with disputed statements from July 2024 Articles needing additional references from August 2017 All articles needing additional references Commons category link is on Wikidata Articles containing video clips This page was last edited on 2 August 2025, at 21:25 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Milgram experiment 52 languages Add topic

