Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Description Toggle Description subsection 1.1 Examples 2 Forward and back substitution Toggle Forward and back substitution subsection 2.1 Forward substitution 2.2 Applications 3 Properties 4 Special forms Toggle Special forms subsection 4.1 Unitriangular matrix 4.2 Strictly triangular matrix 4.3 Atomic triangular matrix 4.4 Block triangular matrix 4.4.1 Upper block triangular 4.4.2 Lower block triangular 5 Triangularisability Toggle Triangularisability subsection 5.1 Simultaneous triangularisability 6 Algebras of triangular matrices Toggle Algebras of triangular matrices subsection 6.1 Borel subgroups and Borel subalgebras 6.2 Examples 7 See also 8 References Toggle the table of contents Triangular matrix 36 languages العربية Català Čeština Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Français Galego 한국어 Bahasa Indonesia Íslenska Italiano עברית Lombard Magyar Nederlands 日本語 Norsk bokmål Norsk nynorsk Олык марий Polski Português Русский Slovenščina Suomi Svenska தமிழ் Türkçe Українська اردو Tiếng Việt 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Triangularization ) Special kind of square matrix Not to be confused with a triangular array , a related concept.

For the rings, see triangular matrix ring .

"Triangularization" redirects here. For the geometric process, see Triangulation .

In mathematics, a triangular matrix is a special kind of square matrix . A square matrix is called lower triangular if all the entries above the main diagonal are zero. Similarly, a square matrix is called upper triangular if all the entries below the main diagonal are zero.

Because matrix equations with triangular matrices are easier to solve, they are very important in numerical analysis . By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero.

Description [ edit ] A matrix of the form L = [ ℓ ℓ 1 , 1 0 ℓ ℓ 2 , 1 ℓ ℓ 2 , 2 ℓ ℓ 3 , 1 ℓ ℓ 3 , 2 ⋱ ⋱ ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋱ ⋱ ℓ ℓ n , 1 ℓ ℓ n , 2 … … ℓ ℓ n , n − − 1 ℓ ℓ n , n ] {\displaystyle L={\begin{bmatrix}\ell _{1,1}&&&&0\\\ell _{2,1}&\ell _{2,2}&&&\\\ell _{3,1}&\ell _{3,2}&\ddots &&\\\vdots &\vdots &\ddots &\ddots &\\\ell _{n,1}&\ell _{n,2}&\ldots &\ell _{n,n-1}&\ell _{n,n}\end{bmatrix}}} is called a lower triangular matrix or left triangular matrix , and analogously a matrix of the form U = [ u 1 , 1 u 1 , 2 u 1 , 3 … … u 1 , n u 2 , 2 u 2 , 3 … … u 2 , n ⋱ ⋱ ⋱ ⋱ ⋮ ⋮ ⋱ ⋱ u n − − 1 , n 0 u n , n ] {\displaystyle U={\begin{bmatrix}u_{1,1}&u_{1,2}&u_{1,3}&\ldots &u_{1,n}\\&u_{2,2}&u_{2,3}&\ldots &u_{2,n}\\&&\ddots &\ddots &\vdots \\&&&\ddots &u_{n-1,n}\\0&&&&u_{n,n}\end{bmatrix}}} is called an upper triangular matrix or right triangular matrix . A lower or left triangular matrix is commonly denoted with the variable L , and an upper or right triangular matrix is commonly denoted with the variable U or R .

A matrix that is both upper and lower triangular is diagonal . Matrices that are similar to triangular matrices are called triangularisable .

A non-square (or sometimes any) matrix with zeros above (below) the diagonal is called a lower (upper) trapezoidal matrix. The non-zero entries form the shape of a trapezoid .

Examples [ edit ] The matrix [ 1 0 0 2 96 0 4 9 69 ] {\displaystyle {\begin{bmatrix}1&0&0\\2&96&0\\4&9&69\end{bmatrix}}} is the lower triangular for the non symmetric matrix: [ 1 5 8 2 96 9 4 9 69 ] {\displaystyle {\begin{bmatrix}1&5&8\\2&96&9\\4&9&69\end{bmatrix}}} and [ 1 4 1 0 6 9 0 0 1 ] {\displaystyle {\begin{bmatrix}1&4&1\\0&6&9\\0&0&1\end{bmatrix}}} is the upper triangular for the non symmetric matrix: [ 1 4 1 99 6 9 40 88 1 ] {\displaystyle {\begin{bmatrix}1&4&1\\99&6&9\\40&88&1\end{bmatrix}}} Forward and back substitution [ edit ] A matrix equation in the form L x = b {\displaystyle L\mathbf {x} =\mathbf {b} } or U x = b {\displaystyle U\mathbf {x} =\mathbf {b} } is very easy to solve by an iterative process called forward substitution for lower triangular matrices and analogously back substitution for upper triangular matrices. The process is so called because for lower triangular matrices, one first computes x 1 {\displaystyle x_{1}} , then substitutes that forward into the next equation to solve for x 2 {\displaystyle x_{2}} , and repeats through to x n {\displaystyle x_{n}} . In an upper triangular matrix, one works backwards, first computing x n {\displaystyle x_{n}} , then substituting that back into the previous equation to solve for x n − − 1 {\displaystyle x_{n-1}} , and repeating through x 1 {\displaystyle x_{1}} .

Notice that this does not require inverting the matrix.

Forward substitution [ edit ] The matrix equation L x = b can be written as a system of linear equations ℓ ℓ 1 , 1 x 1 = b 1 ℓ ℓ 2 , 1 x 1 + ℓ ℓ 2 , 2 x 2 = b 2 ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ ℓ ℓ m , 1 x 1 + ℓ ℓ m , 2 x 2 + ⋯ ⋯ + ℓ ℓ m , m x m = b m {\displaystyle {\begin{matrix}\ell _{1,1}x_{1}&&&&&&&=&b_{1}\\\ell _{2,1}x_{1}&+&\ell _{2,2}x_{2}&&&&&=&b_{2}\\\vdots &&\vdots &&\ddots &&&&\vdots \\\ell _{m,1}x_{1}&+&\ell _{m,2}x_{2}&+&\dotsb &+&\ell _{m,m}x_{m}&=&b_{m}\\\end{matrix}}} Observe that the first equation ( ℓ ℓ 1 , 1 x 1 = b 1 {\displaystyle \ell _{1,1}x_{1}=b_{1}} ) only involves x 1 {\displaystyle x_{1}} , and thus one can solve for x 1 {\displaystyle x_{1}} directly. The second equation only involves x 1 {\displaystyle x_{1}} and x 2 {\displaystyle x_{2}} , and thus can be solved once one substitutes in the already solved value for x 1 {\displaystyle x_{1}} . Continuing in this way, the k {\displaystyle k} -th equation only involves x 1 , … … , x k {\displaystyle x_{1},\dots ,x_{k}} , and one can solve for x k {\displaystyle x_{k}} using the previously solved values for x 1 , … … , x k − − 1 {\displaystyle x_{1},\dots ,x_{k-1}} . The resulting formulas are: x 1 = b 1 ℓ ℓ 1 , 1 , x 2 = b 2 − − ℓ ℓ 2 , 1 x 1 ℓ ℓ 2 , 2 , ⋮ ⋮ x m = b m − − ∑ ∑ i = 1 m − − 1 ℓ ℓ m , i x i ℓ ℓ m , m .

{\displaystyle {\begin{aligned}x_{1}&={\frac {b_{1}}{\ell _{1,1}}},\\x_{2}&={\frac {b_{2}-\ell _{2,1}x_{1}}{\ell _{2,2}}},\\&\ \ \vdots \\x_{m}&={\frac {b_{m}-\sum _{i=1}^{m-1}\ell _{m,i}x_{i}}{\ell _{m,m}}}.\end{aligned}}} A matrix equation with an upper triangular matrix U can be solved in an analogous way, only working backwards.

Applications [ edit ] Forward substitution is used in financial bootstrapping to construct a yield curve .

Properties [ edit ] The transpose of an upper triangular matrix is a lower triangular matrix and vice versa.

A matrix which is both symmetric and triangular is diagonal.
In a similar vein, a matrix which is both normal (meaning A * A = AA * , where A * is the conjugate transpose ) and triangular is also diagonal. This can be seen by looking at the diagonal entries of A * A and AA * .

The determinant and permanent of a triangular matrix equal the product of the diagonal entries, as can be checked by direct computation.

In fact more is true: the eigenvalues of a triangular matrix are exactly its diagonal entries. Moreover, each eigenvalue occurs exactly k times on the diagonal, where k is its algebraic multiplicity , that is, its multiplicity as a root of the characteristic polynomial p A ( x ) = det ( x I − − A ) {\displaystyle p_{A}(x)=\det(xI-A)} of A . In other words, the characteristic polynomial of a triangular n × n matrix A is exactly p A ( x ) = ( x − − a 11 ) ( x − − a 22 ) ⋯ ⋯ ( x − − a n n ) {\displaystyle p_{A}(x)=(x-a_{11})(x-a_{22})\cdots (x-a_{nn})} , that is, the unique degree n polynomial whose roots are the diagonal entries of A (with multiplicities).
To see this, observe that x I − − A {\displaystyle xI-A} is also triangular and hence its determinant det ( x I − − A ) {\displaystyle \det(xI-A)} is the product of its diagonal entries ( x − − a 11 ) ( x − − a 22 ) ⋯ ⋯ ( x − − a n n ) {\displaystyle (x-a_{11})(x-a_{22})\cdots (x-a_{nn})} .

[ 1 ] Special forms [ edit ] Unitriangular matrix [ edit ] If the entries on the main diagonal of a (lower or upper) triangular matrix are all 1, the matrix is called (lower or upper) unitriangular .

Other names used for these matrices are unit (lower or upper) triangular , or very rarely normed (lower or upper) triangular . However, a unit triangular matrix is not the same as the unit matrix , and a normed triangular matrix has nothing to do with the notion of matrix norm .

All finite unitriangular matrices are unipotent .

Strictly triangular matrix [ edit ] If all of the entries on the main diagonal of a (lower or upper) triangular matrix are also 0, the matrix is called strictly (lower or upper) triangular .

All finite strictly triangular matrices are nilpotent of index at most n as a consequence of the Cayley-Hamilton theorem .

Atomic triangular matrix [ edit ] Main article: Frobenius matrix An atomic (lower or upper) triangular matrix is a special form of unitriangular matrix, where all of the off-diagonal elements are zero, except for the entries in a single column. Such a matrix is also called a Frobenius matrix , a Gauss matrix , or a Gauss transformation matrix .

Block triangular matrix [ edit ] Main article: Block matrix A block triangular matrix is a block matrix (partitioned matrix) that is a triangular matrix.

Upper block triangular [ edit ] A matrix A {\displaystyle A} is upper block triangular if A = [ A 11 A 12 ⋯ ⋯ A 1 k 0 A 22 ⋯ ⋯ A 2 k ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ 0 0 ⋯ ⋯ A k k ] {\displaystyle A={\begin{bmatrix}A_{11}&A_{12}&\cdots &A_{1k}\\0&A_{22}&\cdots &A_{2k}\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &A_{kk}\end{bmatrix}}} , where A i j ∈ ∈ F n i × × n j {\displaystyle A_{ij}\in \mathbb {F} ^{n_{i}\times n_{j}}} for all i , j = 1 , … … , k {\displaystyle i,j=1,\ldots ,k} .

[ 2 ] Lower block triangular [ edit ] A matrix A {\displaystyle A} is lower block triangular if A = [ A 11 0 ⋯ ⋯ 0 A 21 A 22 ⋯ ⋯ 0 ⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋮ ⋮ A k 1 A k 2 ⋯ ⋯ A k k ] {\displaystyle A={\begin{bmatrix}A_{11}&0&\cdots &0\\A_{21}&A_{22}&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\A_{k1}&A_{k2}&\cdots &A_{kk}\end{bmatrix}}} , where A i j ∈ ∈ F n i × × n j {\displaystyle A_{ij}\in \mathbb {F} ^{n_{i}\times n_{j}}} for all i , j = 1 , … … , k {\displaystyle i,j=1,\ldots ,k} .

[ 2 ] Triangularisability [ edit ] A matrix that is similar to a triangular matrix is referred to as triangularizable . Abstractly, this is equivalent to stabilizing a flag : upper triangular matrices are precisely those that preserve the standard flag , which is given by the standard ordered basis ( e 1 , … … , e n ) {\displaystyle (e_{1},\ldots ,e_{n})} and the resulting flag 0 < ⟨ e 1 ⟩ < ⟨ e 1 , e 2 ⟩ < ⋯ ⋯ < ⟨ e 1 , … … , e n ⟩ = K n .

{\displaystyle 0<\left\langle e_{1}\right\rangle <\left\langle e_{1},e_{2}\right\rangle <\cdots <\left\langle e_{1},\ldots ,e_{n}\right\rangle =K^{n}.} All flags are conjugate (as the general linear group acts transitively on bases), so any matrix that stabilises a flag is similar to one that stabilizes the standard flag.

Any complex square matrix is triangularizable.

[ 1 ] In fact, a matrix A over a field containing all of the eigenvalues of A (for example, any matrix over an algebraically closed field ) is similar to a triangular matrix. This can be proven by using induction on the fact that A has an eigenvector, by taking the quotient space by the eigenvector and inducting to show that A stabilizes a flag, and is thus triangularizable with respect to a basis for that flag.

A more precise statement is given by the Jordan normal form theorem, which states that in this situation, A is similar to an upper triangular matrix of a very particular form. The simpler triangularization result is often sufficient however, and in any case used in proving the Jordan normal form theorem.

[ 1 ] [ 3 ] In the case of complex matrices, it is possible to say more about triangularization, namely, that any square matrix A has a Schur decomposition . This means that A is unitarily equivalent (i.e. similar, using a unitary matrix as change of basis) to an upper triangular matrix; this follows by taking an Hermitian basis for the flag.

Simultaneous triangularisability [ edit ] See also: Simultaneously diagonalizable A set of matrices A 1 , … … , A k {\displaystyle A_{1},\ldots ,A_{k}} are said to be simultaneously triangularisable if there is a basis under which they are all upper triangular; equivalently, if they are upper triangularizable by a single similarity matrix P.

Such a set of matrices is more easily understood by considering the algebra of matrices it generates, namely all polynomials in the A i , {\displaystyle A_{i},} denoted K [ A 1 , … … , A k ] .

{\displaystyle K[A_{1},\ldots ,A_{k}].} Simultaneous triangularizability means that this algebra is conjugate into the Lie subalgebra of upper triangular matrices, and is equivalent to this algebra being a Lie subalgebra of a Borel subalgebra .

The basic result is that (over an algebraically closed field), the commuting matrices A , B {\displaystyle A,B} or more generally A 1 , … … , A k {\displaystyle A_{1},\ldots ,A_{k}} are simultaneously triangularizable. This can be proven by first showing that commuting matrices have a common eigenvector, and then inducting on dimension as before. This was proven by Frobenius, starting in 1878 for a commuting pair, as discussed at commuting matrices . As for a single matrix, over the complex numbers these can be triangularized by unitary matrices.

The fact that commuting matrices have a common eigenvector can be interpreted as a result of Hilbert's Nullstellensatz : commuting matrices form a commutative algebra K [ A 1 , … … , A k ] {\displaystyle K[A_{1},\ldots ,A_{k}]} over K [ x 1 , … … , x k ] {\displaystyle K[x_{1},\ldots ,x_{k}]} which can be interpreted as a variety in k -dimensional affine space, and the existence of a (common) eigenvalue (and hence a common eigenvector) corresponds to this variety having a point (being non-empty), which is the content of the (weak) Nullstellensatz.

[ citation needed ] In algebraic terms, these operators correspond to an algebra representation of the polynomial algebra in k variables.

This is generalized by Lie's theorem , which shows that any representation of a solvable Lie algebra is simultaneously upper triangularizable, the case of commuting matrices being the abelian Lie algebra case, abelian being a fortiori solvable.

More generally and precisely, a set of matrices A 1 , … … , A k {\displaystyle A_{1},\ldots ,A_{k}} is simultaneously triangularisable if and only if the matrix p ( A 1 , … … , A k ) [ A i , A j ] {\displaystyle p(A_{1},\ldots ,A_{k})[A_{i},A_{j}]} is nilpotent for all polynomials p in k non -commuting variables, where [ A i , A j ] {\displaystyle [A_{i},A_{j}]} is the commutator ; for commuting A i {\displaystyle A_{i}} the commutator vanishes so this holds. This was proven by Drazin, Dungey, and Gruenberg in 1951; [ 4 ] a brief proof is given by Prasolov in 1994.

[ 5 ] One direction is clear: if the matrices are simultaneously triangularisable, then [ A i , A j ] {\displaystyle [A_{i},A_{j}]} is strictly upper triangularizable (hence nilpotent), which is preserved by multiplication by any A k {\displaystyle A_{k}} or combination thereof – it will still have 0s on the diagonal in the triangularizing basis.

Algebras of triangular matrices [ edit ] Binary lower unitriangular Toeplitz matrices, multiplied using F 2 operations. They form the Cayley table of Z 4 and correspond to powers of the 4-bit Gray code permutation .

Upper triangularity is preserved by many operations: The sum of two upper triangular matrices is upper triangular.

The product of two upper triangular matrices is upper triangular.

The inverse of an upper triangular matrix, if it exists, is upper triangular.

The product of an upper triangular matrix and a scalar is upper triangular.

Together these facts mean that the upper triangular matrices form a subalgebra of the associative algebra of square matrices for a given size. Additionally, this also shows that the upper triangular matrices can be viewed as a Lie subalgebra of the Lie algebra of square matrices of a fixed size, where the Lie bracket [ a , b ] given by the commutator ab − ba . The Lie algebra of all upper triangular matrices is a solvable Lie algebra . It is often referred to as a Borel subalgebra of the Lie algebra of all square matrices.

All these results hold if upper triangular is replaced by lower triangular throughout; in particular the lower triangular matrices also form a Lie algebra. However, operations mixing upper and lower triangular matrices do not in general produce triangular matrices. For instance, the sum of an upper and a lower triangular matrix can be any matrix; the product of a lower triangular with an upper triangular matrix is not necessarily triangular either.

The set of unitriangular matrices forms a Lie group .

The set of strictly upper (or lower) triangular matrices forms a nilpotent Lie algebra , denoted n .

{\displaystyle {\mathfrak {n}}.} This algebra is the derived Lie algebra of b {\displaystyle {\mathfrak {b}}} , the Lie algebra of all upper triangular matrices; in symbols, n = [ b , b ] .

{\displaystyle {\mathfrak {n}}=[{\mathfrak {b}},{\mathfrak {b}}].} In addition, n {\displaystyle {\mathfrak {n}}} is the Lie algebra of the Lie group of unitriangular matrices.

In fact, by Engel's theorem , any finite-dimensional nilpotent Lie algebra is conjugate to a subalgebra of the strictly upper triangular matrices, that is to say, a finite-dimensional nilpotent Lie algebra is simultaneously strictly upper triangularizable.

Algebras of upper triangular matrices have a natural generalization in functional analysis which yields nest algebras on Hilbert spaces .

See also: Affine group Borel subgroups and Borel subalgebras [ edit ] Main articles: Borel subgroup and Borel subalgebra The set of invertible triangular matrices of a given kind (lower or upper) forms a group , indeed a Lie group , which is a subgroup of the general linear group of all invertible matrices. A triangular matrix is invertible precisely when its diagonal entries are invertible (non-zero).

Over the real numbers, this group is disconnected, having 2 n {\displaystyle 2^{n}} components accordingly as each diagonal entry is positive or negative. The identity component is invertible triangular matrices with positive entries on the diagonal, and the group of all invertible triangular matrices is a semidirect product of this group and the group of diagonal matrices with ± ± 1 {\displaystyle \pm 1} on the diagonal, corresponding to the components.

The Lie algebra of the Lie group of invertible upper triangular matrices is the set of all upper triangular matrices, not necessarily invertible, and is a solvable Lie algebra . These are, respectively, the standard Borel subgroup B of the Lie group GL n and the standard Borel subalgebra b {\displaystyle {\mathfrak {b}}} of the Lie algebra gl n .

The upper triangular matrices are precisely those that stabilize the standard flag . The invertible ones among them form a subgroup of the general linear group, whose conjugate subgroups are those defined as the stabilizer of some (other) complete flag. These subgroups are Borel subgroups . The group of invertible lower triangular matrices is such a subgroup, since it is the stabilizer of the standard flag associated to the standard basis in reverse order.

The stabilizer of a partial flag obtained by forgetting some parts of the standard flag can be described as a set of block upper triangular matrices (but its elements are not all triangular matrices). The conjugates of such a group are the subgroups defined as the stabilizer of some partial flag. These subgroups are called parabolic subgroups.

Examples [ edit ] The group of 2×2 upper unitriangular matrices is isomorphic to the additive group of the field of scalars; in the case of complex numbers it corresponds to a group formed of parabolic Möbius transformations ; the 3×3 upper unitriangular matrices form the Heisenberg group .

See also [ edit ] Gaussian elimination QR decomposition Cholesky decomposition Hessenberg matrix Tridiagonal matrix Invariant subspace References [ edit ] ^ a b c Axler, Sheldon Jay (1997).

Linear Algebra Done Right (2nd ed.). New York: Springer. pp.

86– 87, 169.

ISBN 0-387-22595-1 .

OCLC 54850562 .

^ a b Bernstein, Dennis S. (2009).

Matrix mathematics: theory, facts, and formulas (2 ed.). Princeton, NJ: Princeton University Press. p. 168.

ISBN 978-0-691-14039-1 .

^ Herstein, I. N. (1975).

Topics in Algebra (2nd ed.). New York: Wiley. pp.

285– 290.

ISBN 0-471-01090-1 .

OCLC 3307396 .

^ Drazin, M. P.; Dungey, J. W.; Gruenberg, K. W. (1951).

"Some Theorems on Commutative Matrices" .

Journal of the London Mathematical Society .

26 (3): 221– 228.

doi : 10.1112/jlms/s1-26.3.221 .

^ Prasolov, V. V. (1994).

Problems and Theorems in Linear Algebra . Simeon Ivanov. Providence, R.I.: American Mathematical Society. pp.

178– 179.

ISBN 9780821802366 .

OCLC 30076024 .

v t e Matrix classes Explicitly constrained entries Alternant Anti-diagonal Anti-Hermitian Anti-symmetric Arrowhead Band Bidiagonal Bisymmetric Block-diagonal Block Block tridiagonal Boolean Cauchy Centrosymmetric Conference Complex Hadamard Copositive Diagonally dominant Diagonal Discrete Fourier Transform Elementary Equivalent Frobenius Generalized permutation Hadamard Hankel Hermitian Hessenberg Hollow Integer Logical Matrix unit Metzler Moore Nonnegative Pentadiagonal Permutation Persymmetric Polynomial Quaternionic Signature Skew-Hermitian Skew-symmetric Skyline Sparse Sylvester Symmetric Toeplitz Triangular Tridiagonal Vandermonde Walsh Z Constant Exchange Hilbert Identity Lehmer Of ones Pascal Pauli Redheffer Shift Zero Conditions on eigenvalues or eigenvectors Companion Convergent Defective Definite Diagonalizable Hurwitz-stable Positive-definite Stieltjes Satisfying conditions on products or inverses Congruent Idempotent or Projection Invertible Involutory Nilpotent Normal Orthogonal Unimodular Unipotent Unitary Totally unimodular Weighing With specific applications Adjugate Alternating sign Augmented Bézout Carleman Cartan Circulant Cofactor Commutation Confusion Coxeter Distance Duplication and elimination Euclidean distance Fundamental (linear differential equation) Generator Gram Hessian Householder Jacobian Moment Payoff Pick Random Rotation Routh-Hurwitz Seifert Shear Similarity Symplectic Totally positive Transformation Used in statistics Centering Correlation Covariance Design Doubly stochastic Fisher information Hat Precision Stochastic Transition Used in graph theory Adjacency Biadjacency Degree Edmonds Incidence Laplacian Seidel adjacency Tutte Used in science and engineering Cabibbo–Kobayashi–Maskawa Density Fundamental (computer vision) Fuzzy associative Gamma Gell-Mann Hamiltonian Irregular Overlap S State transition Substitution Z (chemistry) Related terms Jordan normal form Linear independence Matrix exponential Matrix representation of conic sections Perfect matrix Pseudoinverse Row echelon form Wronskian Mathematics portal List of matrices Category:Matrices (mathematics) NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐frb2h
Cached time: 20250811235617
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.402 seconds
Real time usage: 0.570 seconds
Preprocessor visited node count: 1455/1000000
Revision size: 21296/2097152 bytes
Post‐expand include size: 42861/2097152 bytes
Template argument size: 1471/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 12/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 34344/5000000 bytes
Lua time usage: 0.216/10.000 seconds
Lua memory usage: 5391907/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  382.678      1 -total
 30.88%  118.173      1 Template:Reflist
 24.86%   95.135      4 Template:Cite_book
 21.64%   82.826      1 Template:Matrix_classes
 21.12%   80.806      1 Template:Navbox
 20.34%   77.845      1 Template:Short_description
 11.53%   44.111      2 Template:Pagetype
  9.17%   35.088      1 Template:Citation_needed
  8.00%   30.601      1 Template:Fix
  6.37%   24.362      4 Template:Main_other Saved in parser cache with key enwiki:pcache:374222:|#|:idhash:canonical and timestamp 20250811235617 and revision id 1301245208. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Triangular_matrix&oldid=1301245208 " Categories : Numerical linear algebra Matrices (mathematics) Hidden categories: Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from March 2021 This page was last edited on 18 July 2025, at 21:23 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Triangular matrix 36 languages Add topic

