Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions 2 The normal distribution and percentiles 3 Applications 4 Calculation methods Toggle Calculation methods subsection 4.1 The nearest-rank method 4.2 The linear interpolation between closest ranks method 4.2.1 First variant, C = 1/2 4.2.2 Second variant, C = 1 4.2.3 Third variant, C = 0 4.3 The weighted percentile method 5 See also 6 References Toggle the table of contents Percentile 25 languages العربية Čeština Dansk Deutsch Español Euskara فارسی Français Galego 한국어 Italiano עברית Nederlands Norsk bokmål Polski Português Русский Simple English Српски / srpski Svenska Türkçe Українська اردو 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Statistic which divides a data set into 100 parts and analyzes it as a percentage In statistics , a k -th percentile , also known as percentile score or centile , is a score (e.g., a data point) below which a given percentage k of all scores in its frequency distribution exists (" exclusive " definition). Alternatively, it is a score at or below which a given percentage of the all scores exists (" inclusive " definition). I.e., a score in the k -th percentile would be above approximately k % of all scores in its set. For example, under the exclusive definition, the 97th percentile is the value such that 97% of the data points are less than it. Percentiles depends on how scores are arranged.

Percentiles are a type of quantiles , obtained adopting a subdivision into 100 groups. The 25th percentile is also known as the first quartile ( Q 1 ), the 50th percentile as the median or second quartile ( Q 2 ), and the 75th percentile as the third quartile ( Q 3 ). For example, the 50th percentile (median) is the score below (or at or below , depending on the definition) which 50% of the scores in the distribution are found.

Percentiles are expressed in the same unit of measurement as the input scores, not in percent ; for example, if the scores refer to human weight , the corresponding percentiles will be expressed in kilograms or pounds.
In the limit of an infinite sample size , the percentile approximates the percentile function , the inverse of the cumulative distribution function .

A related quantity is the percentile rank of a score, expressed in percent , which represents the fraction of scores in its distribution that are less than it, an exclusive definition.
Percentile scores and percentile ranks are often used in the reporting of test scores from norm-referenced tests , but, as just noted, they are not the same. For percentile ranks, a score is given and a percentage is computed. Percentile ranks are exclusive: if the percentile rank for a specified score is 90%, then 90% of the scores were lower.  In contrast, for percentiles a percentage is given and a corresponding score is determined, which can be either exclusive or inclusive. The score for a specified percentage (e.g., 90th) indicates a score below which (exclusive definition) or at or below which (inclusive definition) other scores in the distribution fall.

Definitions [ edit ] There is no standard definition of percentile; [ 1 ] [ 2 ] [ 3 ] however, all definitions yield similar results when the number of observations is very large and the probability distribution is continuous.

[ 4 ] In the limit, as the sample size approaches infinity, the 100 p th percentile (0< p <1) approximates the inverse of the cumulative distribution function (CDF) thus formed, evaluated at p , as p approximates the CDF. This can be seen as a consequence of the Glivenko–Cantelli theorem . Some methods for calculating the percentiles are given below.

The normal distribution and percentiles [ edit ] Representation of the three-sigma rule . The dark blue zone represents observations within one standard deviation (σ) to either side of the mean (μ), which accounts for about 68.3% of the population. Two standard deviations from the mean (dark and medium blue) account for about 95.4%, and three standard deviations (dark, medium, and light blue) for about 99.7%.

The methods given in the calculation methods section (below) are approximations for use in small-sample statistics. In general terms, for very large populations following a normal distribution , percentiles may often be represented by reference to a normal curve plot. The normal distribution is plotted along an axis scaled to standard deviations , or sigma ( σ σ {\displaystyle \sigma } ) units. Mathematically, the normal distribution extends to negative infinity on the left and positive infinity on the right. Note, however, that only a very small proportion of individuals in a population will fall outside the −3 σ to +3 σ range. For example, with human heights very few people are above the +3 σ height level.

Percentiles represent the area under the normal curve, increasing from left to right. Each standard deviation represents a fixed percentile. Thus, rounding to two decimal places, −3 σ is the 0.13th percentile, −2 σ the 2.28th percentile, −1 σ the 15.87th percentile, 0 σ the 50th percentile (both the mean and median of the distribution), +1 σ the 84.13th percentile, +2 σ the 97.72nd percentile, and +3 σ the 99.87th percentile. This is related to the 68–95–99.7 rule or the three-sigma rule. Note that in theory the 0th percentile falls at negative infinity and the 100th percentile at positive infinity, although in many practical applications, such as test results, natural lower and/or upper limits are enforced.

Applications [ edit ] When ISPs bill "burstable" internet bandwidth , the 95th or 98th percentile usually cuts off the top 5% or 2% of bandwidth peaks in each month, and then bills at the nearest rate. In this way, infrequent peaks are ignored, and the customer is charged in a fairer way. The reason this statistic is so useful in measuring data throughput is that it gives a very accurate picture of the cost of the bandwidth. The 95th percentile says that 95% of the time, the usage is below this amount: so, the remaining 5% of the time, the usage is above that amount.

Physicians will often use infant and children's weight and height to assess their growth in comparison to national averages and percentiles which are found in growth charts .

The 85th percentile speed of traffic on a road is often used as a guideline in setting speed limits and assessing whether such a limit is too high or low.

[ 5 ] [ 6 ] In finance, value at risk is a standard measure to assess (in a model-dependent way) the quantity under which the value of the portfolio is not expected to sink within a given period of time and given a confidence value.

Calculation methods [ edit ] This section possibly contains original synthesis .

Source material should verifiably mention and relate to the main topic.

Relevant discussion may be found on the talk page .

( February 2023 ) ( Learn how and when to remove this message ) Interpolated and nearest-rank, exclusive and inclusive, percentiles for 10-score distribution Interpolated and nearest-rank, exclusive and inclusive, percentiles for 10-score distribution There are many formulas or algorithms [ 7 ] for a percentile score. Hyndman and Fan [ 1 ] identified nine and most statistical and spreadsheet software use one of the methods they describe.

[ 8 ] Algorithms either return the value of a score that exists in the set of scores (nearest-rank methods) or interpolate between existing scores and are either exclusive or inclusive.

Nearest-rank methods (exclusive/inclusive) PC: percentile specified 0.10 0.25 0.50 0.75 0.90 N: Number of scores 10 10 10 10 10 OR: ordinal rank = PC × N 1 2.5 5 7.5 9 Rank: >OR / ≥OR 2/1 3/3 6/5 8/8 10/9 Score at rank (exc/inc) 2/1 3/3 4/3 5/5 7/5 The figure shows a 10-score distribution, illustrates the percentile scores that result from these different algorithms, and serves as an introduction to the examples given subsequently. The simplest are nearest-rank methods that return a score from the distribution, although compared to interpolation methods, results can be a bit crude. The Nearest-Rank Methods table shows the computational steps for exclusive and inclusive methods.

Interpolated methods (exclusive/inclusive) PC: percentile specified 0.10 0.25 0.50 0.75 0.90 N: number of scores 10 10 10 10 10 OR: PC×(N+1) / PC×(N−1)+1 1.1/1.9 2.75/3.25 5.5/5.5 8.25/7.75 9.9/9.1 LoRank: OR truncated 1/1 2/3 5/5 8/7 9/9 HIRank: OR rounded up 2/2 3/4 6/6 9/8 10/10 LoScore: score at LoRank 1/1 2/3 3/3 5/4 5/5 HiScore: score at HiRank 2/2 3/3 4/4 5/5 7/7 Difference: HiScore − LoScore 1/1 1/0 1/1 0/1 2/2 Mod: fractional part of OR 0.1/0.9 0.75/0.25 0.5/0.5 0.25/0.75 0.9/0.1 Interpolated score (exc/inc) = LoScore + Mod × Difference 1.1/1.9 2.75/3 3.5/3.5 5/4.75 6.8/5.2 Interpolation methods, as the name implies, can return a score that is between scores in the distribution. Algorithms used by  statistical programs typically use interpolation methods, for example, the percentile.exc and percentile.inc functions in Microsoft Excel. The Interpolated Methods table shows the computational steps.

The nearest-rank method [ edit ] The percentile values for the ordered list {15, 20, 35, 40, 50} One definition of percentile, often given in texts, is that the P -th percentile ( 0 < P ≤ ≤ 100 ) {\displaystyle (0<P\leq 100)} of a list of N ordered values (sorted from least to greatest) is the smallest value in the list such that no more than P percent of the data is strictly less than the value and at least P percent of the data is less than or equal to that value. This is obtained by first calculating the ordinal rank and then taking the value from the ordered list that corresponds to that rank. The ordinal rank n is calculated using this formula n = ⌈ P 100 × × N ⌉ .

{\displaystyle n=\left\lceil {\frac {P}{100}}\times N\right\rceil .} Using the nearest-rank method on lists with fewer than 100 distinct values can result in the same value being used for more than one percentile.

A percentile calculated using the nearest-rank method will always be a member of the original ordered list.

The 100th percentile is defined to be the largest value in the ordered list.

The linear interpolation between closest ranks method [ edit ] An alternative to rounding used in many applications is to use linear interpolation between adjacent ranks.

All of the following variants have the following in common. Given the order statistics { v i , i = 1 , 2 , … … , N : v i + 1 ≥ ≥ v i , ∀ ∀ i = 1 , 2 , … … , N − − 1 } , {\displaystyle \{v_{i},i=1,2,\ldots ,N:v_{i+1}\geq v_{i},\forall i=1,2,\ldots ,N-1\},} we seek a linear interpolation function that passes through the points ( v i , i ) {\displaystyle (v_{i},i)} . This is simply accomplished by v ( x ) = v ⌊ ⌊ x ⌋ ⌋ + ( x mod 1 ) ( v ⌊ ⌊ x ⌋ ⌋ + 1 − − v ⌊ ⌊ x ⌋ ⌋ ) , ∀ ∀ x ∈ ∈ [ 1 , N ] : v ( i ) = v i , for i = 1 , 2 , … … , N , {\displaystyle v(x)=v_{\lfloor x\rfloor }+(x{\bmod {1}})(v_{\lfloor x\rfloor +1}-v_{\lfloor x\rfloor }),\forall x\in [1,N]:v(i)=v_{i}{\text{, for }}i=1,2,\ldots ,N,} where ⌊ ⌊ x ⌋ ⌋ {\displaystyle \lfloor x\rfloor } uses the floor function to represent the integral part of positive x , whereas x mod 1 {\displaystyle x{\bmod {1}}} uses the mod function to represent its fractional part (the remainder after division by 1). (Note that, though at the endpoint x = N {\displaystyle x=N} , v ⌊ ⌊ x ⌋ ⌋ + 1 {\displaystyle v_{\lfloor x\rfloor +1}} is undefined, it does not need to be because it is multiplied by x mod 1 = 0 {\displaystyle x{\bmod {1}}=0} .) As we can see, x is the continuous version of the subscript i , linearly interpolating v between adjacent nodes.

There are two ways in which the variant approaches differ. The first is in the linear relationship between the rank x , the percent rank P = 100 p {\displaystyle P=100p} , and a constant that is a function of the sample size N : x = f ( p , N ) = ( N + c 1 ) p + c 2 .

{\displaystyle x=f(p,N)=(N+c_{1})p+c_{2}.} There is the additional requirement that the midpoint of the range ( 1 , N ) {\displaystyle (1,N)} , corresponding to the median , occur at p = 0.5 {\displaystyle p=0.5} : f ( 0.5 , N ) = N + c 1 2 + c 2 = N + 1 2 ∴ ∴ 2 c 2 + c 1 = 1 , {\displaystyle {\begin{aligned}f(0.5,N)&={\frac {N+c_{1}}{2}}+c_{2}={\frac {N+1}{2}}\\\therefore 2c_{2}+c_{1}&=1\end{aligned}},} and our revised function now has just one degree of freedom, looking like this: x = f ( p , N ) = ( N + 1 − − 2 C ) p + C .

{\displaystyle x=f(p,N)=(N+1-2C)p+C.} The second way in which the variants differ is in the definition of the function near the margins of the [ 0 , 1 ] {\displaystyle [0,1]} range of p : f ( p , N ) {\displaystyle f(p,N)} should produce, or be forced to produce, a result in the range [ 1 , N ] {\displaystyle [1,N]} , which may mean the absence of a one-to-one correspondence in the wider region. One author has suggested a choice of C = 1 2 ( 1 + ξ ξ ) {\displaystyle C={\tfrac {1}{2}}(1+\xi )} where ξ is the shape of the Generalized extreme value distribution which is the extreme value limit of the sampled distribution.

First variant, C = 1/2 [ edit ] The result of using each of the three variants on the ordered list {15, 20, 35, 40, 50} (Sources: Matlab "prctile" function, [ 9 ] [ 10 ] ) x = f ( p ) = { N p + 1 2 , ∀ ∀ p ∈ ∈ [ p 1 , p N ] , 1 , ∀ ∀ p ∈ ∈ [ 0 , p 1 ] , N , ∀ ∀ p ∈ ∈ [ p N , 1 ] .

{\displaystyle x=f(p)={\begin{cases}Np+{\frac {1}{2}},\forall p\in \left[p_{1},p_{N}\right],\\1,\forall p\in \left[0,p_{1}\right],\\N,\forall p\in \left[p_{N},1\right].\end{cases}}} where p i = 1 N ( i − − 1 2 ) , i ∈ ∈ [ 1 , N ] ∩ ∩ N {\displaystyle p_{i}={\frac {1}{N}}\left(i-{\frac {1}{2}}\right),i\in [1,N]\cap \mathbb {N} } ∴ ∴ p 1 = 1 2 N , p N = 2 N − − 1 2 N .

{\displaystyle \therefore p_{1}={\frac {1}{2N}},p_{N}={\frac {2N-1}{2N}}.} Furthermore, let P i = 100 p i .

{\displaystyle P_{i}=100p_{i}.} The inverse relationship is restricted to a narrower region: p = 1 N ( x − − 1 2 ) , x ∈ ∈ ( 1 , N ) ∩ ∩ R .

{\displaystyle p={\frac {1}{N}}\left(x-{\frac {1}{2}}\right),x\in (1,N)\cap \mathbb {R} .} Second variant, C = 1 [ edit ] [Source: Some software packages, including NumPy [ 11 ] and Microsoft Excel [ 3 ] (up to and including version 2013 by means of the PERCENTILE.INC function). Noted as an alternative by NIST .

[ 8 ] ] x = f ( p , N ) = p ( N − − 1 ) + 1 , p ∈ ∈ [ 0 , 1 ] {\displaystyle x=f(p,N)=p(N-1)+1{\text{, }}p\in [0,1]} ∴ ∴ p = x − − 1 N − − 1 , x ∈ ∈ [ 1 , N ] .

{\displaystyle \therefore p={\frac {x-1}{N-1}}{\text{, }}x\in [1,N].} Note that the x ↔ ↔ p {\displaystyle x\leftrightarrow p} relationship is one-to-one for p ∈ ∈ [ 0 , 1 ] {\displaystyle p\in [0,1]} , the only one of the three variants with this property; hence the "INC" suffix, for inclusive , on the Excel function.

Third variant, C = 0 [ edit ] (The primary variant recommended by NIST .

[ 8 ] Adopted by Microsoft Excel since 2010 by means of PERCENTIL.EXC function. However, as the "EXC" suffix indicates, the Excel version excludes both endpoints of the range of p , i.e., p ∈ ∈ ( 0 , 1 ) {\displaystyle p\in (0,1)} , whereas the "INC" version, the second variant, does not; in fact, any number smaller than 1 N + 1 {\displaystyle {\frac {1}{N+1}}} is also excluded and would cause an error.) x = f ( p , N ) = { 1 , p ∈ ∈ [ 0 , 1 N + 1 ] p ( N + 1 ) , p ∈ ∈ ( 1 N + 1 , N N + 1 ) N , p ∈ ∈ [ N N + 1 , 1 ] .

{\displaystyle x=f(p,N)={\begin{cases}1{\text{, }}p\in \left[0,{\frac {1}{N+1}}\right]\\p(N+1){\text{, }}p\in \left({\frac {1}{N+1}},{\frac {N}{N+1}}\right)\\N{\text{, }}p\in \left[{\frac {N}{N+1}},1\right]\end{cases}}.} The inverse is restricted to a narrower region: p = x N + 1 , x ∈ ∈ ( 0 , N ) .

{\displaystyle p={\frac {x}{N+1}}{\text{, }}x\in (0,N).} The weighted percentile method [ edit ] See also: Weighted median In addition to the percentile function, there is also a weighted percentile , where the percentage in the total weight is counted instead of the total number. There is no standard function for a weighted percentile. One method extends the above approach in a natural way.

Suppose we have positive weights w 1 , w 2 , w 3 , … … , w N {\displaystyle w_{1},w_{2},w_{3},\dots ,w_{N}} associated, respectively, with our N sorted sample values.  Let S N = ∑ ∑ k = 1 N w k , {\displaystyle S_{N}=\sum _{k=1}^{N}w_{k},} the sum of the weights.  Then the formulas above are generalized by taking p n = 1 S N ( S n − − w n 2 ) {\displaystyle p_{n}={\frac {1}{S_{N}}}\left(S_{n}-{\frac {w_{n}}{2}}\right)} when C = 1 / 2 {\displaystyle C=1/2} , or p n = S n − − C w n S N + ( 1 − − 2 C ) w n {\displaystyle p_{n}={\frac {S_{n}-Cw_{n}}{S_{N}+(1-2C)w_{n}}}} for general C {\displaystyle C} , and v = v k + P − − p k p k + 1 − − p k ( v k + 1 − − v k ) .

{\displaystyle v=v_{k}+{\frac {P-p_{k}}{p_{k+1}-p_{k}}}(v_{k+1}-v_{k}).} The 50% weighted percentile is known as the weighted median .

See also [ edit ] Mathematics portal Decile Percentile rank Quantile Summary statistics References [ edit ] ^ a b Hyndman, Rob J.

; Fan, Yanan (November 1996).

"Sample Quantiles in Statistical Packages" .

American Statistician .

50 (4). American Statistical Association: 361– 365.

doi : 10.2307/2684934 .

JSTOR 2684934 .

^ Lane, David.

"Percentiles" . Retrieved 2007-09-15 .

^ a b Pottel, Hans.

"Statistical flaws in Excel" (PDF) . Archived from the original (PDF) on 2013-06-04 . Retrieved 2013-03-25 .

^ Schoonjans F, De Bacquer D, Schmid P (2011).

"Estimation of population percentiles" .

Epidemiology .

22 (5): 750– 751.

doi : 10.1097/EDE.0b013e318225c1de .

PMC 3171208 .

PMID 21811118 .

^ Johnson, Robert; Kuby, Patricia (2007), "Applied Example 2.15, The 85th Percentile Speed Limit: Going With 85% of the Flow", Elementary Statistics (10th ed.), Cengage Learning, p. 102, ISBN 9781111802493 .

^ "Rational Speed Limits and the 85th Percentile Speed" (PDF) .

lsp.org . Louisiana State Police. Archived from the original (PDF) on 23 September 2018 . Retrieved 28 October 2018 .

^ Wessa, P (2021).

"Percentiles in Free Statistics Software" . Office for Research Development and Education . Retrieved 13 November 2021 .

^ a b c "Engineering Statistics Handbook: Percentile" .

NIST . Retrieved 2009-02-18 .

^ "Matlab Statistics Toolbox – Percentiles" . Retrieved 2006-09-15 .

, This is equivalent to Method 5 discussed here ^ Langford, E. (2006).

"Quartiles in Elementary Statistics" .

Journal of Statistics Education .

14 (3).

doi : 10.1080/10691898.2006.11910589 .

^ "NumPy 1.12 documentation" .

SciPy . Retrieved 2017-03-19 .

v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject Retrieved from " https://en.wikipedia.org/w/index.php?title=Percentile&oldid=1303353246 " Categories : Summary statistics Percentages Hidden categories: Articles with short description Short description is different from Wikidata Articles that may contain original research from February 2023 This page was last edited on 30 July 2025, at 13:58 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Percentile 25 languages Add topic

