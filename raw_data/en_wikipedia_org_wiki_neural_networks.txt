Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 In biology 2 In machine learning 3 History 4 See also 5 References Toggle the table of contents Neural network 22 languages Afrikaans العربية Català فارسی Galego 한국어 Հայերեն Bahasa Indonesia IsiZulu Ligure മലയാളം Nederlands Português Slovenščina Српски / srpski தமிழ் ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Neural networks ) Structure in biology and artificial intelligence For other uses, see Neural network (disambiguation) .

A neural network is a group of interconnected units called neurons that send signals to one another. Neurons can be either biological cells or signal pathways . While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural networks.

In neuroscience , a biological neural network is a physical structure found in brains and complex nervous systems – a population of nerve cells connected by synapses .

In machine learning , an artificial neural network is a mathematical model used to approximate nonlinear functions . Artificial neural networks are used to solve artificial intelligence problems.

In biology [ edit ] Animated confocal micrograph of part of a biological neural network in a mouse's striatum Main article: Neural network (biology) In the context of biology, a neural network is a population of biological neurons chemically connected to each other by synapses . A given neuron can be connected to hundreds of thousands of synapses.

[ 1 ] Each neuron sends and receives electrochemical signals called action potentials to its connected neighbors. A neuron can serve an excitatory role, amplifying and propagating signals it receives, or an inhibitory role, suppressing signals instead.

[ 1 ] Populations of interconnected neurons that are smaller than neural networks are called neural circuits . Very large interconnected networks are called large scale brain networks , and many of these together form brains and nervous systems .

Signals generated by neural networks in the brain eventually travel through the nervous system and across neuromuscular junctions to muscle cells , where they cause contraction and thereby motion.

[ 2 ] In machine learning [ edit ] Main article: Neural network (machine learning) Schematic of a simple feedforward artificial neural network In machine learning, a neural network is an artificial mathematical model used to approximate nonlinear functions. While early artificial neural networks were physical machines, [ 3 ] today they are almost always implemented in software .

Neurons in an artificial neural network are usually arranged into layers, with information passing from the first layer (the input layer) through one or more intermediate layers ( the hidden layers ) to the final layer (the output layer).

[ 4 ] The "signal" input to each neuron is a number, specifically a linear combination of the outputs of the connected neurons in the previous layer. The signal each neuron outputs is calculated from this number, according to its activation function . The behavior of the network depends on the strengths (or weights ) of the connections between neurons. A network is trained by modifying these weights through empirical risk minimization or backpropagation in order to fit some preexisting dataset.

[ 5 ] The term deep neural network refers to neural networks that have more than three layers, typically including at least two hidden layers in addition to the input and output layers.

Neural networks are used to solve problems in artificial intelligence , and have thereby found applications in many disciplines, including predictive modeling , adaptive control , facial recognition , handwriting recognition , general game playing , and generative AI .

History [ edit ] See also: Biological neural network § History , and History of artificial neural networks The theoretical base for contemporary neural networks was independently proposed by Alexander Bain in 1873 [ 6 ] and William James in 1890.

[ 7 ] Both posited that human thought emerged from interactions among large numbers of neurons inside the brain. In 1949, Donald Hebb described Hebbian learning , the idea that neural networks can change and learn over time by strengthening a synapse every time a signal travels along it.

[ 8 ] Artificial neural networks were originally used to model biological neural networks starting in the 1930s under the approach of connectionism . However, starting with the invention of the perceptron , a simple artificial neural network, by Warren McCulloch and Walter Pitts in 1943, [ 9 ] followed by the implementation of one in hardware by Frank Rosenblatt in 1957, [ 3 ] artificial neural networks became increasingly used for machine learning applications instead, and increasingly different from their biological counterparts.

See also [ edit ] Emergence Biological cybernetics Biologically-inspired computing References [ edit ] ^ a b Shao, Feng; Shen, Zheng (January 9, 2022).

"How can artificial neural networks approximate the brain?" .

Front. Psychol .

13 : 970214.

doi : 10.3389/fpsyg.2022.970214 .

PMC 9868316 .

PMID 36698593 .

^ Levitan, Irwin; Kaczmarek, Leonard (August 19, 2015). "Intercellular communication".

The Neuron: Cell and Molecular Biology (4th ed.). New York, NY: Oxford University Press. pp.

153– 328.

ISBN 978-0199773893 .

^ a b Rosenblatt, F. (1958). "The Perceptron: A Probabilistic Model For Information Storage And Organization In The Brain".

Psychological Review .

65 (6): 386– 408.

CiteSeerX 10.1.1.588.3775 .

doi : 10.1037/h0042519 .

PMID 13602029 .

S2CID 12781225 .

^ Bishop, Christopher M. (August 17, 2006).

Pattern Recognition and Machine Learning . New York: Springer.

ISBN 978-0-387-31073-2 .

^ Vapnik, Vladimir N.; Vapnik, Vladimir Naumovich (1998).

The nature of statistical learning theory (Corrected 2nd print. ed.). New York Berlin Heidelberg: Springer.

ISBN 978-0-387-94559-0 .

^ Bain (1873).

Mind and Body: The Theories of Their Relation . New York: D. Appleton and Company.

^ James (1890).

The Principles of Psychology . New York: H. Holt and Company.

^ Hebb, D.O. (1949).

The Organization of Behavior . New York: Wiley & Sons.

^ McCulloch, W; Pitts, W (1943).

"A Logical Calculus of Ideas Immanent in Nervous Activity" (PDF) .

Bulletin of Mathematical Biophysics .

5 (4): 115– 133.

doi : 10.1007/BF02478259 .

Archived from the original on May 17, 2024 . Retrieved February 17, 2024 .

NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐99pws
Cached time: 20250812032032
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.238 seconds
Real time usage: 0.309 seconds
Preprocessor visited node count: 941/1000000
Revision size: 8029/2097152 bytes
Post‐expand include size: 20531/2097152 bytes
Template argument size: 1061/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 34977/5000000 bytes
Lua time usage: 0.149/10.000 seconds
Lua memory usage: 5782616/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  276.500      1 -total
 53.15%  146.950      1 Template:Reflist
 34.56%   95.557      3 Template:Cite_journal
 23.08%   63.803      1 Template:Short_description
 12.58%   34.772      6 Template:Cite_book
 11.80%   32.624      2 Template:Pagetype
  9.06%   25.062      1 Template:Other_uses
  7.88%   21.783      4 Template:Main_other
  7.17%   19.814      1 Template:SDcat
  5.91%   16.329      1 Template:Use_mdy_dates Saved in parser cache with key enwiki:pcache:76121942:|#|:idhash:canonical and timestamp 20250812032032 and revision id 1294792434. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Neural_network&oldid=1294792434 " Category : Neural networks Hidden categories: Articles with short description Short description matches Wikidata Use mdy dates from April 2025 Use American English from April 2025 All Wikipedia articles written in American English Broad-concept articles This page was last edited on 9 June 2025, at 20:41 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Neural network 22 languages Add topic

