Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Examples Toggle Examples subsection 1.1 Voluntary standards 2 Mixed strategy Nash equilibrium 3 Coordination and equilibrium selection 4 Experimental results 5 Other games with externalities 6 See also 7 References Toggle the table of contents Coordination game 7 languages Čeština Deutsch Español فارسی Français Polski 粵語 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Simultaneous game found in game theory A coordination game is a type of simultaneous game found in game theory .  It describes the situation where a player will earn a higher payoff when they select the same course of action as another player. The game is not one of pure conflict, which results in multiple pure strategy Nash equilibria in which players choose matching strategies. Figure 1 shows a 2-player example.

Player 2 Left Right Player 1 Up 2,4 1,3 Down 1,3 2,4 Figure 1: Payoffs for a Coordination Game (Player 1, Player 2) Both (Up, Left) and (Down, Right) are Nash equilibria. If the players expect (Up, Left) to be played, then player 1 thinks their payoff would fall from 2 to 1 if they deviated to Down, and player 2 thinks their payoff would fall from 4 to 3 if they chose Right. If the players expect (Down, Right), player 1 thinks their payoff would fall from 2 to 1 if they deviated to Up, and player 2 thinks their payoff would fall from 4 to 3 if they chose Left. A player's optimal move depends on what they expect the other player to do, and they both do better if they coordinate than if they played an off-equilibrium combination of actions. This setup can be extended to more than two strategies or two players.

Examples [ edit ] A typical case for a coordination game is choosing the sides of the road upon which to drive, a social standard which can save lives if it is widely adhered to. In a simplified example, assume that two drivers meet on a narrow dirt road. Both have to swerve in order to avoid a head-on collision. If both execute the same swerving maneuver they will manage to pass each other, but if they choose differing maneuvers they will collide. In the payoff matrix in Fig. 2, successful passing is represented by a payoff of 8, and a collision by a payoff of 0. In this case there are two pure Nash equilibria: either both swerve to the left, or both swerve to the right. In this example, it doesn't matter which side both players pick, as long as they both pick the same. Both solutions are Pareto efficient . This game is called a pure coordination game . This is not true for all coordination games, as the assurance game in Fig. 3 shows.

An assurance game describes the situation where neither player can offer a sufficient amount if they contribute alone, thus player 1 should defect from playing if player 2 defects. However, if Player 2 opts to contribute then player 1 should contribute also.

[ 1 ] An assurance game is commonly referred to as a “ stag hunt ” (Fig.5), which represents the following scenario. Two hunters can choose to either hunt a stag together (which provides the most economically efficient outcome) or they can individually hunt a Rabbit. Hunting Stags is challenging and requires cooperation. If the two hunters do not cooperate the chances of success is minimal. Thus, the scenario where both hunters choose to coordinate will provide the most beneficial output for society. A common problem associated with the stag hunt is the amount of trust required to achieve this output.

[ 2 ] Fig. 5 shows a situation in which both players (hunters) can benefit if they cooperate (hunting a stag). As you can see, cooperation might fail, because each hunter has an alternative which is safer because it does not require cooperation to succeed (hunting a hare). This example of the potential conflict between safety and social cooperation is originally due to Jean-Jacques Rousseau .

[ 3 ] Fig. 2 Pure Coordination Fig.3 Assurance Game Fig. 4 Battle of the Sexes Fig. 5 Stag Hunt This is different in another type of coordination game commonly called battle of the sexes (or conflicting interest coordination), as seen in Fig. 4. In this game both players prefer engaging in the same activity over going alone, but their preferences differ over which activity they should engage in. Assume that a couple argues over what to do on the weekend. Both know that they will increase their utility by spending the weekend together, however the man prefers to watch a football game and the woman prefers to go shopping.

[ 4 ] Since the couple want to spend time together, they will derive no utility by doing an activity separately. If they go shopping, or to football game one person will derive some utility by being with the other person, but won’t derive utility from the activity itself. Unlike the other forms of coordination games described previously, knowing your opponent’s strategy won’t help you decide on your course of action. Due to this there is a possibility that an equilibrium will not be reached.

[ 5 ] Voluntary standards [ edit ] In social sciences , a voluntary standard (when characterized also as de facto standard ) is a typical solution to a coordination problem.

[ 6 ] The choice of a voluntary standard tends to be stable in situations in which all parties can realize mutual gains, but only by making mutually consistent decisions.

In contrast, an obligation standard (enforced by law as " de jure standard") is a solution to the prisoner's problem .

[ 6 ] Mixed strategy Nash equilibrium [ edit ] Coordination games also have mixed strategy Nash equilibria . In the generic coordination game above, a mixed Nash equilibrium is given by probabilities p = (d-b)/(a+d-b-c) to play Up and 1-p to play Down for player 1, and q = (D-C)/(A+D-B-C) to play Left and 1-q to play Right for player 2. Since d > b and d-b < a+d-b-c, p is always between zero and one, so existence is assured (similarly for q).

Fig 6.

Coordination Game In the generic coordination game in Fig. 6, a mixed Nash equilibrium is given by the probabilities: p = (d-b)/(a+d-b-c), to play Option A and 1-p to play Option B for player 1, and q = (D-C)/(A+D-B-C), to play A and 1-q to play B for player 2. If we look at Fig 1. and apply the same probability equations we obtain the following results: p = (4-3) / (4+4-3-3) = ½   and, q = (2-1) / (2+2-1-1) = ½ The reaction correspondences for 2×2 coordination games are shown in Fig. 7.

Figure 7 - Reaction correspondence for 2x2 coordination games. Nash equilibria are at points where the two players' correspondences cross.

The pure Nash equilibria are the points in the bottom left and top right corners of the strategy space, while the mixed Nash equilibrium lies in the middle, at the intersection of the dashed lines.

Unlike the pure Nash equilibria, the mixed equilibrium is not an evolutionarily stable strategy (ESS). The mixed Nash equilibrium is also Pareto dominated by the two pure Nash equilibria (since the players will fail to coordinate with non-zero probability), a quandary that led Robert Aumann to propose the refinement of a correlated equilibrium .

Coordination and equilibrium selection [ edit ] Games like the driving example above have illustrated the need for solution to coordination problems.  Often we are confronted with circumstances where we must solve coordination problems without the ability to communicate with our partner.  Many authors have suggested that particular equilibria are focal for one reason or another.  For instance, some equilibria may give higher payoffs , be naturally more salient , may be more fair , or may be safer .  Sometimes these refinements conflict, which makes certain coordination games especially complicated and interesting (e.g. the Stag hunt , in which {Stag,Stag} has higher payoffs, but {Hare,Hare} is safer).

Experimental results [ edit ] Coordination games have been studied in laboratory experiments. One such experiment by Bortolotti, Devetag, and Andreas Ortmann was a weak-link experiment in which groups of individuals were asked to count and sort coins in an effort to measure the difference between individual and group incentives. Players in this experiment received a payoff based on their individual performance as well as a bonus that was weighted by the number of errors accumulated by their worst performing team member. Players also had the option to purchase more time, the cost of doing so was subtracted from their payoff. While groups initially failed to coordinate, researchers observed about 80% of the groups in the experiment coordinated successfully when the game was repeated.

[ 7 ] When academics talk about coordination failure, most cases are that subjects achieve risk dominance rather than payoff dominance. Even when payoffs are better when players coordinate on one equilibrium, many times people will choose the less risky option where they are guaranteed some payoff and end up at an equilibrium that has sub-optimal payoff. Players are more likely to fail to coordinate on a riskier option when the difference between taking the risk or the safe option is smaller. The laboratory results suggest that coordination failure is a common phenomenon in the setting of order-statistic games and stag-hunt games.

[ 8 ] Other games with externalities [ edit ] Coordination games are closely linked to the economic concept of externalities , and in particular positive network externalities , the benefit reaped from being in the same network as other agents. Conversely, game theorists have modeled behavior under negative externalities where choosing the same action creates a cost rather than a benefit. The generic term for this class of game is anti-coordination game . The best-known example of a 2-player anti-coordination game is the game of Chicken (also known as Hawk-Dove game ). Using the payoff matrix in Figure 1, a game is an anti-coordination game if B > A and C > D for row-player 1 (with lowercase analogues b > d and c > a for column-player 2). {Down, Left} and {Up, Right} are the two pure Nash equilibria. Chicken also requires that A > C, so a change from {Up, Left} to {Up, Right} improves player 2's payoff but reduces player 1's payoff, introducing conflict. This counters the standard coordination game setup, where all unilateral changes in a strategy lead to either mutual gain or mutual loss.

The concept of anti-coordination games has been extended to multi-player situation. A crowding game is defined as a game where each player's payoff is non-increasing over the number of other players choosing the same strategy (i.e., a game with negative network externalities). For instance, a driver could take U.S. Route 101 or Interstate 280 from San Francisco to San Jose . While 101 is shorter, 280 is considered more scenic, so drivers might have different preferences between the two independent of the traffic flow. But each additional car on either route will slightly increase the drive time on that route, so additional traffic creates negative network externalities, and even scenery-minded drivers might opt to take 101 if 280 becomes too crowded. A congestion game is a crowding game in networks. The minority game is a game where the only objective for all players is to be part of smaller of two groups. A well-known example of the minority game is the El Farol Bar problem proposed by W. Brian Arthur .

A hybrid form of coordination and anti-coordination is the discoordination game , where one player's incentive is to coordinate while the other player tries to avoid this. Discoordination games have no pure Nash equilibria. In Figure 1, choosing payoffs so that A > B, C < D, while a < b, c > d, creates a discoordination game. In each of the four possible states either player 1 or player 2 are better off by switching their strategy, so the only Nash equilibrium is mixed. The canonical example of a discoordination game is the matching pennies game.

See also [ edit ] Collective action Consensus decision-making Cooperative game Coordination failure (economics) Equilibrium selection Guess 2/3 of the average Non-cooperative game Self-fulfilling prophecy Strategic complements Social dilemma Supermodular Uniqueness or multiplicity of equilibrium References [ edit ] ^ "Assurance Game - P2P Foundation" .

wiki.p2pfoundation.net . Retrieved 2021-04-23 .

^ "Assurance game - Game Theory .net" .

www.gametheory.net . Retrieved 2021-04-23 .

^ "Definition of Coordination Game | Higher Rock Education" .

www.higherrockeducation.org . Retrieved 2021-04-23 .

^ "Game theory II: Battle of the sexes | Policonomics" . Retrieved 2021-04-26 .

^ "Game theory II: Battle of the sexes | Policonomics" . Retrieved 2021-04-23 .

^ a b Edna Ullmann-Margalit (1977).

The Emergence of Norms . Oxford University Press.

ISBN 978-0-19-824411-0 .

^ Bortolotti, Stefania; Devetag, Giovanna; Ortmann, Andreas (2016-01-01).

"Group incentives or individual incentives? A real-effort weak-link experiment" .

Journal of Economic Psychology .

56 (C): 60– 73.

doi : 10.1016/j.joep.2016.05.004 .

ISSN 0167-4870 .

^ Devetag, Giovanna; Ortmann, Andreas (2006-08-15). "When and Why? A Critical Survey on Coordination Failure in the Laboratory". Rochester, NY: Social Science Research Network.

SSRN 924186 .

{{ cite journal }} : Cite journal requires |journal= ( help ) Other suggested literature: Russell Cooper : Coordination Games , Cambridge: Cambridge University Press, 1998 ( ISBN 0-521-57896-5 ).

Avinash Dixit & Barry Nalebuff : Thinking Strategically: The Competitive Edge in Business, Politics, and Everyday Life , New York: Norton, 1991 ( ISBN 0-393-32946-1 ).

Robert Gibbons: Game Theory for Applied Economists , Princeton, New Jersey: Princeton University Press, 1992 ( ISBN 0-691-00395-5 ).

David Kellogg Lewis : Convention: A Philosophical Study ,  Oxford:  Blackwell, 1969 ( ISBN 0-631-23257-5 ).

Martin J. Osborne & Ariel Rubinstein : A Course in Game Theory , Cambridge, Massachusetts: MIT Press, 1994 ( ISBN 0-262-65040-1 ).

Thomas Schelling : The Strategy of Conflict , Cambridge, Massachusetts: Harvard University Press, 1960 ( ISBN 0-674-84031-3 ).

Thomas Schelling : Micromotives and Macrobehavior , New York: Norton, 1978 ( ISBN 0-393-32946-1 ).

Adrian Piper: review of 'The Emergence of Norms' (subscription required) in The Philosophical Review, vol. 97, 1988, pp. 99–107.

Bortolotti, Stefania; Devetag, Giovanna; Ortmann, Andreas (2016-01-01).

"Group incentives or individual incentives? A real-effort weak-link experiment" .

Journal of Economic Psychology .

56 (C): 60–73.

ISSN 0167-4870 Devetag, Giovanna; Ortmann, Andreas (2006-08-15). "When and Why? A Critical Survey on Coordination Failure in the Laboratory". Rochester, NY: Social Science Research Network.

v t e Game theory Glossary Game theorists Games Traditional game theory Definitions Asynchrony Bayesian regret Best response Bounded rationality Cheap talk Coalition Complete contract Complete information Complete mixing Confrontation analysis Conjectural variation Contingent cooperator Coopetition Cooperative game theory Dynamic inconsistency Escalation of commitment Farsightedness Game semantics Hierarchy of beliefs Imperfect information Incomplete information Information set Move by nature Mutual knowledge Non-cooperative game theory Non-credible threat Outcome Perfect information Perfect recall Ply Preference Rationality Sequential game Simultaneous action selection Spite Strategic complements Strategic dominance Strategic form Strategic interaction Strategic move Strategy Subgame Succinct game Topological game Tragedy of the commons Uncorrelated asymmetry Equilibrium concepts Backward induction Bayes correlated equilibrium Bayesian efficiency Bayesian game Bayesian Nash equilibrium Berge equilibrium Bertrand–Edgeworth model Coalition-proof Nash equilibrium Core Correlated equilibrium Cursed equilibrium Edgeworth price cycle Epsilon-equilibrium Gibbs equilibrium Incomplete contracts Inequity aversion Individual rationality Iterated elimination of dominated strategies Markov perfect equilibrium Mertens-stable equilibrium Nash equilibrium Open-loop model Pareto efficiency Payoff dominance Perfect Bayesian equilibrium Price of anarchy Program equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Rational agent Rationalizability Rationalizable strategy Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfect equilibrium Trembling hand equilibrium Strategies Appeasement Bid shading Cheap talk Collusion Commitment device De-escalation Deterrence Escalation Fictitious play Focal point Grim trigger Hobbesian trap Markov strategy Max-dominated strategy Mixed strategy Pure strategy Tit for tat Win–stay, lose–switch Games All-pay auction Battle of the sexes Nash bargaining game Bertrand competition Blotto game Centipede game Coordination game Cournot competition Deadlock Dictator game Trust game Diner's dilemma Dollar auction El Farol Bar problem Electronic mail game Gift-exchange game Guess 2/3 of the average Keynesian beauty contest Kuhn poker Lewis signaling game Matching pennies Obligationes Optional prisoner's dilemma Pirate game Prisoner's dilemma Public goods game Rendezvous problem Rock paper scissors Stackelberg competition Stag hunt Traveler's dilemma Ultimatum game Volunteer's dilemma War of attrition Theorems Arrow's impossibility theorem Aumann's agreement theorem Brouwer fixed-point theorem Competitive altruism Folk theorem Gibbard–Satterthwaite theorem Gibbs lemma Glicksberg's theorem Kakutani fixed-point theorem Kuhn's theorem One-shot deviation principle Prim–Read theory Rational ignorance Rational irrationality Sperner's lemma Zermelo's theorem Subfields Algorithmic game theory Behavioral game theory Behavioral strategy Compositional game theory Contract theory Drama theory Graphical game theory Heresthetic Mean-field game theory Negotiation theory Quantum game theory Social software Key people Albert W. Tucker Alvin E. Roth Amos Tversky Antoine Augustin Cournot Ariel Rubinstein David Gale David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Herbert Scarf Hervé Moulin Jean Tirole Jean-François Mertens Jennifer Tour Chayes Ken Binmore Kenneth Arrow Leonid Hurwicz Lloyd Shapley Martin Shubik Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Aumann Robert Axelrod Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Combinatorial game theory Core concepts Combinatorial explosion Determinacy Disjunctive sum First-player and second-player win Game complexity Game tree Impartial game Misère Partisan game Solved game Sprague–Grundy theorem Strategy-stealing argument Zugzwang Games Chess Chomp Clobber Cram Domineering Hackenbush Nim Notakto Subtract a square Sylver coinage Toads and Frogs Mathematical tools Mex Nimber On Numbers and Games Star Surreal number Winning Ways for Your Mathematical Plays Search algorithms Alpha–beta pruning Expectiminimax Minimax Monte Carlo tree search Negamax Paranoid algorithm Principal variation search Key people Claude Shannon John Conway John von Neumann Evolutionary game theory Core concepts Bishop–Cannings theorem Evolution and the Theory of Games Evolutionarily stable set Evolutionarily stable state Evolutionarily stable strategy Replicator equation Risk dominance Stochastically stable equilibrium Weak evolutionarily stable strategy Games Chicken Stag hunt Applications Cultural group selection Fisher's principle Mobbing Terminal investment hypothesis Key people John Maynard Smith Robert Axelrod Mechanism design Core concepts Algorithmic mechanism design Bayesian-optimal mechanism Incentive compatibility Market design Monotonicity Participation constraint Revelation principle Strategyproofness Vickrey–Clarke–Groves mechanism Theorems Myerson–Satterthwaite theorem Revenue equivalence Applications Digital goods auction Knapsack auction Truthful cake-cutting Other topics Bertrand paradox Chainstore paradox Computational complexity of games Helly metric Multi-agent system PPAD-complete Mathematics portal Commons WikiProject Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Coordination_game&oldid=1301932997 " Category : Non-cooperative games Hidden categories: CS1 errors: missing periodical Articles with short description Short description matches Wikidata Pages containing links to subscription-only content This page was last edited on 22 July 2025, at 13:01 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Coordination game 7 languages Add topic

