Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Probability space definition 2 Role in statistical teaching and theory 3 Fair results from a biased coin 4 A better algorithm when P (H) is known Toggle A better algorithm when P (H) is known subsection 4.1 Analysis 5 See also 6 References 7 Further reading Toggle the table of contents Fair coin 4 languages Bahasa Indonesia 日本語 Português 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Statistical concept A fair coin, when tossed, should have an equal chance of landing either side up In probability theory and statistics , a sequence of independent Bernoulli trials with probability 1/2 of success on each trial is metaphorically called a fair coin .  One for which the probability is not 1/2 is called a biased or unfair coin . In theoretical studies, the assumption that a coin is fair is often made by referring to an ideal coin .

John Edmund Kerrich performed experiments in coin flipping and found that a coin made from a wooden disk about the size of a crown and coated on one side with lead landed heads (wooden side up) 679 times out of 1000.

[ 1 ] In this experiment the coin was tossed by balancing it on the forefinger, flipping it using the thumb so that it spun through the air for about a foot before landing on a flat cloth spread over a table.

Edwin Thompson Jaynes claimed that when a coin is caught in the hand, instead of being allowed to bounce, the physical bias in the coin is insignificant compared to the method of the toss, where with sufficient practice a coin can be made to land heads 100% of the time.

[ 2 ] Exploring the problem of checking whether a coin is fair is a well-established pedagogical tool in teaching statistics .

Probability space definition [ edit ] In probability theory , a fair coin is defined as a probability space ( Ω Ω , F , P ) {\displaystyle (\Omega ,{\mathcal {F}},P)} , which is in turn defined by the sample space , event space , and probability measure . Using H {\displaystyle H} for heads and T {\displaystyle T} for tails, the sample space of a coin is defined as: Ω Ω = { H , T } {\displaystyle \Omega =\{H,T\}} The event space for a coin includes all sets of outcomes from the sample space which can be assigned a probability, which is the full power set 2 Ω Ω {\displaystyle 2^{\Omega }} . Thus, the event space is defined as: F = { { } , { H } , { T } , { H , T } } {\displaystyle {\mathcal {F}}=\{\{\},\{H\},\{T\},\{H,T\}\}} { } {\displaystyle \{\}} is the event where neither outcome happens (which is impossible and can therefore be assigned 0 probability), and { H , T } {\displaystyle \{H,T\}} is the event where either outcome happens, (which is guaranteed and can be assigned 1 probability). Because the coin is fair, the possibility of any single outcome is 50-50. The probability measure is then defined by the function: x {\displaystyle x} { } {\displaystyle \{\}} { H } {\displaystyle \{H\}} { T } {\displaystyle \{T\}} { H , T } {\displaystyle \{H,T\}} P ( x ) {\displaystyle P(x)} 0 0.5 0.5 1 So the full probability space which defines a fair coin is the triplet ( Ω Ω , F , P ) {\displaystyle (\Omega ,{\mathcal {F}},P)} as defined above. Note that this is not a random variable because heads and tails do not have inherent numerical values like you might find on a fair two-valued die. A random variable adds the additional structure of assigning a numerical value to each outcome. Common choices are ( H , T ) → → ( 1 , 0 ) {\displaystyle (H,T)\to (1,0)} or ( H , T ) → → ( 1 , − − 1 ) {\displaystyle (H,T)\to (1,-1)} .

Role in statistical teaching and theory [ edit ] The probabilistic and statistical properties of coin-tossing games are often used as examples in both introductory and advanced text books and these are mainly based in assuming that a coin is fair or "ideal". For example, Feller uses this basis to introduce both the idea of random walks and to develop tests for homogeneity within a sequence of observations by looking at the properties of the runs of identical values within a sequence.

[ 3 ] The latter leads on to a runs test . A time-series consisting of the result from tossing a fair coin is called a Bernoulli process .

Fair results from a biased coin [ edit ] If a cheat has altered a coin to prefer one side over another (a biased coin), the coin can still be used for fair results by changing the game slightly.

John von Neumann gave the following procedure: [ 4 ] Toss the coin twice.

If the results match, start over, forgetting both results.

If the results differ, use the first result, forgetting the second.

The reason this process produces a fair result is that the probability of getting heads and then tails must be the same as the probability of getting tails and then heads, as the coin is not changing its bias between flips and the two flips are independent. This works only if getting one result on a trial does not change the bias on subsequent trials, which is the case for most non- malleable coins (but not for processes such as the Pólya urn ). By excluding the events of two heads and two tails by repeating the procedure, the coin flipper is left with the only two remaining outcomes having equivalent probability. This procedure only works if the tosses are paired properly; if part of a pair is reused in another pair, the fairness may be ruined. Also, the coin must not be so biased that one side has a probability of zero .

This method may be extended by also considering sequences of four tosses. That is, if the coin is flipped twice but the results match, and the coin is flipped twice again but the results match now for the opposite side, then the first result can be used. This is because HHTT and TTHH are equally likely. This can be extended to any multiple of 2.

The expected value of flips at the n game E ( F n ) {\displaystyle E(F_{n})} is not hard to calculate, first notice that in step 3 whatever the event H T {\displaystyle HT} or T H {\displaystyle TH} we have flipped the coin twice so E ( F n | H T , T H ) = 2 {\displaystyle E(F_{n}|HT,TH)=2} but in step 2 ( T T {\displaystyle TT} or H H {\displaystyle HH} ) we also have to redo things so we will have 2 flips plus the expected value of flips of the next game that is E ( F n | T T , H H ) = 2 + E ( F n + 1 ) {\displaystyle E(F_{n}|TT,HH)=2+E(F_{n+1})} but as we start over the expected value of the next game is the same as the value of the previous game or any other game so it does not really depend on n thus E ( F ) = E ( F n ) = E ( F n + 1 ) {\displaystyle E(F)=E(F_{n})=E(F_{n+1})} (this can be understood the process being a martingale E ( F n + 1 | F n , .

.

.

, F 1 ) = F n {\displaystyle E(F_{n+1}|F_{n},...,F_{1})=F_{n}} where taking the expectation again get us that E ( E ( F n + 1 | F n , .

.

.

, X 1 ) ) = E ( F n ) {\displaystyle E(E(F_{n+1}|F_{n},...,X_{1}))=E(F_{n})} but because of the law of total expectation we get that E ( F n + 1 ) = E ( E ( F n + 1 | F n , .

.

.

, F 1 ) ) = E ( F n ) {\displaystyle E(F_{n+1})=E(E(F_{n+1}|F_{n},...,F_{1}))=E(F_{n})} ) hence we have: Graph of 1 P ( H ) ( 1 − − P ( H ) ) {\displaystyle {\frac {1}{P(H)(1-P(H))}}} the further away P ( H ) {\displaystyle P(H)} is from 0.5 {\displaystyle 0.5} the further expected number of flips before a successful result E ( F ) = E ( F n ) = E ( F n | T T , H H ) P ( T T , H H ) + E ( F n | H T , T H ) P ( H T , T H ) = ( 2 + E ( F n + 1 ) ) P ( T T , H H ) + 2 P ( H T , T H ) = ( 2 + E ( F ) ) P ( T T , H H ) ) + 2 P ( H T , T H ) = ( 2 + E ( F ) ) ( P ( T T ) + P ( H H ) ) + 2 ( P ( H T ) + P ( T H ) ) = ( 2 + E ( F ) ) ( P ( T ) 2 + P ( H ) 2 ) + 4 P ( H ) P ( T ) = ( 2 + E ( F ) ) ( 1 − − 2 P ( H ) P ( T ) ) + 4 P ( H ) P ( T ) = 2 + E ( F ) − − 2 P ( H ) P ( T ) E ( F ) {\displaystyle {\begin{aligned}E(F)&=E(F_{n})\\&=E(F_{n}|TT,HH)P(TT,HH)+E(F_{n}|HT,TH)P(HT,TH)\\&=(2+E(F_{n+1}))P(TT,HH)+2P(HT,TH)\\&=(2+E(F))P(TT,HH))+2P(HT,TH)\\&=(2+E(F))(P(TT)+P(HH))+2(P(HT)+P(TH))\\&=(2+E(F))(P(T)^{2}+P(H)^{2})+4P(H)P(T)\\&=(2+E(F))(1-2P(H)P(T))+4P(H)P(T)\\&=2+E(F)-2P(H)P(T)E(F)\\\end{aligned}}} ∴ ∴ E ( F ) = 2 + E ( F ) − − 2 P ( H ) P ( T ) E ( F ) ⇒ ⇒ E ( F ) = 1 P ( H ) P ( T ) = 1 P ( H ) ( 1 − − P ( H ) ) {\displaystyle \therefore E(F)=2+E(F)-2P(H)P(T)E(F)\Rightarrow E(F)={\frac {1}{P(H)P(T)}}={\frac {1}{P(H)(1-P(H))}}} The more biased our coin is, the more likely it is that we will have to perform a greater number of trials before a fair result.

A better algorithm when P (H) is known [ edit ] Suppose that the bias b := P ( H ) {\displaystyle b:=P({\mathtt {H}})} is known. In this section, we provide a simple algorithm [ 5 ] that improves the expected number of coin tosses. The algorithm allows simulating a coin with any probability p {\displaystyle p} , and the value of p {\displaystyle p} changes internally across iterations. To get a fair coin, the algorithm first sets p = 0.5 {\displaystyle p=0.5} and then executes the following steps.

Toss the biased coin. Let X ∈ ∈ { H , T } {\displaystyle X\in \{{\mathtt {H}},{\mathtt {T}}\}} be the result.

If p ≥ ≥ b {\displaystyle p\geq b} , use H {\displaystyle {\mathtt {H}}} if the flip result is X = H {\displaystyle X={\mathtt {H}}} . Otherwise, set p {\displaystyle p} to p − − b 1 − − b {\displaystyle {\frac {p-b}{1-b}}} and go back to step 1.

Otherwise, p < b {\displaystyle p<b} , use T {\displaystyle {\mathtt {T}}} if the flip result is X = T {\displaystyle X={\mathtt {T}}} . Otherwise, set p {\displaystyle p} to p b {\displaystyle {\frac {p}{b}}} and go back to step 1.

Note that the above algorithm does not reach the optimal expected number of coin tosses, which is 1 / H ( b ) {\displaystyle 1/H(b)} (here H ( b ) {\displaystyle H(b)} is the binary entropy function ).
There are algorithms that reach this optimal value in expectation. However, those algorithms are more sophisticated than the one above.

The above algorithm has an expected number of biased coinflips being 1 2 b ( 1 − − b ) {\displaystyle {\frac {1}{2b(1-b)}}} , which is exactly half of the expected flips for von Neumann's approach.

Analysis [ edit ] The correctness of the above algorithm is a perfect exercise of conditional expectation.
We now analyze the expected number of coinflips.

Given the bias b = P ( H ) {\displaystyle b=P(H)} and the current value of p {\displaystyle p} , one can define a function f b ( p ) {\displaystyle f_{b}(p)} that represents the expected number of coin tosses before a result is returned. The recurrence relation of f b ( p ) {\displaystyle f_{b}(p)} can be described as follows.

f b ( p ) = { 1 + b ⋅ ⋅ f b ( p b ) if p < b 1 + ( 1 − − b ) ⋅ ⋅ f b ( p − − b 1 − − b ) if p ≥ ≥ b {\displaystyle f_{b}(p)={\begin{cases}1+b\cdot f_{b}\left({\frac {p}{b}}\right)&{\text{if }}p<b\\1+(1-b)\cdot f_{b}\left({\frac {p-b}{1-b}}\right)&{\text{if }}p\geq b\end{cases}}} This solves to the following function: f b ( p ) = b + ( 1 − − 2 b ) p b ( 1 − − b ) {\displaystyle f_{b}(p)={\frac {b+(1-2b)p}{b(1-b)}}} When p = 0.5 {\displaystyle p=0.5} , the expected number of coinflips is f b ( 0.5 ) = 1 2 b ( 1 − − b ) {\displaystyle f_{b}(0.5)={\frac {1}{2b(1-b)}}} as desired.

See also [ edit ] Checking whether a coin is fair Coin flipping Feller's coin-tossing constants References [ edit ] ^ Kerrich, John Edmund (1946).

An experimental introduction to the theory of probability . E. Munksgaard.

^ Jaynes, E.T. (2003).

Probability Theory: The Logic of Science . Cambridge, UK: Cambridge University Press. p. 318.

ISBN 9780521592710 . Archived from the original on 2002-02-05.

anyone familiar with the law of conservation of angular momentum can, after some practice, cheat at the usual coin-toss game and call his shots with 100 per cent accuracy. You can obtain any frequency of heads you want; and the bias of the coin has no influence at all on the results!

{{ cite book }} :  CS1 maint: bot: original URL status unknown ( link ) ^ Feller, W (1968).

An Introduction to Probability Theory and Its Applications . Wiley.

ISBN 978-0-471-25708-0 .

^ von Neumann, John (1951). "Various techniques used in connection with random digits".

National Bureau of Standards Applied Math Series .

12 : 36.

^ Henry Tsai, 2024 April 12.

Further reading [ edit ] Gelman, Andrew; Deborah Nolan (2002). "Teacher's Corner: You Can Load a Die, But You Can't Bias a Coin".

American Statistician .

56 (4): 308– 311.

doi : 10.1198/000313002605 .

Available from Andrew Gelman 's website "Lifelong debunker takes on arbiter of neutral choices: Magician-turned-mathematician uncovers bias in a flip of a coin" .

Stanford Report . 2004-06-07. Archived from the original on 2009-08-27 . Retrieved 2008-03-05 .

John von Neumann, "Various techniques used in connection with random digits," in A.S. Householder, G.E. Forsythe, and H.H. Germond, eds., Monte Carlo Method , National Bureau of Standards Applied Mathematics Series, 12 (Washington, D.C.: U.S. Government Printing Office, 1951): 36-38.

Retrieved from " https://en.wikipedia.org/w/index.php?title=Fair_coin&oldid=1301912974 " Categories : Experiment (probability theory) Gambling mathematics Coin flipping Hidden categories: CS1 maint: bot: original URL status unknown Articles with short description Short description matches Wikidata This page was last edited on 22 July 2025, at 10:02 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Fair coin 4 languages Add topic

