Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 The first and second laws of thermodynamics 2 Relationship to statistical mechanics Toggle Relationship to statistical mechanics subsection 2.1 Derivation from statistical mechanical principles 2.2 Derivation of statistical mechanical principles from the fundamental thermodynamic relation 3 References 4 External links Toggle the table of contents Fundamental thermodynamic relation 12 languages العربية Català Čeština Deutsch Español Hrvatski Nederlands Română Српски / srpski Srpskohrvatski / српскохрватски 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Equations on thermodynamic quantities Thermodynamics The classical Carnot heat engine Branches Classical Statistical Chemical Quantum thermodynamics Equilibrium / Non-equilibrium Laws Zeroth First Second Third Systems Closed system Open system Isolated system State Equation of state Ideal gas Real gas State of matter Phase (matter) Equilibrium Control volume Instruments Processes Isobaric Isochoric Isothermal Adiabatic Isentropic Isenthalpic Quasistatic Polytropic Free expansion Reversibility Irreversibility Endoreversibility Cycles Heat engines Heat pumps Thermal efficiency System properties Note: Conjugate variables in italics Property diagrams Intensive and extensive properties Process functions Work Heat Functions of state Temperature / Entropy ( introduction ) Pressure / Volume Chemical potential / Particle number Vapor quality Reduced properties Material properties Property databases Specific heat capacity c = {\displaystyle c=} T {\displaystyle T} ∂ ∂ S {\displaystyle \partial S} N {\displaystyle N} ∂ ∂ T {\displaystyle \partial T} Compressibility β β = − − {\displaystyle \beta =-} 1 {\displaystyle 1} ∂ ∂ V {\displaystyle \partial V} V {\displaystyle V} ∂ ∂ p {\displaystyle \partial p} Thermal expansion α α = {\displaystyle \alpha =} 1 {\displaystyle 1} ∂ ∂ V {\displaystyle \partial V} V {\displaystyle V} ∂ ∂ T {\displaystyle \partial T} Equations Carnot's theorem Clausius theorem Fundamental relation Ideal gas law Maxwell relations Onsager reciprocal relations Bridgman's equations Table of thermodynamic equations Potentials Free energy Free entropy Internal energy U ( S , V ) {\displaystyle U(S,V)} Enthalpy H ( S , p ) = U + p V {\displaystyle H(S,p)=U+pV} Helmholtz free energy A ( T , V ) = U − − T S {\displaystyle A(T,V)=U-TS} Gibbs free energy G ( T , p ) = H − − T S {\displaystyle G(T,p)=H-TS} History Culture History General Entropy Gas laws "Perpetual motion" machines Philosophy Entropy and time Entropy and life Brownian ratchet Maxwell's demon Heat death paradox Loschmidt's paradox Synergetics Theories Caloric theory Vis viva ("living force") Mechanical equivalent of heat Motive power Key publications An Inquiry Concerning the Source ... Friction On the Equilibrium of Heterogeneous Substances Reflections on the Motive Power of Fire Timelines Thermodynamics Heat engines Art Education Maxwell's thermodynamic surface Entropy as energy dispersal Scientists Bernoulli Boltzmann Bridgman Carathéodory Carnot Clapeyron Clausius de Donder Duhem Gibbs von Helmholtz Joule Kelvin Lewis Massieu Maxwell von Mayer Nernst Onsager Planck Rankine Smeaton Stahl Tait Thompson van der Waals Waterston Other Nucleation Self-assembly Self-organization Category v t e In thermodynamics , the fundamental thermodynamic relation are four fundamental equations which demonstrate how four important thermodynamic quantities depend on variables that can be controlled and measured experimentally. Thus, they are essentially equations of state, and using the fundamental equations, experimental data can be used to determine sought-after quantities like G ( Gibbs free energy ) or H ( enthalpy ).

[ 1 ] The relation is generally expressed as a microscopic change in internal energy in terms of microscopic changes in entropy , and volume for a closed system in thermal equilibrium in the following way.

d U = T d S − − P d V {\displaystyle \mathrm {d} U=T\,\mathrm {d} S-P\,\mathrm {d} V\,} Here, U is internal energy , T is absolute temperature , S is entropy , P is pressure , and V is volume .

This is only one expression of the fundamental thermodynamic relation. It may be expressed in other ways, using different variables (e.g. using thermodynamic potentials ). For example, the fundamental relation may be expressed in terms of the enthalpy H as d H = T d S + V d P {\displaystyle \mathrm {d} H=T\,\mathrm {d} S+V\,\mathrm {d} P\,} in terms of the Helmholtz free energy F as d F = − − S d T − − P d V {\displaystyle \mathrm {d} F=-S\,\mathrm {d} T-P\,\mathrm {d} V\,} and in terms of the Gibbs free energy G as d G = − − S d T + V d P .

{\displaystyle \mathrm {d} G=-S\,\mathrm {d} T+V\,\mathrm {d} P\,.} The first and second laws of thermodynamics [ edit ] The first law of thermodynamics states that: d U = δ δ Q − − δ δ W {\displaystyle \mathrm {d} U=\delta Q-\delta W\,} where δ δ Q {\displaystyle \delta Q} and δ δ W {\displaystyle \delta W} are infinitesimal amounts of heat supplied to the system by its surroundings and work done by the system on its surroundings, respectively.

According to the second law of thermodynamics we have for a reversible process: d S = δ δ Q T {\displaystyle \mathrm {d} S={\frac {\delta Q}{T}}\,} Hence: δ δ Q = T d S {\displaystyle \delta Q=T\,\mathrm {d} S\,} By substituting this into the first law, we have: d U = T d S − − δ δ W {\displaystyle \mathrm {d} U=T\,\mathrm {d} S-\delta W\,} Letting δ δ W {\displaystyle \delta W} be reversible pressure-volume work done by the system on its surroundings, δ δ W = P d V {\displaystyle \delta W\ =P\mathrm {d} V\,} we have: d U = T d S − − P d V {\displaystyle \mathrm {d} U=T\,\mathrm {d} S-P\,\mathrm {d} V\,} This equation has been derived in the case of reversible changes. However, since U , S , and V are thermodynamic state functions that depend on only the initial and final states of a thermodynamic process, the above relation holds also for non-reversible changes. If the composition, i.e. the amounts n i {\displaystyle n_{i}} of the chemical components, in a system of uniform temperature and pressure can also change, e.g. due to a chemical reaction, the fundamental thermodynamic relation generalizes to: d U = T d S − − P d V + ∑ ∑ i μ μ i d n i {\displaystyle \mathrm {d} U=T\,\mathrm {d} S-P\,\mathrm {d} V\ +\sum _{i}\mu _{i}\,\mathrm {d} n_{i}\,} The μ μ i {\displaystyle \mu _{i}} are the chemical potentials corresponding to particles of type i {\displaystyle i} .

If the system has more external parameters than just the volume that can change, the fundamental thermodynamic relation generalizes to d U = T d S + ∑ ∑ j X j d x j + ∑ ∑ i μ μ i d n i {\displaystyle \mathrm {d} U=T\,\mathrm {d} S+\sum _{j}X_{j}\,\mathrm {d} x_{j}+\sum _{i}\mu _{i}\,\mathrm {d} n_{i}\,} Here the X j {\displaystyle X_{j}} are the generalized forces corresponding to the external parameters x j {\displaystyle x_{j}} . (The negative sign used with pressure is unusual and arises because pressure represents a compressive stress that tends to decrease volume. Other generalized forces tend to increase their conjugate displacements.) Relationship to statistical mechanics [ edit ] The fundamental thermodynamic relation and statistical mechanical principles can be derived from one another.

Derivation from statistical mechanical principles [ edit ] The above derivation uses the first and second laws of thermodynamics. The first law of thermodynamics is essentially a definition of heat , i.e. heat is the change in the internal energy of a system that is not caused by a change of the external parameters of the system.

However, the second law of thermodynamics is not a defining relation for the entropy. The fundamental definition of entropy of an isolated system containing an amount of energy E {\displaystyle E} is: S = k B log ⁡ ⁡ [ Ω Ω ( E ) ] {\displaystyle S=k_{\text{B}}\log \left[\Omega \left(E\right)\right]\,} where Ω Ω ( E ) {\displaystyle \Omega \left(E\right)} is the number of microstates in a small interval between E {\displaystyle E} and E + δ δ E {\displaystyle E+\delta E} . Here δ δ E {\displaystyle \delta E} is a macroscopically small energy interval that is kept fixed. Strictly speaking this means that the entropy depends on the choice of δ δ E {\displaystyle \delta E} . However, in the thermodynamic limit (i.e. in the limit of infinitely large system size), the specific entropy (entropy per unit volume or per unit mass) does not depend on δ δ E {\displaystyle \delta E} . The entropy is thus a measure of the uncertainty about exactly which microstate the system is in, given that we know its energy to be in some interval of size δ δ E {\displaystyle \delta E} .

Deriving the fundamental thermodynamic relation from first principles thus amounts to proving that the above definition of entropy implies that for reversible processes we have: d S = δ δ Q T {\displaystyle dS={\frac {\delta Q}{T}}} The relevant assumption from statistical mechanics is that all the Ω Ω ( E ) {\displaystyle \Omega \left(E\right)} states at a particular energy are equally likely. This allows us to extract all the thermodynamical quantities of interest. The temperature is defined as: 1 k B T ≡ ≡ β β ≡ ≡ d log ⁡ ⁡ [ Ω Ω ( E ) ] d E {\displaystyle {\frac {1}{k_{\text{B}}T}}\equiv \beta \equiv {\frac {d\log \left[\Omega (E)\right]}{dE}}} This definition can be derived from the microcanonical ensemble , which is a system of a constant number of particles, a constant volume and that does not exchange energy with its environment. Suppose that the system has some external parameter, x, that can be changed. In general, the energy eigenstates of the system will depend on x . According to the adiabatic theorem of quantum mechanics, in the limit of an infinitely slow change of the system's Hamiltonian, the system will stay in the same energy eigenstate and thus change its energy according to the change in energy of the energy eigenstate it is in.

The generalized force, X , corresponding to the external parameter x is defined such that X d x {\displaystyle Xdx} is the work performed by the system if x is increased by an amount dx . E.g., if x is the volume, then X is the pressure. The generalized force for a system known to be in energy eigenstate E r {\displaystyle E_{r}} is given by: X = − − d E r d x {\displaystyle X=-{\frac {dE_{r}}{dx}}} Since the system can be in any energy eigenstate within an interval of δ δ E {\displaystyle \delta E} , we define the generalized force for the system as the expectation value of the above expression: X = − − ⟨ d E r d x ⟩ {\displaystyle X=-\left\langle {\frac {dE_{r}}{dx}}\right\rangle \,} To evaluate the average, we partition the Ω Ω ( E ) {\displaystyle \Omega (E)} energy eigenstates by counting how many of them have a value for d E r d x {\displaystyle {\frac {dE_{r}}{dx}}} within a range between Y {\displaystyle Y} and Y + δ δ Y {\displaystyle Y+\delta Y} . Calling this number Ω Ω Y ( E ) {\displaystyle \Omega _{Y}\left(E\right)} , we have: Ω Ω ( E ) = ∑ ∑ Y Ω Ω Y ( E ) {\displaystyle \Omega (E)=\sum _{Y}\Omega _{Y}(E)\,} The average defining the generalized force can now be written: X = − − 1 Ω Ω ( E ) ∑ ∑ Y Y Ω Ω Y ( E ) {\displaystyle X=-{\frac {1}{\Omega (E)}}\sum _{Y}Y\Omega _{Y}(E)\,} We can relate this to the derivative of the entropy with respect to x at constant energy E as follows. Suppose we change x to x + dx . Then Ω Ω ( E ) {\displaystyle \Omega \left(E\right)} will change because the energy eigenstates depend on x, causing energy eigenstates to move into or out of the range between E {\displaystyle E} and E + δ δ E {\displaystyle E+\delta E} . Let's focus again on the energy eigenstates for which d E r d x {\displaystyle {\frac {dE_{r}}{dx}}} lies within the range between Y {\displaystyle Y} and Y + δ δ Y {\displaystyle Y+\delta Y} . Since these energy eigenstates increase in energy by Y dx , all such energy eigenstates that are in the interval ranging from E − Y dx to E move from below E to above E . There are N Y ( E ) = Ω Ω Y ( E ) δ δ E Y d x {\displaystyle N_{Y}(E)={\frac {\Omega _{Y}(E)}{\delta E}}Y\,dx} such energy eigenstates. If Y d x ≤ ≤ δ δ E {\displaystyle Ydx\leq \delta E} , all these energy eigenstates will move into the range between E {\displaystyle E} and E + δ δ E {\displaystyle E+\delta E} and contribute to an increase in Ω Ω {\displaystyle \Omega } . The number of energy eigenstates that move from below E + δ δ E {\displaystyle E+\delta E} to above E + δ δ E {\displaystyle E+\delta E} is, of course, given by N Y ( E + δ δ E ) {\displaystyle N_{Y}\left(E+\delta E\right)} . The difference N Y ( E ) − − N Y ( E + δ δ E ) {\displaystyle N_{Y}(E)-N_{Y}(E+\delta E)\,} is thus the net contribution to the increase in Ω Ω {\displaystyle \Omega } . Note that if Y dx is larger than δ δ E {\displaystyle \delta E} there will be energy eigenstates that move from below E {\displaystyle E} to above E + δ δ E {\displaystyle E+\delta E} . They are counted in both N Y ( E ) {\displaystyle N_{Y}(E)} and N Y ( E + δ δ E ) {\displaystyle N_{Y}(E+\delta E)} , therefore the above expression is also valid in that case.

Expressing the above expression as a derivative with respect to E and summing over Y yields the expression: ( ∂ ∂ Ω Ω ∂ ∂ x ) E = − − ∑ ∑ Y Y ( ∂ ∂ Ω Ω Y ∂ ∂ E ) x = ( ∂ ∂ ( Ω Ω X ) ∂ ∂ E ) x {\displaystyle \left({\frac {\partial \Omega }{\partial x}}\right)_{E}=-\sum _{Y}Y\left({\frac {\partial \Omega _{Y}}{\partial E}}\right)_{x}=\left({\frac {\partial (\Omega X)}{\partial E}}\right)_{x}\,} The logarithmic derivative of Ω Ω {\displaystyle \Omega } with respect to x is thus given by: ( ∂ ∂ log ⁡ ⁡ ( Ω Ω ) ∂ ∂ x ) E = β β X + ( ∂ ∂ X ∂ ∂ E ) x {\displaystyle \left({\frac {\partial \log \left(\Omega \right)}{\partial x}}\right)_{E}=\beta X+\left({\frac {\partial X}{\partial E}}\right)_{x}\,} The first term is intensive, i.e. it does not scale with system size. In contrast, the last term scales as the inverse system size and thus vanishes in the thermodynamic limit. We have thus found that: ( ∂ ∂ S ∂ ∂ x ) E = X T {\displaystyle \left({\frac {\partial S}{\partial x}}\right)_{E}={\frac {X}{T}}\,} Combining this with ( ∂ ∂ S ∂ ∂ E ) x = 1 T {\displaystyle \left({\frac {\partial S}{\partial E}}\right)_{x}={\frac {1}{T}}\,} Gives: d S = ( ∂ ∂ S ∂ ∂ E ) x d E + ( ∂ ∂ S ∂ ∂ x ) E d x = d E T + X T d x {\displaystyle dS=\left({\frac {\partial S}{\partial E}}\right)_{x}\,dE+\left({\frac {\partial S}{\partial x}}\right)_{E}\,dx={\frac {dE}{T}}+{\frac {X}{T}}\,dx\,} which we can write as: d E = T d S − − X d x {\displaystyle dE=T\,dS-X\,dx} Derivation of statistical mechanical principles from the fundamental thermodynamic relation [ edit ] It has been shown that the fundamental thermodynamic relation together with the following three postulates [ 2 ] The probability density function is proportional to some function of the ensemble parameters and random variables.

Thermodynamic state functions are described by ensemble averages of random variables.

The entropy as defined by Gibbs entropy formula matches with the entropy as defined in classical thermodynamics .

is sufficient to build the theory of statistical mechanics without the equal a priori probability postulate.

For example, in order to derive the Boltzmann distribution , we assume the probability density of microstate i satisfies Pr ( i ) ∝ ∝ f ( E i , T ) {\textstyle \Pr(i)\propto f(E_{i},T)} . The normalization factor (partition function) is therefore Z = ∑ ∑ i f ( E i , T ) .

{\displaystyle Z=\sum _{i}f(E_{i},T).} The entropy is therefore given by S = k B ∑ ∑ i f ( E i , T ) Z log ⁡ ⁡ ( f ( E i , T ) Z ) .

{\displaystyle S=k_{B}\sum _{i}{\frac {f(E_{i},T)}{Z}}\log \left({\frac {f(E_{i},T)}{Z}}\right).} If we change the temperature T by dT while keeping the volume of the system constant, the change of entropy satisfies d S = ( ∂ ∂ S ∂ ∂ T ) V d T {\displaystyle dS=\left({\frac {\partial S}{\partial T}}\right)_{V}dT} where ( ∂ ∂ S ∂ ∂ T ) V = − − k B ∑ ∑ i Z ⋅ ⋅ ∂ ∂ f ( E i , T ) ∂ ∂ T ⋅ ⋅ log ⁡ ⁡ f ( E i , T ) − − ∂ ∂ Z ∂ ∂ T ⋅ ⋅ f ( E i , T ) ⋅ ⋅ log ⁡ ⁡ f ( E i , T ) Z 2 = − − k B ∑ ∑ i ∂ ∂ ∂ ∂ T ( f ( E i , T ) Z ) ⋅ ⋅ log ⁡ ⁡ f ( E i , T ) {\displaystyle {\begin{aligned}\left({\frac {\partial S}{\partial T}}\right)_{V}&=-k_{B}\sum _{i}{\frac {Z\cdot {\frac {\partial f(E_{i},T)}{\partial T}}\cdot \log f(E_{i},T)-{\frac {\partial Z}{\partial T}}\cdot f(E_{i},T)\cdot \log f(E_{i},T)}{Z^{2}}}\\&=-k_{B}\sum _{i}{\frac {\partial }{\partial T}}\left({\frac {f(E_{i},T)}{Z}}\right)\cdot \log f(E_{i},T)\\\end{aligned}}} Considering that ⟨ E ⟩ = ∑ ∑ i f ( E i , T ) Z ⋅ ⋅ E i {\displaystyle \left\langle E\right\rangle =\sum _{i}{\frac {f(E_{i},T)}{Z}}\cdot E_{i}} we have d ⟨ E ⟩ = ∑ ∑ i ∂ ∂ ∂ ∂ T ( f ( E i , T ) Z ) ⋅ ⋅ E i ⋅ ⋅ d T {\displaystyle d\left\langle E\right\rangle =\sum _{i}{\frac {\partial }{\partial T}}{\left({\frac {f(E_{i},T)}{Z}}\right)}\cdot E_{i}\cdot dT} From the fundamental thermodynamic relation, we have − − d S k B + d ⟨ E ⟩ k B T + P k B T d V = 0 {\displaystyle -{\frac {dS}{k_{\text{B}}}}+{\frac {d\left\langle E\right\rangle }{k_{\text{B}}T}}+{\frac {P}{k_{\text{B}}T}}dV=0} Since we kept V constant when perturbing T , we have d V = 0 {\textstyle dV=0} . Combining the equations above, we have ∑ ∑ i ∂ ∂ ∂ ∂ T ( f ( E i , T ) Z ) ⋅ ⋅ [ log ⁡ ⁡ f ( E i , T ) + E i k B T ] ⋅ ⋅ d T = 0 {\displaystyle \sum _{i}{\frac {\partial }{\partial T}}{\left({\frac {f(E_{i},T)}{Z}}\right)}\cdot \left[\log f(E_{i},T)+{\frac {E_{i}}{k_{\text{B}}T}}\right]\cdot dT=0} Physics laws should be universal, i.e., the above equation must hold for arbitrary systems, and the only way for this to happen is log ⁡ ⁡ f ( E i , T ) + E i k B T = 0 {\displaystyle \log f(E_{i},T)+{\frac {E_{i}}{k_{\text{B}}T}}=0} That is f ( E i , T ) = exp ⁡ ⁡ ( − − E i k B T ) .

{\displaystyle f(E_{i},T)=\exp \left(-{\frac {E_{i}}{k_{\text{B}}T}}\right).} It has been shown that the third postulate in the above formalism can be replaced by the following: [ 3 ] At infinite temperature, all the microstates have the same probability.

However, the mathematical derivation will be much more complicated.

References [ edit ] ^ "Differential Forms of Fundamental Equations" .

Chemistry LibreTexts . 2 October 2013.

^ Gao, Xiang; Gallicchio, Emilio; Roitberg, Adrian (2019).

"The generalized Boltzmann distribution is the only distribution in which the Gibbs-Shannon entropy equals the thermodynamic entropy" .

The Journal of Chemical Physics .

151 (3): 034113.

arXiv : 1903.02121 .

Bibcode : 2019JChPh.151c4113G .

doi : 10.1063/1.5111333 .

PMID 31325924 .

S2CID 118981017 .

^ Gao, Xiang (March 2022).

"The Mathematics of the Ensemble Theory" .

Results in Physics .

34 : 105230.

arXiv : 2006.00485 .

Bibcode : 2022ResPh..3405230G .

doi : 10.1016/j.rinp.2022.105230 .

S2CID 221978379 .

External links [ edit ] The Fundamental Thermodynamic Relation Retrieved from " https://en.wikipedia.org/w/index.php?title=Fundamental_thermodynamic_relation&oldid=1291381876 " Categories : Thermodynamics Statistical mechanics Thermodynamic equations Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 20 May 2025, at 21:27 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Fundamental thermodynamic relation 12 languages Add topic

