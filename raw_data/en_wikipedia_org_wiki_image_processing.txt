Title: Digital image processing

URL Source: https://en.wikipedia.org/wiki/Image_processing

Published Time: 2002-10-02T06:25:50Z

Markdown Content:
This article is about mathematical processing of digital images. For artistic processing of images, see [Image editing](https://en.wikipedia.org/wiki/Image_editing "Image editing"). For compression algorithms, see [Image compression](https://en.wikipedia.org/wiki/Image_compression "Image compression").

**Digital image processing** is the use of a [digital computer](https://en.wikipedia.org/wiki/Digital_computer "Digital computer") to process [digital images](https://en.wikipedia.org/wiki/Digital_image "Digital image") through an [algorithm](https://en.wikipedia.org/wiki/Algorithm "Algorithm").[[1]](https://en.wikipedia.org/wiki/Image_processing#cite_note-1)[[2]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Gonzalez_2018_p.-2) As a subcategory or field of [digital signal processing](https://en.wikipedia.org/wiki/Digital_signal_processing "Digital signal processing"), digital image processing has many advantages over [analog image processing](https://en.wikipedia.org/wiki/Analog_image_processing "Analog image processing"). It allows a much wider range of algorithms to be applied to the input data and can avoid problems such as the build-up of [noise](https://en.wikipedia.org/wiki/Noise_(signal_processing) "Noise (signal processing)") and [distortion](https://en.wikipedia.org/wiki/Distortion "Distortion") during processing. Since images are defined over two dimensions (perhaps more), digital image processing may be modeled in the form of [multidimensional systems](https://en.wikipedia.org/wiki/Multidimensional_system "Multidimensional system"). The generation and development of digital image processing are mainly affected by three factors: first, the development of computers;[[3]](https://en.wikipedia.org/wiki/Image_processing#cite_note-3) second, the development of mathematics (especially the creation and improvement of [discrete mathematics theory](https://en.wikipedia.org/wiki/Discrete_mathematics "Discrete mathematics"));[[4]](https://en.wikipedia.org/wiki/Image_processing#cite_note-4) and third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased.[[5]](https://en.wikipedia.org/wiki/Image_processing#cite_note-5)

Many of the techniques of [digital image](https://en.wikipedia.org/wiki/Digital_image "Digital image") processing, or digital picture processing as it often was called, were developed in the 1960s, at [Bell Laboratories](https://en.wikipedia.org/wiki/Bell_Laboratories "Bell Laboratories"), the [Jet Propulsion Laboratory](https://en.wikipedia.org/wiki/Jet_Propulsion_Laboratory "Jet Propulsion Laboratory"), [Massachusetts Institute of Technology](https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology "Massachusetts Institute of Technology"), [University of Maryland](https://en.wikipedia.org/wiki/University_of_Maryland "University of Maryland"), and a few other research facilities, with application to [satellite imagery](https://en.wikipedia.org/wiki/Satellite_imagery "Satellite imagery"), [wire-photo](https://en.wikipedia.org/wiki/Wirephoto "Wirephoto") standards conversion, [medical imaging](https://en.wikipedia.org/wiki/Medical_physics "Medical physics"), [videophone](https://en.wikipedia.org/wiki/Videophone "Videophone"), [character recognition](https://en.wikipedia.org/wiki/Character_recognition "Character recognition"), and photograph enhancement.[[6]](https://en.wikipedia.org/wiki/Image_processing#cite_note-6) The purpose of early image processing was to improve the quality of the image. It was aimed for human beings to improve the visual effect of people. In image processing, the input is a low-quality image, and the output is an image with improved quality. Common image processing include image enhancement, restoration, encoding, and compression. The first successful application was the American Jet Propulsion Laboratory (JPL). They used image processing techniques such as geometric correction, gradation transformation, noise removal, etc. on the thousands of lunar photos sent back by the Space Detector Ranger 7 in 1964, taking into account the position of the Sun and the environment of the Moon. The impact of the successful mapping of the Moon's surface map by the computer has been a success. Later, more complex image processing was performed on the nearly 100,000 photos sent back by the spacecraft, so that the topographic map, color map and panoramic mosaic of the Moon were obtained, which achieved extraordinary results and laid a solid foundation for human landing on the Moon.[[7]](https://en.wikipedia.org/wiki/Image_processing#cite_note-:1-7)

The cost of processing was fairly high, however, with the computing equipment of that era. That changed in the 1970s, when digital image processing proliferated as cheaper computers and dedicated hardware became available. This led to images being processed in real-time, for some dedicated problems such as [television standards conversion](https://en.wikipedia.org/wiki/Television_standards_conversion "Television standards conversion"). As [general-purpose computers](https://en.wikipedia.org/wiki/General-purpose_computer "General-purpose computer") became faster, they started to take over the role of dedicated hardware for all but the most specialized and computer-intensive operations. With the fast computers and signal processors available in the 2000s, digital image processing has become the most common form of image processing, and is generally used because it is not only the most versatile method, but also the cheapest.

The basis for modern [image sensors](https://en.wikipedia.org/wiki/Image_sensors "Image sensors") is [metal–oxide–semiconductor](https://en.wikipedia.org/wiki/Metal%E2%80%93oxide%E2%80%93semiconductor "Metal–oxide–semiconductor") (MOS) technology,[[8]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Williams-8) invented at Bell Labs between 1955 and 1960,[[9]](https://en.wikipedia.org/wiki/Image_processing#cite_note-9)[[10]](https://en.wikipedia.org/wiki/Image_processing#cite_note-10)[[11]](https://en.wikipedia.org/wiki/Image_processing#cite_note-11)[[12]](https://en.wikipedia.org/wiki/Image_processing#cite_note-12)[[13]](https://en.wikipedia.org/wiki/Image_processing#cite_note-13)[[14]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Lojek1202-14) This led to the development of digital [semiconductor](https://en.wikipedia.org/wiki/Semiconductor "Semiconductor") image sensors, including the [charge-coupled device](https://en.wikipedia.org/wiki/Charge-coupled_device "Charge-coupled device") (CCD) and later the [CMOS sensor](https://en.wikipedia.org/wiki/CMOS_sensor "CMOS sensor").[[8]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Williams-8)

The charge-coupled device was invented by [Willard S. Boyle](https://en.wikipedia.org/wiki/Willard_S._Boyle "Willard S. Boyle") and [George E. Smith](https://en.wikipedia.org/wiki/George_E._Smith "George E. Smith") at Bell Labs in 1969.[[15]](https://en.wikipedia.org/wiki/Image_processing#cite_note-15) While researching MOS technology, they realized that an electric charge was the analogy of the magnetic bubble and that it could be stored on a tiny [MOS capacitor](https://en.wikipedia.org/wiki/MOS_capacitor "MOS capacitor"). As it was fairly straightforward to [fabricate](https://en.wikipedia.org/wiki/Semiconductor_device_fabrication "Semiconductor device fabrication") a series of MOS capacitors in a row, they connected a suitable voltage to them so that the charge could be stepped along from one to the next.[[8]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Williams-8) The CCD is a semiconductor circuit that was later used in the first [digital video cameras](https://en.wikipedia.org/wiki/Digital_video_camera "Digital video camera") for [television broadcasting](https://en.wikipedia.org/wiki/Television_broadcasting "Television broadcasting").[[16]](https://en.wikipedia.org/wiki/Image_processing#cite_note-16)

The [NMOS](https://en.wikipedia.org/wiki/NMOS_logic "NMOS logic")[active-pixel sensor](https://en.wikipedia.org/wiki/Active-pixel_sensor "Active-pixel sensor") (APS) was invented by [Olympus](https://en.wikipedia.org/wiki/Olympus_Corporation "Olympus Corporation") in Japan during the mid-1980s. This was enabled by advances in MOS [semiconductor device fabrication](https://en.wikipedia.org/wiki/Semiconductor_device_fabrication "Semiconductor device fabrication"), with [MOSFET scaling](https://en.wikipedia.org/wiki/MOSFET_scaling "MOSFET scaling") reaching smaller [micron and then sub-micron](https://en.wikipedia.org/wiki/List_of_semiconductor_scale_examples "List of semiconductor scale examples") levels.[[17]](https://en.wikipedia.org/wiki/Image_processing#cite_note-fossum93-17)[[18]](https://en.wikipedia.org/wiki/Image_processing#cite_note-18) The NMOS APS was fabricated by Tsutomu Nakamura's team at Olympus in 1985.[[19]](https://en.wikipedia.org/wiki/Image_processing#cite_note-19) The [CMOS](https://en.wikipedia.org/wiki/CMOS "CMOS") active-pixel sensor (CMOS sensor) was later developed by [Eric Fossum](https://en.wikipedia.org/wiki/Eric_Fossum "Eric Fossum")'s team at the [NASA](https://en.wikipedia.org/wiki/NASA "NASA")[Jet Propulsion Laboratory](https://en.wikipedia.org/wiki/Jet_Propulsion_Laboratory "Jet Propulsion Laboratory") in 1993.[[20]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Fossum2014-20) By 2007, sales of CMOS sensors had surpassed CCD sensors.[[21]](https://en.wikipedia.org/wiki/Image_processing#cite_note-21)

MOS image sensors are widely used in [optical mouse](https://en.wikipedia.org/wiki/Optical_mouse "Optical mouse") technology. The first optical mouse, invented by [Richard F. Lyon](https://en.wikipedia.org/wiki/Richard_F._Lyon "Richard F. Lyon") at [Xerox](https://en.wikipedia.org/wiki/Xerox "Xerox") in 1980, used a [5 μm](https://en.wikipedia.org/wiki/6_%CE%BCm_process "6 μm process")[NMOS](https://en.wikipedia.org/wiki/NMOS_logic "NMOS logic")[integrated circuit](https://en.wikipedia.org/wiki/Integrated_circuit "Integrated circuit") sensor chip.[[22]](https://en.wikipedia.org/wiki/Image_processing#cite_note-22)[[23]](https://en.wikipedia.org/wiki/Image_processing#cite_note-23) Since the first commercial optical mouse, the [IntelliMouse](https://en.wikipedia.org/wiki/IntelliMouse "IntelliMouse") introduced in 1999, most optical mouse devices use CMOS sensors.[[24]](https://en.wikipedia.org/wiki/Image_processing#cite_note-24)[[25]](https://en.wikipedia.org/wiki/Image_processing#cite_note-hackaday-25)

An important development in digital [image compression](https://en.wikipedia.org/wiki/Image_compression "Image compression") technology was the [discrete cosine transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform "Discrete cosine transform") (DCT), a [lossy compression](https://en.wikipedia.org/wiki/Lossy_compression "Lossy compression") technique first proposed by [Nasir Ahmed](https://en.wikipedia.org/wiki/N._Ahmed "N. Ahmed") in 1972.[[26]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Ahmed-26) DCT compression became the basis for [JPEG](https://en.wikipedia.org/wiki/JPEG "JPEG"), which was introduced by the [Joint Photographic Experts Group](https://en.wikipedia.org/wiki/Joint_Photographic_Experts_Group "Joint Photographic Experts Group") in 1992.[[27]](https://en.wikipedia.org/wiki/Image_processing#cite_note-t81-27) JPEG compresses images down to much smaller file sizes, and has become the most widely used [image file format](https://en.wikipedia.org/wiki/Image_file_format "Image file format") on the [Internet](https://en.wikipedia.org/wiki/Internet "Internet").[[28]](https://en.wikipedia.org/wiki/Image_processing#cite_note-28) Its highly efficient DCT compression algorithm was largely responsible for the wide proliferation of [digital images](https://en.wikipedia.org/wiki/Digital_images "Digital images") and [digital photos](https://en.wikipedia.org/wiki/Digital_photo "Digital photo"),[[29]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Atlantic-29) with several billion JPEG images produced every day as of 2015.[[30]](https://en.wikipedia.org/wiki/Image_processing#cite_note-30)

Medical imaging techniques produce very large amounts of data, especially from CT, MRI and PET modalities. As a result, storage and communications of electronic image data are prohibitive without the use of compression.[[31]](https://en.wikipedia.org/wiki/Image_processing#cite_note-31)[[32]](https://en.wikipedia.org/wiki/Image_processing#cite_note-32)[JPEG 2000](https://en.wikipedia.org/wiki/JPEG_2000 "JPEG 2000") image compression is used by the [DICOM](https://en.wikipedia.org/wiki/DICOM "DICOM") standard for storage and transmission of medical images. The cost and feasibility of accessing large image data sets over low or various bandwidths are further addressed by use of another DICOM standard, called [JPIP](https://en.wikipedia.org/wiki/JPIP "JPIP"), to enable efficient streaming of the [JPEG 2000](https://en.wikipedia.org/wiki/JPEG_2000 "JPEG 2000") compressed image data.[[33]](https://en.wikipedia.org/wiki/Image_processing#cite_note-33)

### Digital signal processor (DSP)

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=4 "Edit section: Digital signal processor (DSP)")]

Electronic [signal processing](https://en.wikipedia.org/wiki/Signal_processing "Signal processing") was revolutionized by the wide adoption of [MOS technology](https://en.wikipedia.org/wiki/MOS_technology "MOS technology") in the 1970s.[[34]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Grant-34)[MOS integrated circuit](https://en.wikipedia.org/wiki/MOS_integrated_circuit "MOS integrated circuit") technology was the basis for the first single-chip [microprocessors](https://en.wikipedia.org/wiki/Microprocessors "Microprocessors") and [microcontrollers](https://en.wikipedia.org/wiki/Microcontrollers "Microcontrollers") in the early 1970s,[[35]](https://en.wikipedia.org/wiki/Image_processing#cite_note-ieee-35) and then the first single-chip [digital signal processor](https://en.wikipedia.org/wiki/Digital_signal_processor "Digital signal processor") (DSP) chips in the late 1970s.[[36]](https://en.wikipedia.org/wiki/Image_processing#cite_note-computerhistory1979-36)[[37]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Taranovich-37) DSP chips have since been widely used in digital image processing.[[36]](https://en.wikipedia.org/wiki/Image_processing#cite_note-computerhistory1979-36)

The [discrete cosine transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform "Discrete cosine transform") (DCT) [image compression](https://en.wikipedia.org/wiki/Image_compression "Image compression") algorithm has been widely implemented in DSP chips, with many companies developing DSP chips based on DCT technology. DCTs are widely used for [encoding](https://en.wikipedia.org/wiki/Encoding "Encoding"), decoding, [video coding](https://en.wikipedia.org/wiki/Video_coding "Video coding"), [audio coding](https://en.wikipedia.org/wiki/Audio_coding "Audio coding"), [multiplexing](https://en.wikipedia.org/wiki/Multiplexing "Multiplexing"), control signals, [signaling](https://en.wikipedia.org/wiki/Signaling "Signaling"), [analog-to-digital conversion](https://en.wikipedia.org/wiki/Analog-to-digital_conversion "Analog-to-digital conversion"), formatting [luminance](https://en.wikipedia.org/wiki/Luminance "Luminance") and color differences, and color formats such as [YUV444](https://en.wikipedia.org/wiki/YUV444 "YUV444") and [YUV411](https://en.wikipedia.org/wiki/YUV411 "YUV411"). DCTs are also used for encoding operations such as [motion estimation](https://en.wikipedia.org/wiki/Motion_estimation "Motion estimation"), [motion compensation](https://en.wikipedia.org/wiki/Motion_compensation "Motion compensation"), [inter-frame](https://en.wikipedia.org/wiki/Inter-frame "Inter-frame") prediction, [quantization](https://en.wikipedia.org/wiki/Quantization_(signal_processing) "Quantization (signal processing)"), perceptual weighting, [entropy encoding](https://en.wikipedia.org/wiki/Entropy_encoding "Entropy encoding"), variable encoding, and [motion vectors](https://en.wikipedia.org/wiki/Motion_vector "Motion vector"), and decoding operations such as the inverse operation between different color formats ([YIQ](https://en.wikipedia.org/wiki/YIQ "YIQ"), [YUV](https://en.wikipedia.org/wiki/YUV "YUV") and [RGB](https://en.wikipedia.org/wiki/RGB "RGB")) for display purposes. DCTs are also commonly used for [high-definition television](https://en.wikipedia.org/wiki/High-definition_television "High-definition television") (HDTV) encoder/decoder chips.[[38]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Stankovic-38)

Digital image processing allows the use of much more complex algorithms, and hence, can offer both more sophisticated performance at simple tasks, and the implementation of methods which would be impossible by analogue means.

In particular, digital image processing is a concrete application of, and a practical technology based on:

*   [Classification](https://en.wikipedia.org/wiki/Statistical_classification "Statistical classification")
*   [Feature extraction](https://en.wikipedia.org/wiki/Feature_extraction "Feature extraction")
*   [Multi-scale signal analysis](https://en.wikipedia.org/wiki/Multi-scale_signal_analysis "Multi-scale signal analysis")
*   [Pattern recognition](https://en.wikipedia.org/wiki/Pattern_recognition "Pattern recognition")
*   [Projection](https://en.wikipedia.org/wiki/Graphical_projection "Graphical projection")

Some techniques which are used in digital image processing include:

*   [Anisotropic diffusion](https://en.wikipedia.org/wiki/Anisotropic_diffusion "Anisotropic diffusion")
*   [Hidden Markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model "Hidden Markov model")
*   [Image editing](https://en.wikipedia.org/wiki/Image_editing "Image editing")
*   [Image restoration](https://en.wikipedia.org/wiki/Digital_photograph_restoration "Digital photograph restoration")
*   [Independent component analysis](https://en.wikipedia.org/wiki/Independent_component_analysis "Independent component analysis")
*   [Linear filtering](https://en.wikipedia.org/wiki/Linear_filter "Linear filter")
*   [Neural networks](https://en.wikipedia.org/wiki/Artificial_neural_networks "Artificial neural networks")
*   [Partial differential equations](https://en.wikipedia.org/wiki/Partial_differential_equations "Partial differential equations")
*   [Pixelation](https://en.wikipedia.org/wiki/Pixelation "Pixelation")
*   [Point feature matching](https://en.wikipedia.org/wiki/Point_feature_matching "Point feature matching")
*   [Principal components analysis](https://en.wikipedia.org/wiki/Principal_components_analysis "Principal components analysis")
*   [Self-organizing maps](https://en.wikipedia.org/wiki/Self-organizing_map "Self-organizing map")
*   [Wavelets](https://en.wikipedia.org/wiki/Wavelet "Wavelet")

Digital image transformations
-----------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=6 "Edit section: Digital image transformations")]

Digital filters are used to blur and sharpen digital images. Filtering can be performed by:

*   [convolution](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Convolution "Kernel (image processing)") with specifically designed [kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing) "Kernel (image processing)") (filter array) in the spatial domain[[39]](https://en.wikipedia.org/wiki/Image_processing#cite_note-:0-39)
*   masking specific frequency regions in the frequency (Fourier) domain

The following examples show both methods:[[40]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Gonzalez_2008-40)

| Filter type | Kernel or mask | Example |
| --- | --- | --- |
| **Original Image** | ![Image 1: {\displaystyle {\begin{bmatrix}0&0&0\\0&1&0\\0&0&0\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5bf6623ca763ba780b471a565eb1b06cd14b445c) | [![Image 2](https://upload.wikimedia.org/wikipedia/commons/e/ef/Affine_Transformation_Original_Checkerboard.jpg)](https://en.wikipedia.org/wiki/File:Affine_Transformation_Original_Checkerboard.jpg) |
| **[Spatial Lowpass](https://en.wikipedia.org/wiki/Lowpass "Lowpass")** | ![Image 3: {\displaystyle {\frac {1}{9}}\times {\begin{bmatrix}1&1&1\\1&1&1\\1&1&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fd0334e2eba0c8ade0a603b8fcadb1ecad64042b) | [![Image 4](https://upload.wikimedia.org/wikipedia/commons/c/c0/Spatial_Mean_Filter_Checkerboard.png)](https://en.wikipedia.org/wiki/File:Spatial_Mean_Filter_Checkerboard.png) |
| **[Spatial Highpass](https://en.wikipedia.org/wiki/Edge_detection "Edge detection")** | ![Image 5: {\displaystyle {\begin{bmatrix}0&-1&0\\-1&4&-1\\0&-1&0\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9b629b1894659e926464af9782a0566c993bef9a) | [![Image 6](https://upload.wikimedia.org/wikipedia/commons/6/6b/Spatial_Laplacian_Filter_Checkerboard.png)](https://en.wikipedia.org/wiki/File:Spatial_Laplacian_Filter_Checkerboard.png) |
| **[Fourier Representation](https://en.wikipedia.org/wiki/Fast_Fourier_transform "Fast Fourier transform")** | Pseudo-code: image = checkerboard F = Fourier Transform of image Show Image: log(1+Absolute Value(F)) | [![Image 7](https://upload.wikimedia.org/wikipedia/commons/4/42/Fourier_Space_Checkerboard.png)](https://en.wikipedia.org/wiki/File:Fourier_Space_Checkerboard.png) |
| **Fourier Lowpass** | [![Image 8](https://upload.wikimedia.org/wikipedia/commons/9/99/Lowpass_Butterworth_Checkerboard.png)](https://en.wikipedia.org/wiki/File:Lowpass_Butterworth_Checkerboard.png) | [![Image 9](https://upload.wikimedia.org/wikipedia/commons/3/31/Lowpass_FFT_Filtered_checkerboard.png)](https://en.wikipedia.org/wiki/File:Lowpass_FFT_Filtered_checkerboard.png) |
| **Fourier Highpass** | [![Image 10](https://upload.wikimedia.org/wikipedia/commons/2/21/Highpass_Butterworth_Checkerboard.png)](https://en.wikipedia.org/wiki/File:Highpass_Butterworth_Checkerboard.png) | [![Image 11](https://upload.wikimedia.org/wikipedia/commons/c/ce/Highpass_FFT_Filtered_checkerboard.png)](https://en.wikipedia.org/wiki/File:Highpass_FFT_Filtered_checkerboard.png) |

#### Image padding in Fourier domain filtering

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=8 "Edit section: Image padding in Fourier domain filtering")]

Images are typically padded before being transformed to the Fourier space, the [highpass filtered](https://en.wikipedia.org/wiki/Highpass_filter "Highpass filter") images below illustrate the consequences of different padding techniques:

| Zero padded | Repeated edge padded |
| --- | --- |
| [![Image 12](https://upload.wikimedia.org/wikipedia/commons/c/ce/Highpass_FFT_Filtered_checkerboard.png)](https://en.wikipedia.org/wiki/File:Highpass_FFT_Filtered_checkerboard.png) | [![Image 13](https://upload.wikimedia.org/wikipedia/commons/8/85/Highpass_FFT_Replicate.png)](https://en.wikipedia.org/wiki/File:Highpass_FFT_Replicate.png) |

Notice that the highpass filter shows extra edges when zero padded compared to the repeated edge padding.

#### Filtering code examples

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=9 "Edit section: Filtering code examples")]

MATLAB example for spatial domain highpass filtering.

img=checkerboard(20); % generate checkerboard
% ************************** SPATIAL DOMAIN ***************************
klaplace=[0 -1 0; -1 5 -1; 0 -1 0]; % Laplacian filter kernel
X=conv2(img,klaplace); % convolve test img with
 % 3x3 Laplacian kernel
figure()
imshow(X,[]) % show Laplacian filtered
title('Laplacian Edge Detection')

### Affine transformations

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=10 "Edit section: Affine transformations")]

[Affine transformations](https://en.wikipedia.org/wiki/Affine_transformations "Affine transformations") enable basic image transformations including scale, rotate, translate, mirror and shear as is shown in the following examples:[[40]](https://en.wikipedia.org/wiki/Image_processing#cite_note-Gonzalez_2008-40)

| Transformation Name | Affine Matrix | Example |
| --- | --- | --- |
| **[Identity](https://en.wikipedia.org/wiki/Identity_operation "Identity operation")** | ![Image 14: {\displaystyle {\begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/917dc504a6780a695d578a7b216036af7e49c506) | [![Image 15](https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Checkerboard_identity.svg/160px-Checkerboard_identity.svg.png)](https://en.wikipedia.org/wiki/File:Checkerboard_identity.svg) |
| **[Reflection](https://en.wikipedia.org/wiki/Reflection_(mathematics) "Reflection (mathematics)")** | ![Image 16: {\displaystyle {\begin{bmatrix}-1&0&0\\0&1&0\\0&0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b6f3c4219a22cd7963c3bed901717c1b34edda32) | [![Image 17](https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Checkerboard_reflection.svg/160px-Checkerboard_reflection.svg.png)](https://en.wikipedia.org/wiki/File:Checkerboard_reflection.svg) |
| **[Scale](https://en.wikipedia.org/wiki/Scale_(ratio) "Scale (ratio)")** | ![Image 18: {\displaystyle {\begin{bmatrix}c_{x}=2&0&0\\0&c_{y}=1&0\\0&0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/75c9c1d42880a29086ffc303cd6aecd0d83c3bb9) | [![Image 19](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Checkerboard_scale.svg/240px-Checkerboard_scale.svg.png)](https://en.wikipedia.org/wiki/File:Checkerboard_scale.svg) |
| **[Rotate](https://en.wikipedia.org/wiki/Rotate "Rotate")** | ![Image 20: {\displaystyle {\begin{bmatrix}\cos(\theta )&\sin(\theta )&0\\-\sin(\theta )&\cos(\theta )&0\\0&0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1e7686d473b2f40fbb3e867b4b3409bf63bcd823) | [![Image 21](https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Checkerboard_rotate.svg/160px-Checkerboard_rotate.svg.png)](https://en.wikipedia.org/wiki/File:Checkerboard_rotate.svg) where _θ_ = ⁠π/6⁠ =30° |
| **[Shear](https://en.wikipedia.org/wiki/Shear_matrix "Shear matrix")** | ![Image 22: {\displaystyle {\begin{bmatrix}1&c_{x}=0.5&0\\c_{y}=0&1&0\\0&0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0063f16565cecf78a3732068701f46390ad2f4a7) | [![Image 23](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Checkerboard_shear.svg/160px-Checkerboard_shear.svg.png)](https://en.wikipedia.org/wiki/File:Checkerboard_shear.svg) |

To apply the affine matrix to an image, the image is converted to matrix in which each entry corresponds to the pixel intensity at that location. Then each pixel's location can be represented as a vector indicating the coordinates of that pixel in the image, [_x_, _y_], where _x_ and _y_ are the row and column of a pixel in the image matrix. This allows the coordinate to be multiplied by an affine-transformation matrix, which gives the position that the pixel value will be copied to in the output image.

However, to allow transformations that require translation transformations, 3-dimensional [homogeneous coordinates](https://en.wikipedia.org/wiki/Homogeneous_coordinates "Homogeneous coordinates") are needed. The third dimension is usually set to a non-zero constant, usually 1, so that the new coordinate is [_x_, _y_, 1]. This allows the coordinate vector to be multiplied by a 3×3 matrix, enabling translation shifts. Thus, the third dimension, i.e. the constant 1, allows translation.

Because matrix multiplication is [associative](https://en.wikipedia.org/wiki/Associative "Associative"), multiple affine transformations can be combined into a single affine transformation by multiplying the matrix of each individual transformation in the order that the transformations are done. This results in a single matrix that, when applied to a point vector, gives the same result as all the individual transformations performed on the vector [_x_, _y_, 1] in sequence. Thus a sequence of affine transformation matrices can be reduced to a single affine transformation matrix.

For example, 2-dimensional coordinates only permit rotation about the origin (0, 0). But 3-dimensional homogeneous coordinates can be used to first translate any point to (0, 0), then perform the rotation, and lastly translate the origin (0, 0) back to the original point (the opposite of the first translation). These three affine transformations can be combined into a single matrix—thus allowing rotation around any point in the image.[[41]](https://en.wikipedia.org/wiki/Image_processing#cite_note-41)

### Image denoising with mathematical morphology

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=11 "Edit section: Image denoising with mathematical morphology")]

[Mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology "Mathematical morphology") (MM) is a nonlinear image processing framework that analyzes shapes within images by probing local pixel neighborhoods using a small, predefined function called a [structuring element](https://en.wikipedia.org/wiki/Structuring_element "Structuring element"). In the context of [grayscale images](https://en.wikipedia.org/wiki/Grayscale_image "Grayscale image"), MM is especially useful for denoising through [dilation](https://en.wikipedia.org/wiki/Dilation_(morphology) "Dilation (morphology)") and [erosion](https://en.wikipedia.org/wiki/Erosion_(morphology) "Erosion (morphology)")—primitive operators that can be combined to build more complex filters.

Suppose we have:

*   A discrete grayscale image: ![Image 24: {\displaystyle f={\begin{bmatrix}45&50&65\\40&60&55\\25&15&5\end{bmatrix}},\quad f:\Omega \rightarrow \mathbb {R} ,\quad \Omega =\{0,1,2\}^{2},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a204a261a319d147c8dfc0c982c243606df9d52d)

*   A structuring element: ![Image 25: {\displaystyle B={\begin{bmatrix}1&2&1\\2&1&1\\1&0&3\end{bmatrix}},\quad B:{\mathcal {S}}\rightarrow \mathbb {R} ,\quad {\mathcal {S}}=\{-1,0,1\}^{2}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fda8004a9622f89d8dac474a9a57037b4284969b)

Here, ![Image 26: {\displaystyle {\mathcal {S}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2302a18e269dbecc43c57c0c2aced3bfae15278d) defines the neighborhood of relative coordinates ![Image 27: {\displaystyle (m,n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/274d4857135a7d28a94ba9ee8135779615084d43) over which local operations are computed. The values of ![Image 28: {\displaystyle B(m,n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7f1a73c7fa714079c1d7d34ac057cc268407d334) bias the image during dilation and erosion.

Dilation Grayscale dilation is defined as:
![Image 29: {\displaystyle (f\oplus B)(i,j)=\max _{(m,n)\in {\mathcal {S}}}{\Bigl \{}f(i+m,j+n)+B(m,n){\Bigr \}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b78ed98cb4a8d30ae8851720aed0e162be8bb868)

For example, the dilation at position (1, 1) is calculated as:
![Image 30: {\displaystyle {\begin{aligned}(f\oplus B)(1,1)=\max \!{\Bigl (}&f(0,0)+B(-1,-1),&\;45+1;&\\&f(1,0)+B(0,-1),&\;50+2;&\\&f(2,0)+B(1,-1),&\;65+1;&\\&f(0,1)+B(-1,0),&\;40+2;&\\&f(1,1)+B(0,0),&\;60+1;&\\&f(2,1)+B(1,0),&\;55+1;&\\&f(0,2)+B(-1,1),&\;25+1;&\\&f(1,2)+B(0,1),&\;15+0;&\\&f(2,2)+B(1,1)&\;5+3{\Bigr )}=66.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0631728a2ffadc5df7daa75d19f73b120edc8ad6)

Erosion Grayscale erosion is defined as:
![Image 31: {\displaystyle (f\ominus B)(i,j)=\min _{(m,n)\in {\mathcal {S}}}{\Bigl \{}f(i+m,j+n)-B(m,n){\Bigr \}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/544fef5e8877af94fd8f2f7edba8694d8f7f23a7)

For example, the erosion at position (1, 1) is calculated as:
![Image 32: {\displaystyle {\begin{aligned}(f\ominus B)(1,1)=\min \!{\Bigl (}&f(0,0)-B(-1,-1),&\;45-1;&\\&f(1,0)-B(0,-1),&\;50-2;&\\&f(2,0)-B(1,-1),&\;65-1;&\\&f(0,1)-B(-1,0),&\;40-2;&\\&f(1,1)-B(0,0),&\;60-1;&\\&f(2,1)-B(1,0),&\;55-1;&\\&f(0,2)-B(-1,1),&\;25-1;&\\&f(1,2)-B(0,1),&\;15-0;&\\&f(2,2)-B(1,1)&\;5-3{\Bigr )}=2.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f01a0f563d9856869b98e80f7322f38d9503c69a)

After applying dilation to ![Image 33: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61): ![Image 34: {\displaystyle {\begin{bmatrix}45&50&65\\40&66&55\\25&15&5\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a8018d84926100ebe927c7bcd87ad0aedc72414)

After applying erosion to ![Image 35: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61): ![Image 36: {\displaystyle {\begin{bmatrix}45&50&65\\40&2&55\\25&15&5\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/04b3c5634fb9066a2ecc712dd064f643e9925fc5)

#### Opening and Closing

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=13 "Edit section: Opening and Closing")]

MM operations, such as [opening](https://en.wikipedia.org/wiki/Opening_(morphology) "Opening (morphology)") and [closing](https://en.wikipedia.org/wiki/Closing_(morphology) "Closing (morphology)"), are composite processes that utilize both dilation and erosion to modify the structure of an image. These operations are particularly useful for tasks such as noise removal, shape smoothing, and object separation.

*   _Opening_: This operation is performed by applying erosion to an image first, followed by dilation. The purpose of opening is to remove small objects or noise from the foreground while preserving the overall structure of larger objects. It is especially effective in situations where noise appears as isolated bright pixels or small, disconnected features.

For example, applying opening to an image ![Image 37: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) with a structuring element ![Image 38: {\displaystyle B}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47136aad860d145f75f3eed3022df827cee94d7a) would first reduce small details (through erosion) and then restore the main shapes (through dilation). This ensures that unwanted noise is removed without significantly altering the size or shape of larger objects.

*   _Closing_: This operation is performed by applying dilation first, followed by erosion. Closing is typically used to fill small holes or gaps within objects and to connect broken parts of the foreground. It works by initially expanding the boundaries of objects (through dilation) and then refining the boundaries (through erosion).

For instance, applying closing to the same image ![Image 39: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) would fill in small gaps within objects, such as connecting breaks in thin lines or closing small holes, while ensuring that the surrounding areas are not significantly affected.

Both opening and closing can be visualized as ways of refining the structure of an image: opening simplifies and removes small, unnecessary details, while closing consolidates and connects objects to form more cohesive structures.

| Structuring element | Mask | Code | Example |
| --- | --- | --- | --- |
| **Original Image** | None | Use Matlab to read Original image original = imread('scene.jpg'); image = rgb2gray(original); [r, c, channel] = size(image); se = logical([1 1 1 ; 1 1 1 ; 1 1 1]); [p, q] = size(se); halfH = floor(p/2); halfW = floor(q/2); time = 3; % denoising 3 times with all method | [![Image 40](https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Lotus_free.jpg/250px-Lotus_free.jpg)](https://en.wikipedia.org/wiki/File:Lotus_free.jpg) Original lotus |
| **[Dilation](https://en.wikipedia.org/wiki/Dilation_(morphology) "Dilation (morphology)")** | ![Image 41: {\displaystyle {\begin{bmatrix}1&1&1\\1&1&1\\1&1&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5350c22386c6f1c2c32769f4fc14ca3a0121a3ea) | Use Matlab to dilation imwrite(image, "scene_dil.jpg") extractmax = zeros(size(image), class(image)); for i = 1 : time dil_image = imread('scene_dil.jpg'); for col = (halfW + 1): (c - halfW) for row = (halfH + 1) : (r - halfH) dpointD = row - halfH; dpointU = row + halfH; dpointL = col - halfW; dpointR = col + halfW; dneighbor = dil_image(dpointD:dpointU, dpointL:dpointR); filter = dneighbor(se); extractmax(row, col) = max(filter); end end imwrite(extractmax, "scene_dil.jpg"); end | [![Image 42](https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Lotus_free_dil.jpg/250px-Lotus_free_dil.jpg)](https://en.wikipedia.org/wiki/File:Lotus_free_dil.jpg) Denoising picture with dilation method |
| **[Erosion](https://en.wikipedia.org/wiki/Erosion_(morphology) "Erosion (morphology)")** | ![Image 43: {\displaystyle {\begin{bmatrix}1&1&1\\1&1&1\\1&1&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5350c22386c6f1c2c32769f4fc14ca3a0121a3ea) | Use Matlab to erosion imwrite(image, 'scene_ero.jpg'); extractmin = zeros(size(image), class(image)); for i = 1: time ero_image = imread('scene_ero.jpg'); for col = (halfW + 1): (c - halfW) for row = (halfH +1): (r -halfH) pointDown = row-halfH; pointUp = row+halfH; pointLeft = col-halfW; pointRight = col+halfW; neighbor = ero_image(pointDown:pointUp,pointLeft:pointRight); filter = neighbor(se); extractmin(row, col) = min(filter); end end imwrite(extractmin, "scene_ero.jpg"); end | [![Image 44](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Lotus_free_erosion.jpg/250px-Lotus_free_erosion.jpg)](https://en.wikipedia.org/wiki/File:Lotus_free_erosion.jpg) |
| **[Opening](https://en.wikipedia.org/wiki/Opening_(morphology) "Opening (morphology)")** | ![Image 45: {\displaystyle {\begin{bmatrix}1&1&1\\1&1&1\\1&1&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5350c22386c6f1c2c32769f4fc14ca3a0121a3ea) | Use Matlab to Opening imwrite(extractmin, "scene_opening.jpg") extractopen = zeros(size(image), class(image)); for i = 1 : time dil_image = imread('scene_opening.jpg'); for col = (halfW + 1): (c - halfW) for row = (halfH + 1) : (r - halfH) dpointD = row - halfH; dpointU = row + halfH; dpointL = col - halfW; dpointR = col + halfW; dneighbor = dil_image(dpointD:dpointU, dpointL:dpointR); filter = dneighbor(se); extractopen(row, col) = max(filter); end end imwrite(extractopen, "scene_opening.jpg"); end | [![Image 46](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Lotus_free_opening.jpg/250px-Lotus_free_opening.jpg)](https://en.wikipedia.org/wiki/File:Lotus_free_opening.jpg) |
| **[Closing](https://en.wikipedia.org/wiki/Closing_(morphology) "Closing (morphology)")** | ![Image 47: {\displaystyle {\begin{bmatrix}1&1&1\\1&1&1\\1&1&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5350c22386c6f1c2c32769f4fc14ca3a0121a3ea) | Use Matlab to Closing imwrite(extractmax, "scene_closing.jpg") extractclose = zeros(size(image), class(image)); for i = 1 : time ero_image = imread('scene_closing.jpg'); for col = (halfW + 1): (c - halfW) for row = (halfH + 1) : (r - halfH) dpointD = row - halfH; dpointU = row + halfH; dpointL = col - halfW; dpointR = col + halfW; dneighbor = ero_image(dpointD:dpointU, dpointL:dpointR); filter = dneighbor(se); extractclose(row, col) = min(filter); end end imwrite(extractclose, "scene_closing.jpg"); end | [![Image 48](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Lotus_free_closing.jpg/250px-Lotus_free_closing.jpg)](https://en.wikipedia.org/wiki/File:Lotus_free_closing.jpg) Denoising picture with closing method |

### Digital camera images

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=15 "Edit section: Digital camera images")]

Digital cameras generally include specialized digital image processing hardware – either dedicated chips or added circuitry on other chips – to convert the raw data from their [image sensor](https://en.wikipedia.org/wiki/Image_sensor "Image sensor") into a [color-corrected](https://en.wikipedia.org/wiki/Color_correction "Color correction") image in a standard [image file format](https://en.wikipedia.org/wiki/Image_file_format "Image file format"). Additional post processing techniques increase edge sharpness or color saturation to create more naturally looking images.

_[Westworld](https://en.wikipedia.org/wiki/Westworld\_(film) "Westworld (film)")_ (1973) was the first feature film to use the digital image processing to [pixellate](https://en.wikipedia.org/wiki/Pixellate "Pixellate") photography to simulate an android's point of view.[[42]](https://en.wikipedia.org/wiki/Image_processing#cite_note-42) Image processing is also vastly used to produce the [chroma key](https://en.wikipedia.org/wiki/Chroma_key "Chroma key") effect that replaces the background of actors with natural or artistic scenery.

[![Image 49](https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Face_detection_process_V1.jpg/250px-Face_detection_process_V1.jpg)](https://en.wikipedia.org/wiki/File:Face_detection_process_V1.jpg)

Face detection process

[Face detection](https://en.wikipedia.org/wiki/Face_detection "Face detection") can be implemented with [mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology "Mathematical morphology"), the [discrete cosine transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform "Discrete cosine transform") (DCT), and horizontal [projection](https://en.wikipedia.org/wiki/Projection_(mathematics) "Projection (mathematics)").

**General method with feature-based method**

The feature-based method of face detection is using skin tone, edge detection, face shape, and feature of a face (like eyes, mouth, etc.) to achieve face detection. The skin tone, face shape, and all the unique elements that only the human face have can be described as features.

**Process explanation**

1.   Given a batch of face images, first, extract the skin tone range by sampling face images. The skin tone range is just a skin filter. 
    1.   [Structural similarity](https://en.wikipedia.org/wiki/Structural_similarity "Structural similarity") index measure (SSIM) can be applied to compare images in terms of extracting the skin tone.
    2.   Normally, HSV or RGB color spaces are suitable for the skin filter. E.g. HSV mode, the skin tone range is [0,48,50] ~ [20,255,255]

2.   After filtering images with skin tone, to get the face edge, morphology and DCT are used to remove noise and fill up missing skin areas. 
    1.   Opening method or closing method can be used to achieve filling up missing skin.
    2.   DCT is to avoid the object with skin-like tone. Since human faces always have higher texture.
    3.   Sobel operator or other operators can be applied to detect face edge.

3.   To position human features like eyes, using the projection and find the peak of the histogram of projection help to get the detail feature like mouth, hair, and lip. 
    1.   Projection is just projecting the image to see the high frequency which is usually the feature position.

### Improvement of image quality method

[[edit](https://en.wikipedia.org/w/index.php?title=Digital_image_processing&action=edit&section=18 "Edit section: Improvement of image quality method")]

Image quality can be influenced by camera vibration, over-exposure, gray level distribution too centralized, and noise, etc. For example, noise problem can be solved by [smoothing](https://en.wikipedia.org/wiki/Smoothing "Smoothing") method while gray level distribution problem can be improved by [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization "Histogram equalization").

**[Smoothing](https://en.wikipedia.org/wiki/Smoothing "Smoothing") method**

In drawing, if there is some dissatisfied color, taking some color around dissatisfied color and averaging them. This is an easy way to think of Smoothing method.

Smoothing method can be implemented with mask and [convolution](https://en.wikipedia.org/wiki/Convolution "Convolution"). Take the small image and mask for instance as below.

image is ![Image 50: {\displaystyle {\begin{bmatrix}2&5&6&5\\3&1&4&6\\1&28&30&2\\7&3&2&2\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ba73023ac222584748d50094fd2b5c8ff4fb3fc4)

mask is ![Image 51: {\displaystyle {\begin{bmatrix}1/9&1/9&1/9\\1/9&1/9&1/9\\1/9&1/9&1/9\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9a61c215b24aa9c824f9615efbedb4edf03ab15c)

After convolution and smoothing, image is ![Image 52: {\displaystyle {\begin{bmatrix}2&5&6&5\\3&9&10&6\\1&9&9&2\\7&3&2&2\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/855545cfa40bd44d635cbd904ae86c853209a8b7)

Observing image[1, 1], image[1, 2], image[2, 1], and image[2, 2].

The original image pixel is 1, 4, 28, 30. After smoothing mask, the pixel becomes 9, 10, 9, 9 respectively.

new image[1, 1] = ![Image 53: {\displaystyle {\tfrac {1}{9}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca7fbb8c7af3dce2f4bb214f14a76358a32a49d2) * (image[0,0]+image[0,1]+image[0,2]+image[1,0]+image[1,1]+image[1,2]+image[2,0]+image[2,1]+image[2,2])

new image[1, 1] = floor(![Image 54: {\displaystyle {\tfrac {1}{9}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca7fbb8c7af3dce2f4bb214f14a76358a32a49d2) * (2+5+6+3+1+4+1+28+30)) = 9

new image[1, 2] = floor({![Image 55: {\displaystyle {\tfrac {1}{9}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca7fbb8c7af3dce2f4bb214f14a76358a32a49d2) * (5+6+5+1+4+6+28+30+2)) = 10

new image[2, 1] = floor(![Image 56: {\displaystyle {\tfrac {1}{9}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca7fbb8c7af3dce2f4bb214f14a76358a32a49d2) * (3+1+4+1+28+30+7+3+2)) = 9

new image[2, 2] = floor(![Image 57: {\displaystyle {\tfrac {1}{9}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca7fbb8c7af3dce2f4bb214f14a76358a32a49d2) * (1+4+6+28+30+2+3+2+2)) = 9

**Gray Level Histogram method**

Generally, given a gray level histogram from an image as below. Changing the histogram to uniform distribution from an image is usually what we called [histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization "Histogram equalization").

[![Image 58](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Gray_level_histogram.jpg/250px-Gray_level_histogram.jpg)](https://en.wikipedia.org/wiki/File:Gray_level_histogram.jpg)

Figure 1

[![Image 59](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Uniform_distribution.jpg/250px-Uniform_distribution.jpg)](https://en.wikipedia.org/wiki/File:Uniform_distribution.jpg)

Figure 2

In discrete time, the area of gray level histogram is ![Image 60: {\displaystyle \sum _{i=0}^{k}H(p_{i})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/abf8541658f07b519e88ce11222fb7653e7066f5)(see figure 1) while the area of uniform distribution is ![Image 61: {\displaystyle \sum _{i=0}^{k}G(q_{i})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3315d247848798770d0f3c21a86f1dd8c6d837e1)(see figure 2). It is clear that the area will not change, so ![Image 62: {\displaystyle \sum _{i=0}^{k}H(p_{i})=\sum _{i=0}^{k}G(q_{i})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f5a03a27e52e7dae4eaec2248d84c2d112021c57).

From the uniform distribution, the probability of ![Image 63: {\displaystyle q_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2752dcbff884354069fe332b8e51eb0a70a531b6) is ![Image 64: {\displaystyle {\tfrac {N^{2}}{q_{k}-q_{0}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/65ade21483343c9cd5b40ec715577f6d5c16bf9a) while the ![Image 65: {\displaystyle 0<i<k}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a10b8f01bb97f7dc0f56d3f67f22c83944b2464b)

In continuous time, the equation is ![Image 66: {\displaystyle \displaystyle \int _{q_{0}}^{q}{\tfrac {N^{2}}{q_{k}-q_{0}}}ds=\displaystyle \int _{p_{0}}^{p}H(s)ds}](https://wikimedia.org/api/rest_v1/media/math/render/svg/13b3fefe6b5ce78e6247284089d22f16c60fc7b7).

Moreover, based on the definition of a function, the Gray level histogram method is like finding a function ![Image 67: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) that satisfies f(p)=q.

| Improvement method | Issue | Before improvement | Process | After improvement |
| --- | --- | --- | --- | --- |
| Smoothing method | noise with Matlab, salt & pepper with 0.01 parameter is added to the original image in order to create a noisy image. | [![Image 68](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Helmet_with_noise.jpg/250px-Helmet_with_noise.jpg)](https://en.wikipedia.org/wiki/File:Helmet_with_noise.jpg) | 1. read image and convert image into grayscale 2. convolution the grayscale image with the mask ![Image 69: {\displaystyle {\begin{bmatrix}1/9&1/9&1/9\\1/9&1/9&1/9\\1/9&1/9&1/9\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9a61c215b24aa9c824f9615efbedb4edf03ab15c) 3. denoisy image will be the result of step 2. | [![Image 70](https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Helmet_without_noise.jpg/250px-Helmet_without_noise.jpg)](https://en.wikipedia.org/wiki/File:Helmet_without_noise.jpg) |
| Histogram Equalization | Gray level distribution too centralized | [![Image 71](https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Cave_scene_before_improvement.jpg/250px-Cave_scene_before_improvement.jpg)](https://en.wikipedia.org/wiki/File:Cave_scene_before_improvement.jpg) | Refer to the [Histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization "Histogram equalization") | [![Image 72](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Cave_scene_after_improvement.jpg/250px-Cave_scene_after_improvement.jpg)](https://en.wikipedia.org/wiki/File:Cave_scene_after_improvement.jpg) |

1.   **Noise and [distortions](https://en.wikipedia.org/wiki/Distortion "Distortion")**: Imperfections in images due to poor lighting, limited sensors, and file compression can result in unclear images that impact accurate image conversion.
2.   **Variability in image quality**: Variations in image quality and resolution, including blurry images and incomplete details, can hinder uniform processing across a database.
3.   **[Object detection](https://en.wikipedia.org/wiki/Object_detection "Object detection") and Recognition**: Identifying and recognising objects within images, especially in complex scenarios with multiple objects and occlusions, poses a significant challenge.
4.   **Data annotation and labelling**: Labelling diverse and multiple images for machine recognition is crucial for further processing accuracy, as incorrect identification can lead to unrealistic results.
5.   **Computational resource intensity**: Accessing adequate computational resources for image processing can be challenging and costly, hindering progress without sufficient resources.

*   [Digital imaging](https://en.wikipedia.org/wiki/Digital_imaging "Digital imaging")
*   [Computer graphics](https://en.wikipedia.org/wiki/Computer_graphics "Computer graphics")
*   [Computer vision](https://en.wikipedia.org/wiki/Computer_vision "Computer vision")
*   [CVIPtools](https://en.wikipedia.org/wiki/CVIPtools "CVIPtools")
*   [Digitizing](https://en.wikipedia.org/wiki/Digitizing "Digitizing")
*   [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform "Fourier transform")
*   [Free boundary condition](https://en.wikipedia.org/wiki/Free_boundary_condition "Free boundary condition")
*   [GPGPU](https://en.wikipedia.org/wiki/GPGPU "GPGPU")
*   [Homomorphic filtering](https://en.wikipedia.org/wiki/Homomorphic_filtering "Homomorphic filtering")
*   [Image analysis](https://en.wikipedia.org/wiki/Image_analysis "Image analysis")
*   [IEEE Intelligent Transportation Systems Society](https://en.wikipedia.org/wiki/IEEE_Intelligent_Transportation_Systems_Society "IEEE Intelligent Transportation Systems Society")
*   [Least-squares spectral analysis](https://en.wikipedia.org/wiki/Least-squares_spectral_analysis "Least-squares spectral analysis")
*   [Medical imaging](https://en.wikipedia.org/wiki/Medical_imaging "Medical imaging")
*   [Multidimensional systems](https://en.wikipedia.org/wiki/Multidimensional_systems "Multidimensional systems")
*   [Relaxation labelling](https://en.wikipedia.org/wiki/Relaxation_labelling "Relaxation labelling")
*   [Remote sensing software](https://en.wikipedia.org/wiki/Remote_sensing_software "Remote sensing software")
*   [Standard test image](https://en.wikipedia.org/wiki/Standard_test_image "Standard test image")
*   [Superresolution](https://en.wikipedia.org/wiki/Superresolution "Superresolution")
*   [Total variation denoising](https://en.wikipedia.org/wiki/Total_variation_denoising "Total variation denoising")
*   [Machine Vision](https://en.wikipedia.org/wiki/Machine_Vision "Machine Vision")
*   [Bounded variation](https://en.wikipedia.org/wiki/Bounded_variation "Bounded variation")
*   [Radiomics](https://en.wikipedia.org/wiki/Radiomics "Radiomics")
*   [Remote sensing](https://en.wikipedia.org/wiki/Remote_sensing "Remote sensing")

1.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-1 "Jump up")**Chakravorty, Pragnan (2018). "What is a Signal? [Lecture Notes]". _IEEE Signal Processing Magazine_. **35** (5): 175–177. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2018ISPM...35e.175C](https://ui.adsabs.harvard.edu/abs/2018ISPM...35e.175C). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/MSP.2018.2832195](https://doi.org/10.1109%2FMSP.2018.2832195). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[52164353](https://api.semanticscholar.org/CorpusID:52164353).
2.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Gonzalez_2018_p._2-0 "Jump up")**Gonzalez, Rafael (2018). _Digital image processing_. New York, NY: Pearson. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-335672-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-335672-4 "Special:BookSources/978-0-13-335672-4"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[966609831](https://search.worldcat.org/oclc/966609831).
3.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-3 "Jump up")**Nagornov, Nikolay N.; Lyakhov, Pavel A.; Bergerman, Maxim V.; Kalita, Diana I. (2024). ["Modern Trends in Improving the Technical Characteristics of Devices and Systems for Digital Image Processing"](https://doi.org/10.1109%2FACCESS.2024.3381493). _IEEE Access_. **12**: 44659–44681. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2024IEEEA..1244659N](https://ui.adsabs.harvard.edu/abs/2024IEEEA..1244659N). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/ACCESS.2024.3381493](https://doi.org/10.1109%2FACCESS.2024.3381493). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[2169-3536](https://search.worldcat.org/issn/2169-3536).
4.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-4 "Jump up")**Yamni, Mohamed; Daoui, Achraf; Abd El-Latif, Ahmed A. (February 2024). ["Efficient color image steganography based on new adapted chaotic dynamical system with discrete orthogonal moment transforms"](https://linkinghub.elsevier.com/retrieve/pii/S0378475424000351). _Mathematics and Computers in Simulation_. **225**: 1170–1198. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.matcom.2024.01.023](https://doi.org/10.1016%2Fj.matcom.2024.01.023).
5.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-5 "Jump up")**Hung, Che-Lun (28 May 2020). ["Computational Algorithms on Medical Image Processing"](https://www.eurekaselect.com/180828/article). _Current Medical Imaging_. **16** (5): 467–468. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.2174/157340561605200410144743](https://doi.org/10.2174%2F157340561605200410144743). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[32484080](https://pubmed.ncbi.nlm.nih.gov/32484080).
6.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-6 "Jump up")**Azriel Rosenfeld, _Picture Processing by Computer_, New York: Academic Press, 1969
7.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-:1_7-0 "Jump up")**Gonzalez, Rafael C. (2008). _Digital image processing_. Woods, Richard E. (Richard Eugene), 1954– (3rd ed.). Upper Saddle River, N.J.: Prentice Hall. pp.23–28. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-168728-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-168728-8 "Special:BookSources/978-0-13-168728-8"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[137312858](https://search.worldcat.org/oclc/137312858).
8.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Williams_8-0)[_**b**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Williams_8-1)[_**c**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Williams_8-2)Williams, J. B. (2017). [_The Electronics Revolution: Inventing the Future_](https://books.google.com/books?id=v4QlDwAAQBAJ&pg=PA245). Springer. pp.245–8. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-319-49088-5](https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-49088-5 "Special:BookSources/978-3-319-49088-5").
9.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-9 "Jump up")**[US2802760A](https://patents.google.com/patent/US2802760A), Lincoln, Derick & Frosch, Carl J., "Oxidation of semiconductive surfaces for controlled diffusion", issued 13 August 1957
10.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-10 "Jump up")**Frosch, C. J.; Derick, L (1957). ["Surface Protection and Selective Masking during Diffusion in Silicon"](https://iopscience.iop.org/article/10.1149/1.2428650). _Journal of the Electrochemical Society_. **104** (9): 547. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1149/1.2428650](https://doi.org/10.1149%2F1.2428650).
11.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-11 "Jump up")**KAHNG, D. (1961). ["Silicon-Silicon Dioxide Surface Device"](https://doi.org/10.1142/9789814503464_0076). _Technical Memorandum of Bell Laboratories_: 583–596. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1142/9789814503464_0076](https://doi.org/10.1142%2F9789814503464_0076). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-981-02-0209-5](https://en.wikipedia.org/wiki/Special:BookSources/978-981-02-0209-5 "Special:BookSources/978-981-02-0209-5").
12.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-12 "Jump up")**Lojek, Bo (2007). _History of Semiconductor Engineering_. Berlin, Heidelberg: Springer-Verlag Berlin Heidelberg. p.321. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-34258-8](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-34258-8 "Special:BookSources/978-3-540-34258-8").
13.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-13 "Jump up")**Ligenza, J.R.; Spitzer, W.G. (1960). ["The mechanisms for silicon oxidation in steam and oxygen"](https://linkinghub.elsevier.com/retrieve/pii/0022369760902195). _Journal of Physics and Chemistry of Solids_. **14**: 131–136. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1960JPCS...14..131L](https://ui.adsabs.harvard.edu/abs/1960JPCS...14..131L). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0022-3697(60)90219-5](https://doi.org/10.1016%2F0022-3697%2860%2990219-5).
14.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Lojek1202_14-0 "Jump up")**Lojek, Bo (2007). _History of Semiconductor Engineering_. [Springer Science & Business Media](https://en.wikipedia.org/wiki/Springer_Science_%26_Business_Media "Springer Science & Business Media"). p.120. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9783540342588](https://en.wikipedia.org/wiki/Special:BookSources/9783540342588 "Special:BookSources/9783540342588").
15.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-15 "Jump up")**James R. Janesick (2001). [_Scientific charge-coupled devices_](https://books.google.com/books?id=3GyE4SWytn4C&pg=PA3). SPIE Press. pp.3–4. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8194-3698-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8194-3698-6 "Special:BookSources/978-0-8194-3698-6").
16.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-16 "Jump up")**Boyle, William S; Smith, George E. (1970). "Charge Coupled Semiconductor Devices". _Bell Syst. Tech. J_. **49** (4): 587–593. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1970BSTJ...49..587B](https://ui.adsabs.harvard.edu/abs/1970BSTJ...49..587B). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1002/j.1538-7305.1970.tb01790.x](https://doi.org/10.1002%2Fj.1538-7305.1970.tb01790.x).
17.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-fossum93_17-0 "Jump up")**[Fossum, Eric R.](https://en.wikipedia.org/wiki/Eric_Fossum "Eric Fossum") (12 July 1993). "Active pixel sensors: Are CCDS dinosaurs?". In Blouke, Morley M. (ed.). _Charge-Coupled Devices and Solid State Optical Sensors III_. Proceedings of the SPIE. Vol.1900. pp.2–14. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1993SPIE.1900....2F](https://ui.adsabs.harvard.edu/abs/1993SPIE.1900....2F). [CiteSeerX](https://en.wikipedia.org/wiki/CiteSeerX_(identifier) "CiteSeerX (identifier)")[10.1.1.408.6558](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.408.6558). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1117/12.148585](https://doi.org/10.1117%2F12.148585). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[10556755](https://api.semanticscholar.org/CorpusID:10556755).
18.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-18 "Jump up")**[Fossum, Eric R.](https://en.wikipedia.org/wiki/Eric_Fossum "Eric Fossum") (2007). ["Active Pixel Sensors"](http://ericfossum.com/Publications/Papers/Active%20Pixel%20Sensors%20LASER%20FOCUS.pdf)(PDF). _Eric Fossum_. [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[18831792](https://api.semanticscholar.org/CorpusID:18831792). [Archived](https://web.archive.org/web/20190829162855/http://ericfossum.com/Publications/Papers/Active%20Pixel%20Sensors%20LASER%20FOCUS.pdf)(PDF) from the original on 29 August 2019.
19.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-19 "Jump up")**Matsumoto, Kazuya; et al. (1985). "A new MOS phototransistor operating in a non-destructive readout mode". _Japanese Journal of Applied Physics_. **24** (5A): L323. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1985JaJAP..24L.323M](https://ui.adsabs.harvard.edu/abs/1985JaJAP..24L.323M). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1143/JJAP.24.L323](https://doi.org/10.1143%2FJJAP.24.L323). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[108450116](https://api.semanticscholar.org/CorpusID:108450116).
20.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Fossum2014_20-0 "Jump up")**[Fossum, Eric R.](https://en.wikipedia.org/wiki/Eric_Fossum "Eric Fossum"); Hondongwa, D. B. (2014). ["A Review of the Pinned Photodiode for CCD and CMOS Image Sensors"](https://doi.org/10.1109%2FJEDS.2014.2306412). _IEEE Journal of the Electron Devices Society_. **2** (3): 33–43. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/JEDS.2014.2306412](https://doi.org/10.1109%2FJEDS.2014.2306412).
21.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-21 "Jump up")**["CMOS Image Sensor Sales Stay on Record-Breaking Pace"](http://www.icinsights.com/news/bulletins/CMOS-Image-Sensor-Sales-Stay-On-RecordBreaking-Pace/). _IC Insights_. 8 May 2018. [Archived](https://web.archive.org/web/20190621180401/http://www.icinsights.com/news/bulletins/CMOS-Image-Sensor-Sales-Stay-On-RecordBreaking-Pace/) from the original on 21 June 2019. Retrieved 6 October 2019.
22.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-22 "Jump up")**[Lyon, Richard F.](https://en.wikipedia.org/wiki/Richard_F._Lyon "Richard F. Lyon") (2014). ["The Optical Mouse: Early Biomimetic Embedded Vision"](https://books.google.com/books?id=p_GbBQAAQBAJ&pg=PA3). _Advances in Embedded Computer Vision_. Springer. pp.3–22 (3). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9783319093871](https://en.wikipedia.org/wiki/Special:BookSources/9783319093871 "Special:BookSources/9783319093871").
23.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-23 "Jump up")**[Lyon, Richard F.](https://en.wikipedia.org/wiki/Richard_F._Lyon "Richard F. Lyon") (August 1981). ["The Optical Mouse, and an Architectural Methodology for Smart Digital Sensors"](http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/VLSI-81-1_The_Optical_Mouse.pdf)(PDF). In H. T. Kung; Robert F. Sproull; Guy L. Steele (eds.). _VLSI Systems and Computations_. Computer Science Press. pp.1–19. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-3-642-68402-9_1](https://doi.org/10.1007%2F978-3-642-68402-9_1). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-642-68404-3](https://en.wikipedia.org/wiki/Special:BookSources/978-3-642-68404-3 "Special:BookSources/978-3-642-68404-3"). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[60722329](https://api.semanticscholar.org/CorpusID:60722329). [Archived](https://web.archive.org/web/20140226021235/http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/VLSI-81-1_The_Optical_Mouse.pdf)(PDF) from the original on 26 February 2014.
24.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-24 "Jump up")**Brain, Marshall; Carmack, Carmen (24 April 2000). ["How Computer Mice Work"](https://computer.howstuffworks.com/mouse4.htm). _[HowStuffWorks](https://en.wikipedia.org/wiki/HowStuffWorks "HowStuffWorks")_. Retrieved 9 October 2019.
25.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-hackaday_25-0 "Jump up")**Benchoff, Brian (17 April 2016). ["Building the First Digital Camera"](http://hackaday.com/2016/04/17/building-the-first-digital-camera/). _[Hackaday](https://en.wikipedia.org/wiki/Hackaday "Hackaday")_. Retrieved 30 April 2016. the Cyclops was the first digital camera
26.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Ahmed_26-0 "Jump up")**[Ahmed, Nasir](https://en.wikipedia.org/wiki/N._Ahmed "N. Ahmed") (January 1991). ["How I Came Up With the Discrete Cosine Transform"](https://www.scribd.com/doc/52879771/DCT-History-How-I-Came-Up-with-the-Discrete-Cosine-Transform). _[Digital Signal Processing](https://en.wikipedia.org/wiki/Digital\_Signal\_Processing\_(journal) "Digital Signal Processing (journal)")_. **1** (1): 4–5. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1991DSP.....1....4A](https://ui.adsabs.harvard.edu/abs/1991DSP.....1....4A). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/1051-2004(91)90086-Z](https://doi.org/10.1016%2F1051-2004%2891%2990086-Z). [Archived](https://web.archive.org/web/20160610013109/https://www.scribd.com/doc/52879771/DCT-History-How-I-Came-Up-with-the-Discrete-Cosine-Transform) from the original on 10 June 2016. Retrieved 10 October 2019.
27.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-t81_27-0 "Jump up")**["T.81 – Digital compression and coding of continuous-tone still images – requirements and guidelines"](https://www.w3.org/Graphics/JPEG/itu-t81.pdf)(PDF). [CCITT](https://en.wikipedia.org/wiki/CCITT "CCITT"). September 1992. [Archived](https://web.archive.org/web/20190717052727/http://www.w3.org/Graphics/JPEG/itu-t81.pdf)(PDF) from the original on 17 July 2019. Retrieved 12 July 2019.
28.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-28 "Jump up")**Svetlik, Joe (31 May 2018). ["The JPEG image format explained"](https://web.archive.org/web/20190805194553/https://home.bt.com/tech-gadgets/photography/what-is-a-jpeg-11364206889349). [BT Group](https://en.wikipedia.org/wiki/BT_Group "BT Group"). Archived from [the original](https://home.bt.com/tech-gadgets/photography/what-is-a-jpeg-11364206889349) on 5 August 2019. Retrieved 5 August 2019.
29.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Atlantic_29-0 "Jump up")**Caplan, Paul (24 September 2013). ["What Is a JPEG? The Invisible Object You See Every Day"](https://www.theatlantic.com/technology/archive/2013/09/what-is-a-jpeg-the-invisible-object-you-see-every-day/279954/). _[The Atlantic](https://en.wikipedia.org/wiki/The\_Atlantic "The Atlantic")_. [Archived](https://web.archive.org/web/20191009054159/https://www.theatlantic.com/technology/archive/2013/09/what-is-a-jpeg-the-invisible-object-you-see-every-day/279954/) from the original on 9 October 2019. Retrieved 13 September 2019.
30.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-30 "Jump up")**Baraniuk, Chris (15 October 2015). ["JPeg lockdown: Restriction options sought by committee"](https://www.bbc.co.uk/news/technology-34538705). [BBC News](https://en.wikipedia.org/wiki/BBC_News "BBC News"). [Archived](https://web.archive.org/web/20191009193610/https://www.bbc.co.uk/news/technology-34538705) from the original on 9 October 2019. Retrieved 13 September 2019.
31.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-31 "Jump up")**Nagornov, Nikolay N.; Lyakhov, Pavel A.; Valueva, Maria V.; Bergerman, Maxim V. (2022). ["RNS-Based FPGA Accelerators for High-Quality 3D Medical Image Wavelet Processing Using Scaled Filter Coefficients"](https://doi.org/10.1109%2FACCESS.2022.3151361). _IEEE Access_. **10**: 19215–19231. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2022IEEEA..1019215N](https://ui.adsabs.harvard.edu/abs/2022IEEEA..1019215N). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/ACCESS.2022.3151361](https://doi.org/10.1109%2FACCESS.2022.3151361). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[2169-3536](https://search.worldcat.org/issn/2169-3536). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[246895876](https://api.semanticscholar.org/CorpusID:246895876). Medical imaging systems produce increasingly accurate images with improved quality using higher spatial resolutions and color bit-depth. Such improvements increase the amount of information that needs to be stored, processed, and transmitted.
32.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-32 "Jump up")**Dhouib, D.; Naït-Ali, A.; Olivier, C.; Naceur, M.S. (June 2021). ["ROI-Based Compression Strategy of 3D MRI Brain Datasets for Wireless Communications"](https://linkinghub.elsevier.com/retrieve/pii/S1959031820300853). _IRBM_. **42** (3): 146–153. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.irbm.2020.05.001](https://doi.org/10.1016%2Fj.irbm.2020.05.001). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[219437400](https://api.semanticscholar.org/CorpusID:219437400). Because of the large amount of medical imaging data, the transmission process becomes complicated in telemedicine applications. Thus, in order to adapt the data bit streams to the constraints related to the limitation of the bandwidths a reduction of the size of the data by compression of the images is essential.
33.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-33 "Jump up")**Xin, Gangtao; Fan, Pingyi (11 June 2021). ["A lossless compression method for multi-component medical images based on big data mining"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8196061). _Scientific Reports_. **11** (1): 12372. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1038/s41598-021-91920-x](https://doi.org/10.1038%2Fs41598-021-91920-x). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[2045-2322](https://search.worldcat.org/issn/2045-2322). [PMC](https://en.wikipedia.org/wiki/PMC_(identifier) "PMC (identifier)")[8196061](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8196061). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[34117350](https://pubmed.ncbi.nlm.nih.gov/34117350).
34.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Grant_34-0 "Jump up")**Grant, Duncan Andrew; Gowar, John (1989). [_Power MOSFETS: theory and applications_](https://books.google.com/books?id=ZiZTAAAAMAAJ). [Wiley](https://en.wikipedia.org/wiki/Wiley_(publisher) "Wiley (publisher)"). p.1. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-471-82867-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-82867-9 "Special:BookSources/978-0-471-82867-9"). The metal–oxide–semiconductor field-effect transistor (MOSFET) is the most commonly used active device in the very large-scale integration of digital integrated circuits (VLSI). During the 1970s these components revolutionized electronic signal processing, control systems and computers.
35.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-ieee_35-0 "Jump up")**Shirriff, Ken (30 August 2016). ["The Surprising Story of the First Microprocessors"](https://spectrum.ieee.org/the-surprising-story-of-the-first-microprocessors). _[IEEE Spectrum](https://en.wikipedia.org/wiki/IEEE\_Spectrum "IEEE Spectrum")_. **53** (9). [Institute of Electrical and Electronics Engineers](https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers "Institute of Electrical and Electronics Engineers"): 48–54. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/MSPEC.2016.7551353](https://doi.org/10.1109%2FMSPEC.2016.7551353). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[32003640](https://api.semanticscholar.org/CorpusID:32003640). [Archived](https://web.archive.org/web/20191013012248/https://spectrum.ieee.org/tech-history/silicon-revolution/the-surprising-story-of-the-first-microprocessors) from the original on 13 October 2019. Retrieved 13 October 2019.
36.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-computerhistory1979_36-0)[_**b**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-computerhistory1979_36-1)["1979: Single Chip Digital Signal Processor Introduced"](https://www.computerhistory.org/siliconengine/single-chip-digital-signal-processor-introduced/). _The Silicon Engine_. [Computer History Museum](https://en.wikipedia.org/wiki/Computer_History_Museum "Computer History Museum"). [Archived](https://web.archive.org/web/20191003072500/https://www.computerhistory.org/siliconengine/single-chip-digital-signal-processor-introduced/) from the original on 3 October 2019. Retrieved 14 October 2019.
37.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Taranovich_37-0 "Jump up")**Taranovich, Steve (27 August 2012). ["30 years of DSP: From a child's toy to 4G and beyond"](https://www.edn.com/design/systems-design/4394792/30-years-of-DSP--From-a-child-s-toy-to-4G-and-beyond). _[EDN](https://en.wikipedia.org/wiki/EDN\_(magazine) "EDN (magazine)")_. [Archived](https://web.archive.org/web/20191014044347/https://www.edn.com/design/systems-design/4394792/30-years-of-DSP--From-a-child-s-toy-to-4G-and-beyond) from the original on 14 October 2019. Retrieved 14 October 2019.
38.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Stankovic_38-0 "Jump up")**Stanković, Radomir S.; Astola, Jaakko T. (2012). ["Reminiscences of the Early Work in DCT: Interview with K.R. Rao"](http://ticsp.cs.tut.fi/reports/ticsp-report-60-reprint-rao-corrected.pdf)(PDF). _Reprints from the Early Days of Information Sciences_. **60**. [Archived](https://web.archive.org/web/20191013204147/http://ticsp.cs.tut.fi/reports/ticsp-report-60-reprint-rao-corrected.pdf)(PDF) from the original on 13 October 2019. Retrieved 13 October 2019.
39.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-:0_39-0 "Jump up")**Zhang, M. Z.; Livingston, A. R.; Asari, V. K. (2008). "A High Performance Architecture for Implementation of 2-D Convolution with Quadrant Symmetric Kernels". _International Journal of Computers and Applications_. **30** (4): 298–308. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1080/1206212x.2008.11441909](https://doi.org/10.1080%2F1206212x.2008.11441909). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[57289814](https://api.semanticscholar.org/CorpusID:57289814).
40.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Gonzalez_2008_40-0)[_**b**_](https://en.wikipedia.org/wiki/Image_processing#cite_ref-Gonzalez_2008_40-1)Gonzalez, Rafael (2008). _Digital Image Processing, 3rd_. Pearson Hall. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-168728-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-168728-8 "Special:BookSources/978-0-13-168728-8").
41.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-41 "Jump up")**House, Keyser (6 December 2016). [_Affine Transformations_](https://people.cs.clemson.edu/~dhouse/courses/401/notes/affines-matrices.pdf)(PDF). Foundations of Physically Based Modeling & Animation. A K Peters/CRC Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4822-3460-2](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4822-3460-2 "Special:BookSources/978-1-4822-3460-2"). [Archived](https://web.archive.org/web/20170830052734/https://people.cs.clemson.edu/~dhouse/courses/401/notes/affines-matrices.pdf)(PDF) from the original on 30 August 2017. Retrieved 26 March 2019.
42.   **[^](https://en.wikipedia.org/wiki/Image_processing#cite_ref-42 "Jump up")**[A Brief, Early History of Computer Graphics in Film](http://www.beanblossom.in.us/larryy/cgi.html)[Archived](https://web.archive.org/web/20120717074134/http://www.beanblossom.in.us/larryy/cgi.html) 17 July 2012 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine"), [Larry Yaeger](https://en.wikipedia.org/wiki/Larry_Yaeger "Larry Yaeger"), 16 August 2002 (last update), retrieved 24 March 2010

*   Solomon, C.J.; Breckon, T.P. (2010). _Fundamentals of Digital Image Processing: A Practical Approach with Examples in Matlab_. Wiley-Blackwell. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1002/9780470689776](https://doi.org/10.1002%2F9780470689776). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-470-84473-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-470-84473-1 "Special:BookSources/978-0-470-84473-1").
*   Wilhelm Burger; Mark J. Burge (2007). [_Digital Image Processing: An Algorithmic Approach Using Java_](http://www.imagingbook.com/). [Springer](https://en.wikipedia.org/wiki/Springer_Science%2BBusiness_Media "Springer Science+Business Media"). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-84628-379-6](https://en.wikipedia.org/wiki/Special:BookSources/978-1-84628-379-6 "Special:BookSources/978-1-84628-379-6").
*   R. Fisher; K Dawson-Howe; A. Fitzgibbon; C. Robertson; E. Trucco (2005). _Dictionary of Computer Vision and Image Processing_. John Wiley. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-470-01526-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-470-01526-1 "Special:BookSources/978-0-470-01526-1").
*   Rafael C. Gonzalez; Richard E. Woods; Steven L. Eddins (2004). _Digital Image Processing using MATLAB_. Pearson Education. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-81-7758-898-9](https://en.wikipedia.org/wiki/Special:BookSources/978-81-7758-898-9 "Special:BookSources/978-81-7758-898-9").
*   Tim Morris (2004). _Computer Vision and Image Processing_. Palgrave Macmillan. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-333-99451-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-333-99451-1 "Special:BookSources/978-0-333-99451-1").
*   Vipin Tyagi (2018). _Understanding Digital Image Processing_. Taylor and Francis CRC Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-11-3856-6842](https://en.wikipedia.org/wiki/Special:BookSources/978-11-3856-6842 "Special:BookSources/978-11-3856-6842").
*   Milan Sonka; Vaclav Hlavac; Roger Boyle (1999). _Image Processing, Analysis, and Machine Vision_. PWS Publishing. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-534-95393-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-534-95393-5 "Special:BookSources/978-0-534-95393-5").
*   Gonzalez, Rafael C.; Woods, Richard E. (2008). _Digital image processing_. Upper Saddle River, N.J.: Prentice Hall. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-168728-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-168728-8 "Special:BookSources/978-0-13-168728-8"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[137312858](https://search.worldcat.org/oclc/137312858).
*   Kovalevsky, Vladimir (2019). _Modern algorithms for image processing: computer imagery by example using C#_. [New York, New York]. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4842-4237-7](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4842-4237-7 "Special:BookSources/978-1-4842-4237-7"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[1080084533](https://search.worldcat.org/oclc/1080084533).`{{cite book}}`: CS1 maint: location missing publisher ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_location_missing_publisher "Category:CS1 maint: location missing publisher"))

*   [Lectures on Image Processing](https://archive.org/details/Lectures_on_Image_Processing), by Alan Peters. Vanderbilt University. Updated 7 January 2016.
*   [Processing digital images with computer algorithms](http://www.mathworks.com/discovery/digital-image-processing.html)
*   [Pengertian Citra Digital: Pemahaman Dasar dan Penerapannya dalam Teknologi](https://www.informatika.web.id/2013/10/pengertian-citra-digital-pemahaman.html)
