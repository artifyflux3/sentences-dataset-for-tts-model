Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Overview and history 2 Gaussian probability space 3 Invariance principle 4 Clark–Ocone formula 5 Skorokhod integral 6 Applications 7 References 8 External links Toggle the table of contents Malliavin calculus 6 languages العربية Deutsch Español فارسی Français 日本語 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikiquote Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Mathematical techniques used in probability theory and related fields In probability theory and related fields, Malliavin calculus is a set of mathematical techniques and ideas that extend the mathematical field of calculus of variations from  deterministic functions to stochastic processes . In particular, it allows the computation of derivatives of random variables . Malliavin calculus is also called the stochastic calculus of variations . P. Malliavin first initiated the calculus on infinite dimensional space. Then, the significant contributors such as S. Kusuoka, D. Stroock, J-M. Bismut , Shinzo Watanabe , I. Shigekawa, and so on finally completed the foundations.

Malliavin calculus is named after Paul Malliavin whose ideas led to a proof that Hörmander's condition implies the existence and smoothness of a density for the solution of a stochastic differential equation ; Hörmander 's original proof was based on the theory of partial differential equations . The calculus has been applied to stochastic partial differential equations as well.

The calculus allows integration by parts with random variables; this operation is used in mathematical finance to compute the sensitivities of financial derivatives . The calculus has applications in, for example, stochastic filtering .

Overview and history [ edit ] Malliavin introduced Malliavin calculus to provide a stochastic proof that Hörmander's condition implies the existence of a density for the solution of a stochastic differential equation ; Hörmander 's original proof was based on the theory of partial differential equations . His calculus enabled Malliavin to prove regularity bounds for the solution's density. The calculus has been applied to stochastic partial differential equations .

Gaussian probability space [ edit ] Main article: Gaussian probability space Consider a Wiener functional F {\displaystyle F} (a functional from the classical Wiener space ) and consider the task of finding a derivative for it. The natural idea would be to use the Gateaux derivative D g F := d d τ τ F [ f + τ τ g ] | τ τ = 0 , {\displaystyle D_{g}F:=\left.{\frac {d}{d\tau }}F[f+\tau g]\right|_{\tau =0},} however this does not always exist. Therefore it does make sense to find a new differential calculus for such spaces by limiting the directions.

The toy model of Malliavin calculus is an irreducible Gaussian probability space X = ( Ω Ω , F , P , H ) {\displaystyle X=(\Omega ,{\mathcal {F}},P,{\mathcal {H}})} . This is a (complete) probability space ( Ω Ω , F , P ) {\displaystyle (\Omega ,{\mathcal {F}},P)} together with a closed subspace H ⊂ ⊂ L 2 ( Ω Ω , F , P ) {\displaystyle {\mathcal {H}}\subset L^{2}(\Omega ,{\mathcal {F}},P)} such that all H ∈ ∈ H {\displaystyle H\in {\mathcal {H}}} are mean zero Gaussian variables and F = σ σ ( H : H ∈ ∈ H ) {\displaystyle {\mathcal {F}}=\sigma (H:H\in {\mathcal {H}})} . If one chooses a basis for H {\displaystyle {\mathcal {H}}} then one calls X {\displaystyle X} a numerical model . On the other hand, for any separable Hilbert space G {\displaystyle {\mathcal {G}}} exists a canonical irreducible Gaussian probability space Seg ⁡ ⁡ ( G ) {\displaystyle \operatorname {Seg} ({\mathcal {G}})} named the Segal model (named after Irving Segal ) having G {\displaystyle {\mathcal {G}}} as its Gaussian subspace. In this case for a g ∈ ∈ G {\displaystyle g\in {\mathcal {G}}} one notates the associated random variable in Seg ⁡ ⁡ ( G ) {\displaystyle \operatorname {Seg} ({\mathcal {G}})} as W ( g ) {\displaystyle W(g)} .

Properties of a Gaussian probability space that do not depend on the particular choice of basis are called intrinsic and such that do depend on the choice extrensic .

[ 1 ] We denote the countably infinite product of real spaces as R N = ∏ ∏ i = 1 ∞ ∞ R {\displaystyle \mathbb {R} ^{\mathbb {N} }=\prod \limits _{i=1}^{\infty }\mathbb {R} } .

Recall the modern version of the Cameron-Martin theorem Consider a locally convex vector space E {\displaystyle E} with a cylindrical Gaussian measure γ γ {\displaystyle \gamma } on it. For an element in the topological dual f ∈ ∈ E ′ {\displaystyle f\in E'} define the distance to the mean t γ γ ( f ) := f − − ∫ ∫ E f ( x ) γ γ ( d x ) , {\displaystyle t_{\gamma }(f):=f-\int _{E}f(x)\gamma (\mathrm {d} x),} which is a map t γ γ : : E ′ → → L 2 ( E , γ γ ) {\displaystyle t_{\gamma }\colon E'\to L^{2}(E,\gamma )} , and denote the closure in L 2 ( E , γ γ ) {\displaystyle L^{2}(E,\gamma )} as E γ γ ′ := clos ⁡ ⁡ { t γ γ ( f ) : : f ∈ ∈ E ′ } {\displaystyle E_{\gamma }':=\operatorname {clos} \left\{t_{\gamma }(f)\colon \ f\in E'\right\}} Let γ γ m := γ γ ( ⋅ ⋅ − − m ) {\displaystyle \gamma _{m}:=\gamma (\cdot -m)} denote the translation by m ∈ ∈ E {\displaystyle m\in E} . Then E γ γ ′ {\displaystyle E_{\gamma }'} respectively the covariance operator R γ γ : E γ γ ′ → → ( E γ γ ′ ) ∗ ∗ {\displaystyle R_{\gamma }:E_{\gamma }'\to (E_{\gamma }')^{*}} on it induces a reproducing kernel Hilbert space R {\displaystyle R} called the Cameron-Martin space such that for any m ∈ ∈ R {\displaystyle m\in R} there is equivalence γ γ m ∼ ∼ γ γ {\displaystyle \gamma _{m}\sim \gamma } .

[ 2 ] In fact one can use here the Feldman–Hájek theorem to find that for any other h ∉ R {\displaystyle h\not \in R} such measure would be singular.

Let γ γ {\displaystyle \gamma } be the canonical Gaussian measure, by transferring the Cameron-Martin theorem from ( R N , B ( R N ) , γ γ N = ⊗ ⊗ n ∈ ∈ N γ γ ) {\displaystyle (\mathbb {R} ^{\mathbb {N} },{\mathcal {B}}(\mathbb {R} ^{\mathbb {N} }),\gamma ^{\mathbb {N} }=\otimes _{n\in \mathbb {N} }\gamma )} into a numerical model X {\displaystyle X} , the additive group of H {\displaystyle {\mathcal {H}}} will define a quasi-automorphism group on Ω Ω {\displaystyle \Omega } . A construction can be done as follows: choose an orthonormal basis in H {\displaystyle {\mathcal {H}}} , let τ τ α α ( x ) = x + α α {\displaystyle \tau _{\alpha }(x)=x+\alpha } denote the translation on R N {\displaystyle \mathbb {R} ^{\mathbb {N} }} by α α {\displaystyle \alpha } , denote the map into the Cameron-Martin space by j : H → → ℓ ℓ 2 {\displaystyle j:{\mathcal {H}}\to \ell ^{2}} , denote L ∞ ∞ − − 0 ( Ω Ω , F , P ) = ⋂ ⋂ p < ∞ ∞ L p ( Ω Ω , F , P ) {\displaystyle L^{\infty -0}(\Omega ,{\mathcal {F}},P)=\bigcap \limits _{p<\infty }L^{p}(\Omega ,{\mathcal {F}},P)\quad } and q : L ∞ ∞ − − 0 ( R N , B ( R N ) , γ γ N ) → → L ∞ ∞ − − 0 ( Ω Ω , F , P ) , {\displaystyle \quad q:L^{\infty -0}(\mathbb {R} ^{\mathbb {N} },{\mathcal {B}}(\mathbb {R} ^{\mathbb {N} }),\gamma ^{\mathbb {N} })\to L^{\infty -0}(\Omega ,{\mathcal {F}},P),} we get a canonical representation of the additive group ρ ρ : H → → End ⁡ ⁡ ( L ∞ ∞ − − 0 ( Ω Ω , F , P ) ) {\displaystyle \rho :{\mathcal {H}}\to \operatorname {End} (L^{\infty -0}(\Omega ,{\mathcal {F}},P))} acting on the endomorphisms by defining ρ ρ ( h ) = q ∘ ∘ τ τ j ( h ) ∘ ∘ q − − 1 .

{\displaystyle \rho (h)=q\circ \tau _{j(h)}\circ q^{-1}.} One can show that the action of ρ ρ {\displaystyle \rho } is extrinsic meaning it does not depend on the choice of basis for H {\displaystyle {\mathcal {H}}} , further ρ ρ ( h + h ′ ) = ρ ρ ( h ) ρ ρ ( h ′ ) {\displaystyle \rho (h+h')=\rho (h)\rho (h')} for h , h ′ ∈ ∈ H {\displaystyle h,h'\in {\mathcal {H}}} and for the infinitesimal generator of ( ρ ρ ( h ) ) h {\displaystyle (\rho (h))_{h}} that lim ε ε → → 0 ρ ρ ( ε ε h ) − − I ε ε = M h {\displaystyle \lim \limits _{\varepsilon \to 0}{\frac {\rho (\varepsilon h)-I}{\varepsilon }}=M_{h}} where I {\displaystyle I} is the identity operator and M h {\displaystyle M_{h}} denotes the multiplication operator by the random variable h ∈ ∈ H {\displaystyle h\in {\mathcal {H}}} (acting on the endomorphisms). In the case of an arbitrary Hilbert space G {\displaystyle {\mathcal {G}}} and the Segal model Seg ⁡ ⁡ ( G ) {\displaystyle \operatorname {Seg} ({\mathcal {G}})} one has j : G → → ℓ ℓ 2 {\displaystyle j:{\mathcal {G}}\to \ell ^{2}} (and thus ρ ρ : G → → End ⁡ ⁡ ( L ∞ ∞ − − 0 ( Ω Ω , F , P ) ) {\displaystyle \rho :{\mathcal {G}}\to \operatorname {End} (L^{\infty -0}(\Omega ,{\mathcal {F}},P))} . Then the limit above becomes the multiplication operator by the random variable W ( g ) {\displaystyle W(g)} associated to g ∈ ∈ G {\displaystyle g\in {\mathcal {G}}} .

[ 3 ] For F ∈ ∈ L ∞ ∞ − − 0 ( Ω Ω , F , P ) {\displaystyle F\in L^{\infty -0}(\Omega ,{\mathcal {F}},P)} and h ∈ ∈ H {\displaystyle h\in {\mathcal {H}}} one now defines the directional derivative ⟨ ⟨ D F , h ⟩ ⟩ = D h F = lim ε ε → → 0 ( ρ ρ ( ε ε h ) − − I ) F ε ε .

{\displaystyle \langle DF,h\rangle =D_{h}F=\lim \limits _{\varepsilon \to 0}{\frac {\left(\rho (\varepsilon h)-I\right)F}{\varepsilon }}.} Given a Hilbert space H {\displaystyle H} and a Segal model Seg ⁡ ⁡ ( H ) {\displaystyle \operatorname {Seg} (H)} with its Gaussian space H = { W ( h ) : h ∈ ∈ H } {\displaystyle {\mathcal {H}}=\{W(h):h\in H\}} . One can now deduce for F ∈ ∈ L ∞ ∞ − − 0 ( Ω Ω , F , P ) {\displaystyle F\in L^{\infty -0}(\Omega ,{\mathcal {F}},P)} the integration by parts formula E [ D h F ] = E [ M W ( h ) F ] = E [ W ( h ) F ] {\displaystyle \mathbb {E} [D_{h}F]=\mathbb {E} [M_{W(h)}F]=\mathbb {E} [W(h)F]} .

[ 4 ] Invariance principle [ edit ] The usual invariance principle for Lebesgue integration over the whole real line is that, for any real number ε and integrable function f , the
following holds ∫ ∫ − − ∞ ∞ ∞ ∞ f ( x ) d λ λ ( x ) = ∫ ∫ − − ∞ ∞ ∞ ∞ f ( x + ε ε ) d λ λ ( x ) {\displaystyle \int _{-\infty }^{\infty }f(x)\,d\lambda (x)=\int _{-\infty }^{\infty }f(x+\varepsilon )\,d\lambda (x)} and hence ∫ ∫ − − ∞ ∞ ∞ ∞ f ′ ( x ) d λ λ ( x ) = 0.

{\displaystyle \int _{-\infty }^{\infty }f'(x)\,d\lambda (x)=0.} This can be used to derive the integration by parts formula since, setting f = gh , it implies 0 = ∫ ∫ − − ∞ ∞ ∞ ∞ f ′ d λ λ = ∫ ∫ − − ∞ ∞ ∞ ∞ ( g h ) ′ d λ λ = ∫ ∫ − − ∞ ∞ ∞ ∞ g h ′ d λ λ + ∫ ∫ − − ∞ ∞ ∞ ∞ g ′ h d λ λ .

{\displaystyle 0=\int _{-\infty }^{\infty }f'\,d\lambda =\int _{-\infty }^{\infty }(gh)'\,d\lambda =\int _{-\infty }^{\infty }gh'\,d\lambda +\int _{-\infty }^{\infty }g'h\,d\lambda .} A similar idea can be applied in stochastic analysis for the differentiation along a Cameron-Martin-Girsanov direction. Indeed, let h s {\displaystyle h_{s}} be a square-integrable predictable process and set φ φ ( t ) = ∫ ∫ 0 t h s d s .

{\displaystyle \varphi (t)=\int _{0}^{t}h_{s}\,ds.} If W {\displaystyle W} is a Wiener process , the Girsanov theorem then yields the following analogue of the invariance principle: E ( F ( W + ε ε φ φ ) ) = E [ F ( W ) exp ⁡ ⁡ ( ε ε ∫ ∫ 0 1 h s d w s − − 1 2 ε ε 2 ∫ ∫ 0 1 h s 2 d s ) ] .

{\displaystyle E(F(W+\varepsilon \varphi ))=E\left[F(W)\exp \left(\varepsilon \int _{0}^{1}h_{s}\,dw_{s}-{\frac {1}{2}}\varepsilon ^{2}\int _{0}^{1}h_{s}^{2}\,ds\right)\right].} Differentiating with respect to ε on both sides and evaluating at ε=0, one obtains the following integration by parts formula: E ( ⟨ ⟨ D F ( W ) , φ φ ⟩ ⟩ ) = E [ F ( W ) ∫ ∫ 0 1 h s d w s ] .

{\displaystyle E(\langle DF(W),\varphi \rangle )=E{\Big [}F(W)\int _{0}^{1}h_{s}\,dw_{s}{\Big ]}.} Here, the left-hand side is the Malliavin derivative of the random variable F {\displaystyle F} in the direction φ φ {\displaystyle \varphi } and the integral appearing on the right hand side should be interpreted as an Itô integral .

Clark–Ocone formula [ edit ] Main article: Clark–Ocone theorem One of the most useful results from Malliavin calculus is the Clark–Ocone theorem , which allows the process in the martingale representation theorem to be identified explicitly. A simplified version of this theorem is as follows: Consider the standard Wiener measure on the canonical space C [ 0 , 1 ] {\displaystyle C[0,1]} , equipped with its canonical filtration. For F : C [ 0 , 1 ] → → R {\displaystyle F:C[0,1]\to \mathbb {R} } satisfying E ( F ( X ) 2 ) < ∞ ∞ {\displaystyle E(F(X)^{2})<\infty } which is Lipschitz and such that F has a strong derivative kernel, in the sense that
for φ φ {\displaystyle \varphi } in C [0,1] lim ε ε → → 0 1 ε ε ( F ( X + ε ε φ φ ) − − F ( X ) ) = ∫ ∫ 0 1 F ′ ( X , d t ) φ φ ( t ) a .

e .

X {\displaystyle \lim _{\varepsilon \to 0}{\frac {1}{\varepsilon }}(F(X+\varepsilon \varphi )-F(X))=\int _{0}^{1}F'(X,dt)\varphi (t)\ \mathrm {a.e.} \ X} then F ( X ) = E ( F ( X ) ) + ∫ ∫ 0 1 H t d X t , {\displaystyle F(X)=E(F(X))+\int _{0}^{1}H_{t}\,dX_{t},} where H is the previsible projection of F '( x , ( t ,1]) which may be viewed as the derivative of the function F with respect to a suitable parallel shift of the process X over the portion ( t ,1] of its domain.

This may be more concisely expressed by F ( X ) = E ( F ( X ) ) + ∫ ∫ 0 1 E ( D t F ∣ ∣ F t ) d X t .

{\displaystyle F(X)=E(F(X))+\int _{0}^{1}E(D_{t}F\mid {\mathcal {F}}_{t})\,dX_{t}.} Much of the work in the formal development of the Malliavin calculus involves extending this result to the largest possible class of functionals F by replacing the derivative kernel used above by the " Malliavin derivative " denoted D t {\displaystyle D_{t}} in the above statement of the result.

[ citation needed ] Skorokhod integral [ edit ] Main article: Skorokhod integral The Skorokhod integral operator which is conventionally denoted δ is defined as the adjoint of the Malliavin derivative in the white noise case when the Hilbert space is an L 2 {\displaystyle L^{2}} space, thus for u in the domain of the operator which is a subset of L 2 ( [ 0 , ∞ ∞ ) × × Ω Ω ) {\displaystyle L^{2}([0,\infty )\times \Omega )} ,
for F in the domain of the Malliavin derivative, we require E ( ⟨ ⟨ D F , u ⟩ ⟩ ) = E ( F δ δ ( u ) ) , {\displaystyle E(\langle DF,u\rangle )=E(F\delta (u)),} where the inner product is that on L 2 [ 0 , ∞ ∞ ) {\displaystyle L^{2}[0,\infty )} viz ⟨ ⟨ f , g ⟩ ⟩ = ∫ ∫ 0 ∞ ∞ f ( s ) g ( s ) d s .

{\displaystyle \langle f,g\rangle =\int _{0}^{\infty }f(s)g(s)\,ds.} The existence of this adjoint follows from the Riesz representation theorem for linear operators on Hilbert spaces .

It can be shown that if u is adapted then δ δ ( u ) = ∫ ∫ 0 ∞ ∞ u t d W t , {\displaystyle \delta (u)=\int _{0}^{\infty }u_{t}\,dW_{t},} where the integral is to be understood in the Itô sense.   Thus this provides a method of extending the Itô integral to non adapted integrands.

Applications [ edit ] The calculus allows integration by parts with random variables ; this operation is used in mathematical finance to compute the sensitivities of financial derivatives . The calculus has applications for example in stochastic filtering .

This article includes a list of references , related reading , or external links , but its sources remain unclear because it lacks inline citations .

Please help improve this article by introducing more precise citations.

( June 2011 ) ( Learn how and when to remove this message ) References [ edit ] ^ Malliavin, Paul (1997).

Stochastic Analysis . Grundlehren der mathematischen Wissenschaften. Berlin, Heidelberg: Springer. pp.

4– 15.

ISBN 3-540-57024-1 .

^ Bogachev, Vladimir (1998).

Gaussian Measures . Rhode Island: American Mathematical Society .

^ Malliavin, Paul (1997).

Stochastic Analysis . Grundlehren der mathematischen Wissenschaften. Berlin, Heidelberg: Springer. pp.

20– 22.

ISBN 3-540-57024-1 .

^ Malliavin, Paul (1997).

Stochastic Analysis . Grundlehren der mathematischen Wissenschaften. Berlin, Heidelberg: Springer. p. 36.

ISBN 3-540-57024-1 .

Kusuoka, S. and Stroock, D. (1981) "Applications of Malliavin Calculus I", Stochastic Analysis, Proceedings Taniguchi International Symposium Katata and Kyoto 1982, pp 271–306 Kusuoka, S. and Stroock, D. (1985) "Applications of Malliavin Calculus II", J. Faculty Sci. Uni. Tokyo Sect. 1A Math.

, 32 pp 1–76 Kusuoka, S. and Stroock, D. (1987) "Applications of Malliavin Calculus III", J. Faculty Sci. Univ. Tokyo Sect. 1A Math.

, 34 pp 391–442 Malliavin, Paul and Thalmaier, Anton.

Stochastic Calculus of Variations in Mathematical Finance , Springer 2005, ISBN 3-540-43431-3 Nualart, David (2006).

The Malliavin calculus and related topics (Second ed.). Springer-Verlag.

ISBN 978-3-540-28328-7 .

Bell, Denis. (2007) The Malliavin Calculus , Dover.

ISBN 0-486-44994-7 ; ebook Sanz-Solé, Marta (2005) Malliavin Calculus, with applications to stochastic partial differential equations . EPFL Press, distributed by CRC Press, Taylor & Francis Group.

Schiller, Alex (2009) Malliavin Calculus for Monte Carlo Simulation with Financial Applications . Thesis, Department of Mathematics, Princeton University Øksendal, Bernt K.

(1997) An Introduction To Malliavin Calculus With Applications To Economics . Lecture Notes, Dept. of Mathematics, University of Oslo (Zip file containing Thesis and addendum) Di Nunno, Giulia , Øksendal, Bernt, Proske, Frank (2009) "Malliavin Calculus for Lévy Processes with Applications to Finance", Universitext, Springer.

ISBN 978-3-540-78571-2 External links [ edit ] Quotations related to Malliavin calculus at Wikiquote Friz, Peter K.

(2005-04-10).

"An Introduction to Malliavin Calculus" (PDF) . Archived from the original (PDF) on 2007-04-17 . Retrieved 2007-07-23 .

Lecture Notes, 43 pages Zhang, H. (2004-11-11).

"The Malliavin Calculus" (PDF) . Retrieved 2004-11-11 .

Thesis, 100 pages NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐xhvrc
Cached time: 20250812053818
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.323 seconds
Real time usage: 0.519 seconds
Preprocessor visited node count: 1507/1000000
Revision size: 16132/2097152 bytes
Post‐expand include size: 21674/2097152 bytes
Template argument size: 1544/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 33466/5000000 bytes
Lua time usage: 0.167/10.000 seconds
Lua memory usage: 5178861/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  304.575      1 -total
 34.70%  105.679      1 Template:Reflist
 32.41%   98.726      5 Template:Cite_book
 23.88%   72.720      1 Template:Short_description
 15.80%   48.135      2 Template:Pagetype
 11.70%   35.633      1 Template:Citation_needed
 10.29%   31.328      1 Template:No_footnotes
  9.96%   30.323      1 Template:Fix
  9.01%   27.430      1 Template:Ambox
  7.50%   22.856      3 Template:Main Saved in parser cache with key enwiki:pcache:837875:|#|:idhash:canonical and timestamp 20250812053818 and revision id 1298853812. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Malliavin_calculus&oldid=1298853812 " Categories : Stochastic calculus Integral calculus Mathematical finance Calculus of variations Malliavin calculus Hidden categories: Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from August 2011 Articles lacking in-text citations from June 2011 All articles lacking in-text citations This page was last edited on 5 July 2025, at 04:25 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Malliavin calculus 6 languages Add topic

