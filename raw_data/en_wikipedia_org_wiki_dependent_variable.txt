Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 In pure mathematics 2 In modeling and statistics 3 Synonyms 4 Other variables 5 Examples 6 See also 7 Notes 8 References Toggle the table of contents Dependent and independent variables 29 languages العربية বাংলা Беларуская Català Deutsch Español Euskara فارسی Gaeilge 한국어 हिन्दी Ido Italiano Kreyòl ayisyen Magyar Nederlands 日本語 Polski Português Русский Simple English Suomi Svenska தமிழ் Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Dependent variable ) For dependent and independent random variables, see Independence (probability theory) .

Concept in mathematical modeling, statistical modeling and experimental sciences A variable is considered dependent if it depends on (or is hypothesized to depend on) an independent variable . Dependent variables are studied under the supposition or demand that they depend, by some law or rule (e.g., by a mathematical function ), on the values of other variables. Independent variables, on the other hand, are not seen as depending on any other variable in the scope of the experiment in question.

[ a ] Rather, they are controlled by the experimenter.

In single variable calculus , a function is typically graphed with the horizontal axis representing the independent variable and the vertical axis representing the dependent variable.

[ 1 ] In this function, y is the dependent variable and x is the independent variable.

In pure mathematics [ edit ] In mathematics, a function is a rule for taking an input (in the simplest case, a number or set of numbers) [ 2 ] and providing an output (which may also be a number or set of numbers).

[ 2 ] A symbol that stands for an arbitrary input is called an independent variable , while a symbol that stands for an arbitrary output is called a dependent variable .

[ 3 ] The most common symbol for the input is x , and the most common symbol for the output is y ; the function itself is commonly written y = f ( x ) .

[ 3 ] [ 4 ] It is possible to have multiple independent variables or multiple dependent variables. For instance, in multivariable calculus , one often encounters functions of the form z = f ( x , y ) , where z is a dependent variable and x and y are independent variables.

[ 5 ] Functions with multiple outputs are often referred to as vector-valued functions .

In modeling and statistics [ edit ] In mathematical modeling , the relationship between the set of dependent variables and set of independent variables is studied.

[ citation needed ] In the simple stochastic linear model y i = a + b x i + e i the term y i is the i th value of the dependent variable and x i is the i th value of the independent variable. The term e i is known as the "error" and contains the variability of the dependent variable not explained by the independent variable.

[ citation needed ] With multiple independent variables, the model is y i = a + b x i ,1 + b x i ,2 + ... + b x i,n + e i , where n is the number of independent variables.

[ citation needed ] In statistics, more specifically in linear regression , a scatter plot of data is generated with X as the independent variable and Y as the dependent variable. This is also called a bivariate dataset, ( x 1 , y 1 )( x 2 , y 2 ) ...( x i , y i ) . The simple linear regression model takes the form of Y i = a + B x i + U i , for i = 1, 2, ... , n . In this case, U i , ... , U n are independent random variables. This occurs when the measurements do not influence each other. Through propagation of independence, the independence of U i implies independence of Y i , even though each Y i has a different expectation value. Each U i has an expectation value of 0 and a variance of σ 2 .

[ 6 ] Expectation of Y i Proof: [ 6 ] E ⁡ ⁡ [ Y i ] = E ⁡ ⁡ [ α α + β β x i + U i ] = α α + β β x i + E ⁡ ⁡ [ U i ] = α α + β β x i .

{\displaystyle \operatorname {E} [Y_{i}]=\operatorname {E} [\alpha +\beta x_{i}+U_{i}]=\alpha +\beta x_{i}+\operatorname {E} [U_{i}]=\alpha +\beta x_{i}.} The line of best fit for the bivariate dataset takes the form y = α + βx and is called the regression line.

α and β correspond to the intercept and slope, respectively.

[ 6 ] In an experiment , the variable manipulated by an experimenter is something that is proven to work, called an independent variable.

[ 7 ] The dependent variable is the event expected to change when the independent variable is manipulated.

[ 8 ] In data mining tools (for multivariate statistics and machine learning ), the dependent variable is assigned a role as target variable (or in some tools as label attribute ), while an independent variable may be assigned a role as regular variable [ 9 ] or feature variable. Known values for the target variable are provided for the training data set and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in unsupervised learning.

Synonyms [ edit ] Depending on the context, an independent variable is sometimes called a "predictor variable", "regressor", "covariate", "manipulated variable", "explanatory variable", "exposure variable" (see reliability theory ), " risk factor " (see medical statistics ), " feature " (in machine learning and pattern recognition ) or "input variable".

[ 10 ] [ 11 ] In econometrics , the term "control variable" is usually used instead of "covariate".

[ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] " Explanatory variable " is preferred by some authors over "independent variable" when the quantities treated as independent variables may not be statistically independent or independently manipulable by the researcher.

[ 17 ] [ 18 ] If the independent variable is referred to as an "explanatory variable" then the term " response variable " is preferred by some authors for the dependent variable.

[ 11 ] [ 17 ] [ 18 ] Depending on the context, a dependent variable is sometimes called a "response variable", "regressand", "criterion", "predicted variable", "measured variable", "explained variable", "experimental variable", "responding variable", "outcome variable", "output variable", "target" or "label".

[ 11 ] In economics endogenous variables are usually referencing the target.

" Explained variable " is preferred by some authors over "dependent variable" when the quantities treated as "dependent variables" may not be statistically dependent.

[ 19 ] If the dependent variable is referred to as an "explained variable" then the term " predictor variable " is preferred by some authors for the independent variable.

[ 19 ] An example is provided by the analysis of trend in sea level by Woodworth (1987) . Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a covariate consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the covariate allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the covariate.

Antonym pairs independent dependent input output regressor regressand predictor predicted explanatory explained exogenous endogenous manipulated measured exposure outcome feature label or target Other variables [ edit ] A variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that the variable will be kept constant or monitored to try to minimize its effect on the experiment. Such variables may be designated as either a "controlled variable", " control variable ", or "fixed variable".

Extraneous variables, if included in a regression analysis as independent variables, may aid a researcher with accurate response parameter estimation, prediction , and goodness of fit , but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable . If included in a regression, it can improve the fit of the model . If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression's result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias ; in these situations, design changes and/or controlling for a variable statistical control is necessary.

Extraneous variables are often classified into three types: Subject variables, which are the characteristics of the individuals being studied that might affect their actions. These variables include age, gender, health status, mood, background, etc.

Blocking variables or experimental variables are characteristics of the persons conducting the experiment which might influence how a person behaves. Gender, the presence of racial discrimination, language, or other factors may qualify as such variables.

Situational variables are features of the environment in which the study or research was conducted, which have a bearing on the outcome of the experiment in a negative way. Included are the air temperature, level of activity, lighting, and time of day.

In modelling, variability that is not covered by the independent variable is designated by e I {\displaystyle e_{I}} and is known as the " residual ", "side effect", " error ", "unexplained share", "residual variable", "disturbance", or "tolerance".

Examples [ edit ] Effect of fertilizer on plant growths: In a study measuring the influence of different quantities of fertilizer on plant growth, the independent variable would be the amount of fertilizer used. The dependent variable would be the growth in height or mass of the plant. The controlled variables would be the type of plant, the type of fertilizer, the amount of sunlight the plant gets, the size of the pots, etc.

Effect of drug dosage on symptom severity: In a study of how different doses of a drug affect the severity of symptoms, a researcher could compare the frequency and intensity of symptoms when different doses are administered. Here the independent variable is the dose and the dependent variable is the frequency/intensity of symptoms.

Effect of temperature on pigmentation: In measuring the amount of color removed from beetroot samples at different temperatures, temperature is the independent variable and amount of pigment removed is the dependent variable.

Effect of sugar added in a coffee: The taste varies with the amount of sugar added in the coffee. Here, the sugar is the independent variable, while the taste is the dependent variable.

See also [ edit ] Abscissa and ordinate Blocking (statistics) Latent and observable variables Mediator variable Notes [ edit ] ^ Even if the existing dependency is invertible (e.g., by finding the inverse function when it exists), the nomenclature is kept if the inverse dependency is not the object of study in the experiment.

References [ edit ] ^ Hastings, Nancy Baxter (1998).

Workshop calculus: guided exploration with review . Vol. 2. Springer Science & Business Media. p. 31.

^ a b Carlson, Robert. A concrete introduction to real analysis. CRC Press, 2006. p.183 ^ a b Stewart, James (2011). "1.1".

Calculus . Cengage Learning.

^ Anton, Howard, Irl C. Bivens, and Stephen Davis. Calculus Single Variable. John Wiley & Sons, 2012. Section 0.1 ^ Larson, Ron, and Bruce Edwards. Calculus. Cengage Learning, 2009. Section 13.1 ^ a b c Dekking, Frederik Michel (2005), A modern introduction to probability and statistics: understanding why and how , Springer, ISBN 1-85233-896-2 , OCLC 783259968 ^ "Variables" .

^ Random House Webster's Unabridged Dictionary.

Random House, Inc. 2001. Page 534, 971.

ISBN 0-375-42566-7 .

^ English Manual version 1.0 Archived 2014-02-10 at the Wayback Machine for RapidMiner 5.0, October 2013.

^ Dodge, Y. (2003) The Oxford Dictionary of Statistical Terms , OUP.

ISBN 0-19-920613-9 (entry for "independent variable") ^ a b c Dodge, Y. (2003) The Oxford Dictionary of Statistical Terms , OUP.

ISBN 0-19-920613-9 (entry for "regression") ^ Gujarati, Damodar N.; Porter, Dawn C.

(2009). "Terminology and Notation".

Basic Econometrics (Fifth international ed.). New York: McGraw-Hill. p. 21.

ISBN 978-007-127625-2 .

^ Wooldridge, Jeffrey (2012).

Introductory Econometrics: A Modern Approach (Fifth ed.). Mason, OH: South-Western Cengage Learning. pp.

22– 23.

ISBN 978-1-111-53104-1 .

^ Last, John M., ed. (2001).

A Dictionary of Epidemiology (Fourth ed.). Oxford UP.

ISBN 0-19-514168-7 .

^ Everitt, B. S. (2002).

The Cambridge Dictionary of Statistics (2nd ed.). Cambridge UP.

ISBN 0-521-81099-X .

^ Woodworth, P. L. (1987). "Trends in U.K. mean sea level".

Marine Geodesy .

11 (1): 57– 87.

Bibcode : 1987MarGe..11...57W .

doi : 10.1080/15210608709379549 .

^ a b Everitt, B.S. (2002) Cambridge Dictionary of Statistics, CUP.

ISBN 0-521-81099-X ^ a b Dodge, Y. (2003) The Oxford Dictionary of Statistical Terms , OUP.

ISBN 0-19-920613-9 ^ a b Ash Narayan Sah (2009) Data Analysis Using Microsoft Excel, New Delhi.

ISBN 978-81-7446-716-4 Wikiversity has learning resources about Independent variable Wikiversity has learning resources about Dependent variable v t e Differential equations Classification Operations Differential operator Notation for differentiation Ordinary Partial Differential-algebraic Integro-differential Fractional Linear Non-linear Holonomic Attributes of variables Dependent and independent variables Homogeneous Nonhomogeneous Coupled Decoupled Order Degree Autonomous Exact differential equation On jet bundles Relation to processes Difference (discrete analogue) Stochastic Stochastic partial Delay Solutions Existence/uniqueness Picard–Lindelöf theorem Peano existence theorem Carathéodory's existence theorem Cauchy–Kowalevski theorem Solution topics Wronskian Phase portrait Phase space Lyapunov stability Asymptotic stability Exponential stability Rate of convergence Series solutions Integral solutions Numerical integration Dirac delta function Solution methods Inspection Substitution Separation of variables Method of undetermined coefficients Variation of parameters Integrating factor Integral transforms Euler method Finite difference method Crank–Nicolson method Runge–Kutta methods Finite element method Finite volume method Galerkin method Perturbation theory Examples List of named differential equations List of linear ordinary differential equations List of nonlinear ordinary differential equations List of nonlinear partial differential equations Mathematicians Isaac Newton Gottfried Wilhelm Leibniz Leonhard Euler Jacob Bernoulli Émile Picard Józef Maria Hoene-Wroński Ernst Lindelöf Rudolf Lipschitz Joseph-Louis Lagrange Augustin-Louis Cauchy John Crank Phyllis Nicolson Carl David Tolmé Runge Martin Kutta Sofya Kovalevskaya NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐2k76k
Cached time: 20250811235704
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.473 seconds
Real time usage: 0.630 seconds
Preprocessor visited node count: 3322/1000000
Revision size: 15715/2097152 bytes
Post‐expand include size: 59647/2097152 bytes
Template argument size: 5975/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 67653/5000000 bytes
Lua time usage: 0.284/10.000 seconds
Lua memory usage: 7205915/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  527.512      1 -total
 31.59%  166.645      2 Template:Reflist
 20.03%  105.652      6 Template:Cite_book
 14.91%   78.637      3 Template:Navbox
 14.70%   77.564      1 Template:Differential_equations_topics
 12.31%   64.916      1 Template:Short_description
 10.65%   56.206      2 Template:Cn
 10.07%   53.109      3 Template:Fix
  6.41%   33.823      6 Template:Category_handler
  6.34%   33.459      1 Template:For Saved in parser cache with key enwiki:pcache:437701:|#|:idhash:canonical and timestamp 20250811235704 and revision id 1302134010. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Dependent_and_independent_variables&oldid=1302134010 " Categories : Design of experiments Regression analysis Mathematical terminology Independence (probability theory) Hidden categories: Webarchive template wayback links Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from February 2024 Articles with unsourced statements from November 2019 This page was last edited on 23 July 2025, at 15:38 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Dependent and independent variables 29 languages Add topic

