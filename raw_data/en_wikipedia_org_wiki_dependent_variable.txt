Title: Dependent and independent variables

URL Source: https://en.wikipedia.org/wiki/Dependent_variable

Published Time: 2004-01-21T14:14:29Z

Markdown Content:
From Wikipedia, the free encyclopedia

A variable is considered **dependent** if it depends on (or is hypothesized to depend on) an **independent variable**. Dependent variables are studied under the supposition or demand that they depend, by some law or rule (e.g., by a [mathematical function](https://en.wikipedia.org/wiki/Mathematical_function "Mathematical function")), on the values of other variables. Independent variables, on the other hand, are not seen as depending on any other variable in the scope of the experiment in question.[[a]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-1) Rather, they are controlled by the experimenter.

[![Image 1](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Polynomialdeg2.svg/250px-Polynomialdeg2.svg.png)](https://en.wikipedia.org/wiki/File:Polynomialdeg2.svg)

In single variable [calculus](https://en.wikipedia.org/wiki/Calculus "Calculus"), a [function](https://en.wikipedia.org/wiki/Function_(mathematics) "Function (mathematics)") is typically [graphed](https://en.wikipedia.org/wiki/Graph_of_a_function "Graph of a function") with the [horizontal axis](https://en.wikipedia.org/wiki/Horizontal_axis "Horizontal axis") representing the independent variable and the [vertical axis](https://en.wikipedia.org/wiki/Vertical_axis "Vertical axis") representing the dependent variable.[[1]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-2) In this function, _y_ is the dependent variable and _x_ is the independent variable.

In pure mathematics
-------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Dependent_and_independent_variables&action=edit&section=1 "Edit section: In pure mathematics")]

In mathematics, a [function](https://en.wikipedia.org/wiki/Function_(mathematics) "Function (mathematics)") is a rule for taking an input (in the simplest case, a number or set of numbers)[[2]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-carlson-3) and providing an output (which may also be a number or set of numbers).[[2]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-carlson-3) A symbol that stands for an arbitrary input is called an **independent variable**, while a symbol that stands for an arbitrary output is called a **dependent variable**.[[3]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-stewart-4) The most common symbol for the input is _x_, and the most common symbol for the output is _y_; the function itself is commonly written _y_ = _f_(_x_).[[3]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-stewart-4)[[4]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-5)

It is possible to have multiple independent variables or multiple dependent variables. For instance, in [multivariable calculus](https://en.wikipedia.org/wiki/Multivariable_calculus "Multivariable calculus"), one often encounters functions of the form _z_ = _f_(_x_,_y_), where _z_ is a dependent variable and _x_ and _y_ are independent variables.[[5]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-6) Functions with multiple outputs are often referred to as [vector-valued functions](https://en.wikipedia.org/wiki/Vector-valued_functions "Vector-valued functions").

In modeling and statistics
--------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Dependent_and_independent_variables&action=edit&section=2 "Edit section: In modeling and statistics")]

In [mathematical modeling](https://en.wikipedia.org/wiki/Mathematical_modeling "Mathematical modeling"), the relationship between the set of dependent variables and set of independent variables is studied.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\_needed "Wikipedia:Citation needed")_]

In the simple [stochastic](https://en.wikipedia.org/wiki/Stochastic "Stochastic")[linear model](https://en.wikipedia.org/wiki/Linear_model "Linear model")_y_ _i_ = a + b _x_ _i_ + _e_ _i_ the term _y_ _i_ is the i th value of the dependent variable and _x_ _i_ is the i th value of the independent variable. The term _e_ _i_ is known as the "error" and contains the variability of the dependent variable not explained by the independent variable.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\_needed "Wikipedia:Citation needed")_]

With multiple independent variables, the model is _y_ _i_ = a + b _x_ _i_,1 + b _x_ _i_,2 + ... + b _x_ _i,n_ + _e_ i, where _n_ is the number of independent variables.[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\_needed "Wikipedia:Citation needed")_]

In statistics, more specifically in [linear regression](https://en.wikipedia.org/wiki/Linear_regression "Linear regression"), a [scatter plot](https://en.wikipedia.org/wiki/Scatter_plot "Scatter plot") of data is generated with X as the independent variable and Y as the dependent variable. This is also called a bivariate dataset, (_x_ 1, _y_ 1)(_x_ 2, _y_ 2) ...(_x_ _i_, _y_ _i_). The simple linear regression model takes the form of _Y_ _i_ = a + B _x_ _i_ + _U_ _i_, for _i_ = 1, 2, ... , _n_. In this case, _U_ _i_, ... ,_U_ _n_ are independent random variables. This occurs when the measurements do not influence each other. Through propagation of independence, the independence of _U_ _i_ implies independence of _Y_ _i_, even though each _Y_ _i_ has a different expectation value. Each _U_ _i_ has an expectation value of 0 and a variance of σ 2.[[6]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dekking-7) Expectation of _Y_ _i_ Proof:[[6]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dekking-7)

![Image 2: {\displaystyle \operatorname {E} [Y_{i}]=\operatorname {E} [\alpha +\beta x_{i}+U_{i}]=\alpha +\beta x_{i}+\operatorname {E} [U_{i}]=\alpha +\beta x_{i}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/01802d1130f257585edb31f1e92249f43db82803)

The line of best fit for the [bivariate dataset](https://en.wikipedia.org/wiki/Bivariate_data "Bivariate data") takes the form _y_ = _α_ + _βx_ and is called the regression line. α and β correspond to the intercept and slope, respectively.[[6]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dekking-7)

In an [experiment](https://en.wikipedia.org/wiki/Design_of_experiments "Design of experiments"), the variable manipulated by an experimenter is something that is proven to work, called an independent variable.[[7]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-8) The dependent variable is the event expected to change when the independent variable is manipulated.[[8]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-random_house-9)

In [data mining](https://en.wikipedia.org/wiki/Data_mining "Data mining") tools (for [multivariate statistics](https://en.wikipedia.org/wiki/Multivariate_statistics "Multivariate statistics") and [machine learning](https://en.wikipedia.org/wiki/Machine_learning "Machine learning")), the dependent variable is assigned a _role_ as **target variable** (or in some tools as _label attribute_), while an independent variable may be assigned a role as _regular variable_[[9]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-10) or feature variable. Known values for the target variable are provided for the training data set and [test data](https://en.wikipedia.org/wiki/Test_data "Test data") set, but should be predicted for other data. The target variable is used in [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning "Supervised learning") algorithms but not in unsupervised learning.

Depending on the context, an independent variable is sometimes called a "predictor variable", "regressor", "covariate", "manipulated variable", "explanatory variable", "exposure variable" (see [reliability theory](https://en.wikipedia.org/wiki/Reliability_theory "Reliability theory")), "[risk factor](https://en.wikipedia.org/wiki/Risk_factor "Risk factor")" (see [medical statistics](https://en.wikipedia.org/wiki/Medical_statistics "Medical statistics")), "[feature](https://en.wikipedia.org/wiki/Feature_(machine_learning) "Feature (machine learning)")" (in [machine learning](https://en.wikipedia.org/wiki/Machine_learning "Machine learning") and [pattern recognition](https://en.wikipedia.org/wiki/Pattern_recognition "Pattern recognition")) or "input variable".[[10]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodgeindepvar-11)[[11]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodgeregression-12) In [econometrics](https://en.wikipedia.org/wiki/Econometrics "Econometrics"), the term "control variable" is usually used instead of "covariate".[[12]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-13)[[13]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-14)[[14]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-15)[[15]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-16)[[16]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-17)

"Explanatory variable" is preferred by some authors over "independent variable" when the quantities treated as independent variables may not be statistically independent or independently manipulable by the researcher.[[17]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Everitt1-18)[[18]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodge1-19) If the independent variable is referred to as an "explanatory variable" then the term "response variable" is preferred by some authors for the dependent variable.[[11]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodgeregression-12)[[17]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Everitt1-18)[[18]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodge1-19)

Depending on the context, a dependent variable is sometimes called a "response variable", "regressand", "criterion", "predicted variable", "measured variable", "explained variable", "experimental variable", "responding variable", "outcome variable", "output variable", "target" or "label".[[11]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-Dodgeregression-12) In economics endogenous variables are usually referencing the target.

"Explained variable" is preferred by some authors over "dependent variable" when the quantities treated as "dependent variables" may not be statistically dependent.[[19]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-DAUME-20) If the dependent variable is referred to as an "explained variable" then the term "predictor variable" is preferred by some authors for the independent variable.[[19]](https://en.wikipedia.org/wiki/Dependent_variable#cite_note-DAUME-20)

An example is provided by the analysis of trend in sea level by [Woodworth (1987)](https://en.wikipedia.org/wiki/Dependent_variable#CITEREFWoodworth1987). Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a covariate consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the covariate allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the covariate.

Antonym pairs independent dependent
input output
regressor regressand
predictor predicted
explanatory explained
exogenous endogenous
manipulated measured
exposure outcome
feature label or target

A variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that the variable will be kept constant or monitored to try to minimize its effect on the experiment. Such variables may be designated as either a "controlled variable", "[control variable](https://en.wikipedia.org/wiki/Control_variable "Control variable")", or "fixed variable".

Extraneous variables, if included in a [regression analysis](https://en.wikipedia.org/wiki/Regression_analysis "Regression analysis") as independent variables, may aid a researcher with accurate response parameter estimation, [prediction](https://en.wikipedia.org/wiki/Prediction "Prediction"), and [goodness of fit](https://en.wikipedia.org/wiki/Goodness_of_fit "Goodness of fit"), but are not of substantive interest to the [hypothesis](https://en.wikipedia.org/wiki/Hypothesis "Hypothesis") under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the [dependent variable](https://en.wikipedia.org/wiki/Dependent_variable "Dependent variable"). If included in a regression, it can improve the [fit of the model](https://en.wikipedia.org/wiki/Model_fitting "Model fitting"). If it is excluded from the regression and if it has a non-zero [covariance](https://en.wikipedia.org/wiki/Covariance "Covariance") with one or more of the independent variables of interest, its omission will [bias](https://en.wikipedia.org/wiki/Bias_(statistics) "Bias (statistics)") the regression's result for the effect of that independent variable of interest. This effect is called [confounding](https://en.wikipedia.org/wiki/Confounding "Confounding") or [omitted variable bias](https://en.wikipedia.org/wiki/Omitted_variable_bias "Omitted variable bias"); in these situations, design changes and/or controlling for a variable statistical control is necessary.

Extraneous variables are often classified into three types:

1.   Subject variables, which are the characteristics of the individuals being studied that might affect their actions. These variables include age, gender, health status, mood, background, etc.
2.   Blocking variables or experimental variables are characteristics of the persons conducting the experiment which might influence how a person behaves. Gender, the presence of racial discrimination, language, or other factors may qualify as such variables.
3.   Situational variables are features of the environment in which the study or research was conducted, which have a bearing on the outcome of the experiment in a negative way. Included are the air temperature, level of activity, lighting, and time of day.

In modelling, variability that is not covered by the independent variable is designated by ![Image 3: {\displaystyle e_{I}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dc8f6a77f9502357c64944f69d25b9148162e822) and is known as the "[residual](https://en.wikipedia.org/wiki/Errors_and_residuals "Errors and residuals")", "side effect", "[error](https://en.wikipedia.org/wiki/Errors_and_residuals "Errors and residuals")", "unexplained share", "residual variable", "disturbance", or "tolerance".

*   Effect of fertilizer on plant growths: In a study measuring the influence of different quantities of fertilizer on plant growth, the independent variable would be the amount of fertilizer used. The dependent variable would be the growth in height or mass of the plant. The controlled variables would be the type of plant, the type of fertilizer, the amount of sunlight the plant gets, the size of the pots, etc.
*   Effect of drug dosage on symptom severity: In a study of how different doses of a drug affect the severity of symptoms, a researcher could compare the frequency and intensity of symptoms when different doses are administered. Here the independent variable is the dose and the dependent variable is the frequency/intensity of symptoms.
*   Effect of temperature on pigmentation: In measuring the amount of color removed from beetroot samples at different temperatures, temperature is the independent variable and amount of pigment removed is the dependent variable.
*   Effect of sugar added in a coffee: The taste varies with the amount of sugar added in the coffee. Here, the sugar is the independent variable, while the taste is the dependent variable.

*   [Abscissa and ordinate](https://en.wikipedia.org/wiki/Abscissa_and_ordinate "Abscissa and ordinate")
*   [Blocking (statistics)](https://en.wikipedia.org/wiki/Blocking_(statistics) "Blocking (statistics)")
*   [Latent and observable variables](https://en.wikipedia.org/wiki/Latent_and_observable_variables "Latent and observable variables")
*   [Mediator variable](https://en.wikipedia.org/wiki/Mediator_variable "Mediator variable")

1.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-1 "Jump up")**Even if the existing dependency is invertible (e.g., by finding the [inverse function](https://en.wikipedia.org/wiki/Inverse_function "Inverse function") when it exists), the nomenclature is kept if the inverse dependency is not the object of study in the experiment.

1.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-2 "Jump up")**Hastings, Nancy Baxter (1998). _Workshop calculus: guided exploration with review_. Vol.2. Springer Science & Business Media. p.31.
2.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-carlson_3-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-carlson_3-1)Carlson, Robert. A concrete introduction to real analysis. CRC Press, 2006. p.183
3.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-stewart_4-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-stewart_4-1)Stewart, James (2011). "1.1". _Calculus_. Cengage Learning.
4.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-5 "Jump up")**Anton, Howard, Irl C. Bivens, and Stephen Davis. Calculus Single Variable. John Wiley & Sons, 2012. Section 0.1
5.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-6 "Jump up")**Larson, Ron, and Bruce Edwards. Calculus. Cengage Learning, 2009. Section 13.1
6.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dekking_7-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dekking_7-1)[_**c**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dekking_7-2)Dekking, Frederik Michel (2005), _A modern introduction to probability and statistics: understanding why and how_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[1-85233-896-2](https://en.wikipedia.org/wiki/Special:BookSources/1-85233-896-2 "Special:BookSources/1-85233-896-2"), [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[783259968](https://search.worldcat.org/oclc/783259968)
7.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-8 "Jump up")**["Variables"](http://onlinestatbook.com/2/introduction/variables.html).
8.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-random_house_9-0 "Jump up")**_Random House Webster's Unabridged Dictionary._ Random House, Inc. 2001. Page 534, 971. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-375-42566-7](https://en.wikipedia.org/wiki/Special:BookSources/0-375-42566-7 "Special:BookSources/0-375-42566-7").
9.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-10 "Jump up")**[English Manual version 1.0](http://1xltkxylmzx3z8gd647akcdvov.wpengine.netdna-cdn.com/wp-content/uploads/2013/10/rapidminer-5.0-manual-english_v1.0.pdf)[Archived](https://web.archive.org/web/20140210002634/http://1xltkxylmzx3z8gd647akcdvov.wpengine.netdna-cdn.com/wp-content/uploads/2013/10/rapidminer-5.0-manual-english_v1.0.pdf) 2014-02-10 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine") for [RapidMiner](https://en.wikipedia.org/wiki/RapidMiner "RapidMiner") 5.0, October 2013.
10.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodgeindepvar_11-0 "Jump up")**Dodge, Y. (2003) _The Oxford Dictionary of Statistical Terms_, OUP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-19-920613-9](https://en.wikipedia.org/wiki/Special:BookSources/0-19-920613-9 "Special:BookSources/0-19-920613-9") (entry for "independent variable")
11.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodgeregression_12-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodgeregression_12-1)[_**c**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodgeregression_12-2)Dodge, Y. (2003) _The Oxford Dictionary of Statistical Terms_, OUP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-19-920613-9](https://en.wikipedia.org/wiki/Special:BookSources/0-19-920613-9 "Special:BookSources/0-19-920613-9") (entry for "regression")
12.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-13 "Jump up")**Gujarati, Damodar N.; [Porter, Dawn C.](https://en.wikipedia.org/wiki/Dawn_C._Porter "Dawn C. Porter") (2009). "Terminology and Notation". _Basic Econometrics_ (Fifth international ed.). New York: McGraw-Hill. p.21. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-007-127625-2](https://en.wikipedia.org/wiki/Special:BookSources/978-007-127625-2 "Special:BookSources/978-007-127625-2").
13.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-14 "Jump up")**Wooldridge, Jeffrey (2012). _Introductory Econometrics: A Modern Approach_ (Fifth ed.). Mason, OH: South-Western Cengage Learning. pp.22–23. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-111-53104-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-111-53104-1 "Special:BookSources/978-1-111-53104-1").
14.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-15 "Jump up")**Last, John M., ed. (2001). _A Dictionary of Epidemiology_ (Fourth ed.). Oxford UP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-19-514168-7](https://en.wikipedia.org/wiki/Special:BookSources/0-19-514168-7 "Special:BookSources/0-19-514168-7").
15.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-16 "Jump up")**Everitt, B. S. (2002). _The Cambridge Dictionary of Statistics_ (2nd ed.). Cambridge UP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-521-81099-X](https://en.wikipedia.org/wiki/Special:BookSources/0-521-81099-X "Special:BookSources/0-521-81099-X").
16.   **[^](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-17 "Jump up")**Woodworth, P. L. (1987). "Trends in U.K. mean sea level". _Marine Geodesy_. **11** (1): 57–87. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1987MarGe..11...57W](https://ui.adsabs.harvard.edu/abs/1987MarGe..11...57W). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1080/15210608709379549](https://doi.org/10.1080%2F15210608709379549).
17.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Everitt1_18-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Everitt1_18-1)Everitt, B.S. (2002) Cambridge Dictionary of Statistics, CUP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-521-81099-X](https://en.wikipedia.org/wiki/Special:BookSources/0-521-81099-X "Special:BookSources/0-521-81099-X")
18.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodge1_19-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-Dodge1_19-1)Dodge, Y. (2003) _The Oxford Dictionary of Statistical Terms_, OUP. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-19-920613-9](https://en.wikipedia.org/wiki/Special:BookSources/0-19-920613-9 "Special:BookSources/0-19-920613-9")
19.   ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-DAUME_20-0)[_**b**_](https://en.wikipedia.org/wiki/Dependent_variable#cite_ref-DAUME_20-1)Ash Narayan Sah (2009) Data Analysis Using Microsoft Excel, New Delhi. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-81-7446-716-4](https://en.wikipedia.org/wiki/Special:BookSources/978-81-7446-716-4 "Special:BookSources/978-81-7446-716-4")
