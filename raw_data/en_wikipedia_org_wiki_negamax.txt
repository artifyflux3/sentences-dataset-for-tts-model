Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Negamax base algorithm 2 Negamax variant with no color parameter 3 Negamax with alpha beta pruning 4 Negamax with alpha beta pruning and transposition tables 5 References 6 External links Toggle the table of contents Negamax 5 languages Español فارسی Italiano Português Српски / srpski Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Variation of minimax game tree search Negamax search is a variant form of minimax search that relies on the zero-sum property of a two-player game .

This algorithm relies on the fact that ⁠ min ( a , b ) = − − max ( − − b , − − a ) {\displaystyle \min(a,b)=-\max(-b,-a)} ⁠ to simplify the implementation of the minimax algorithm. More precisely, the value of a position to player A in such a game is the negation of the value to player B. Thus, the player on move looks for a move that maximizes the negation of the value resulting from the move: this successor position must by definition have been valued by the opponent. The reasoning of the previous sentence works regardless of whether A or B is on move. This means that a single procedure can be used to value both positions. This is a coding simplification over minimax, which requires that A selects the move with the maximum-valued successor while B selects the move with the minimum-valued successor.

It should not be confused with negascout , an algorithm to compute the minimax or negamax value quickly by clever use of alpha–beta pruning discovered in the 1980s. Note that alpha–beta pruning is itself a way to compute the minimax or negamax value of a position quickly by avoiding the search of certain uninteresting positions.

Most adversarial search engines are coded using some form of negamax search.

Negamax base algorithm [ edit ] An animated pedagogical example showing the plain negamax algorithm (that is, without alpha–beta pruning). The person performing the game tree search is considered to be the one that has to move first from the current state of the game ( player in this case) NegaMax operates on the same game trees as those used with the minimax search algorithm. Each node and root node in the tree are game states (such as game board configuration) of a two player game. Transitions to child nodes represent moves available to a player who is about to play from a given node.

The negamax search objective is to find the node score value for the player who is playing at the root node. The pseudocode below shows the negamax base algorithm, [ 1 ] with a configurable limit for the maximum search depth: function negamax(node, depth, color) is if depth = 0 or node is a terminal node then return color × the heuristic value of node
    value := −∞ for each child of node do value := max(value, −negamax(child, depth − 1, −color)) return value (* Initial call for Player A's root node *) negamax(rootNode, depth, 1) (* Initial call for Player B's root node *) negamax(rootNode, depth, −1) The root node inherits its score from one of its immediate child nodes. The child node that ultimately sets the root node's best score also represents the best move to play. Although the negamax function shown only returns the node's best score, practical negamax implementations will retain and return both best move and best score for the root node. Only the node's best score is essential with non-root nodes. And a node's best move isn't necessary to retain nor return for non-root nodes.

What can be confusing is how the heuristic value of the current node is calculated. In this implementation, this value is always calculated from the point of view of player A, whose color value is one. In other words, higher heuristic values always represent situations more favorable for player A. This is the same behavior as the normal minimax algorithm. The heuristic value is not necessarily the same as a node's return value due to value negation by negamax and the color parameter. The negamax node's return value is a heuristic score from the point of view of the node's current player.

Negamax scores match minimax scores for nodes where player A is about to play, and where player A is the maximizing player in the minimax equivalent. Negamax always searches for the maximum value for all its nodes. Hence for player B nodes, the minimax score is a negation of its negamax score. Player B is the minimizing player in the minimax equivalent.

Negamax variant with no color parameter [ edit ] Negamax can be implemented without the color parameter. In this case, the heuristic evaluation function must return values from the point of view of the node's current player rather than an absolute score. For example, the heuristic evaluation function in chess should return a positive value if the current node's player is black and black is winning.

function negamax(node, depth) is if depth = 0 or node is a terminal node then return evaluatePosition() // From current player's perspective
    value := −∞ for each child of node do value := max(value, −negamax(child, depth − 1)) return value // Example picking best move in a chess game using negamax function above function think(boardState) is allMoves := generateLegalMoves(boardState)
    bestMove := null
    bestEvaluation := -∞ for each move in allMoves
        board.apply(move)
        evaluateMove := -negamax(boardState, depth=3)
        board.undo(move) if evaluateMove > bestEvaluation
            bestMove := move
            bestEvaluation := evaluateMove return bestMove Negamax with alpha beta pruning [ edit ] An animated pedagogical example showing the negamax algorithm with alpha–beta pruning. The person performing the game tree search is considered to be the one that has to move first from the current state of the game ( player in this case) Algorithm optimizations for minimax are also equally applicable for Negamax.

Alpha–beta pruning can decrease the number of nodes the negamax algorithm evaluates in a search tree in a manner similar with its use with the minimax algorithm.

The pseudocode for depth-limited negamax search with alpha–beta pruning follows: [ 1 ] function negamax(node, depth, α, β, color) is if depth = 0 or node is a terminal node then return color × the heuristic value of node

    childNodes := generateMoves(node)
    childNodes := orderMoves(childNodes)
    value := −∞ foreach child in childNodes do value := max(value, −negamax(child, depth − 1, −β, −α, −color))
        α := max(α, value) if α ≥ β then break (* cut-off *) return value (* Initial call for Player A's root node *) negamax(rootNode, depth, −∞, +∞, 1) Alpha (α) and beta (β) represent lower and upper bounds for child node values at a given tree depth. Negamax sets the arguments α and β for the root node to the lowest and highest values possible. Other search algorithms, such as negascout and MTD(f) , may initialize α and β with alternate values to further improve tree search performance.

When negamax encounters a child node value outside an alpha/beta range, the negamax search cuts off thereby pruning portions of the game tree from exploration. Cut offs are implicit based on the node return value. A node value found within the range of its initial α and β is the node's exact (or true) value. This value is identical to the result the negamax base algorithm would return, without cut offs and without any α and β bounds. If a node return value is out of range, then the value represents an upper (if value ≤ α) or lower (if value ≥ β) bound for the node's exact value. Alpha–beta pruning eventually discards any value bound results. Such values do not contribute nor affect the negamax value at its root node.

This pseudocode shows the fail-soft variation of alpha–beta pruning. Fail-soft never returns α or β directly as a node value. Thus, a node value may be outside the initial α and β range bounds set with a negamax function call. In contrast, fail-hard alpha–beta pruning always limits a node value in the range of α and β.

This implementation also shows optional move ordering prior to the foreach loop that evaluates child nodes. Move ordering [ 2 ] is an optimization for alpha beta pruning that attempts to guess the most probable child nodes that yield the node's score. The algorithm searches those child nodes first. The result of good guesses is earlier and more frequent alpha/beta cut offs occur, thereby pruning additional game tree branches and remaining child nodes from the search tree.

Negamax with alpha beta pruning and transposition tables [ edit ] Transposition tables selectively memoize the values of nodes in the game tree.

Transposition is a term reference that a given game board position can be reached in more than one way with differing game move sequences.

When negamax searches the game tree, and encounters the same node multiple times, a transposition table can return a previously computed value of the node, skipping potentially lengthy and duplicate re-computation of the node's value. Negamax performance improves particularly for game trees with many paths that lead to a given node in common.

The pseudo code that adds transposition table functions to negamax with alpha/beta pruning is given as follows: [ 1 ] function negamax(node, depth, α, β, color) is alphaOrig := α (* Transposition Table Lookup; node is the lookup key for ttEntry *) ttEntry := transpositionTableLookup(node) if ttEntry.is_valid and ttEntry.depth ≥ depth then if ttEntry.flag = EXACT then return ttEntry.value else if ttEntry.flag = LOWERBOUND and ttEntry.value ≥ beta then return ttEntry.value else if ttEntry.flag = UPPERBOUND and ttEntry.value ≤ alpha then return ttEntry.value if depth = 0 or node is a terminal node then return color × the heuristic value of node

    childNodes := generateMoves(node)
    childNodes := orderMoves(childNodes)
    value := −∞ for each child in childNodes do value := max(value, −negamax(child, depth − 1, −β, −α, −color))
        α := max(α, value) if α ≥ β then break (* Transposition Table Store; node is the lookup key for ttEntry *) ttEntry.value := value if value ≤ alphaOrig then ttEntry.flag := UPPERBOUND else if value ≥ β then ttEntry.flag := LOWERBOUND else ttEntry.flag := EXACT
    ttEntry.depth := depth
    ttEntry.is_valid := true
    transpositionTableStore(node, ttEntry) return value (* Initial call for Player A's root node *) negamax(rootNode, depth, −∞, +∞, 1) Alpha/beta pruning and maximum search depth constraints in negamax can result in partial, inexact, and entirely skipped evaluation of nodes in a game tree. This complicates adding transposition table optimizations for negamax. It is insufficient to track only the node's value in the table, because value may not be the node's true value. The code therefore must preserve and restore the relationship of value with alpha/beta parameters and the search depth for each transposition table entry.

Transposition tables are typically lossy and will omit or overwrite previous values of certain game tree nodes in its tables. This is necessary since the number of nodes negamax visits often far exceeds the transposition table size. Lost or omitted table entries are non-critical and will not affect the negamax result. However, lost entries may require negamax to re-compute certain game tree node values more frequently, thus affecting performance.

References [ edit ] George T. Heineman; Gary Pollice & Stanley Selkow (2008). "Chapter 7:Path Finding in AI".

Algorithms in a Nutshell .

Oreilly Media . pp.

213– 217.

ISBN 978-0-596-51624-6 .

John P. Fishburn (1984). "Appendix A: Some Optimizations of α-β Search".

Analysis of Speedup in Distributed Algorithms (revision of 1981 PhD thesis) .

UMI Research Press . pp.

107– 111.

ISBN 0-8357-1527-2 .

^ a b c Breuker, Dennis M.

Memory versus Search in Games , Maastricht University, October 16, 1998 ^ Schaeffer, Jonathan (1989). "The History Heuristic and Alpha–Beta Search Enhancements in Practice".

IEEE Transactions on Pattern Analysis and Machine Intelligence .

11 (11): 1203– 12.

doi : 10.1109/34.42858 .

External links [ edit ] Negamax at the Chess Programming Wiki A C99 implementation of the Negamax algorithm for the Tic-Tac-Toe game v t e Game theory Glossary Game theorists Games Traditional game theory Definitions Asynchrony Bayesian regret Best response Bounded rationality Cheap talk Coalition Complete contract Complete information Complete mixing Confrontation analysis Conjectural variation Contingent cooperator Coopetition Cooperative game theory Dynamic inconsistency Escalation of commitment Farsightedness Game semantics Hierarchy of beliefs Imperfect information Incomplete information Information set Move by nature Mutual knowledge Non-cooperative game theory Non-credible threat Outcome Perfect information Perfect recall Ply Preference Rationality Sequential game Simultaneous action selection Spite Strategic complements Strategic dominance Strategic form Strategic interaction Strategic move Strategy Subgame Succinct game Topological game Tragedy of the commons Uncorrelated asymmetry Equilibrium concepts Backward induction Bayes correlated equilibrium Bayesian efficiency Bayesian game Bayesian Nash equilibrium Berge equilibrium Bertrand–Edgeworth model Coalition-proof Nash equilibrium Core Correlated equilibrium Cursed equilibrium Edgeworth price cycle Epsilon-equilibrium Gibbs equilibrium Incomplete contracts Inequity aversion Individual rationality Iterated elimination of dominated strategies Markov perfect equilibrium Mertens-stable equilibrium Nash equilibrium Open-loop model Pareto efficiency Payoff dominance Perfect Bayesian equilibrium Price of anarchy Program equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Rational agent Rationalizability Rationalizable strategy Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfect equilibrium Trembling hand equilibrium Strategies Appeasement Bid shading Cheap talk Collusion Commitment device De-escalation Deterrence Escalation Fictitious play Focal point Grim trigger Hobbesian trap Markov strategy Max-dominated strategy Mixed strategy Pure strategy Tit for tat Win–stay, lose–switch Games All-pay auction Battle of the sexes Nash bargaining game Bertrand competition Blotto game Centipede game Coordination game Cournot competition Deadlock Dictator game Trust game Diner's dilemma Dollar auction El Farol Bar problem Electronic mail game Gift-exchange game Guess 2/3 of the average Keynesian beauty contest Kuhn poker Lewis signaling game Matching pennies Obligationes Optional prisoner's dilemma Pirate game Prisoner's dilemma Public goods game Rendezvous problem Rock paper scissors Stackelberg competition Stag hunt Traveler's dilemma Ultimatum game Volunteer's dilemma War of attrition Theorems Arrow's impossibility theorem Aumann's agreement theorem Brouwer fixed-point theorem Competitive altruism Folk theorem Gibbard–Satterthwaite theorem Gibbs lemma Glicksberg's theorem Kakutani fixed-point theorem Kuhn's theorem One-shot deviation principle Prim–Read theory Rational ignorance Rational irrationality Sperner's lemma Zermelo's theorem Subfields Algorithmic game theory Behavioral game theory Behavioral strategy Compositional game theory Contract theory Drama theory Graphical game theory Heresthetic Mean-field game theory Negotiation theory Quantum game theory Social software Key people Albert W. Tucker Alvin E. Roth Amos Tversky Antoine Augustin Cournot Ariel Rubinstein David Gale David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Herbert Scarf Hervé Moulin Jean Tirole Jean-François Mertens Jennifer Tour Chayes Ken Binmore Kenneth Arrow Leonid Hurwicz Lloyd Shapley Martin Shubik Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Aumann Robert Axelrod Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Combinatorial game theory Core concepts Combinatorial explosion Determinacy Disjunctive sum First-player and second-player win Game complexity Game tree Impartial game Misère Partisan game Solved game Sprague–Grundy theorem Strategy-stealing argument Zugzwang Games Chess Chomp Clobber Cram Domineering Hackenbush Nim Notakto Subtract a square Sylver coinage Toads and Frogs Mathematical tools Mex Nimber On Numbers and Games Star Surreal number Winning Ways for Your Mathematical Plays Search algorithms Alpha–beta pruning Expectiminimax Minimax Monte Carlo tree search Negamax Paranoid algorithm Principal variation search Key people Claude Shannon John Conway John von Neumann Evolutionary game theory Core concepts Bishop–Cannings theorem Evolution and the Theory of Games Evolutionarily stable set Evolutionarily stable state Evolutionarily stable strategy Replicator equation Risk dominance Stochastically stable equilibrium Weak evolutionarily stable strategy Games Chicken Stag hunt Applications Cultural group selection Fisher's principle Mobbing Terminal investment hypothesis Key people John Maynard Smith Robert Axelrod Mechanism design Core concepts Algorithmic mechanism design Bayesian-optimal mechanism Incentive compatibility Market design Monotonicity Participation constraint Revelation principle Strategyproofness Vickrey–Clarke–Groves mechanism Theorems Myerson–Satterthwaite theorem Revenue equivalence Applications Digital goods auction Knapsack auction Truthful cake-cutting Other topics Bertrand paradox Chainstore paradox Computational complexity of games Helly metric Multi-agent system PPAD-complete Mathematics portal Commons WikiProject Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Negamax&oldid=1292169742 " Categories : Game artificial intelligence Optimization algorithms and methods Combinatorial game theory Hidden categories: Articles with short description Short description is different from Wikidata Articles with example pseudocode This page was last edited on 25 May 2025, at 15:23 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Negamax 5 languages Add topic

