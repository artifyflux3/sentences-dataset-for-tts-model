Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Applications 2 Definition and calculation 3 Related quantities 4 Interpretation 5 Example 6 Confidence intervals 7 Determining significance 8 Correspondence analysis based on Spearman's ρ 9 Approximating Spearman's ρ from a stream 10 Software implementations 11 See also 12 References 13 Further reading 14 External links Toggle the table of contents Spearman's rank correlation coefficient 28 languages العربية Català Čeština Ελληνικά Español Euskara فارسی Français 한국어 हिन्दी Italiano עברית Latviešu Magyar Nederlands 日本語 Polski Português Русский Simple English Slovenščina Suomi Svenska Tagalog Türkçe Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Nonparametric measure of rank correlation A Spearman correlation of 1 {\textstyle 1} results when the two variables being compared are monotonically related, even if their relationship is not linear. This means that all data points with greater x {\textstyle x} values than that of a given data point will have greater y {\textstyle y} values as well. In contrast, this does not give a perfect Pearson correlation.

When the data are roughly elliptically distributed and there are no prominent outliers, the Spearman correlation and Pearson correlation give similar values.

The Spearman correlation is less sensitive than the Pearson correlation to strong outliers that are in the tails of both samples. That is because Spearman's ρ limits the outlier to the value of its rank.

In statistics , Spearman's rank correlation coefficient or Spearman's ρ is a number ranging from -1 to 1 that indicates how strongly two sets of ranks are correlated. It could be used in a situation where one only has ranked data, such as a tally of gold, silver, and bronze medals. If a statistician wanted to know whether people who are high ranking in sprinting are also high ranking in long-distance running, they would use a Spearman rank correlation coefficient.

The coefficient is named after Charles Spearman [ 1 ] and often denoted by the Greek letter ρ ρ {\displaystyle \rho } (rho) or as r s {\displaystyle r_{s}} . It is a nonparametric measure of rank correlation ( statistical dependence between the rankings of two variables ). It assesses how well the relationship between two variables can be described using a monotonic function .

The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other.

Intuitively, the Spearman correlation between two variables will be high when observations have a similar (or identical for a correlation of 1) rank (i.e. relative position label of the observations within the variable: 1st, 2nd, 3rd, etc.) between the two variables, and low when observations have a dissimilar (or fully opposed for a correlation of −1) rank between the two variables.

Spearman's coefficient is appropriate for both continuous and discrete ordinal variables .

[ 2 ] [ 3 ] Both Spearman's ρ ρ {\displaystyle \rho } and Kendall's τ τ {\displaystyle \tau } can be formulated as special cases of a more general correlation coefficient .

Applications [ edit ] The coefficient can be used to determine how well data fits a model, [ 4 ] like when determining the similarity of text documents.

[ 5 ] Definition and calculation [ edit ] The Spearman correlation coefficient is defined as the Pearson correlation coefficient between the rank variables .

[ 6 ] For a sample of size n , {\displaystyle \ n\ ,} the n {\displaystyle \ n\ } pairs of raw scores ( X i , Y i ) {\displaystyle \ \left(X_{i},Y_{i}\right)\ } are converted to ranks R ⁡ ⁡ [ X i ] , R ⁡ ⁡ [ Y i ] , {\displaystyle \ \operatorname {R} [{X_{i}}],\operatorname {R} [{Y_{i}}]\ ,} and r s {\displaystyle \ r_{s}\ } is computed as r s = ρ ρ ⁡ ⁡ [ R ⁡ ⁡ [ X ] , R ⁡ ⁡ [ Y ] ] = c o v ⁡ ⁡ [ R ⁡ ⁡ [ X ] , R ⁡ ⁡ [ Y ] ] σ σ R ⁡ ⁡ [ X ] σ σ R ⁡ ⁡ [ Y ] , {\displaystyle r_{s}=\operatorname {\rho } {\bigl [}\ \operatorname {R} [X],\operatorname {R} [Y]\ {\bigr ]}={\frac {\ \operatorname {\mathsf {cov}} {\bigl [}\ \operatorname {R} [X],\operatorname {R} [Y]\ {\bigr ]}\ }{\ \sigma _{\operatorname {R} [X]}\ \sigma _{\operatorname {R} [Y]}\ }},} where ρ ρ ⁡ ⁡ {\displaystyle \operatorname {\rho } \ } denotes the conventional Pearson correlation coefficient operator , but applied to the rank variables, c o v ⁡ ⁡ [ R ⁡ ⁡ [ X ] , R ⁡ ⁡ [ Y ] ] {\displaystyle \operatorname {\mathsf {cov}} {\bigl [}\ \operatorname {R} [X],\operatorname {R} [Y]\ {\bigr ]}\ } is the covariance of the rank variables, σ σ R ⁡ ⁡ [ X ] {\displaystyle \sigma _{\operatorname {R} [X]}\ } and σ σ R ⁡ ⁡ [ Y ] {\displaystyle \ \sigma _{\operatorname {R} [Y]}\ } are the standard deviations of the rank variables.

Only when all n {\displaystyle \ n\ } ranks are distinct integers (no ties), it can be computed using the popular formula r s = 1 − − 6 ∑ ∑ d i 2 n ( n 2 − − 1 ) , {\displaystyle r_{s}=1-{\frac {6\sum d_{i}^{2}}{\ n\left(n^{2}-1\right)\ }}\ ,} where d i ≡ ≡ R ⁡ ⁡ [ X i ] − − R ⁡ ⁡ [ Y i ] {\displaystyle d_{i}\equiv \operatorname {R} [X_{i}]-\operatorname {R} [Y_{i}]\ } is the difference between the two ranks of each observation, n {\displaystyle \ n\ } is the number of observations.

[Proof] Consider a bivariate sample ( X i , Y i ) , i = 1 , … … n {\displaystyle \ (X_{i},Y_{i})\ ,\ i=1,\ldots \ n\ } with corresponding rank pairs ( R ⁡ ⁡ [ X i ] , R ⁡ ⁡ [ Y i ] ) = ( R i , S i ) .

{\displaystyle \ \left(\operatorname {R} [X_{i}],\operatorname {R} [Y_{i}]\right)=(R_{i},S_{i})~.} Then the Spearman correlation coefficient of ( X , Y ) {\displaystyle \ (X,Y)\ } is r s = 1 n ∑ ∑ i = 1 n R i S i − − R ¯ ¯ S ¯ ¯ σ σ R σ σ S , {\displaystyle r_{s}={\frac {{\frac {\ 1\ }{n}}\ \sum _{i=1}^{n}R_{i}\ S_{i}-{\overline {R}}\ {\overline {S}}}{\sigma _{R}\sigma _{S}}}\ ,} where, as usual, R ¯ ¯ = 1 n ∑ ∑ i = 1 n R i , {\displaystyle {\overline {R}}=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}R_{i}\ ,} S ¯ ¯ = 1 n ∑ ∑ i = 1 n S i , {\displaystyle {\overline {S}}=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}S_{i}\ ,} σ σ R 2 = 1 n ∑ ∑ i = 1 n ( R i − − R ¯ ¯ ) 2 , {\displaystyle \sigma _{R}^{2}=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}\left(R_{i}-{\overline {R}}\right)^{2}\ ,} and σ σ S 2 = 1 n ∑ ∑ i = 1 n ( S i − − S ¯ ¯ ) 2 .

{\displaystyle \sigma _{S}^{2}=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}\left(S_{i}-{\overline {S}}\right)^{2}~.} We shall show that r s {\displaystyle \ r_{s}\ } can be expressed purely in terms of d i ≡ ≡ R i − − S i , {\displaystyle \ d_{i}\equiv R_{i}-S_{i}\ ,} provided we assume that there be no ties within each sample.

Under this assumption, we have that R , S {\displaystyle \ R,S\ } can be viewed as random variables
distributed like a uniformly distributed discrete random variable, U , {\displaystyle \ U\ ,} on { 1 , 2 , … … , n } .

{\displaystyle \ \{\ 1,2,\ \ldots ,\ n\ \}~.} Hence R ¯ ¯ = S ¯ ¯ = E ⁡ ⁡ [ U ] {\displaystyle \ {\overline {R}}={\overline {S}}=\operatorname {\mathbb {E} } \left[\ U\ \right]\ } and σ σ R 2 = σ σ S 2 = V a r ⁡ ⁡ [ U ] = E ⁡ ⁡ [ U 2 ] − − E ⁡ ⁡ [ U ] 2 , {\displaystyle \ \sigma _{R}^{2}=\sigma _{S}^{2}=\operatorname {\mathsf {Var}} \left[\ U\ \right]=\operatorname {\mathbb {E} } \left[\ U^{2}\ \right]-\operatorname {\mathbb {E} } \left[\ U\ \right]^{2}\ ,} where E ⁡ ⁡ [ U ] = 1 n ∑ ∑ i = 1 n i = n + 1 2 , {\displaystyle \operatorname {\mathbb {E} } \left[\ U\ \right]=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}i=\textstyle {\frac {\ n+1\ }{2}}\ ,} E ⁡ ⁡ [ U 2 ] = 1 n ∑ ∑ i = 1 n i 2 = ( n + 1 ) ( 2 n + 1 ) 6 , {\displaystyle \operatorname {\mathbb {E} } \left[\ U^{2}\ \right]=\textstyle {\frac {\ 1\ }{n}}\ \textstyle \sum _{i=1}^{n}i^{2}=\textstyle {\frac {\ \left(n+1\right)\left(2n+1\right)\ }{6}}\ ,} and thus v a r ⁡ ⁡ [ U ] = ( n + 1 ) ( 2 n + 1 ) 6 − − ( n + 1 2 ) 2 = n 2 − − 1 12 .

{\displaystyle \operatorname {\mathsf {var}} \left[\ U\right]=\textstyle {\frac {\ \left(n+1\right)\ \left(2n+1\right)\ }{6}}-\left(\textstyle {\frac {\ n+1\ }{2}}\right)^{2}=\textstyle {\frac {\ n^{2}-1\ }{12}}~.} (These sums can be computed using the formulas for the triangular numbers and square pyramidal numbers , or basic summation results from umbral calculus .) Observe now that 1 n ∑ ∑ i = 1 n R i S i − − R ¯ ¯ S ¯ ¯ = 1 n ∑ ∑ i = 1 n 1 2 ( R i 2 + S i 2 − − d i 2 ) − − R ¯ ¯ 2 = 1 2 1 n ∑ ∑ i = 1 n R i 2 + 1 2 1 n ∑ ∑ i = 1 n S i 2 − − 1 2 n ∑ ∑ i = 1 n d i 2 − − R ¯ ¯ 2 = ( 1 n ∑ ∑ i = 1 n R i 2 − − R ¯ ¯ 2 ) − − 1 2 n ∑ ∑ i = 1 n d i 2 = σ σ R 2 − − 1 2 n ∑ ∑ i = 1 n d i 2 = σ σ R σ σ S − − 1 2 n ∑ ∑ i = 1 n d i 2 {\displaystyle {\begin{aligned}{\frac {\ 1\ }{n}}\ &\sum _{i=1}^{n}R_{i}S_{i}-{\overline {R}}{\overline {S}}\\&={\frac {\ 1\ }{n}}\ \sum _{i=1}^{n}{\frac {\ 1\ }{2}}\left(R_{i}^{2}+S_{i}^{2}-d_{i}^{2}\right)-{\overline {R}}^{2}\\&={\frac {\ 1\ }{2}}{\frac {\ 1\ }{n}}\ \sum _{i=1}^{n}R_{i}^{2}+{\frac {\ 1\ }{2}}{\frac {\ 1\ }{n}}\ \sum _{i=1}^{n}S_{i}^{2}-{\frac {\ 1\ }{2n}}\ \sum _{i=1}^{n}d_{i}^{2}-{\overline {R}}^{2}\\&=\left({\frac {\ 1\ }{n}}\ \sum _{i=1}^{n}R_{i}^{2}-{\overline {R}}^{2}\right)-{\frac {\ 1\ }{2n}}\ \sum _{i=1}^{n}d_{i}^{2}\\&=\sigma _{R}^{2}-{\frac {\ 1\ }{2n}}\ \sum _{i=1}^{n}d_{i}^{2}\\&=\sigma _{R}\ \sigma _{S}-{\frac {\ 1\ }{2n}}\ \sum _{i=1}^{n}d_{i}^{2}\\\end{aligned}}} Putting this all together thus yields r s = σ σ R σ σ S − − 1 2 n ∑ ∑ i = 1 n d i 2 σ σ R σ σ S = 1 − − ∑ ∑ i = 1 n d i 2 2 n ⋅ ⋅ n 2 − − 1 12 = 1 − − 6 ∑ ∑ i = 1 n d i 2 n ( n 2 − − 1 ) .

{\displaystyle {\begin{aligned}r_{s}&={\frac {\ \sigma _{R}\ \sigma _{S}-{\frac {\ 1\ }{2n}}\ \sum _{i=1}^{n}d_{i}^{2}\ }{\sigma _{R}\ \sigma _{S}}}\\&=1-{\frac {\ \sum _{i=1}^{n}d_{i}^{2}\ }{2n\cdot {\frac {\ n^{2}-1\ }{12}}}}\\&=1-{\frac {\ 6\ \sum _{i=1}^{n}d_{i}^{2}}{\ n(n^{2}-1)\ }}~.\end{aligned}}} Identical values are usually [ 7 ] each assigned fractional ranks equal to the average of their positions in the ascending order of the values, which is equivalent to averaging over all possible permutations.

If ties are present in the data set, the simplified formula above yields incorrect results: Only if in both variables all ranks are distinct, then σ σ R ⁡ ⁡ [ X ] σ σ R ⁡ ⁡ [ Y ] = {\displaystyle \ \sigma _{\operatorname {R} [X]}\ \sigma _{\operatorname {R} [Y]}=} v a r ⁡ ⁡ [ R ⁡ ⁡ [ X ] ] = {\displaystyle \ \operatorname {{\mathsf {v}}ar} {\bigl [}\ \operatorname {R} [X]\ {\bigr ]}=} v a r ⁡ ⁡ [ R ⁡ ⁡ [ Y ] ] = {\displaystyle \ \operatorname {{\mathsf {v}}ar} {\bigl [}\ \operatorname {R} [Y]\ {\bigr ]}=} 1 12 ( n 2 − − 1 ) {\displaystyle \ {\tfrac {\ 1\ }{12}}\left(n^{2}-1\right)\ } (calculated according to biased variance).
The first equation — normalizing by the standard deviation — may be used even when ranks are normalized to [0, 1] ("relative ranks") because it is insensitive both to translation and linear scaling.

The simplified method should also not be used in cases where the data set is truncated; that is, when the Spearman's correlation coefficient is desired for the top X records (whether by pre-change rank or post-change rank, or both), the user should use the Pearson correlation coefficient formula given above.

[ 8 ] Related quantities [ edit ] Main article: Correlation and dependence There are several other numerical measures that quantify the extent of statistical dependence between pairs of observations. The most common of these is the Pearson product-moment correlation coefficient , which is a similar correlation method to Spearman's rank, that measures the "linear" relationships between the raw numbers rather than between their ranks.

An alternative name for the Spearman rank correlation is the "grade correlation"; [ 9 ] in this, the "rank" of an observation is replaced by the "grade". In continuous distributions, the grade of an observation is, by convention, always one half less than the rank, and hence the grade and rank correlations are the same in this case. More generally, the "grade" of an observation is proportional to an estimate of the fraction of a population less than a given value, with the half-observation adjustment at observed values. Thus this corresponds to one possible treatment of tied ranks. While unusual, the term "grade correlation" is still in use.

[ 10 ] Interpretation [ edit ] Positive and negative Spearman rank correlations A positive Spearman correlation coefficient corresponds to an increasing monotonic trend between X and Y .

A negative Spearman correlation coefficient corresponds to a decreasing monotonic trend between X and Y .

The sign of the Spearman correlation indicates the direction of association between X (the independent variable) and Y (the dependent variable).  If Y tends to increase when X increases, the Spearman correlation coefficient is positive.  If Y tends to decrease when X increases, the Spearman correlation coefficient is negative.  A Spearman correlation of zero indicates that there is no tendency for Y to either increase or decrease when X increases.  The Spearman correlation increases in magnitude as X and Y become closer to being perfectly monotonic functions of each other.  When X and Y are perfectly monotonically related, the Spearman correlation coefficient becomes 1.  A perfectly monotonic increasing relationship implies that for any two pairs of data values X i , Y i and X j , Y j , that X i − X j and Y i − Y j always have the same sign.  A perfectly monotonic decreasing relationship implies that these differences always have opposite signs.

The Spearman correlation coefficient is often described as being "nonparametric".  This can have two meanings.  First, a perfect Spearman correlation results when X and Y are related by any monotonic function . Contrast this with the Pearson correlation, which only gives a perfect value when X and Y are related by a linear function. The other sense in which the Spearman correlation is nonparametric is that its exact sampling distribution can be obtained without requiring knowledge (i.e., knowing the parameters) of the joint probability distribution of X and Y .

Example [ edit ] In this example, the arbitrary raw data in the table below is used to calculate the correlation between the IQ of a person with the number of hours spent in front of TV per week [fictitious values used].

IQ , X i {\displaystyle X_{i}} Hours of TV per week, Y i {\displaystyle Y_{i}} 106 7 100 27 86 2 101 50 99 28 103 29 97 20 113 12 112 6 110 17 Firstly, evaluate d i 2 {\displaystyle d_{i}^{2}} . To do so use the following steps, reflected in the table below.

Sort the data by the first column ( X i {\displaystyle X_{i}} ). Create a new column x i {\displaystyle x_{i}} and assign it the ranked values 1, 2, 3, ..., n .

Next, sort the augmented (with x i {\displaystyle x_{i}} ) data by the second column ( Y i {\displaystyle Y_{i}} ). Create a fourth column y i {\displaystyle y_{i}} and similarly assign it the ranked values 1, 2, 3, ..., n .

Create a fifth column d i {\displaystyle d_{i}} to hold the differences between the two rank columns ( x i {\displaystyle x_{i}} and y i {\displaystyle y_{i}} ).

Create one final column d i 2 {\displaystyle d_{i}^{2}} to hold the value of column d i {\displaystyle d_{i}} squared.

IQ , X i {\displaystyle X_{i}} Hours of TV per week, Y i {\displaystyle Y_{i}} rank x i {\displaystyle x_{i}} rank y i {\displaystyle y_{i}} d i {\displaystyle d_{i}} d i 2 {\displaystyle d_{i}^{2}} 86 2 1 1 0 0 97 20 2 6 −4 16 99 28 3 8 −5 25 100 27 4 7 −3 9 101 50 5 10 −5 25 103 29 6 9 −3 9 106 7 7 3 4 16 110 17 8 5 3 9 112 6 9 2 7 49 113 12 10 4 6 36 With d i 2 {\displaystyle d_{i}^{2}} found, add them to find ∑ ∑ d i 2 = 194 {\displaystyle \sum d_{i}^{2}=194} . The value of n is 10. These values can now be substituted back into the equation ρ ρ = 1 − − 6 ∑ ∑ d i 2 n ( n 2 − − 1 ) {\displaystyle \rho =1-{\frac {6\sum d_{i}^{2}}{n(n^{2}-1)}}} to give ρ ρ = 1 − − 6 × × 194 10 ( 10 2 − − 1 ) , {\displaystyle \rho =1-{\frac {6\times 194}{10(10^{2}-1)}},} which evaluates to ρ = −29/165 = −0.175757575...

with a p -value = 0.627188 (using the t -distribution ).

Chart of the data presented. It can be seen that there might be a negative correlation, but that the relationship does not appear definitive.

That the value is close to zero shows that the correlation between IQ and hours spent watching TV is very low, although the negative value suggests that the longer the time spent watching television the lower the IQ. In the case of ties in the original values, this formula should not be used; instead, the Pearson correlation coefficient should be calculated on the ranks (where ties are given ranks, as described above).

Confidence intervals [ edit ] Confidence intervals for Spearman's ρ can be easily obtained using the Jackknife Euclidean likelihood approach in de Carvalho and Marques (2012).

[ 11 ] The confidence interval with level α α {\displaystyle \alpha } is based on a Wilks' theorem given in the latter paper, and is given by { θ θ : { ∑ ∑ i = 1 n ( Z i − − θ θ ) } 2 ∑ ∑ i = 1 n ( Z i − − θ θ ) 2 ≤ ≤ χ χ 1 , α α 2 } , {\displaystyle \left\{\theta :{\frac {\{\sum _{i=1}^{n}(Z_{i}-\theta )\}^{2}}{\sum _{i=1}^{n}(Z_{i}-\theta )^{2}}}\leq \chi _{1,\alpha }^{2}\right\},} where χ χ 1 , α α 2 {\displaystyle \chi _{1,\alpha }^{2}} is the α α {\displaystyle \alpha } quantile of a chi-square distribution with one degree of freedom, and the Z i {\displaystyle Z_{i}} are jackknife pseudo-values. This approach is implemented in the R package spearmanCI .

Determining significance [ edit ] One approach to test whether an observed value of ρ is significantly different from zero ( r will always maintain −1 ≤ r ≤ 1 ) is to calculate the probability that it would be greater than or equal to the observed r , given the null hypothesis , by using a permutation test . An advantage of this approach is that it automatically takes into account the number of tied data values in the sample and the way they are treated in computing the rank correlation.

Another approach parallels the use of the Fisher transformation in the case of the Pearson product-moment correlation coefficient. That is, confidence intervals and hypothesis tests relating to the population value ρ can be carried out using the Fisher transformation: F ( r ) = 1 2 ln ⁡ ⁡ 1 + r 1 − − r = arctanh ⁡ ⁡ r .

{\displaystyle F(r)={\frac {1}{2}}\ln {\frac {1+r}{1-r}}=\operatorname {arctanh} r.} If F ( r ) is the Fisher transformation of r , the sample Spearman rank correlation coefficient, and n is the sample size, then z = n − − 3 1.06 F ( r ) {\displaystyle z={\sqrt {\frac {n-3}{1.06}}}F(r)} is a z -score for r , which approximately follows a standard normal distribution under the null hypothesis of statistical independence ( ρ = 0 ).

[ 12 ] [ 13 ] One can also test for significance using t = r n − − 2 1 − − r 2 , {\displaystyle t=r{\sqrt {\frac {n-2}{1-r^{2}}}},} which is distributed approximately as Student's t -distribution with n − 2 degrees of freedom under the null hypothesis .

[ 14 ] A justification for this result relies on a permutation argument.

[ 15 ] A generalization of the Spearman coefficient is useful in the situation where there are three or more conditions, a number of subjects are all observed in each of them, and it is predicted that the observations will have a particular order.  For example, a number of subjects might each be given three trials at the same task, and it is predicted that performance will improve from trial to trial.  A test of the significance of the trend between conditions in this situation was developed by E. B. Page [ 16 ] and is usually referred to as Page's trend test for ordered alternatives.

Correspondence analysis based on Spearman's ρ [ edit ] Classic correspondence analysis is a statistical method that gives a score to every value of two nominal variables. In this way the Pearson correlation coefficient between them is maximized.

There exists an equivalent of this method, called grade correspondence analysis , which maximizes Spearman's ρ or Kendall's τ .

[ 17 ] Approximating Spearman's ρ from a stream [ edit ] There are two existing approaches to approximating the Spearman's rank correlation coefficient from streaming data.

[ 18 ] [ 19 ] The first approach [ 18 ] involves coarsening the joint distribution of ( X , Y ) {\displaystyle (X,Y)} . For continuous X , Y {\displaystyle X,Y} values: m 1 , m 2 {\displaystyle m_{1},m_{2}} cutpoints are selected for X {\displaystyle X} and Y {\displaystyle Y} respectively, discretizing
these random variables. Default cutpoints are added at − − ∞ ∞ {\displaystyle -\infty } and ∞ ∞ {\displaystyle \infty } .  A count matrix of size ( m 1 + 1 ) × × ( m 2 + 1 ) {\displaystyle (m_{1}+1)\times (m_{2}+1)} , denoted M {\displaystyle M} , is then constructed where M [ i , j ] {\displaystyle M[i,j]} stores the number of observations that
fall into the two-dimensional cell indexed by ( i , j ) {\displaystyle (i,j)} . For streaming data, when a new observation arrives, the appropriate M [ i , j ] {\displaystyle M[i,j]} element is incremented. The Spearman's rank
correlation can then be computed, based on the count matrix M {\displaystyle M} , using linear algebra operations (Algorithm 2 [ 18 ] ). Note that for discrete random
variables, no discretization procedure is necessary. This method is applicable to stationary streaming data as well as large data sets. For non-stationary streaming data, where the Spearman's rank correlation coefficient may change over time, the same procedure can be applied, but to a moving window of observations. When using a moving window, memory requirements grow linearly with chosen window size.

The second approach to approximating the Spearman's rank correlation coefficient from streaming data involves the use of Hermite series based estimators.

[ 19 ] These estimators, based on Hermite polynomials ,
allow sequential estimation of the probability density function and cumulative distribution function in univariate and bivariate cases. Bivariate Hermite series density
estimators and univariate Hermite series based cumulative distribution function estimators are plugged into a large sample version of the
Spearman's rank correlation coefficient estimator, to give a sequential Spearman's correlation estimator. This estimator is phrased in
terms of linear algebra operations for computational efficiency (equation (8) and algorithm 1 and 2 [ 19 ] ). These algorithms are only applicable to continuous random variable data, but have
certain advantages over the count matrix approach in this setting. The first advantage is improved accuracy when applied to large numbers of observations. The second advantage is that the Spearman's rank correlation coefficient can be
computed on non-stationary streams without relying on a moving window.  Instead, the Hermite series based estimator uses an exponential weighting scheme to track time-varying Spearman's rank correlation from streaming data,
which has constant memory requirements with respect to "effective" moving window size. A software implementation of these Hermite series based algorithms exists [ 20 ] and is discussed in Software implementations.

Software implementations [ edit ] R 's statistics base-package implements the test cor.test(x, y, method = "spearman") in its "stats" package (also cor(x, y, method = "spearman") will work). The package spearmanCI computes confidence intervals. The package hermiter [ 20 ] computes fast batch estimates of the Spearman correlation along with sequential estimates (i.e. estimates that are updated in an online/incremental manner as new observations are incorporated).

Stata implementation: spearman varlist calculates all pairwise correlation coefficients for all variables in varlist .

MATLAB implementation: [r,p] = corr(x,y,'Type','Spearman') where r is the Spearman's rank correlation coefficient, p is the p-value, and x and y are vectors.

[ 21 ] Python has many different implementations of the spearman correlation statistic: it can be computed with the spearmanr function of the scipy.stats module, as well as with the DataFrame.corr(method='spearman') method from the pandas library, and the corr(x, y, method='spearman') function from the statistical package pingouin .

See also [ edit ] Mathematics portal Kendall tau rank correlation coefficient Chebyshev's sum inequality , rearrangement inequality (These two articles may shed light on the mathematical properties of Spearman's ρ .) Distance correlation Polychoric correlation References [ edit ] ^ Spearman, C. (January 1904).

"The Proof and Measurement of Association between Two Things" (PDF) .

The American Journal of Psychology .

15 (1): 72– 101.

doi : 10.2307/1412159 .

JSTOR 1412159 .

^ Scale types .

^ Lehman, Ann (2005).

Jmp For Basic Univariate And Multivariate Statistics: A Step-by-step Guide . Cary, NC: SAS Press. p.

123 .

ISBN 978-1-59047-576-8 .

^ Royal Geographic Society.

"A Guide to Spearman's Rank" (PDF) .

^ Nino Arsov; Milan Dukovski; Milan Dukovski; Blagoja Evkoski (November 2019).

"A Measure of Similarity in Textual Data Using Spearman's Rank Correlation Coefficient" .

^ Myers, Jerome L.; Well, Arnold D. (2003).

Research Design and Statistical Analysis (2nd ed.). Lawrence Erlbaum. pp.

508 .

ISBN 978-0-8058-4037-7 .

^ Dodge, Yadolah, ed. (2010).

The Concise Encyclopedia of Statistics . New York, NY: Springer-Verlag. p.

502 .

ISBN 978-0-387-31742-7 .

^ al Jaber, Ahmed Odeh; Elayyan, Haifaa Omar (2018).

Toward Quality Assurance and Excellence in Higher Education . River Publishers. p. 284.

ISBN 978-87-93609-54-9 .

^ Yule, G. U.; Kendall, M. G. (1968) [1950].

An Introduction to the Theory of Statistics (14th ed.). Charles Griffin & Co. p. 268.

^ Piantadosi, J.; Howlett, P.; Boland, J. (2007).

"Matching the grade correlation coefficient using a copula with maximum disorder" .

Journal of Industrial and Management Optimization .

3 (2): 305– 312.

doi : 10.3934/jimo.2007.3.305 .

^ de Carvalho, M.; Marques, F. (2012).

"Jackknife Euclidean likelihood-based inference for Spearman's rho" (PDF) .

North American Actuarial Journal .

16 (4): 487‒492.

doi : 10.1080/10920277.2012.10597644 .

S2CID 55046385 .

^ Choi, S. C. (1977). "Tests of Equality of Dependent Correlation Coefficients".

Biometrika .

64 (3): 645– 647.

doi : 10.1093/biomet/64.3.645 .

^ Fieller, E. C.; Hartley, H. O.; Pearson, E. S. (1957). "Tests for rank correlation coefficients. I".

Biometrika .

44 ( 3– 4): 470– 481.

CiteSeerX 10.1.1.474.9634 .

doi : 10.1093/biomet/44.3-4.470 .

^ Press; Vettering; Teukolsky; Flannery (1992).

Numerical Recipes in C: The Art of Scientific Computing (2nd ed.). Cambridge University Press. p. 640.

ISBN 9780521437202 .

^ Kendall, M. G.; Stuart, A. (1973). "Sections 31.19, 31.21".

The Advanced Theory of Statistics, Volume 2: Inference and Relationship . Griffin.

ISBN 978-0-85264-215-3 .

^ Page, E. B. (1963). "Ordered hypotheses for multiple treatments: A significance test for linear ranks".

Journal of the American Statistical Association .

58 (301): 216– 230.

doi : 10.2307/2282965 .

JSTOR 2282965 .

^ Kowalczyk, T.; Pleszczyńska, E.; Ruland, F., eds. (2004).

Grade Models and Methods for Data Analysis with Applications for the Analysis of Data Populations . Studies in Fuzziness and Soft Computing. Vol. 151. Berlin Heidelberg New York: Springer Verlag.

ISBN 978-3-540-21120-4 .

^ a b c Xiao, W. (2019). "Novel Online Algorithms for Nonparametric Correlations with Application to Analyze Sensor Data".

2019 IEEE International Conference on Big Data (Big Data) . pp.

404– 412.

doi : 10.1109/BigData47090.2019.9006483 .

ISBN 978-1-7281-0858-2 .

S2CID 211298570 .

^ a b c Stephanou, Michael; Varughese, Melvin (July 2021). "Sequential estimation of Spearman rank correlation using Hermite series estimators".

Journal of Multivariate Analysis .

186 : 104783.

arXiv : 2012.06287 .

doi : 10.1016/j.jmva.2021.104783 .

S2CID 235742634 .

^ a b Stephanou, Michaeal; Varughese, Melvin (2023). "Hermiter: R package for sequential nonparametric estimation".

Computational Statistics .

39 (3): 1127– 1163.

arXiv : 2111.14091 .

doi : 10.1007/s00180-023-01382-0 .

S2CID 244715035 .

^ "Linear or rank correlation - MATLAB corr" .

www.mathworks.com .

Further reading [ edit ] Corder, G. W. & Foreman, D. I. (2014). Nonparametric Statistics: A Step-by-Step Approach, Wiley.

ISBN 978-1118840313 .

Daniel, Wayne W. (1990).

"Spearman rank correlation coefficient" .

Applied Nonparametric Statistics (2nd ed.). Boston: PWS-Kent. pp.

358– 365.

ISBN 978-0-534-91976-4 .

Spearman C. (1904).

"The proof and measurement of association between two things" .

American Journal of Psychology .

15 (1): 72– 101.

doi : 10.2307/1412159 .

JSTOR 1412159 .

Bonett, D. G.; Wright, T. A. (2000). "Sample size requirements for Pearson, Kendall, and Spearman correlations".

Psychometrika .

65 : 23– 28.

doi : 10.1007/bf02294183 .

S2CID 120558581 .

Kendall M. G. (1970).

Rank correlation methods (4th ed.). London: Griffin.

ISBN 978-0-852-6419-96 .

OCLC 136868 .

Hollander M., Wolfe D. A. (1973).

Nonparametric statistical methods . New York: Wiley.

ISBN 978-0-471-40635-8 .

OCLC 520735 .

Caruso J. C., Cliff N. (1997). "Empirical size, coverage, and power of confidence intervals for Spearman's Rho".

Educational and Psychological Measurement .

57 (4): 637– 654.

doi : 10.1177/0013164497057004009 .

S2CID 120481551 .

External links [ edit ] Wikiversity has learning resources about Spearman's rank correlation coefficient Table of critical values of ρ for significance with small samples Spearman's Rank Correlation Coefficient – Excel Guide : sample data and formulae for Excel, developed by the Royal Geographical Society .

v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject Retrieved from " https://en.wikipedia.org/w/index.php?title=Spearman%27s_rank_correlation_coefficient&oldid=1296128954 " Categories : Covariance and correlation Information retrieval evaluation Nonparametric statistics Statistical tests Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 18 June 2025, at 00:47 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Spearman's rank correlation coefficient 28 languages Add topic

