Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Examples 2 History 3 See also 4 References Toggle the table of contents Parameter space 5 languages Eesti Español فارسی Italiano Nederlands Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Set of values for a mathematical model The parameter space is the space of all possible parameter values that define a particular mathematical model . It is also sometimes called weight space , and is often a subset of finite-dimensional Euclidean space .

In statistics , parameter spaces are particularly useful for describing parametric families of probability distributions . They also form the background for parameter estimation . In the case of extremum estimators for parametric models , a certain objective function is maximized or minimized over the parameter space.

[ 1 ] Theorems of existence and consistency of such estimators require some assumptions about the topology of the parameter space. For instance, compactness of the parameter space, together with continuity of the objective function, suffices for the existence of an extremum estimator.

[ 1 ] Sometimes, parameters are analyzed to view how they affect their statistical model. In that context, they can be viewed as inputs of a function , in which case the technical term for the parameter space is domain of a function . The ranges of values of the parameters may form the axes of a plot , and particular outcomes of the model may be plotted against these axes to illustrate how different regions of the parameter space produce different types of behavior in the model.

Examples [ edit ] A simple model of health deterioration after developing lung cancer could include the two parameters gender [ 2 ] and smoker/non-smoker, in which case the parameter space is the following set of four possibilities: {(Male, Smoker), (Male, Non-smoker), (Female, Smoker), (Female, Non-smoker)} .

The logistic map x n + 1 = r x n ( 1 − − x n ) {\displaystyle x_{n+1}=rx_{n}(1-x_{n})} has one parameter, r , which can take any positive value. The parameter space is therefore positive real numbers .

For some values of r , this function ends up cycling around a few values or becomes fixed on one value. These long-term values can be plotted against r in a bifurcation diagram to show the different behaviours of the function for different values of r .

In a sine wave model y ( t ) = A ⋅ ⋅ sin ⁡ ⁡ ( ω ω t + ϕ ϕ ) , {\displaystyle y(t)=A\cdot \sin(\omega t+\phi ),} the parameters are amplitude A > 0, angular frequency ω > 0, and phase φ ∈ S 1 . Thus the parameter space is R + × × R + × × S 1 .

{\displaystyle R^{+}\times R^{+}\times S^{1}.} In complex dynamics , the parameter space is the complex plane C = { z = x + y i : x, y ∈ R }, where i 2 = −1.

The famous Mandelbrot set is a subset of this parameter space, consisting of the points in the complex plane which give a bounded set of numbers when a particular iterated function is repeatedly applied from that starting point. The remaining points, which are not in the set, give an unbounded set of numbers (they tend to infinity) when this function is repeatedly applied from that starting point.

In machine learning , hyperparameters are used to describe models. In deep learning , the parameters of a deep network are called weights.

Due to the layered structure of deep networks, their weight space has a complex structure and geometry.

[ 3 ] [ 4 ] For example, in multilayer perceptrons , the same function is preserved when permuting the nodes of a hidden layer, amounting to permuting weight matrices of the network. This property is known as equivariance to permutation of deep weight spaces .

[ 3 ] The study seeks hyperparameter optimization .

History [ edit ] Parameter space contributed to the liberation of geometry from the confines of three-dimensional space . For instance, the parameter space of spheres in three dimensions, has four dimensions—three for the sphere center and another for the radius.  According to Dirk Struik , it was the book Neue Geometrie des Raumes (1849) by Julius Plücker that showed ...geometry need not solely be based on points as basic elements. Lines, planes, circles, spheres can all be used as the elements ( Raumelemente ) on which a geometry can be based. This fertile conception threw new light on both synthetic and algebraic geometry and created new forms of duality. The number of dimensions of a particular form of geometry could now be any positive number, depending on the number of parameters necessary to define the "element".

[ 5 ] : 165 The requirement for higher dimensions is illustrated by Plücker's line geometry . Struik writes [Plücker's] geometry of lines in three-space could be considered as a four-dimensional geometry, or, as Klein has stressed, as the geometry of a four-dimensional quadric in a five-dimensional space.

[ 5 ] : 168 Thus the Klein quadric describes the parameters of lines in space.

See also [ edit ] Sample space Configuration space Data analysis Dimensionality reduction Model selection Parametric equation Parametric surface Phase space References [ edit ] ^ a b Hayashi, Fumio (2000).

Econometrics . Princeton University Press. p. 446.

ISBN 0-691-01018-8 .

^ Gasperino, J.; Rom, W. N. (2004). "Gender and lung cancer".

Clinical Lung Cancer .

5 (6): 353– 359.

doi : 10.3816/CLC.2004.n.013 .

PMID 15217534 .

^ a b Navon, Aviv; Shamsian, Aviv; Achituve, Idan; Fetaya, Ethan; Chechik, Gal; Maron, Haggai (2023-07-03).

"Equivariant Architectures for Learning in Deep Weight Spaces" .

Proceedings of the 40th International Conference on Machine Learning . PMLR: 25790– 25816.

arXiv : 2301.12780 .

^ Hecht-Nielsen, Robert (1990-01-01), Eckmiller, Rolf (ed.), "ON THE ALGEBRAIC STRUCTURE OF FEEDFORWARD NETWORK WEIGHT SPACES" , Advanced Neural Computers , Amsterdam: North-Holland, pp.

129– 135, ISBN 978-0-444-88400-8 , retrieved 2023-12-01 ^ a b Dirk Struik (1967) A Concise History of Mathematics , 3rd edition, Dover Books Retrieved from " https://en.wikipedia.org/w/index.php?title=Parameter_space&oldid=1299307533 " Categories : Estimation theory Mathematical terminology Hidden categories: Articles with short description Short description is different from Wikidata This page was last edited on 7 July 2025, at 16:44 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Parameter space 5 languages Add topic

