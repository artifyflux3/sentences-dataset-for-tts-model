Title: Linear differential equation

URL Source: https://en.wikipedia.org/wiki/Linear_differential_equation

Published Time: 2003-11-26T09:59:03Z

Markdown Content:
In [mathematics](https://en.wikipedia.org/wiki/Mathematics "Mathematics"), a **linear differential equation** is a [differential equation](https://en.wikipedia.org/wiki/Differential_equation "Differential equation") that is [linear](https://en.wikipedia.org/wiki/Linear_equation "Linear equation") in the unknown function and its derivatives, so it can be written in the form ![Image 1: {\displaystyle a_{0}(x)y+a_{1}(x)y'+a_{2}(x)y''\cdots +a_{n}(x)y^{(n)}=b(x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8760cf055e70d4f2844a87221e4e4fd3933d957c) where _a_ 0(_x_), ..., _a_ _n_(_x_) and _b_(_x_) are arbitrary [differentiable functions](https://en.wikipedia.org/wiki/Differentiable_function "Differentiable function") that do not need to be linear, and _y_′, ..., _y_(_n_) are the successive derivatives of an unknown function y of the variable x.

Such an equation is an [ordinary differential equation](https://en.wikipedia.org/wiki/Ordinary_differential_equation "Ordinary differential equation") (ODE). A _linear differential equation_ may also be a linear [partial differential equation](https://en.wikipedia.org/wiki/Partial_differential_equation "Partial differential equation") (PDE), if the unknown function depends on several variables, and the derivatives that appear in the equation are [partial derivatives](https://en.wikipedia.org/wiki/Partial_derivative "Partial derivative").

A linear differential equation or a [system of linear equations](https://en.wikipedia.org/wiki/System_of_linear_equations "System of linear equations") such that the associated homogeneous equations have constant coefficients may be **solved by quadrature**, which means that the solutions may be expressed in terms of [integrals](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative"). This is also true for a linear equation of order one, with non-constant coefficients. An equation of order two or higher with non-constant coefficients cannot, in general, be solved by quadrature. For order two, [Kovacic's algorithm](https://en.wikipedia.org/wiki/Kovacic%27s_algorithm "Kovacic's algorithm") allows deciding whether there are solutions in terms of integrals, and computing them if any.

The solutions of homogeneous linear differential equations with [polynomial](https://en.wikipedia.org/wiki/Polynomial "Polynomial") coefficients are called [holonomic functions](https://en.wikipedia.org/wiki/Holonomic_function "Holonomic function"). This class of functions is stable under sums, products, [differentiation](https://en.wikipedia.org/wiki/Derivative "Derivative"), [integration](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative"), and contains many usual functions and [special functions](https://en.wikipedia.org/wiki/Special_function "Special function") such as [exponential function](https://en.wikipedia.org/wiki/Exponential_function "Exponential function"), [logarithm](https://en.wikipedia.org/wiki/Logarithm "Logarithm"), [sine](https://en.wikipedia.org/wiki/Sine "Sine"), [cosine](https://en.wikipedia.org/wiki/Cosine "Cosine"), [inverse trigonometric functions](https://en.wikipedia.org/wiki/Inverse_trigonometric_functions "Inverse trigonometric functions"), [error function](https://en.wikipedia.org/wiki/Error_function "Error function"), [Bessel functions](https://en.wikipedia.org/wiki/Bessel_function "Bessel function") and [hypergeometric functions](https://en.wikipedia.org/wiki/Hypergeometric_function "Hypergeometric function"). Their representation by the defining differential equation and initial conditions allows making algorithmic (on these functions) most operations of [calculus](https://en.wikipedia.org/wiki/Calculus "Calculus"), such as computation of [antiderivatives](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative"), [limits](https://en.wikipedia.org/wiki/Limit_(mathematics) "Limit (mathematics)"), [asymptotic expansion](https://en.wikipedia.org/wiki/Asymptotic_expansion "Asymptotic expansion"), and numerical evaluation to any precision, with a certified error bound.

The highest [order of derivation](https://en.wikipedia.org/wiki/Order_of_derivation "Order of derivation") that appears in a (linear) differential equation is the _order_ of the equation. The term _b_(_x_), which does not depend on the unknown function and its derivatives, is sometimes called the _constant term_ of the equation (by analogy with [algebraic equations](https://en.wikipedia.org/wiki/Algebraic_equation "Algebraic equation")), even when this term is a non-constant function. If the constant term is the [zero function](https://en.wikipedia.org/wiki/Zero_function "Zero function"), then the differential equation is said to be _[homogeneous](https://en.wikipedia.org/wiki/Homogeneous\_differential\_equation "Homogeneous differential equation")_, as it is a [homogeneous polynomial](https://en.wikipedia.org/wiki/Homogeneous_polynomial "Homogeneous polynomial") in the unknown function and its derivatives. The equation obtained by replacing, in a linear differential equation, the constant term by the zero function is the _associated homogeneous equation_. A differential equation has _constant coefficients_ if only [constant functions](https://en.wikipedia.org/wiki/Constant_function "Constant function") appear as coefficients in the associated homogeneous equation.

A _solution_ of a differential equation is a function that satisfies the equation. The solutions of a homogeneous linear differential equation form a [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space"). In the ordinary case, this vector space has a finite dimension, equal to the order of the equation. All solutions of a linear differential equation are found by adding to a particular solution any solution of the associated homogeneous equation.

Linear differential operator
----------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=3 "Edit section: Linear differential operator")]

A _basic differential operator_ of order i is a mapping that maps any [differentiable function](https://en.wikipedia.org/wiki/Differentiable_function "Differentiable function") to its [i th derivative](https://en.wikipedia.org/wiki/Higher_derivative "Higher derivative"), or, in the case of several variables, to one of its [partial derivatives](https://en.wikipedia.org/wiki/Partial_derivative "Partial derivative") of order i. It is commonly denoted ![Image 2: {\displaystyle {\frac {d^{i}}{dx^{i}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/69fbc39902ee7645872e7819971972b6b2558717) in the case of [univariate](https://en.wikipedia.org/wiki/Univariate "Univariate") functions, and ![Image 3: {\displaystyle {\frac {\partial ^{i_{1}+\cdots +i_{n}}}{\partial x_{1}^{i_{1}}\cdots \partial x_{n}^{i_{n}}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/be95bff7b7a1e12e9ee7d72731ef289e06b35b0c) in the case of functions of n variables. The basic differential operators include the derivative of order 0, which is the identity mapping.

A **linear differential operator** (abbreviated, in this article, as _linear operator_ or, simply, _operator_) is a [linear combination](https://en.wikipedia.org/wiki/Linear_combination "Linear combination") of basic differential operators, with differentiable functions as coefficients. In the univariate case, a linear operator has thus the form[[1]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-1)![Image 4: {\displaystyle a_{0}(x)+a_{1}(x){\frac {d}{dx}}+\cdots +a_{n}(x){\frac {d^{n}}{dx^{n}}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/017c6e7ee34a521fd3096540ee1bf2616946c6fc) where _a_ 0(_x_), ..., _a_ _n_(_x_) are differentiable functions, and the nonnegative integer n is the _order_ of the operator (if _a_ _n_(_x_) is not the [zero function](https://en.wikipedia.org/wiki/Zero_function "Zero function")).

Let L be a linear differential operator. The application of L to a function f is usually denoted _Lf_ or _Lf_(_X_), if one needs to specify the variable (this must not be confused with a multiplication). A linear differential operator is a [linear operator](https://en.wikipedia.org/wiki/Linear_operator "Linear operator"), since it maps sums to sums and the product by a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)") to the product by the same scalar.

As the sum of two linear operators is a linear operator, as well as the product (on the left) of a linear operator by a differentiable function, the linear differential operators form a [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") over the [real numbers](https://en.wikipedia.org/wiki/Real_number "Real number") or the [complex numbers](https://en.wikipedia.org/wiki/Complex_number "Complex number") (depending on the nature of the functions that are considered). They form also a [free module](https://en.wikipedia.org/wiki/Free_module "Free module") over the [ring](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)") of differentiable functions.

The language of operators allows a compact writing for differentiable equations: if ![Image 5: {\displaystyle L=a_{0}(x)+a_{1}(x){\frac {d}{dx}}+\cdots +a_{n}(x){\frac {d^{n}}{dx^{n}}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/def05e62f20f9966d4c97344e0b40c9adee2d158) is a linear differential operator, then the equation ![Image 6: {\displaystyle a_{0}(x)y+a_{1}(x)y'+a_{2}(x)y''+\cdots +a_{n}(x)y^{(n)}=b(x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d63c75fe260aceab6d00575a3a9e233971aa8b6) may be rewritten ![Image 7: {\displaystyle Ly=b(x).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a542d0b70ae7c8549f59045a104b0aaebb4ccb3)

There may be several variants to this notation; in particular the variable of differentiation may appear explicitly or not in y and the right-hand and of the equation, such as _Ly_(_x_) = _b_(_x_) or _Ly_ = _b_.

The _kernel_ of a linear differential operator is its [kernel](https://en.wikipedia.org/wiki/Kernel_(linear_algebra) "Kernel (linear algebra)") as a linear mapping, that is the [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") of the solutions of the (homogeneous) differential equation _Ly_ = 0.

In the case of an ordinary differential operator of order n, [Carathéodory's existence theorem](https://en.wikipedia.org/wiki/Carath%C3%A9odory%27s_existence_theorem "Carathéodory's existence theorem") implies that, under very mild conditions, the kernel of L is a vector space of dimension n, and that the solutions of the equation _Ly_(_x_) = _b_(_x_) have the form ![Image 8: {\displaystyle S_{0}(x)+c_{1}S_{1}(x)+\cdots +c_{n}S_{n}(x),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4b36b3d2133e5c1fa0127d0188350417933a0394) where _c_ 1, ..., _c_ _n_ are arbitrary numbers. Typically, the hypotheses of Carathéodory's theorem are satisfied in an interval I, if the functions _b_, _a_ 0, ..., _a_ _n_ are continuous in I, and there is a positive real number k such that |_a_ _n_(_x_)| >_k_ for every x in I.

Homogeneous equation with constant coefficients
-----------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=4 "Edit section: Homogeneous equation with constant coefficients")]

A homogeneous linear differential equation has _constant coefficients_ if it has the form ![Image 9: {\displaystyle a_{0}y+a_{1}y'+a_{2}y''+\cdots +a_{n}y^{(n)}=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/71826dd904f4752956cecb3677586141391871df) where _a_ 1, ..., _a_ _n_ are (real or complex) numbers. In other words, it has constant coefficients if it is defined by a linear operator with constant coefficients.

The study of these differential equations with constant coefficients dates back to [Leonhard Euler](https://en.wikipedia.org/wiki/Leonhard_Euler "Leonhard Euler"), who introduced the [exponential function](https://en.wikipedia.org/wiki/Exponential_function "Exponential function")_e_ _x_, which is the unique solution of the equation _f_′ = _f_ such that _f_(0) = 1. It follows that the n th derivative of _e_ _cx_ is _c_ _n_ _e_ _cx_, and this allows solving homogeneous linear differential equations rather easily.

Let ![Image 10: {\displaystyle a_{0}y+a_{1}y'+a_{2}y''+\cdots +a_{n}y^{(n)}=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/71826dd904f4752956cecb3677586141391871df) be a homogeneous linear differential equation with constant coefficients (that is _a_ 0, ..., _a_ _n_ are real or complex numbers).

Searching solutions of this equation that have the form _e_ _αx_ is equivalent to searching the constants α such that ![Image 11: {\displaystyle a_{0}e^{\alpha x}+a_{1}\alpha e^{\alpha x}+a_{2}\alpha ^{2}e^{\alpha x}+\cdots +a_{n}\alpha ^{n}e^{\alpha x}=0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86048c463c74b31e48aa19e1374ed895cb91ffa9) Factoring out _e_ _αx_ (which is never zero), shows that α must be a root of the _characteristic polynomial_![Image 12: {\displaystyle a_{0}+a_{1}t+a_{2}t^{2}+\cdots +a_{n}t^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8d63406a427b1998244410f26288529da6b2e2cd) of the differential equation, which is the left-hand side of the [characteristic equation](https://en.wikipedia.org/wiki/Characteristic_equation_(calculus) "Characteristic equation (calculus)")![Image 13: {\displaystyle a_{0}+a_{1}t+a_{2}t^{2}+\cdots +a_{n}t^{n}=0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca5b7219506f4e51cd6df8d0e731250653b85601)

When these roots are all [distinct](https://en.wikipedia.org/wiki/Distinct_roots "Distinct roots"), one has n distinct solutions that are not necessarily real, even if the coefficients of the equation are real. These solutions can be shown to be [linearly independent](https://en.wikipedia.org/wiki/Linearly_independent "Linearly independent"), by considering the [Vandermonde determinant](https://en.wikipedia.org/wiki/Vandermonde_determinant "Vandermonde determinant") of the values of these solutions at _x_ = 0, ..., _n_ – 1. Together they form a [basis](https://en.wikipedia.org/wiki/Basis_(linear_algebra) "Basis (linear algebra)") of the [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") of solutions of the differential equation (that is, the kernel of the differential operator).

| Example |
| --- |
| ![Image 14: {\displaystyle y''''-2y'''+2y''-2y'+y=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2db4f5307f2da97b3b5663b3ea426c2ad8346319) has the characteristic equation ![Image 15: {\displaystyle z^{4}-2z^{3}+2z^{2}-2z+1=0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b547a91498ca9a799ef1e26e3247ddf228d13b3e) This has zeros, i, −_i_, and 1 (multiplicity 2). The solution basis is thus ![Image 16: {\displaystyle e^{ix},\;e^{-ix},\;e^{x},\;xe^{x}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/747c7cb665475a9c5a502a7a6aa3f7dc3ca3f052) A real basis of solution is thus ![Image 17: {\displaystyle \cos x,\;\sin x,\;e^{x},\;xe^{x}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/46f8877ea370a30b30bd31e7ebc6fd4246bb657d) |

In the case where the characteristic polynomial has only [simple roots](https://en.wikipedia.org/wiki/Simple_root "Simple root"), the preceding provides a complete basis of the solutions vector space. In the case of [multiple roots](https://en.wikipedia.org/wiki/Multiple_root "Multiple root"), more linearly independent solutions are needed for having a basis. These have the form ![Image 18: {\displaystyle x^{k}e^{\alpha x},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/acc12c83868bdecf7f4351abed8aa74477661101) where k is a nonnegative integer, α is a root of the characteristic polynomial of multiplicity m, and _k_<_m_. For proving that these functions are solutions, one may remark that if α is a root of the characteristic polynomial of multiplicity m, the characteristic polynomial may be factored as _P_(_t_)(_t_ − _α_)_m_. Thus, applying the differential operator of the equation is equivalent with applying first m times the operator ![Image 19: {\textstyle {\frac {d}{dx}}-\alpha }](https://wikimedia.org/api/rest_v1/media/math/render/svg/2140792c87582dceabafae59b739b1695693ac15), and then the operator that has P as characteristic polynomial. By the [exponential shift theorem](https://en.wikipedia.org/wiki/Shift_theorem "Shift theorem"), ![Image 20: {\displaystyle \left({\frac {d}{dx}}-\alpha \right)\left(x^{k}e^{\alpha x}\right)=kx^{k-1}e^{\alpha x},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/09a71413cdc3dcace862ce7e9f3eaee0eb1c0501)

and thus one gets zero after _k_ + 1 application of ![Image 21: {\textstyle {\frac {d}{dx}}-\alpha }](https://wikimedia.org/api/rest_v1/media/math/render/svg/2140792c87582dceabafae59b739b1695693ac15).

As, by the [fundamental theorem of algebra](https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra "Fundamental theorem of algebra"), the sum of the multiplicities of the roots of a polynomial equals the degree of the polynomial, the number of above solutions equals the order of the differential equation, and these solutions form a basis of the vector space of the solutions.

In the common case where the coefficients of the equation are real, it is generally more convenient to have a basis of the solutions consisting of [real-valued functions](https://en.wikipedia.org/wiki/Real-valued_function "Real-valued function"). Such a basis may be obtained from the preceding basis by remarking that, if _a_ + _ib_ is a root of the characteristic polynomial, then _a_ – _ib_ is also a root, of the same multiplicity. Thus a real basis is obtained by using [Euler's formula](https://en.wikipedia.org/wiki/Euler%27s_formula "Euler's formula"), and replacing ![Image 22: {\displaystyle x^{k}e^{(a+ib)x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0881a1f69e326f9674d8d7223cd19ccc01ee48c9) and ![Image 23: {\displaystyle x^{k}e^{(a-ib)x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6c39be687f07b5ef152306aeef46a7055aa0a9c) by ![Image 24: {\displaystyle x^{k}e^{ax}\cos(bx)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0191b903346a38237d4aee5e8c69e15030eb0678) and ![Image 25: {\displaystyle x^{k}e^{ax}\sin(bx)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc5de26c83cfe793c7b09b17c67940613648ad5).

A homogeneous linear differential equation of the second order may be written ![Image 26: {\displaystyle y''+ay'+by=0,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1cf036ca106b71f409363a42518d73fcda38c32) and its characteristic polynomial is ![Image 27: {\displaystyle r^{2}+ar+b.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/450bcb61975b5d6084ebefb9dae2436f476537f8)

If a and b are [real](https://en.wikipedia.org/wiki/Real_number "Real number"), there are three cases for the solutions, depending on the discriminant _D_ = _a_ 2 − 4 _b_. In all three cases, the general solution depends on two arbitrary constants _c_ 1 and _c_ 2.

Finding the solution _y_(_x_) satisfying _y_(0) = _d_ 1 and _y_′(0) = _d_ 2, one equates the values of the above general solution at 0 and its derivative there to _d_ 1 and _d_ 2, respectively. This results in a linear system of two linear equations in the two unknowns _c_ 1 and _c_ 2. Solving this system gives the solution for a so-called [Cauchy problem](https://en.wikipedia.org/wiki/Cauchy_boundary_condition "Cauchy boundary condition"), in which the values at 0 for the solution of the DEQ and its derivative are specified.

Non-homogeneous equation with constant coefficients
---------------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=6 "Edit section: Non-homogeneous equation with constant coefficients")]

A non-homogeneous equation of order n with constant coefficients may be written ![Image 28: {\displaystyle y^{(n)}(x)+a_{1}y^{(n-1)}(x)+\cdots +a_{n-1}y'(x)+a_{n}y(x)=f(x),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/556d2cd4a9fbe463048427ce9c72a08ca97bec61) where _a_ 1, ..., _a_ _n_ are real or complex numbers, f is a given function of x, and y is the unknown function (for sake of simplicity, "(_x_)" will be omitted in the following).

There are several methods for solving such an equation. The best method depends on the nature of the function f that makes the equation non-homogeneous. If f is a linear combination of exponential and sinusoidal functions, then the [exponential response formula](https://en.wikipedia.org/wiki/Exponential_response_formula "Exponential response formula") may be used. If, more generally, f is a linear combination of functions of the form _x_ _n_ _e_ _ax_, _x_ _n_ cos(_ax_), and _x_ _n_ sin(_ax_), where n is a nonnegative integer, and a a constant (which need not be the same in each term), then the [method of undetermined coefficients](https://en.wikipedia.org/wiki/Method_of_undetermined_coefficients "Method of undetermined coefficients") may be used. Still more general, the [annihilator method](https://en.wikipedia.org/wiki/Annihilator_method "Annihilator method") applies when f satisfies a homogeneous linear differential equation, typically, a [holonomic function](https://en.wikipedia.org/wiki/Holonomic_function "Holonomic function").

The most general method is the [variation of constants](https://en.wikipedia.org/wiki/Variation_of_constants "Variation of constants"), which is presented here.

The general solution of the associated homogeneous equation ![Image 29: {\displaystyle y^{(n)}+a_{1}y^{(n-1)}+\cdots +a_{n-1}y'+a_{n}y=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/990139b2afcc43200a28b5679c96487c25697ef5) is ![Image 30: {\displaystyle y=u_{1}y_{1}+\cdots +u_{n}y_{n},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7fb5f4f705702bd057748a8200e3ae6026377028) where (_y_ 1, ..., _y_ _n_) is a basis of the vector space of the solutions and _u_ 1, ..., _u_ _n_ are arbitrary constants. The method of variation of constants takes its name from the following idea. Instead of considering _u_ 1, ..., _u_ _n_ as constants, they can be considered as unknown functions that have to be determined for making y a solution of the non-homogeneous equation. For this purpose, one adds the constraints ![Image 31: {\displaystyle {\begin{aligned}0&=u'_{1}y_{1}+u'_{2}y_{2}+\cdots +u'_{n}y_{n}\\0&=u'_{1}y'_{1}+u'_{2}y'_{2}+\cdots +u'_{n}y'_{n}\\&\;\;\vdots \\0&=u'_{1}y_{1}^{(n-2)}+u'_{2}y_{2}^{(n-2)}+\cdots +u'_{n}y_{n}^{(n-2)},\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aaecbd72ff05aafdeead12cfbaee5ef97b7e6e21) which imply (by [product rule](https://en.wikipedia.org/wiki/Product_rule "Product rule") and [induction](https://en.wikipedia.org/wiki/Mathematical_induction "Mathematical induction")) ![Image 32: {\displaystyle y^{(i)}=u_{1}y_{1}^{(i)}+\cdots +u_{n}y_{n}^{(i)}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4e139b27449baa1094eef51cd79f5b0912469bda) for _i_ = 1, ..., _n_ – 1, and ![Image 33: {\displaystyle y^{(n)}=u_{1}y_{1}^{(n)}+\cdots +u_{n}y_{n}^{(n)}+u'_{1}y_{1}^{(n-1)}+u'_{2}y_{2}^{(n-1)}+\cdots +u'_{n}y_{n}^{(n-1)}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a02985252c9b7336782b610b15d87a856d16507)

Replacing in the original equation y and its derivatives by these expressions, and using the fact that _y_ 1, ..., _y_ _n_ are solutions of the original homogeneous equation, one gets ![Image 34: {\displaystyle f=u'_{1}y_{1}^{(n-1)}+\cdots +u'_{n}y_{n}^{(n-1)}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3843fb6327cb83a308f8fcec8962bf815feedebe)

This equation and the above ones with 0 as left-hand side form a system of n linear equations in _u_′1, ..., _u_′_n_ whose coefficients are known functions (f, the _y_ i, and their derivatives). This system can be solved by any method of [linear algebra](https://en.wikipedia.org/wiki/Linear_algebra "Linear algebra"). The computation of [antiderivatives](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative") gives _u_ 1, ..., _u_ _n_, and then _y_ = _u_ 1 _y_ 1 + ⋯ + _u_ _n_ _y_ _n_.

As antiderivatives are defined up to the addition of a constant, one finds again that the general solution of the non-homogeneous equation is the sum of an arbitrary solution and the general solution of the associated homogeneous equation.

First-order equation with variable coefficients
-----------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=7 "Edit section: First-order equation with variable coefficients")]

The general form of a linear ordinary differential equation of order 1, after dividing out the coefficient of _y_′(_x_), is: ![Image 35: {\displaystyle y'(x)=f(x)y(x)+g(x).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ff33a7c5cd01af84dc5dd83bbf1d42892ac72fce)

If the equation is homogeneous, i.e. _g_(_x_) = 0, one may rewrite and integrate: ![Image 36: {\displaystyle {\frac {y'}{y}}=f,\qquad \log y=k+F,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bfc47ddbb5644c4e1e19d6afb997dbc97a5076f8) where k is an arbitrary [constant of integration](https://en.wikipedia.org/wiki/Constant_of_integration "Constant of integration") and ![Image 37: {\displaystyle F=\textstyle \int f\,dx}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e83b528e35de6d539943c0fffed384671da0fadb) is any [antiderivative](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative") of f. Thus, the general solution of the homogeneous equation is ![Image 38: {\displaystyle y=ce^{F},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b51809534aa47122c25f5931d78790ad051aaab6) where _c_ = _e_ _k_ is an arbitrary constant.

For the general non-homogeneous equation, it is useful to multiply both sides of the equation by the [reciprocal](https://en.wikipedia.org/wiki/Multiplicative_inverse "Multiplicative inverse")_e_−_F_ of a solution of the homogeneous equation.[[2]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-2) This gives ![Image 39: {\displaystyle y'e^{-F}-yfe^{-F}=ge^{-F}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ae0b61373f9d15bfdb87cbfeffe724bcd3586018) As ⁠![Image 40: {\displaystyle -fe^{-F}={\tfrac {d}{dx}}\left(e^{-F}\right),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5708d08338653f8917319e97ce221c939360c367)⁠ the [product rule](https://en.wikipedia.org/wiki/Product_rule "Product rule") allows rewriting the equation as ![Image 41: {\displaystyle {\frac {d}{dx}}\left(ye^{-F}\right)=ge^{-F}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/700ba17af9a78ef9bd965d233769cf9aa65aa6ba) Thus, the general solution is ![Image 42: {\displaystyle y=ce^{F}+e^{F}\int ge^{-F}dx,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e4a792725b5d9957a2d43eaabb81ce93e14cd0d) where c is a constant of integration, and F is any antiderivative of f (changing of antiderivative amounts to change the constant of integration).

Solving the equation ![Image 43: {\displaystyle y'(x)+{\frac {y(x)}{x}}=3x.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6c7affe2fd54b62c4ec676ea6b95ed2c58f54d4b) The associated homogeneous equation ![Image 44: {\displaystyle y'(x)+{\frac {y(x)}{x}}=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/098e1032ebd243450840eedcc0f8b7efacc884a7) gives ![Image 45: {\displaystyle {\frac {y'}{y}}=-{\frac {1}{x}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/908bdaa49c516928ac5dc75615404eedf7daa9cd) that is ![Image 46: {\displaystyle y={\frac {c}{x}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/feb49b9f92ddbebe7050ac996f8297aab3cb1499)

Dividing the original equation by one of these solutions gives ![Image 47: {\displaystyle xy'+y=3x^{2}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fe05310dd086f662ac240350adf77ec246d38cb5) That is ![Image 48: {\displaystyle (xy)'=3x^{2},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1546d757c13d7b63a09ee49b26f419adb22273fc)![Image 49: {\displaystyle xy=x^{3}+c,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c1f7d403014ef05af8211b714bfa46da19bd4aa5) and ![Image 50: {\displaystyle y(x)=x^{2}+c/x.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/23bdd950841c355739363df9f8f855fa5c7f0bc0) For the initial condition ![Image 51: {\displaystyle y(1)=\alpha ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e6f98e6fff7eb131a669540161a68271748e8249) one gets the particular solution ![Image 52: {\displaystyle y(x)=x^{2}+{\frac {\alpha -1}{x}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c659bad51350bb5e224c3dc015dbd0258373b0ee)

System of linear differential equations
---------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=9 "Edit section: System of linear differential equations")]

A system of linear differential equations consists of several linear differential equations that involve several unknown functions. In general one restricts the study to systems such that the number of unknown functions equals the number of equations.

An arbitrary linear ordinary differential equation and a system of such equations can be converted into a first order system of linear differential equations by adding variables for all but the highest order derivatives. That is, if ⁠![Image 53: {\displaystyle y',y'',\ldots ,y^{(k)}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d911ae9d27da0cf13c738b535adec871223e3f1c)⁠ appear in an equation, one may replace them by new unknown functions ⁠![Image 54: {\displaystyle y_{1},\ldots ,y_{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/26c8aae5c5f91885b9a5ebb23c6d8dcf29b63f4d)⁠ that must satisfy the equations ⁠![Image 55: {\displaystyle y'=y_{1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0d707c952095f60a1d4a9456906581bc075b4a0a)⁠ and ⁠![Image 56: {\displaystyle y_{i}'=y_{i+1},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d536e590983cb653a4d48fee18919c9919b332df)⁠ for _i_ = 1, ..., _k_ – 1.

A linear system of the first order, which has n unknown functions and n differential equations may normally be solved for the derivatives of the unknown functions. If it is not the case this is a [differential-algebraic system](https://en.wikipedia.org/wiki/Differential-algebraic_system_of_equations "Differential-algebraic system of equations"), and this is a different theory. Therefore, the systems that are considered here have the form ![Image 57: {\displaystyle {\begin{aligned}y_{1}'(x)&=b_{1}(x)+a_{1,1}(x)y_{1}+\cdots +a_{1,n}(x)y_{n}\\[1ex]&\;\;\vdots \\[1ex]y_{n}'(x)&=b_{n}(x)+a_{n,1}(x)y_{1}+\cdots +a_{n,n}(x)y_{n},\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5d8ad99cc0cbe0a5a4a4f5d9c0411b0aa92555c9) where ⁠![Image 58: {\displaystyle b_{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/28e2d72f6dd9375c8f1f59f1effd9b4e5492ac97)⁠ and the ⁠![Image 59: {\displaystyle a_{i,j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4bb5a346f58c6568306a02596dd318d1b7e6b2c2)⁠ are functions of x. In matrix notation, this system may be written (omitting "(_x_)") ![Image 60: {\displaystyle \mathbf {y} '=A\mathbf {y} +\mathbf {b} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b7efc3eb2cc49ea501df8c012e07a64c2e03a201)

The solving method is similar to that of a single first order linear differential equations, but with complications stemming from noncommutativity of matrix multiplication.

Let ![Image 61: {\displaystyle \mathbf {u} '=A\mathbf {u} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5f4466394e44b6d8d24a0e9895a40c8685355ed3) be the homogeneous equation associated to the above matrix equation. Its solutions form a [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") of dimension n, and are therefore the columns of a [square matrix](https://en.wikipedia.org/wiki/Square_matrix "Square matrix") of functions ⁠![Image 62: {\displaystyle U(x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d626d3a1e65c94535c811c73fa83389cfb76683)⁠, whose [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") is not the zero function. If _n_ = 1, or A is a matrix of constants, or, more generally, if A commutes with its [antiderivative](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative")⁠![Image 63: {\displaystyle \textstyle B=\int Adx}](https://wikimedia.org/api/rest_v1/media/math/render/svg/34a56edffff3fbe4fc00eaeaad86847f7d259c6e)⁠, then one may choose U equal the [exponential](https://en.wikipedia.org/wiki/Matrix_exponential "Matrix exponential") of B. In fact, in these cases, one has ![Image 64: {\displaystyle {\frac {d}{dx}}\exp(B)=A\exp(B).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4276767ec589c79db43830075f7f19e78ff0b79f) In the general case there is no closed-form solution for the homogeneous equation, and one has to use either a [numerical method](https://en.wikipedia.org/wiki/Numerical_method "Numerical method"), or an approximation method such as [Magnus expansion](https://en.wikipedia.org/wiki/Magnus_expansion "Magnus expansion").

Knowing the matrix U, the general solution of the non-homogeneous equation is ![Image 65: {\displaystyle \mathbf {y} (x)=U(x)\mathbf {y_{0}} +U(x)\int U^{-1}(x)\mathbf {b} (x)\,dx,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8db67010b86be6fdba836799d0d5fc79bae60ff9) where the column matrix ![Image 66: {\displaystyle \mathbf {y_{0}} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/f534a382ac36a867142d2c3b26f9a6fc42bccee8) is an arbitrary [constant of integration](https://en.wikipedia.org/wiki/Constant_of_integration "Constant of integration").

If initial conditions are given as ![Image 67: {\displaystyle \mathbf {y} (x_{0})=\mathbf {y} _{0},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/67215454dabb3fecf74be286c87055d74f11591d) the solution that satisfies these initial conditions is ![Image 68: {\displaystyle \mathbf {y} (x)=U(x)U^{-1}(x_{0})\mathbf {y_{0}} +U(x)\int _{x_{0}}^{x}U^{-1}(t)\mathbf {b} (t)\,dt.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/092c47214eeae567dafa1c530cce003b5230cf6f)

Higher order with variable coefficients
---------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=10 "Edit section: Higher order with variable coefficients")]

A linear ordinary equation of order one with variable coefficients may be solved by [quadrature](https://en.wikipedia.org/wiki/Quadrature_(mathematics) "Quadrature (mathematics)"), which means that the solutions may be expressed in terms of [integrals](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative"). This is not the case for order at least two. This is the main result of [Picard–Vessiot theory](https://en.wikipedia.org/wiki/Picard%E2%80%93Vessiot_theory "Picard–Vessiot theory") which was initiated by [Émile Picard](https://en.wikipedia.org/wiki/%C3%89mile_Picard "Émile Picard") and [Ernest Vessiot](https://en.wikipedia.org/wiki/Ernest_Vessiot "Ernest Vessiot"), and whose recent developments are called [differential Galois theory](https://en.wikipedia.org/wiki/Differential_Galois_theory "Differential Galois theory").

The impossibility of solving by quadrature can be compared with the [Abel–Ruffini theorem](https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem "Abel–Ruffini theorem"), which states that an [algebraic equation](https://en.wikipedia.org/wiki/Algebraic_equation "Algebraic equation") of degree at least five cannot, in general, be solved by radicals. This analogy extends to the proof methods and motivates the denomination of [differential Galois theory](https://en.wikipedia.org/wiki/Differential_Galois_theory "Differential Galois theory").

Similarly to the algebraic case, the theory allows deciding which equations may be solved by quadrature, and if possible solving them. However, for both theories, the necessary computations are extremely difficult, even with the most powerful computers.

Nevertheless, the case of order two with rational coefficients has been completely solved by [Kovacic's algorithm](https://en.wikipedia.org/wiki/Kovacic%27s_algorithm "Kovacic's algorithm").

### Cauchy–Euler equation

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=11 "Edit section: Cauchy–Euler equation")]

[Cauchy–Euler equations](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Euler_equation "Cauchy–Euler equation") are examples of equations of any order, with variable coefficients, that can be solved explicitly. These are the equations of the form ![Image 69: {\displaystyle x^{n}y^{(n)}(x)+a_{n-1}x^{n-1}y^{(n-1)}(x)+\cdots +a_{0}y(x)=0,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/895e59b6e9dc631d431c8a8e57e47c4d1eecec13) where ⁠![Image 70: {\displaystyle a_{0},\ldots ,a_{n-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/140c0c55154a5e80226b111b7165da7e5582e6d7)⁠ are constant coefficients.

Holonomic functions
-------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&action=edit&section=12 "Edit section: Holonomic functions")]

A [holonomic function](https://en.wikipedia.org/wiki/Holonomic_function "Holonomic function"), also called a _D-finite function_, is a function that is a solution of a homogeneous linear differential equation with polynomial coefficients.

Most functions that are commonly considered in mathematics are holonomic or quotients of holonomic functions. In fact, holonomic functions include [polynomials](https://en.wikipedia.org/wiki/Polynomial "Polynomial"), [algebraic functions](https://en.wikipedia.org/wiki/Algebraic_function "Algebraic function"), [logarithm](https://en.wikipedia.org/wiki/Logarithm "Logarithm"), [exponential function](https://en.wikipedia.org/wiki/Exponential_function "Exponential function"), [sine](https://en.wikipedia.org/wiki/Sine "Sine"), [cosine](https://en.wikipedia.org/wiki/Cosine "Cosine"), [hyperbolic sine](https://en.wikipedia.org/wiki/Hyperbolic_sine "Hyperbolic sine"), [hyperbolic cosine](https://en.wikipedia.org/wiki/Hyperbolic_cosine "Hyperbolic cosine"), [inverse trigonometric](https://en.wikipedia.org/wiki/Inverse_trigonometric_functions "Inverse trigonometric functions") and [inverse hyperbolic functions](https://en.wikipedia.org/wiki/Inverse_hyperbolic_functions "Inverse hyperbolic functions"), and many [special functions](https://en.wikipedia.org/wiki/Special_function "Special function") such as [Bessel functions](https://en.wikipedia.org/wiki/Bessel_function "Bessel function") and [hypergeometric functions](https://en.wikipedia.org/wiki/Hypergeometric_function "Hypergeometric function").

Holonomic functions have several [closure properties](https://en.wikipedia.org/wiki/Closure_property "Closure property"); in particular, sums, products, [derivative](https://en.wikipedia.org/wiki/Derivative "Derivative") and [integrals](https://en.wikipedia.org/wiki/Antiderivative "Antiderivative") of holonomic functions are holonomic. Moreover, these closure properties are effective, in the sense that there are [algorithms](https://en.wikipedia.org/wiki/Algorithm "Algorithm") for computing the differential equation of the result of any of these operations, knowing the differential equations of the input.[[3]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-zeilberger-3)

Usefulness of the concept of holonomic functions results of Zeilberger's theorem, which follows.[[3]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-zeilberger-3)

A _holonomic sequence_ is a sequence of numbers that may be generated by a [recurrence relation](https://en.wikipedia.org/wiki/Recurrence_relation "Recurrence relation") with polynomial coefficients. The coefficients of the [Taylor series](https://en.wikipedia.org/wiki/Taylor_series "Taylor series") at a point of a holonomic function form a holonomic sequence. Conversely, if the sequence of the coefficients of a [power series](https://en.wikipedia.org/wiki/Power_series "Power series") is holonomic, then the series defines a holonomic function (even if the [radius of convergence](https://en.wikipedia.org/wiki/Radius_of_convergence "Radius of convergence") is zero). There are efficient algorithms for both conversions, that is for computing the recurrence relation from the differential equation, and _vice versa_. [[3]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-zeilberger-3)

It follows that, if one represents (in a computer) holonomic functions by their defining differential equations and initial conditions, most [calculus](https://en.wikipedia.org/wiki/Calculus "Calculus") operations can be done automatically on these functions, such as [derivative](https://en.wikipedia.org/wiki/Derivative "Derivative"), [indefinite](https://en.wikipedia.org/wiki/Indefinite_integral "Indefinite integral") and [definite integral](https://en.wikipedia.org/wiki/Definite_integral "Definite integral"), fast computation of Taylor series (thanks of the recurrence relation on its coefficients), evaluation to a high precision with certified bound of the [approximation error](https://en.wikipedia.org/wiki/Approximation_error "Approximation error"), [limits](https://en.wikipedia.org/wiki/Limit_(mathematics) "Limit (mathematics)"), localization of [singularities](https://en.wikipedia.org/wiki/Singularity_(mathematics) "Singularity (mathematics)"), [asymptotic behavior](https://en.wikipedia.org/wiki/Asymptotic_behavior "Asymptotic behavior") at infinity and near singularities, proof of identities, etc.[[4]](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_note-4)

*   [Continuous-repayment mortgage](https://en.wikipedia.org/wiki/Continuous-repayment_mortgage#Ordinary_time_differential_equation "Continuous-repayment mortgage")
*   [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform "Fourier transform")
*   [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform")
*   [Linear difference equation](https://en.wikipedia.org/wiki/Linear_difference_equation "Linear difference equation")
*   [Variation of parameters](https://en.wikipedia.org/wiki/Variation_of_parameters "Variation of parameters")

1.   **[^](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-1)**Gershenfeld 1999, p.9
2.   **[^](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-2)**Motivation: In analogy to [completing the square](https://en.wikipedia.org/wiki/Completing_the_square "Completing the square") technique we write the equation as _y_′ − _fy_ = _g_, and try to modify the left side so it becomes a derivative. Specifically, we seek an "integrating factor" _h_ = _h_(_x_) such that multiplying by it makes the left side equal to the derivative of _hy_, namely _hy_′ − _hfy_ = (_hy_)′. This means _h_′ = −_hf_, so that _h_ = _e_−∫ _f_ _dx_ = _e_−_F_, as in the text.
3.   ^ [_**a**_](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-zeilberger_3-0)[_**b**_](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-zeilberger_3-1)[_**c**_](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-zeilberger_3-2)Zeilberger, Doron. _[A holonomic systems approach to special functions identities](https://www.sciencedirect.com/science/article/pii/037704279090042X/pdf?md5=8b21c545d20a52a50dffdf6808bba4a8&isDTMRedir=Y&pid=1-s2.0-037704279090042X-main.pdf)_. Journal of computational and applied mathematics. 32.3 (1990): 321-368
4.   **[^](https://en.wikipedia.org/wiki/Linear_differential_equation#cite_ref-4)**Benoit, A., Chyzak, F., Darrasse, A., Gerhold, S., Mezzarobba, M., & Salvy, B. (2010, September). _[The dynamic dictionary of mathematical functions (DDMF)](https://hal.inria.fr/docs/00/78/30/48/PDF/ddmf.pdf)_. In International Congress on Mathematical Software (pp. 35-41). Springer, Berlin, Heidelberg.

*   Birkhoff, Garrett & Rota, Gian-Carlo (1978), _Ordinary Differential Equations_, New York: John Wiley and Sons, Inc., [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-471-07411-X](https://en.wikipedia.org/wiki/Special:BookSources/0-471-07411-X "Special:BookSources/0-471-07411-X")
*   Gershenfeld, Neil (1999), _The Nature of Mathematical Modeling_, Cambridge, UK.: Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-57095-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-57095-4 "Special:BookSources/978-0-521-57095-4")
*   Robinson, James C. (2004), _An Introduction to Ordinary Differential Equations_, Cambridge, UK.: Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-521-82650-0](https://en.wikipedia.org/wiki/Special:BookSources/0-521-82650-0 "Special:BookSources/0-521-82650-0")

*   [http://eqworld.ipmnet.ru/en/solutions/ode.htm](http://eqworld.ipmnet.ru/en/solutions/ode.htm)
*   [Dynamic Dictionary of Mathematical Function](http://ddmf.msr-inria.inria.fr/). Automatic and interactive study of many holonomic functions.
