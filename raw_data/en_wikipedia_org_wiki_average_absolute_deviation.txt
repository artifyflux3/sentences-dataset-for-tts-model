Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Measures of dispersion 2 Mean absolute deviation around a central point Toggle Mean absolute deviation around a central point subsection 2.1 Mean absolute deviation around the mean 2.1.1 Relation to standard deviation 2.2 Mean absolute deviation around the median 3 Median absolute deviation around a central point Toggle Median absolute deviation around a central point subsection 3.1 Median absolute deviation around the median 4 Maximum absolute deviation 5 Minimization 6 Estimation 7 See also 8 References 9 External links Toggle the table of contents Average absolute deviation 25 languages العربية Català Чӑвашла Deutsch Español Esperanto Français 한국어 Italiano עברית Македонски Nederlands Norsk bokmål Norsk nynorsk Polski Português Русский Shqip Slovenščina Српски / srpski Sunda Svenska Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Summary statistic of variability The average absolute deviation ( AAD ) of a data set is the average of the absolute deviations from a central point . It is a summary statistic of statistical dispersion or variability. In the general form, the central point can be a mean , median , mode , or the result of any other measure of central tendency or any reference value related to the given data set. 
AAD includes the mean absolute deviation and the median absolute deviation (both abbreviated as MAD ).

Measures of dispersion [ edit ] Several measures of statistical dispersion are defined in terms of the absolute deviation.
The term "average absolute deviation" does not uniquely identify a measure of statistical dispersion , as there are several measures that can be used to measure absolute deviations, and there are several measures of central tendency that can be used as well. Thus, to uniquely identify the absolute deviation it is necessary to specify both the measure of deviation and the measure of central tendency. The statistical literature has not yet adopted a standard notation, as both the mean absolute deviation around the mean and the median absolute deviation around the median have been denoted by their initials "MAD" in the literature, which may lead to confusion, since they generally have values considerably different from each other.

Mean absolute deviation around a central point [ edit ] For arbitrary differences (not around a central point), see Mean absolute difference .

For paired differences (also known as mean absolute deviation), see Mean absolute error .

The mean absolute deviation of a set X = { x 1 , x 2 , …, x n } is 1 n ∑ ∑ i = 1 n | x i − − m ( X ) | .

{\displaystyle {\frac {1}{n}}\sum _{i=1}^{n}|x_{i}-m(X)|.} The choice of measure of central tendency, m ( X ) {\displaystyle m(X)} , has a marked effect on the value of the mean deviation. For example, for the data set {2, 2, 3, 4, 14}: Measure of central tendency m ( X ) {\displaystyle m(X)} Mean absolute deviation Arithmetic Mean = 5 | 2 − − 5 | + | 2 − − 5 | + | 3 − − 5 | + | 4 − − 5 | + | 14 − − 5 | 5 = 3.6 {\displaystyle {\frac {|2-5|+|2-5|+|3-5|+|4-5|+|14-5|}{5}}=3.6} Median = 3 | 2 − − 3 | + | 2 − − 3 | + | 3 − − 3 | + | 4 − − 3 | + | 14 − − 3 | 5 = 2.8 {\displaystyle {\frac {|2-3|+|2-3|+|3-3|+|4-3|+|14-3|}{5}}=2.8} Mode = 2 | 2 − − 2 | + | 2 − − 2 | + | 3 − − 2 | + | 4 − − 2 | + | 14 − − 2 | 5 = 3.0 {\displaystyle {\frac {|2-2|+|2-2|+|3-2|+|4-2|+|14-2|}{5}}=3.0} Mean absolute deviation around the mean [ edit ] The mean absolute deviation (MAD), also referred to as the "mean deviation" or sometimes "average absolute deviation", is the mean of the data's absolute deviations around the data's mean: the average (absolute) distance from the mean. "Average absolute deviation" can refer to either this usage, or to the general form with respect to a specified central point (see above).

MAD has been proposed to be used in place of standard deviation since it corresponds better to real life.

[ 1 ] Because the MAD is a simpler measure of variability than the standard deviation , it can be useful in school teaching.

[ 2 ] [ 3 ] This method's forecast accuracy is very closely related to the mean squared error (MSE) method which is just the average squared error of the forecasts. Although these methods are very closely related, MAD is more commonly used because it is both easier to compute (avoiding the need for squaring) [ 4 ] and easier to understand.

[ 5 ] Relation to standard deviation [ edit ] See also: Median absolute deviation § Relation to standard deviation For the normal distribution , the ratio of mean absolute deviation from the mean to standard deviation is 2 / π π = 0.79788456 … … {\textstyle {\sqrt {2/\pi }}=0.79788456\ldots } . Thus if X is a normally distributed random variable with expected value 0 then, see Geary (1935): [ 6 ] w = E | X | E ( X 2 ) = 2 π π .

{\displaystyle w={\frac {E|X|}{\sqrt {E(X^{2})}}}={\sqrt {\frac {2}{\pi }}}.} In other words, for a normal distribution, mean absolute deviation is about 0.8 times the standard deviation.
However, in-sample measurements deliver values of the ratio of mean average deviation / standard deviation for a given Gaussian sample n with the following bounds: w n ∈ ∈ [ 0 , 1 ] {\displaystyle w_{n}\in [0,1]} , with a bias for small n .

[ 7 ] The mean absolute deviation from the mean is less than or equal to the standard deviation ; one way of proving this relies on Jensen's inequality .

Proof Jensen's inequality is φ φ ( E [ Y ] ) ≤ ≤ E [ φ φ ( Y ) ] {\displaystyle \varphi \left(\mathbb {E} [Y]\right)\leq \mathbb {E} \left[\varphi (Y)\right]} , where φ is a convex function, this implies for Y = | X − − μ μ | {\displaystyle Y=\vert X-\mu \vert } that: ( E | X − − μ μ | ) 2 ≤ ≤ E ( | X − − μ μ | 2 ) {\displaystyle \left(\mathbb {E} |X-\mu \right|)^{2}\leq \mathbb {E} \left(|X-\mu |^{2}\right)} ( E | X − − μ μ | ) 2 ≤ ≤ Var ⁡ ⁡ ( X ) {\displaystyle \left(\mathbb {E} |X-\mu \right|)^{2}\leq \operatorname {Var} (X)} Since both sides are positive, and the square root is a monotonically increasing function in the positive domain: E ( | X − − μ μ | ) ≤ ≤ Var ⁡ ⁡ ( X ) {\displaystyle \mathbb {E} \left(|X-\mu \right|)\leq {\sqrt {\operatorname {Var} (X)}}} For a general case of this statement, see Hölder's inequality .

Mean absolute deviation around the median [ edit ] The median is the point about which the mean deviation is minimized. The MAD median offers a direct measure of the scale of a random variable around its median D med = E | X − − median | {\displaystyle D_{\text{med}}=E|X-{\text{median}}|} This is the maximum likelihood estimator of the scale parameter b {\displaystyle b} of the Laplace distribution .

Since the median minimizes the average absolute distance, we have D med ≤ ≤ D mean {\displaystyle D_{\text{med}}\leq D_{\text{mean}}} .
The mean absolute deviation from the median is less than or equal to the mean absolute deviation from the mean. In fact, the mean absolute deviation from the median is always less than or equal to the mean absolute deviation from any other fixed number.

By using the general dispersion function, Habib (2011) defined MAD about median as D med = E | X − − median | = 2 Cov ⁡ ⁡ ( X , I O ) {\displaystyle D_{\text{med}}=E|X-{\text{median}}|=2\operatorname {Cov} (X,I_{O})} where the indicator function is I O := { 1 if x > median , 0 otherwise .

{\displaystyle \mathbf {I} _{O}:={\begin{cases}1&{\text{if }}x>{\text{median}},\\0&{\text{otherwise}}.\end{cases}}} This representation allows for obtaining MAD median correlation coefficients.

[ citation needed ] Median absolute deviation around a central point [ edit ] Main article: Median absolute deviation While in principle the mean or any other central point could be taken as the central point for the median absolute deviation, most often the median value is taken instead.

Median absolute deviation around the median [ edit ] Main article: Median absolute deviation The median absolute deviation (also MAD) is the median of the absolute deviation from the median . It is a robust estimator of dispersion .

For the example {2, 2, 3, 4, 14}: 3 is the median, so the absolute deviations from the median are {1, 1, 0, 1, 11} (reordered as {0, 1, 1, 1, 11}) with a median of 1, in this case unaffected by the value of the outlier 14, so the median absolute deviation is 1.

For a symmetric distribution, the median absolute deviation is equal to half the interquartile range .

Maximum absolute deviation [ edit ] The maximum absolute deviation around an arbitrary point is the maximum of the absolute deviations of a sample from that point. While not strictly a measure of central tendency, the maximum absolute deviation can be found using the formula for the average absolute deviation as above with m ( X ) = max ( X ) {\displaystyle m(X)=\max(X)} , where max ( X ) {\displaystyle \max(X)} is the sample maximum .

Minimization [ edit ] The measures of statistical dispersion derived from absolute deviation characterize various measures of central tendency as minimizing dispersion:
The median is the measure of central tendency most associated with the absolute deviation. Some location parameters can be compared as follows: L 2 norm statistics: the mean minimizes the mean squared error L 1 norm statistics: the median minimizes average absolute deviation, L ∞ norm statistics: the mid-range minimizes the maximum absolute deviation trimmed L ∞ norm statistics: for example, the midhinge (average of first and third quartiles ) which minimizes the median absolute deviation of the whole distribution, also minimizes the maximum absolute deviation of the distribution after the top and bottom 25% have been trimmed off.

Estimation [ edit ] The mean absolute deviation of a sample is a biased estimator of the mean absolute deviation of the population.
In order for the absolute deviation to be an unbiased estimator, the expected value (average) of all the sample absolute deviations must equal the population absolute deviation. However, it does not. For the population 1,2,3 both the population absolute deviation about the median and the population absolute deviation about the mean are 2/3. The average of all the sample absolute deviations about the mean of size 3 that can be drawn from the population is 44/81, while the average of all the sample absolute deviations about the median is 4/9. Therefore, the absolute deviation is a biased estimator.

However, this argument is based on the notion of mean-unbiasedness. Each measure of location has its own form of unbiasedness (see entry on biased estimator ). The relevant form of unbiasedness here is median unbiasedness.

See also [ edit ] Deviation (statistics) Median absolute deviation Squared deviations from the mean Least absolute deviations Errors Mean absolute error Mean absolute percentage error Probable error Mean absolute difference Average rectified value References [ edit ] ^ Taleb, Nassim Nicholas (2014).

"What scientific idea is ready for retirement?" .

Edge . Archived from the original on 2014-01-16 . Retrieved 2014-01-16 .

{{ cite web }} :  CS1 maint: bot: original URL status unknown ( link ) ^ Kader, Gary (March 1999).

"Means and MADS" .

Mathematics Teaching in the Middle School .

4 (6): 398– 403.

doi : 10.5951/MTMS.4.6.0398 .

Archived from the original on 2013-05-18 . Retrieved 20 February 2013 .

^ Franklin, Christine, Gary Kader, Denise Mewborn, Jerry Moreno, Roxy Peck , Mike Perry, and Richard Scheaffer (2007).

Guidelines for Assessment and Instruction in Statistics Education (PDF) . American Statistical Association.

ISBN 978-0-9791747-1-1 .

Archived (PDF) from the original on 2013-03-07 . Retrieved 2013-02-20 .

{{ cite book }} :  CS1 maint: multiple names: authors list ( link ) ^ Nahmias, Steven; Olsen, Tava Lennon (2015), Production and Operations Analysis (7th ed.), Waveland Press, p. 62, ISBN 9781478628248 , MAD is often the preferred method of measuring the forecast error because it does not require squaring.

^ Stadtler, Hartmut; Kilger, Christoph; Meyr, Herbert, eds. (2014), Supply Chain Management and Advanced Planning: Concepts, Models, Software, and Case Studies , Springer Texts in Business and Economics (5th ed.), Springer, p. 143, ISBN 9783642553097 , the meaning of the MAD is easier to interpret .

^ Geary, R. C. (1935). The ratio of the mean deviation to the standard deviation as a test of normality. Biometrika, 27(3/4), 310–332.

^ See also Geary's 1936 and 1946 papers: Geary, R. C. (1936). Moments of the ratio of the mean deviation to the standard deviation for normal samples. Biometrika, 28(3/4), 295–307 and Geary, R. C. (1947). Testing for normality. Biometrika, 34(3/4), 209–242.

External links [ edit ] Advantages of the mean absolute deviation v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐jqs2z
Cached time: 20250812005623
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.370 seconds
Real time usage: 0.518 seconds
Preprocessor visited node count: 1875/1000000
Revision size: 13228/2097152 bytes
Post‐expand include size: 161305/2097152 bytes
Template argument size: 3162/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 34745/5000000 bytes
Lua time usage: 0.205/10.000 seconds
Lua memory usage: 6527713/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  350.971      1 -total
 36.21%  127.101      1 Template:Statistics
 35.51%  124.621      1 Template:Navbox_with_collapsible_groups
 30.81%  108.147      1 Template:Reflist
 20.41%   71.641      1 Template:Cite_web
 15.13%   53.090      1 Template:Short_description
 12.69%   44.549     11 Template:Navbox
  9.61%   33.727      2 Template:Pagetype
  8.31%   29.159      1 Template:Citation_needed
  7.43%   26.085      1 Template:Hlist Saved in parser cache with key enwiki:pcache:344242:|#|:idhash:canonical and timestamp 20250812005623 and revision id 1301022098. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Average_absolute_deviation&oldid=1301022098 " Category : Statistical deviation and dispersion Hidden categories: CS1 maint: bot: original URL status unknown CS1 maint: multiple names: authors list Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from November 2019 This page was last edited on 17 July 2025, at 17:46 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Average absolute deviation 25 languages Add topic

