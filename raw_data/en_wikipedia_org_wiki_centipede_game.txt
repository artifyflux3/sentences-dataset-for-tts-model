Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Play Toggle Play subsection 1.1 Formal definition 2 Equilibrium analysis and backward induction 3 Empirical results Toggle Empirical results subsection 3.1 Preference-based explanation 3.2 Bounded rationality explanation 4 Significance 5 See also 6 References 7 External links Toggle the table of contents Centipede game 9 languages Español Euskara فارسی Français Italiano עברית Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Two-player extensive form game For the arcade game, see Centipede (video game) .

In game theory , the centipede game , first introduced by Robert Rosenthal in 1981, is an extensive form game in which two players take turns choosing either to take a slightly larger share of an increasing pot, or to pass the pot to the other player.  The payoffs are arranged so that if one passes the pot to one's opponent and the opponent takes the pot on the next round, one receives slightly less than if one had taken the pot on this round, but after an additional switch the potential payoff will be higher. Therefore, although at each round a player has an incentive to take the pot, it would be better for them to wait. Although the traditional centipede game had a limit of 100 rounds (hence the name), any game with this structure but a different number of rounds is also called a centipede game.

The unique subgame perfect equilibrium (and every Nash equilibrium ) of these games results in the first player taking the pot on the first round of the game; however, in empirical tests, relatively few players do so, and as a result, achieve a higher payoff than in the subgame perfect and Nash equilibria. These results are taken to show that subgame perfect equilibria and Nash equilibria fail to predict human play in some circumstances. The Centipede game is commonly used in introductory game theory courses and texts to highlight the concept of backward induction and the iterated elimination of dominated strategies , which show a standard way of providing a solution to the game.

A centipede game with starting piles of 1 and 4 coins Play [ edit ] One possible version of a centipede game could be played as follows: Consider two players: Alice and Bob . Alice moves first. At the start of the game, Alice has two piles of coins in front of her: one pile contains 4 coins and the other pile contains 1 coin. Each player has two moves available: either "take" the larger pile of coins and give the smaller pile to the other player or "push" both piles across the table to the other player. Each time the piles of coins pass across the table, the quantity of coins in each pile doubles. For example, assume that Alice chooses to "push" the piles on her first move, handing the piles of 1 and 4 coins over to Bob, doubling them to 2 and 8. Bob could now use his first move to either "take" the pile of 8 coins and give 2 coins to Alice, or he can "push" the two piles back across the table again to Alice, again increasing the size of the piles to 4 and 16 coins. The game continues for a fixed number of rounds or until a player decides to end the game by pocketing a pile of coins.

The addition of coins is taken to be an externality , as it is not contributed by either player.

Formal definition [ edit ] The centipede game may be written as G ( N , m 0 , m 1 ) {\displaystyle {\mathcal {G}}(N,~m_{0},~m_{1})} where N , m 0 , m 1 ∈ ∈ N {\displaystyle N,m_{0},m_{1}\in \mathbb {N} } and m 0 > m 1 {\displaystyle m_{0}>m_{1}} . Players I {\displaystyle I} and I I {\displaystyle II} alternate, starting with player I {\displaystyle I} , and may on each turn play a move from { t a k e , p u s h } {\displaystyle \{\mathrm {take} ,\mathrm {push} \}} with a maximum of N {\displaystyle N} rounds. The game terminates when t a k e {\displaystyle \mathrm {take} } is played for the first time, otherwise  upon N {\displaystyle N} moves, if t a k e {\displaystyle \mathrm {take} } is never played.

Suppose the game ends on round t ∈ ∈ { 0 , … … , N − − 1 } {\displaystyle t\in \{0,\ldots ,N-1\}} with player p ∈ ∈ { I , I I } {\displaystyle p\in \{I,II\}} making the final move. Then the outcome of the game at round t {\displaystyle t} is defined as follows: If p {\displaystyle p} played t a k e {\displaystyle \mathrm {take} } , then p {\displaystyle p} gains 2 t m 0 {\displaystyle 2^{t}m_{0}} coins and p ∗ ∗ {\displaystyle p^{\ast }} gains 2 t m 1 {\displaystyle 2^{t}m_{1}} .

If p {\displaystyle p} played p u s h {\displaystyle \mathrm {push} } , then p {\displaystyle p} gains 2 t + 1 m 1 {\displaystyle 2^{t+1}m_{1}} coins and p ∗ ∗ {\displaystyle p^{\ast }} gains 2 t + 1 m 0 {\displaystyle 2^{t+1}m_{0}} .

Here, p ∗ ∗ ∈ ∈ { I , I I } {\displaystyle p^{\ast }\in \{I,II\}} denotes the other player.

Equilibrium analysis and backward induction [ edit ] An extensive form representation of a four-stage centipede game, which ends after four rounds with the money being split. Passing the coins across the table is represented by a move of R (going across the row of the lattice, sometimes also represented by A for across) and pocketing the coins is a move D (down the lattice). The numbers 1 and 2 along the top of the diagram show the alternating decision-maker between two players denoted here as 1 and 2, and the numbers at the bottom of each branch show the payoff for players 1 and 2 respectively.

Standard game theoretic tools predict that the first player will defect on the first round, taking the pile of coins for himself.  In the centipede game, a pure strategy consists of a set of actions (one for each choice point in the game, even though some of these choice points may never be reached) and a mixed strategy is a probability distribution over the possible pure strategies.  There are several pure strategy Nash equilibria of the centipede game and infinitely many mixed strategy Nash equilibria.  However, there is only one subgame perfect equilibrium (a popular refinement to the Nash equilibrium concept).

In the unique subgame perfect equilibrium, each player chooses to defect at every opportunity.  This, of course, means defection at the first stage.  In the Nash equilibria, however, the actions that would be taken after the initial choice opportunities (even though they are never reached since the first player defects immediately) may be cooperative.

Defection by the first player is the unique subgame perfect equilibrium and required by any Nash equilibrium , it can be established by backward induction .  Suppose two players reach the final round of the game; the second player will do better by defecting and taking a slightly larger share of the pot.  Since we suppose the second player will defect, the first player does better by defecting in the second to last round, taking a slightly higher payoff than she would have received by allowing the second player to defect in the last round.  But knowing this, the second player ought to defect in the third to last round, taking a slightly higher payoff than he would have received by allowing the first player to defect in the second to last round.  This reasoning proceeds backwards through the game tree until one concludes that the best action is for the first player to defect in the first round.  The same reasoning can apply to any node in the game tree.

For a game that ends after four rounds, this reasoning proceeds as follows.  If we were to reach the last round of the game, Player 2 would do better by choosing d instead of r , receiving 4 coins instead of 3.  However, given that 2 will choose d , 1 should choose D in the second to last round, receiving 3 instead of 2.  Given that 1 would choose D in the second to last round, 2 should choose d in the third to last round, receiving 2 instead of 1.  But given this, Player 1 should choose D in the first round, receiving 1 instead of 0.

There are a large number of Nash equilibria in a centipede game, but in each, the first player defects on the first round and the second player defects in the next round frequently enough to dissuade the first player from passing.  Being in a Nash equilibrium does not require that strategies be rational at every point in the game as in the subgame perfect equilibrium.  This means that strategies that are cooperative in the never-reached later rounds of the game could still be in a Nash equilibrium.  In the example above, one Nash equilibrium is for both players to defect on each round (even in the later rounds that are never reached).  Another Nash equilibrium is for player 1 to defect on the first round, but pass on the third round and for player 2 to defect at any opportunity.

Empirical results [ edit ] Several studies have demonstrated that the Nash equilibrium (and likewise, subgame perfect equilibrium) play is rarely observed.  Instead, subjects regularly show partial cooperation, playing "R" (or "r") for several moves before eventually choosing "D" (or "d").  It is also rare for subjects to cooperate through the whole game.  For examples see McKelvey and Palfrey (1992), Nagel and Tang (1998) or Krockow et al. (2016) [ 1 ] for a survey.  Scholars have investigated the effect of increasing the stakes.  As with other games, for instance the ultimatum game , as the stakes increase the play approaches (but does not reach) Nash equilibrium play.

[ 2 ] Since the empirical studies have produced results that are inconsistent with the traditional equilibrium analysis, several explanations of this behavior have been offered. To explain the experimental data, we either need some altruistic agents or some bounded rational agents.

Preference-based explanation [ edit ] One reason people may deviate from equilibrium behavior is if some are altruistic . The basic idea is that you have a certain probability at each game to play against an altruistic agent and if this probability is high enough, you should defect on the last round rather than the first. If enough people are altruists, sacrificing the payoff of first-round defection is worth the price in order to determine whether or not your opponent is an altruist.

McKelvey and Palfrey (1992) create a model with some altruistic agents and some rational agents who will end up playing a mixed strategy (i.e. they play at multiple nodes with some probability). To match well the experimental data, around 5% of the players need to be altruistic in the model. Elmshauser (2022) [ 3 ] shows that a model including altruistic agents and uncertainty-averse agents (instead of rational agents) explain even better the experimental data. Some experiments tried to see whether players who passing a lot would also be the most altruistic agents in other games or other life situations (see for instance Pulford et al [ 4 ] or Gamba and Regner (2019) [ 5 ] who assessed Social Value Orientation ). Players passing a lot were indeed more altruistic but the difference wasn't huge.

Bounded rationality explanation [ edit ] Rosenthal (1981) suggested that if one has reason to believe his opponent will deviate from Nash behavior, then it may be advantageous to not defect on the first round. Another possibility involves error. If there is a significant possibility of error in action, perhaps because your opponent has not reasoned completely through the backward induction, it may be advantageous (and rational) to cooperate in the initial rounds. The quantal response equilibrium of McKelvey and Palfrey (1995) [ 6 ] created a model with agents playing Nash equilibrium with errors and they applied it to the Centipede game.

Another modelling able to explain behaviors in the centipede game is the level-k model, which is a cognitive hierarchy theory : a L0 player plays randomly, the L1 player best responds to the L0 player, the L2 player best responds to the L1 player and so on. In many games, scholars observed that most of the player were L2 or L3 players, which is consistent with the centipede game experimental data. Garcia-Pola et al. (2020) [ 7 ] concluded from an experiment that most of the players either play following a Level-k logic or a Quantal response logic.

However, Parco, Rapoport and Stein (2002) illustrated that the level of financial incentives can have a profound effect on the outcome in a three-player game: the larger the incentives are for deviation, the greater propensity for learning behavior in a repeated single-play experimental design to move toward the Nash equilibrium.

Palacios-Huerta and Volij (2009) find that expert chess players play differently from college students. With a rising Elo , the probability of continuing the game declines; all Grandmasters in the experiment stopped at their first chance. They conclude that chess players are familiar with using backward induction reasoning and hence need less learning to reach the equilibrium. However, in an attempt to replicate these findings, Levitt, List, and Sadoff (2010) find strongly contradictory results, with zero of sixteen Grandmasters stopping the game at the first node.

Qualitative research by Krockow et al., which employed think-aloud protocols that required players in a Centipede game to vocalise their reasoning during the game, indicated a range of decision biases such as action bias or completion bias, which may drive irrational choices in the game.

[ 8 ] Significance [ edit ] Like the prisoner's dilemma , this game presents a conflict between self-interest and mutual benefit.  If it could be enforced, both players would prefer that they both cooperate throughout the entire game.  However, a player's self-interest or players' distrust can interfere and create a situation where both do worse than if they had blindly cooperated.  Although the Prisoner's Dilemma has received substantial attention for this fact, the Centipede Game has received relatively less.

Additionally, Binmore (2005) has argued that some real-world situations can be described by the Centipede game.  One example he presents is the exchange of goods between parties that distrust each other.  Another example Binmore (2005) likens to the Centipede game is the mating behavior of a hermaphroditic sea bass which takes turns exchanging eggs to fertilize.  In these cases, we find cooperation to be abundant.

Since the payoffs for some amount of cooperation in the Centipede game are so much larger than immediate defection, the "rational" solutions given by backward induction can seem paradoxical.  This, coupled with the fact that experimental subjects regularly cooperate in the Centipede game, has prompted debate over the usefulness of the idealizations involved in the backward induction solutions, see Aumann (1995, 1996) and Binmore (1996).

See also [ edit ] Backward induction Experimental economics Traveler's dilemma Unexpected hanging paradox References [ edit ] ^ Krockow, Eva M.; Colman, Andrew M.; Pulford, Briony D. (2016-01-01).

"Cooperation in repeated interactions: A systematic review of Centipede game experiments, 1992–2016" .

European Review of Social Psychology .

27 (1): 231– 282.

doi : 10.1080/10463283.2016.1249640 .

hdl : 2381/39513 .

ISSN 1046-3283 .

S2CID 32932923 .

^ Rapoport, Amnon; Stein, William E.; Parco, James E.; Nicholas, Thomas E. (2003-05-01).

"Equilibrium play and adaptive learning in a three-person centipede game" .

Games and Economic Behavior .

43 (2): 239– 265.

doi : 10.1016/S0899-8256(03)00009-5 .

ISSN 0899-8256 .

S2CID 1823952 .

^ "Altruism and Ambiguity in the Centipede game" .

osf.io . Retrieved 2022-10-10 .

^ Pulford, Briony D.; Colman, Andrew M.; Lawrence, Catherine L.; Krockow, Eva M. (April 2017).

"Reasons for cooperating in repeated interactions: Social value orientations, fuzzy traces, reciprocity, and activity bias" .

Decision .

4 (2): 102– 122.

doi : 10.1037/dec0000057 .

ISSN 2325-9973 .

S2CID 32870881 .

^ Gamba, Astrid; Regner, Tobias (2019-11-01).

"Preferences-dependent learning in the centipede game: The persistence of mistrust" .

European Economic Review .

120 103316.

doi : 10.1016/j.euroecorev.2019.103316 .

ISSN 0014-2921 .

S2CID 204429302 .

^ McKelvey, Richard D.; Palfrey, Thomas R. (1995-07-01).

"Quantal Response Equilibria for Normal Form Games" .

Games and Economic Behavior .

10 (1): 6– 38.

doi : 10.1006/game.1995.1023 .

ISSN 0899-8256 .

^ García-Pola, Bernardo; Iriberri, Nagore; Kovářík, Jaromír (2020-03-01).

"Non-equilibrium play in centipede games" .

Games and Economic Behavior .

120 : 391– 433.

doi : 10.1016/j.geb.2020.01.007 .

ISSN 0899-8256 .

S2CID 44043202 .

^ Krockow, Eva M.; Colman, Andrew M.; Pulford, Briony D. (October 2016).

"Exploring cooperation and competition in the Centipede game through verbal protocol analysis: Exploring cooperation" .

European Journal of Social Psychology .

46 (6): 746– 761.

doi : 10.1002/ejsp.2226 .

hdl : 2381/37754 .

Aumann, R. (1995). "Backward Induction and Common Knowledge of Rationality".

Games and Economic Behavior .

8 (1): 6– 19.

doi : 10.1016/S0899-8256(05)80015-6 .

——— (1996). "A Reply to Binmore".

Games and Economic Behavior .

17 (1): 138– 146.

doi : 10.1006/game.1996.0099 .

Binmore, K. (2005).

Natural Justice . New York: Oxford University Press.

ISBN 978-0-19-517811-1 .

——— (1996). "A Note on Backward Induction".

Games and Economic Behavior .

17 (1): 135– 137.

doi : 10.1006/game.1996.0098 .

Levitt, S. D.; List, J. A. & Sadoff, S. E. (2010).

"Checkmate: Exploring Backward Induction Among Chess Players" (PDF) .

American Economic Review .

101 (2): 975– 990.

doi : 10.1257/aer.101.2.975 .

McKelvey, R. & Palfrey, T. (1992). "An experimental study of the centipede game".

Econometrica .

60 (4): 803– 836.

CiteSeerX 10.1.1.295.2774 .

doi : 10.2307/2951567 .

JSTOR 2951567 .

Nagel, R. & Tang, F. F. (1998). "An Experimental Study on the Centipede Game in Normal Form: An Investigation on Learning".

Journal of Mathematical Psychology .

42 ( 2– 3): 356– 384.

doi : 10.1006/jmps.1998.1225 .

PMID 9710555 .

Palacios-Huerta, I. & Volij, O. (2009). "Field Centipedes".

American Economic Review .

99 (4): 1619– 1635.

doi : 10.1257/aer.99.4.1619 .

Parco, J. E.; Rapoport, A. & Stein, W. E. (2002). "Effects of financial incentives on the breakdown of mutual trust".

Psychological Science .

13 (3): 292– 297.

CiteSeerX 10.1.1.612.8407 .

doi : 10.1111/1467-9280.00454 .

PMID 12009054 .

S2CID 2915973 .

Rapoport, A.; Stein, W. E.; Parco, J. E. & Nicholas, T. E. (2003). "Equilibrium play and adaptive learning in a three-person centipede game".

Games and Economic Behavior .

43 (2): 239– 265.

doi : 10.1016/S0899-8256(03)00009-5 .

S2CID 1823952 .

Rosenthal, R. (1981). "Games of Perfect Information, Predatory Pricing, and the Chain Store".

Journal of Economic Theory .

25 (1): 92– 100.

CiteSeerX 10.1.1.482.8534 .

doi : 10.1016/0022-0531(81)90018-1 .

External links [ edit ] EconPort article on the Centipede Game Rationality and Game Theory - AMS column about the centipede game Online experiment in VeconLab Play the Centipede game in your browser on gametheorygame.nl v t e Game theory Glossary Game theorists Games Traditional game theory Definitions Asynchrony Bayesian regret Best response Bounded rationality Cheap talk Coalition Complete contract Complete information Complete mixing Confrontation analysis Conjectural variation Contingent cooperator Coopetition Cooperative game theory Dynamic inconsistency Escalation of commitment Farsightedness Game semantics Hierarchy of beliefs Imperfect information Incomplete information Information set Move by nature Mutual knowledge Non-cooperative game theory Non-credible threat Outcome Perfect information Perfect recall Ply Preference Rationality Sequential game Simultaneous action selection Spite Strategic complements Strategic dominance Strategic form Strategic interaction Strategic move Strategy Subgame Succinct game Topological game Tragedy of the commons Uncorrelated asymmetry Equilibrium concepts Backward induction Bayes correlated equilibrium Bayesian efficiency Bayesian game Bayesian Nash equilibrium Berge equilibrium Bertrand–Edgeworth model Coalition-proof Nash equilibrium Core Correlated equilibrium Cursed equilibrium Edgeworth price cycle Epsilon-equilibrium Gibbs equilibrium Incomplete contracts Inequity aversion Individual rationality Iterated elimination of dominated strategies Markov perfect equilibrium Mertens-stable equilibrium Nash equilibrium Open-loop model Pareto efficiency Payoff dominance Perfect Bayesian equilibrium Price of anarchy Program equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Rational agent Rationalizability Rationalizable strategy Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfect equilibrium Trembling hand equilibrium Strategies Appeasement Bid shading Cheap talk Collusion Commitment device De-escalation Deterrence Escalation Fictitious play Focal point Grim trigger Hobbesian trap Markov strategy Max-dominated strategy Mixed strategy Pure strategy Tit for tat Win–stay, lose–switch Games All-pay auction Battle of the sexes Nash bargaining game Bertrand competition Blotto game Centipede game Coordination game Cournot competition Deadlock Dictator game Trust game Diner's dilemma Dollar auction El Farol Bar problem Electronic mail game Gift-exchange game Guess 2/3 of the average Keynesian beauty contest Kuhn poker Lewis signaling game Matching pennies Obligationes Optional prisoner's dilemma Pirate game Prisoner's dilemma Public goods game Rendezvous problem Rock paper scissors Stackelberg competition Stag hunt Traveler's dilemma Ultimatum game Volunteer's dilemma War of attrition Theorems Arrow's impossibility theorem Aumann's agreement theorem Brouwer fixed-point theorem Competitive altruism Folk theorem Gibbard–Satterthwaite theorem Gibbs lemma Glicksberg's theorem Kakutani fixed-point theorem Kuhn's theorem One-shot deviation principle Prim–Read theory Rational ignorance Rational irrationality Sperner's lemma Zermelo's theorem Subfields Algorithmic game theory Behavioral game theory Behavioral strategy Compositional game theory Contract theory Drama theory Graphical game theory Heresthetic Mean-field game theory Negotiation theory Quantum game theory Social software Key people Albert W. Tucker Alvin E. Roth Amos Tversky Antoine Augustin Cournot Ariel Rubinstein David Gale David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Herbert Scarf Hervé Moulin Jean Tirole Jean-François Mertens Jennifer Tour Chayes Ken Binmore Kenneth Arrow Leonid Hurwicz Lloyd Shapley Martin Shubik Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Aumann Robert Axelrod Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Combinatorial game theory Core concepts Combinatorial explosion Determinacy Disjunctive sum First-player and second-player win Game complexity Game tree Impartial game Misère Partisan game Solved game Sprague–Grundy theorem Strategy-stealing argument Zugzwang Games Chess Chomp Clobber Cram Domineering Hackenbush Nim Notakto Subtract a square Sylver coinage Toads and Frogs Mathematical tools Mex Nimber On Numbers and Games Star Surreal number Winning Ways for Your Mathematical Plays Search algorithms Alpha–beta pruning Expectiminimax Minimax Monte Carlo tree search Negamax Paranoid algorithm Principal variation search Key people Claude Shannon John Conway John von Neumann Evolutionary game theory Core concepts Bishop–Cannings theorem Evolution and the Theory of Games Evolutionarily stable set Evolutionarily stable state Evolutionarily stable strategy Replicator equation Risk dominance Stochastically stable equilibrium Weak evolutionarily stable strategy Games Chicken Stag hunt Applications Cultural group selection Fisher's principle Mobbing Terminal investment hypothesis Key people John Maynard Smith Robert Axelrod Mechanism design Core concepts Algorithmic mechanism design Bayesian-optimal mechanism Incentive compatibility Market design Monotonicity Participation constraint Revelation principle Strategyproofness Vickrey–Clarke–Groves mechanism Theorems Myerson–Satterthwaite theorem Revenue equivalence Applications Digital goods auction Knapsack auction Truthful cake-cutting Other topics Bertrand paradox Chainstore paradox Computational complexity of games Helly metric Multi-agent system PPAD-complete Mathematics portal Commons WikiProject Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Centipede_game&oldid=1305367252 " Category : Non-cooperative games Hidden categories: Articles with short description Short description is different from Wikidata This page was last edited on 11 August 2025, at 17:07 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Centipede game 9 languages Add topic

