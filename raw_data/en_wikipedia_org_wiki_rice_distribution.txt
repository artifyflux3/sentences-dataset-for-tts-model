Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Characterization 2 Properties Toggle Properties subsection 2.1 Moments 3 Related distributions 4 Limiting cases 5 Parameter estimation (the Koay inversion technique) 6 Applications 7 See also 8 References 9 Further reading 10 External links Toggle the table of contents Rice distribution 9 languages Català Français Italiano עברית Русский Slovenščina Türkçe Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Probability distribution In the 2D plane, pick a fixed point at distance ν from the origin. Generate a distribution of 2D points centered around that point, where the x and y coordinates are chosen independently from a Gaussian distribution with standard deviation σ (blue region). If R is the distance from these points to the origin, then R has a Rice distribution.

Probability density function Cumulative distribution function Parameters ν ν ≥ ≥ 0 {\displaystyle \nu \geq 0} , distance between the reference point and the center of the bivariate distribution, σ σ ≥ ≥ 0 {\displaystyle \sigma \geq 0} , scale Support x ∈ ∈ [ 0 , ∞ ∞ ) {\displaystyle x\in [0,\infty )} PDF x σ σ 2 exp ⁡ ⁡ ( − − ( x 2 + ν ν 2 ) 2 σ σ 2 ) I 0 ( x ν ν σ σ 2 ) {\displaystyle {\frac {x}{\sigma ^{2}}}\exp \left({\frac {-(x^{2}+\nu ^{2})}{2\sigma ^{2}}}\right)I_{0}\left({\frac {x\nu }{\sigma ^{2}}}\right)} CDF 1 − − Q 1 ( ν ν σ σ , x σ σ ) {\displaystyle 1-Q_{1}\left({\frac {\nu }{\sigma }},{\frac {x}{\sigma }}\right)} where Q 1 is the Marcum Q-function Mean σ σ π π / 2 L 1 / 2 ( − − ν ν 2 / 2 σ σ 2 ) {\displaystyle \sigma {\sqrt {\pi /2}}\,\,L_{1/2}(-\nu ^{2}/2\sigma ^{2})} Variance 2 σ σ 2 + ν ν 2 − − π π σ σ 2 2 L 1 / 2 2 ( − − ν ν 2 2 σ σ 2 ) {\displaystyle 2\sigma ^{2}+\nu ^{2}-{\frac {\pi \sigma ^{2}}{2}}L_{1/2}^{2}\left({\frac {-\nu ^{2}}{2\sigma ^{2}}}\right)} Skewness (complicated) Excess kurtosis (complicated) In probability theory , the Rice distribution or Rician distribution (or, less commonly, Ricean distribution ) is the probability distribution of the magnitude of a circularly-symmetric bivariate normal random variable , possibly with non-zero mean (noncentral). It was named after Stephen O. Rice (1907–1986).

Characterization [ edit ] The probability density function is f ( x ∣ ∣ ν ν , σ σ ) = x σ σ 2 exp ⁡ ⁡ ( − − ( x 2 + ν ν 2 ) 2 σ σ 2 ) I 0 ( x ν ν σ σ 2 ) , {\displaystyle f(x\mid \nu ,\sigma )={\frac {x}{\sigma ^{2}}}\exp \left({\frac {-(x^{2}+\nu ^{2})}{2\sigma ^{2}}}\right)I_{0}\left({\frac {x\nu }{\sigma ^{2}}}\right),} where I 0 ( z ) is the modified Bessel function of the first kind with order zero.

In the context of Rician fading , the distribution is often also rewritten using the Shape Parameter K = ν ν 2 2 σ σ 2 {\displaystyle K={\frac {\nu ^{2}}{2\sigma ^{2}}}} , defined as the ratio of the power contributions by line-of-sight path to the remaining multipaths, and the Scale parameter Ω Ω = ν ν 2 + 2 σ σ 2 {\displaystyle \Omega =\nu ^{2}+2\sigma ^{2}} , defined as the total power received in all paths.

[ 1 ] The characteristic function of the Rice distribution is given as: [ 2 ] [ 3 ] χ χ X ( t ∣ ∣ ν ν , σ σ ) = exp ⁡ ⁡ ( − − ν ν 2 2 σ σ 2 ) [ Ψ Ψ 2 ( 1 ; 1 , 1 2 ; ν ν 2 2 σ σ 2 , − − 1 2 σ σ 2 t 2 ) + i 2 σ σ t Ψ Ψ 2 ( 3 2 ; 1 , 3 2 ; ν ν 2 2 σ σ 2 , − − 1 2 σ σ 2 t 2 ) ] , {\displaystyle {\begin{aligned}\chi _{X}(t\mid \nu ,\sigma )=\exp \left(-{\frac {\nu ^{2}}{2\sigma ^{2}}}\right)&\left[\Psi _{2}\left(1;1,{\frac {1}{2}};{\frac {\nu ^{2}}{2\sigma ^{2}}},-{\frac {1}{2}}\sigma ^{2}t^{2}\right)\right.\\[8pt]&\left.{}+i{\sqrt {2}}\sigma t\Psi _{2}\left({\frac {3}{2}};1,{\frac {3}{2}};{\frac {\nu ^{2}}{2\sigma ^{2}}},-{\frac {1}{2}}\sigma ^{2}t^{2}\right)\right],\end{aligned}}} where Ψ Ψ 2 ( α α ; γ γ , γ γ ′ ; x , y ) {\displaystyle \Psi _{2}\left(\alpha ;\gamma ,\gamma ';x,y\right)} is one of Horn's confluent hypergeometric functions with two variables and convergent for all finite values of x {\displaystyle x} and y {\displaystyle y} . It is given by: [ 4 ] [ 5 ] Ψ Ψ 2 ( α α ; γ γ , γ γ ′ ; x , y ) = ∑ ∑ n = 0 ∞ ∞ ∑ ∑ m = 0 ∞ ∞ ( α α ) m + n ( γ γ ) m ( γ γ ′ ) n x m y n m !

n !

, {\displaystyle \Psi _{2}\left(\alpha ;\gamma ,\gamma ';x,y\right)=\sum _{n=0}^{\infty }\sum _{m=0}^{\infty }{\frac {(\alpha )_{m+n}}{(\gamma )_{m}(\gamma ')_{n}}}{\frac {x^{m}y^{n}}{m!n!}},} where ( x ) n = x ( x + 1 ) ⋯ ⋯ ( x + n − − 1 ) = Γ Γ ( x + n ) Γ Γ ( x ) {\displaystyle (x)_{n}=x(x+1)\cdots (x+n-1)={\frac {\Gamma (x+n)}{\Gamma (x)}}} is the rising factorial .

Properties [ edit ] Moments [ edit ] The first few raw moments are: μ μ 1 ′ = σ σ π π / 2 L 1 / 2 ( − − ν ν 2 / 2 σ σ 2 ) μ μ 2 ′ = 2 σ σ 2 + ν ν 2 μ μ 3 ′ = 3 σ σ 3 π π / 2 L 3 / 2 ( − − ν ν 2 / 2 σ σ 2 ) μ μ 4 ′ = 8 σ σ 4 + 8 σ σ 2 ν ν 2 + ν ν 4 μ μ 5 ′ = 15 σ σ 5 π π / 2 L 5 / 2 ( − − ν ν 2 / 2 σ σ 2 ) μ μ 6 ′ = 48 σ σ 6 + 72 σ σ 4 ν ν 2 + 18 σ σ 2 ν ν 4 + ν ν 6 {\displaystyle {\begin{aligned}\mu _{1}^{'}&=\sigma {\sqrt {\pi /2}}\,\,L_{1/2}(-\nu ^{2}/2\sigma ^{2})\\\mu _{2}^{'}&=2\sigma ^{2}+\nu ^{2}\,\\\mu _{3}^{'}&=3\sigma ^{3}{\sqrt {\pi /2}}\,\,L_{3/2}(-\nu ^{2}/2\sigma ^{2})\\\mu _{4}^{'}&=8\sigma ^{4}+8\sigma ^{2}\nu ^{2}+\nu ^{4}\,\\\mu _{5}^{'}&=15\sigma ^{5}{\sqrt {\pi /2}}\,\,L_{5/2}(-\nu ^{2}/2\sigma ^{2})\\\mu _{6}^{'}&=48\sigma ^{6}+72\sigma ^{4}\nu ^{2}+18\sigma ^{2}\nu ^{4}+\nu ^{6}\end{aligned}}} and, in general, the raw moments are given by μ μ k ′ = σ σ k 2 k / 2 Γ Γ ( 1 + k / 2 ) L k / 2 ( − − ν ν 2 / 2 σ σ 2 ) .

{\displaystyle \mu _{k}^{'}=\sigma ^{k}2^{k/2}\,\Gamma (1\!+\!k/2)\,L_{k/2}(-\nu ^{2}/2\sigma ^{2}).\,} Here L q ( x ) denotes a Laguerre polynomial : L q ( x ) = L q ( 0 ) ( x ) = M ( − − q , 1 , x ) = 1 F 1 ( − − q ; 1 ; x ) {\displaystyle L_{q}(x)=L_{q}^{(0)}(x)=M(-q,1,x)=\,_{1}F_{1}(-q;1;x)} where M ( a , b , z ) = 1 F 1 ( a ; b ; z ) {\displaystyle M(a,b,z)=_{1}F_{1}(a;b;z)} is the confluent hypergeometric function of the first kind. When k is even, the raw moments become simple polynomials in σ and ν , as in the examples above.

For the case q = 1/2: L 1 / 2 ( x ) = 1 F 1 ( − − 1 2 ; 1 ; x ) = e x / 2 [ ( 1 − − x ) I 0 ( − − x 2 ) − − x I 1 ( − − x 2 ) ] .

{\displaystyle {\begin{aligned}L_{1/2}(x)&=\,_{1}F_{1}\left(-{\frac {1}{2}};1;x\right)\\&=e^{x/2}\left[\left(1-x\right)I_{0}\left(-{\frac {x}{2}}\right)-xI_{1}\left(-{\frac {x}{2}}\right)\right].\end{aligned}}} The second central moment , the variance , is μ μ 2 = 2 σ σ 2 + ν ν 2 − − ( π π σ σ 2 / 2 ) L 1 / 2 2 ( − − ν ν 2 / 2 σ σ 2 ) .

{\displaystyle \mu _{2}=2\sigma ^{2}+\nu ^{2}-(\pi \sigma ^{2}/2)\,L_{1/2}^{2}(-\nu ^{2}/2\sigma ^{2}).} Note that L 1 / 2 2 ( ⋅ ⋅ ) {\displaystyle L_{1/2}^{2}(\cdot )} indicates the square of the Laguerre polynomial L 1 / 2 ( ⋅ ⋅ ) {\displaystyle L_{1/2}(\cdot )} , not the generalized Laguerre polynomial L 1 / 2 ( 2 ) ( ⋅ ⋅ ) .

{\displaystyle L_{1/2}^{(2)}(\cdot ).} Related distributions [ edit ] R ∼ ∼ R i c e ( | ν ν | , σ σ ) {\displaystyle R\sim \mathrm {Rice} \left(|\nu |,\sigma \right)} if R = X 2 + Y 2 {\displaystyle R={\sqrt {X^{2}+Y^{2}}}} where X ∼ ∼ N ( ν ν cos ⁡ ⁡ θ θ , σ σ 2 ) {\displaystyle X\sim N\left(\nu \cos \theta ,\sigma ^{2}\right)} and Y ∼ ∼ N ( ν ν sin ⁡ ⁡ θ θ , σ σ 2 ) {\displaystyle Y\sim N\left(\nu \sin \theta ,\sigma ^{2}\right)} are statistically independent normal random variables and θ θ {\displaystyle \theta } is any real number.

Another case where R ∼ ∼ R i c e ( ν ν , σ σ ) {\displaystyle R\sim \mathrm {Rice} \left(\nu ,\sigma \right)} comes from the following steps: Generate P {\displaystyle P} having a Poisson distribution with parameter (also mean, for a Poisson) λ λ = ν ν 2 2 σ σ 2 .

{\displaystyle \lambda ={\frac {\nu ^{2}}{2\sigma ^{2}}}.} Generate X {\displaystyle X} having a chi-squared distribution with 2 P + 2 degrees of freedom.

Set R = σ σ X .

{\displaystyle R=\sigma {\sqrt {X}}.} If R ∼ ∼ Rice ⁡ ⁡ ( ν ν , 1 ) {\displaystyle R\sim \operatorname {Rice} (\nu ,1)} then R 2 {\displaystyle R^{2}} has a noncentral chi-squared distribution with two degrees of freedom and noncentrality parameter ν ν 2 {\displaystyle \nu ^{2}} .

If R ∼ ∼ Rice ⁡ ⁡ ( ν ν , 1 ) {\displaystyle R\sim \operatorname {Rice} (\nu ,1)} then R {\displaystyle R} has a noncentral chi distribution with two degrees of freedom and noncentrality parameter ν ν {\displaystyle \nu } .

If R ∼ ∼ Rice ⁡ ⁡ ( 0 , σ σ ) {\displaystyle R\sim \operatorname {Rice} (0,\sigma )} then R ∼ ∼ Rayleigh ⁡ ⁡ ( σ σ ) {\displaystyle R\sim \operatorname {Rayleigh} (\sigma )} , i.e., for the special case of the Rice distribution given by ν ν = 0 {\displaystyle \nu =0} , the distribution becomes the Rayleigh distribution , for which the variance is μ μ 2 = 4 − − π π 2 σ σ 2 {\displaystyle \mu _{2}={\frac {4-\pi }{2}}\sigma ^{2}} .

If R ∼ ∼ Rice ⁡ ⁡ ( 0 , σ σ ) {\displaystyle R\sim \operatorname {Rice} (0,\sigma )} then R 2 {\displaystyle R^{2}} has an exponential distribution .

[ 6 ] If R ∼ ∼ Rice ⁡ ⁡ ( ν ν , σ σ ) {\displaystyle R\sim \operatorname {Rice} \left(\nu ,\sigma \right)} then 1 / R {\displaystyle 1/R} has an Inverse Rician distribution.

[ 7 ] The folded normal distribution is the univariate special case of the Rice distribution.

Limiting cases [ edit ] For large values of the argument, the Laguerre polynomial becomes [ 8 ] lim x → → − − ∞ ∞ L ν ν ( x ) = | x | ν ν Γ Γ ( 1 + ν ν ) .

{\displaystyle \lim _{x\to -\infty }L_{\nu }(x)={\frac {|x|^{\nu }}{\Gamma (1+\nu )}}.} It is seen that as ν becomes large or σ becomes small the mean becomes ν and the variance becomes σ 2 .

The transition to a Gaussian approximation proceeds as follows.  From Bessel function theory we have I α α ( z ) → → e z 2 π π z ( 1 − − 4 α α 2 − − 1 8 z + ⋯ ⋯ ) as z → → ∞ ∞ {\displaystyle I_{\alpha }(z)\to {\frac {e^{z}}{\sqrt {2\pi z}}}\left(1-{\frac {4\alpha ^{2}-1}{8z}}+\cdots \right){\text{ as }}z\rightarrow \infty } so, in the large x ν ν / σ σ 2 {\displaystyle x\nu /\sigma ^{2}} region, an asymptotic expansion of the Rician distribution: f ( x , ν ν , σ σ ) = x σ σ 2 exp ⁡ ⁡ ( − − ( x 2 + ν ν 2 ) 2 σ σ 2 ) I 0 ( x ν ν σ σ 2 ) is x σ σ 2 exp ⁡ ⁡ ( − − ( x 2 + ν ν 2 ) 2 σ σ 2 ) σ σ 2 2 π π x ν ν exp ⁡ ⁡ ( 2 x ν ν 2 σ σ 2 ) ( 1 + σ σ 2 8 x ν ν + ⋯ ⋯ ) → → 1 σ σ 2 π π exp ⁡ ⁡ ( − − ( x − − ν ν ) 2 2 σ σ 2 ) x ν ν , as x ν ν σ σ 2 → → ∞ ∞ {\displaystyle {\begin{aligned}f(x,\nu ,\sigma )={}&{\frac {x}{\sigma ^{2}}}\exp \left({\frac {-(x^{2}+\nu ^{2})}{2\sigma ^{2}}}\right)I_{0}\left({\frac {x\nu }{\sigma ^{2}}}\right)\\{\text{  is  }}\\&{\frac {x}{\sigma ^{2}}}\exp \left({\frac {-(x^{2}+\nu ^{2})}{2\sigma ^{2}}}\right){\sqrt {\frac {\sigma ^{2}}{2\pi x\nu }}}\exp \left({\frac {2x\nu }{2\sigma ^{2}}}\right)\left(1+{\frac {\sigma ^{2}}{8x\nu }}+\cdots \right)\\\rightarrow {}&{\frac {1}{\sigma {\sqrt {2\pi }}}}\exp \left(-{\frac {(x-\nu )^{2}}{2\sigma ^{2}}}\right){\sqrt {\frac {x}{\nu }}},\;\;\;{\text{ as }}{\frac {x\nu }{\sigma ^{2}}}\rightarrow \infty \end{aligned}}} Moreover, when the density is concentrated around ν ν {\textstyle \nu } and | x − − ν ν | ≪ ≪ σ σ {\textstyle |x-\nu |\ll \sigma } because of the Gaussian exponent, we can also write x / ν ν ≈ ≈ 1 {\textstyle {\sqrt {{x}/{\nu }}}\approx 1} and finally get the Normal approximation f ( x , ν ν , σ σ ) ≈ ≈ 1 σ σ 2 π π exp ⁡ ⁡ ( − − ( x − − ν ν ) 2 2 σ σ 2 ) , ν ν σ σ ≫ ≫ 1 {\displaystyle f(x,\nu ,\sigma )\approx {\frac {1}{\sigma {\sqrt {2\pi }}}}\exp \left(-{\frac {(x-\nu )^{2}}{2\sigma ^{2}}}\right),\;\;\;{\frac {\nu }{\sigma }}\gg 1} The approximation becomes usable for ν ν σ σ > 3 {\displaystyle {\frac {\nu }{\sigma }}>3} Parameter estimation (the Koay inversion technique) [ edit ] There are three different methods for estimating the parameters of the Rice distribution, (1) method of moments , [ 9 ] [ 10 ] [ 11 ] [ 12 ] (2) method of maximum likelihood , [ 9 ] [ 10 ] [ 11 ] [ 13 ] and (3) method of least squares.

[ citation needed ] In the first two methods the interest is in estimating the parameters of the distribution, ν and σ, from a sample of data. This can be done using the method of moments, e.g., the sample mean and the sample standard deviation. The sample mean is an estimate of μ 1 ' and the sample standard deviation is an estimate of μ 2 1/2 .

The following is an efficient method, known as the "Koay inversion technique".

[ 14 ] for solving the estimating equations , based on the sample mean and the sample standard deviation, simultaneously . This inversion technique is also known as the fixed point formula of SNR . Earlier works [ 9 ] [ 15 ] on the method of moments usually use a root-finding method to solve the problem, which is not efficient.

First, the ratio of the sample mean to the sample standard deviation is defined as r , i.e., r = μ μ 1 ′ / μ μ 2 1 / 2 {\displaystyle r=\mu _{1}^{'}/\mu _{2}^{1/2}} . The fixed point formula of SNR is expressed as g ( θ θ ) = ξ ξ ( θ θ ) [ 1 + r 2 ] − − 2 , {\displaystyle g(\theta )={\sqrt {\xi {(\theta )}\left[1+r^{2}\right]-2}},} where θ θ {\displaystyle \theta } is the ratio of the parameters, i.e., θ θ = ν ν / σ σ {\displaystyle \theta ={\nu }/{\sigma }} , and ξ ξ ( θ θ ) {\displaystyle \xi {\left(\theta \right)}} is given by: ξ ξ ( θ θ ) = 2 + θ θ 2 − − π π 8 exp ⁡ ⁡ ( − − θ θ 2 / 2 ) [ ( 2 + θ θ 2 ) I 0 ( θ θ 2 / 4 ) + θ θ 2 I 1 ( θ θ 2 / 4 ) ] 2 , {\displaystyle \xi {\left(\theta \right)}=2+\theta ^{2}-{\frac {\pi }{8}}\exp {(-\theta ^{2}/2)}\left[(2+\theta ^{2})I_{0}(\theta ^{2}/4)+\theta ^{2}I_{1}(\theta ^{2}/4)\right]^{2},} where I 0 {\displaystyle I_{0}} and I 1 {\displaystyle I_{1}} are modified Bessel functions of the first kind .

Note that ξ ξ ( θ θ ) {\displaystyle \xi {\left(\theta \right)}} is a scaling factor of σ σ {\displaystyle \sigma } and is related to μ μ 2 {\displaystyle \mu _{2}} by: μ μ 2 = ξ ξ ( θ θ ) σ σ 2 .

{\displaystyle \mu _{2}=\xi {\left(\theta \right)}\sigma ^{2}.} To find the fixed point, θ θ ∗ ∗ {\displaystyle \theta ^{*}} , of g {\displaystyle g} , an initial solution is selected, θ θ 0 {\displaystyle {\theta }_{0}} , that is greater than the lower bound, which is θ θ lower bound = 0 {\displaystyle {\theta }_{\text{lower bound}}=0} and occurs when r = π π / ( 4 − − π π ) {\textstyle r={\sqrt {\pi /(4-\pi )}}} [ 14 ] (Notice that this is the r = μ μ 1 ′ / μ μ 2 1 / 2 {\displaystyle r=\mu _{1}^{'}/\mu _{2}^{1/2}} of a Rayleigh distribution). This provides a starting point for the iteration, which uses functional composition, [ clarification needed ] and this continues until | g i ( θ θ 0 ) − − θ θ i − − 1 | {\displaystyle \left|g^{i}\left(\theta _{0}\right)-\theta _{i-1}\right|} is less than some small positive value. Here, g i {\displaystyle g^{i}} denotes the composition of the same function, g {\displaystyle g} , i {\displaystyle i} times. In practice, we associate the final θ θ n {\displaystyle \theta _{n}} for some integer n {\displaystyle n} as the fixed point, θ θ ∗ ∗ {\displaystyle \theta ^{*}} , i.e., θ θ ∗ ∗ = g ( θ θ ∗ ∗ ) {\displaystyle \theta ^{*}=g\left(\theta ^{*}\right)} .

Once the fixed point is found, the estimates ν ν {\displaystyle \nu } and σ σ {\displaystyle \sigma } are found through the scaling function, ξ ξ ( θ θ ) {\displaystyle \xi {\left(\theta \right)}} , as follows: σ σ = μ μ 2 1 / 2 ξ ξ ( θ θ ∗ ∗ ) , {\displaystyle \sigma ={\frac {\mu _{2}^{1/2}}{\sqrt {\xi \left(\theta ^{*}\right)}}},} and ν ν = ( μ μ 1 ′ 2 + ( ξ ξ ( θ θ ∗ ∗ ) − − 2 ) σ σ 2 ) .

{\displaystyle \nu ={\sqrt {\left(\mu _{1}^{'~2}+\left(\xi \left(\theta ^{*}\right)-2\right)\sigma ^{2}\right)}}.} To speed up the iteration even more, one can use the Newton's method of root-finding.

[ 14 ] This particular approach is highly efficient.

Applications [ edit ] The Euclidean norm of a bivariate circularly-symmetric normally distributed random vector .

Rician fading (for multipath interference )) Effect of sighting error on target shooting.

[ 16 ] Analysis of diversity receivers in radio communications.

[ 17 ] [ 18 ] Distribution of eccentricities for models of the inner Solar System after long-term numerical integration .

[ 19 ] Distribution of noise in magnetic resonance imaging images is rician [ 20 ] See also [ edit ] Hoyt distribution Rayleigh distribution References [ edit ] ^ Abdi, A. and Tepedelenlioglu, C. and Kaveh, M. and Giannakis, G., "On the estimation of the K parameter for the Rice fading distribution ", IEEE Communications Letters , March 2001, p. 92–94 ^ Liu 2007 (in one of Horn's confluent hypergeometric functions with two variables).

^ Annamalai 2000 (in a sum of infinite series).

^ Erdelyi 1953.

^ Srivastava 1985.

^ Richards, M.A., Rice Distribution for RCS , Georgia Institute of Technology (Sep 2006) ^ Jones, Jessica L., Joyce McLaughlin, and Daniel Renzi.

"The noise distribution in a shear wave speed image computed using arrival times at fixed spatial positions." , Inverse Problems 33.5 (2017): 055012.

^ Abramowitz and Stegun (1968) §13.5.1 ^ a b c Talukdar et al. 1991 ^ a b Bonny et al. 1996 ^ a b Sijbers et al. 1998 ^ den Dekker and Sijbers 2014 ^ Varadarajan and Haldar 2015 ^ a b c Koay et al. 2006 (known as the SNR fixed point formula).

^ Abdi 2001 ^ "Ballistipedia" . Retrieved 4 May 2014 .

^ Beaulieu, Norman C; Hemachandra, Kasun (September 2011). "Novel Representations for the Bivariate Rician Distribution".

IEEE Transactions on Communications .

59 (11): 2951– 2954.

doi : 10.1109/TCOMM.2011.092011.090171 .

S2CID 1221747 .

^ Dharmawansa, Prathapasinghe; Rajatheva, Nandana; Tellambura, Chinthananda (March 2009).

"New Series Representation for the Trivariate Non-Central Chi-Squared Distribution" (PDF) .

IEEE Transactions on Communications .

57 (3): 665– 675.

CiteSeerX 10.1.1.582.533 .

doi : 10.1109/TCOMM.2009.03.070083 .

S2CID 15706035 .

^ Laskar, J. (1 July 2008).

"Chaotic diffusion in the Solar System" .

Icarus .

196 (1): 1– 15.

arXiv : 0802.3371 .

Bibcode : 2008Icar..196....1L .

doi : 10.1016/j.icarus.2008.02.017 .

ISSN 0019-1035 .

S2CID 11586168 .

^ Gudbjartsson, HáKon; Patz, Samuel (December 1995). "The rician distribution of noisy mri data".

Magnetic Resonance in Medicine .

34 (6): 910– 914.

doi : 10.1002/mrm.1910340618 .

Further reading [ edit ] Abramowitz, M. and Stegun, I. A.  (ed.), Handbook of Mathematical Functions , National Bureau of Standards, 1964; reprinted Dover Publications, 1965.

ISBN 0-486-61272-4 Rice, S. O.

, Mathematical Analysis of Random Noise. Bell System Technical Journal 24 (1945) 46–156.

I. Soltani Bozchalooi; Ming Liang (20 November 2007). "A smoothness index-guided approach to wavelet parameter selection in signal de-noising and fault detection".

Journal of Sound and Vibration .

308 ( 1– 2): 253– 254.

Bibcode : 2007JSV...308..246B .

doi : 10.1016/j.jsv.2007.07.038 .

Wang, Dong; Zhou, Qiang; Tsui, Kwok-Leung (2017). "On the distribution of the modulus of Gabor wavelet coefficients and the upper bound of the dimensionless smoothness index in the case of additive Gaussian noises: Revisited".

Journal of Sound and Vibration .

395 : 393– 400.

doi : 10.1016/j.jsv.2017.02.013 .

Liu, X. and Hanzo, L., A Unified Exact BER Performance Analysis of Asynchronous DS-CDMA Systems Using BPSK Modulation over Fading Channels , IEEE Transactions on Wireless Communications, Volume 6, Issue 10, October 2007, pp. 3504–3509.

Annamalai, A., Tellambura, C. and Bhargava, V. K., Equal-Gain Diversity Receiver Performance in Wireless Channels , IEEE Transactions on Communications, Volume 48, October 2000, pp. 1732–1745.

Erdelyi, A., Magnus, W., Oberhettinger, F. and Tricomi, F. G., Higher Transcendental Functions, Volume 1.

Archived 11 August 2011 at the Wayback Machine McGraw-Hill Book Company Inc., 1953.

Srivastava, H. M. and Karlsson, P. W., Multiple Gaussian Hypergeometric Series. Ellis Horwood Ltd., 1985.

Sijbers J., den Dekker A. J., Scheunders P. and Van Dyck D., "Maximum Likelihood estimation of Rician distribution parameters" Archived 19 October 2011 at the Wayback Machine , IEEE Transactions on Medical Imaging, Vol. 17, Nr. 3, pp. 357–361, (1998) Varadarajan D. and Haldar J. P., "A Majorize-Minimize Framework for Rician and Non-Central Chi MR Images" , IEEE Transactions on Medical Imaging, Vol. 34, no. 10, pp. 2191–2202, (2015) den Dekker, A.J.; Sijbers, J (December 2014). "Data distributions in magnetic resonance images: a review".

Physica Medica .

30 (7): 725– 741.

doi : 10.1016/j.ejmp.2014.05.002 .

PMID 25059432 .

Koay, C.G. and Basser, P. J., Analytically exact correction scheme for signal extraction from noisy magnitude MR signals , Journal of Magnetic Resonance, Volume 179, Issue = 2, p. 317–322, (2006) Abdi, A., Tepedelenlioglu, C., Kaveh, M., and Giannakis, G.

On the estimation of the K parameter for the Rice fading distribution , IEEE Communications Letters, Volume 5, Number 3, March 2001, pp. 92–94.

Talukdar, K.K.; Lawing, William D. (March 1991). "Estimation of the parameters of the Rice distribution".

Journal of the Acoustical Society of America .

89 (3): 1193– 1197.

Bibcode : 1991ASAJ...89.1193T .

doi : 10.1121/1.400532 .

Bonny, J.M.; Renou, J.P.; Zanca, M. (November 1996). "Optimal Measurement of Magnitude and Phase from MR Data".

Journal of Magnetic Resonance, Series B .

113 (2): 136– 144.

Bibcode : 1996JMRB..113..136B .

doi : 10.1006/jmrb.1996.0166 .

PMID 8954899 .

External links [ edit ] MATLAB code for Rice/Rician distribution (PDF, mean and variance, and generating random samples) v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Rice_distribution&oldid=1302129163 " Category : Continuous distributions Hidden categories: Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from June 2012 Wikipedia articles needing clarification from June 2012 Webarchive template wayback links Use dmy dates from August 2019 This page was last edited on 23 July 2025, at 14:59 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Rice distribution 9 languages Add topic

