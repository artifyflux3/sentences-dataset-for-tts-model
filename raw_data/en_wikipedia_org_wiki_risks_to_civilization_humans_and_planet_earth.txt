Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition and classification Toggle Definition and classification subsection 1.1 Defining global catastrophic risks 1.2 Defining existential risks 1.2.1 Non-extinction risks 2 Potential sources of risk 3 Methodological challenges Toggle Methodological challenges subsection 3.1 Lack of historical precedent 3.2 Incentives and coordination 3.3 Cognitive biases 4 Proposed mitigation Toggle Proposed mitigation subsection 4.1 Multi-layer defense 4.2 Funding 4.3 Survival planning 4.4 Global catastrophic risks and global governance 4.5 Climate emergency plans 4.6 Space colonization 5 Organizations 6 See also 7 References 8 Further reading 9 External links Toggle the table of contents Global catastrophic risk 32 languages العربية Brezhoneg Català Čeština Deutsch Eesti Español فارسی Français 한국어 Hausa Հայերեն עברית Jawa Қазақша Magyar Nederlands 日本語 پښتو Português Русский Sakizaya Slovenčina Српски / srpski Svenska தமிழ் ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Risks to civilization, humans and planet Earth ) Hypothetical global-scale disaster risk "Doomsday scenario" redirects here. For other uses, see Doomsday (disambiguation) .

Not to be confused with Global Catastrophic Risks (book) .

For broader coverage of this topic, see Human extinction and Global catastrophe scenarios .

Artist's impression of a major asteroid impact . An asteroid caused the extinction of the non-avian dinosaurs .

[ 1 ] Futures studies Concepts Accelerating change Cashless society Global catastrophic risk Future Earth Mathematics Race Climate Space exploration Universe Historical materialism Kondratiev wave Kardashev scale Moore's law Peak oil Population cycle Resource depletion Singularity Swanson's law Techniques Backcasting Causal layered analysis Chain-linked model Consensus forecast Cross impact analysis Delphi Real-time Delphi Foresight Future-proof Futures wheel Future workshop Horizon scanning Reference class forecasting Scenario planning Systems analysis Threatcasting Trend analysis Technology assessment and forecasting Critical design Design fiction Exploratory engineering FTA Hype cycle Science fiction prototyping Speculative design TRL Technology scouting Related topics Futarchy Transhumanism v t e A global catastrophic risk or a doomsday scenario is a hypothetical event that could damage human well-being on a global scale, [ 2 ] endangering or even destroying modern civilization .

[ 3 ] Existential risk is a related term limited to events that could cause full-blown human extinction or permanently and drastically curtail humanity's existence or potential.

[ 4 ] In the 21st century, a number of academic and non-profit organizations have been established to research global catastrophic and existential risks, formulate potential mitigation measures, and either advocate for or implement these measures.

Definition and classification [ edit ] Scope–severity grid from Bostrom's paper "Existential Risk Prevention as Global Priority" [ 5 ] Defining global catastrophic risks [ edit ] The term global catastrophic risk "lacks a sharp definition", and generally refers (loosely) to a risk that could inflict "serious damage to human well-being on a global scale".

[ 6 ] Humanity has suffered large catastrophes before. Some of these have caused serious damage but were only local in scope—e.g. the Black Death may have resulted in the deaths of a third of Europe's population, [ 7 ] 10% of the global population at the time.

[ 8 ] Some were global, but were not as severe—e.g. the 1918 influenza pandemic killed an estimated 3–6% of the world's population.

[ 9 ] Most global catastrophic risks would not be so intense as to kill the majority of life on earth, but even if one did, the ecosystem and humanity would eventually recover (in contrast to existential risks ).

Similarly, in Catastrophe: Risk and Response , Richard Posner singles out and groups together events that bring about "utter overthrow or ruin" on a global, rather than a "local or regional" scale. Posner highlights such events as worthy of special attention on cost–benefit grounds because they could directly or indirectly jeopardize the survival of the human race as a whole.

[ 10 ] Defining existential risks [ edit ] Existential risks are defined as "risks that threaten the destruction of humanity's long-term potential." [ 11 ] The instantiation of an existential risk (an existential catastrophe [ 12 ] ) would either cause outright human extinction or irreversibly lock in a drastically inferior state of affairs.

[ 5 ] [ 13 ] Existential risks are a sub-class of global catastrophic risks, where the damage is not only global but also terminal and permanent, preventing recovery and thereby affecting both current and all future generations.

[ 5 ] Non-extinction risks [ edit ] While extinction is the most obvious way in which humanity's long-term potential could be destroyed, there are others, including unrecoverable collapse and unrecoverable dystopia .

[ 14 ] A disaster severe enough to cause the permanent, irreversible collapse of human civilisation would constitute an existential catastrophe, even if it fell short of extinction.

[ 14 ] Similarly, if humanity fell under a totalitarian regime, and there were no chance of recovery, then such a dystopia would also be an existential catastrophe.

[ 15 ] Bryan Caplan writes that "perhaps an eternity of totalitarianism would be worse than extinction".

[ 15 ] ( George Orwell 's novel Nineteen Eighty-Four suggests [ 16 ] an example.

[ 17 ] ) A dystopian scenario shares the key features of extinction and unrecoverable collapse of civilization: before the catastrophe humanity faced a vast range of bright futures to choose from; after the catastrophe, humanity is locked forever in a terrible state.

[ 14 ] Potential sources of risk [ edit ] Main article: Global catastrophe scenarios Potential global catastrophic risks are conventionally classified as anthropogenic or non-anthropogenic hazards. Examples of non-anthropogenic risks are an asteroid or comet impact event , a supervolcanic eruption , a natural pandemic , a lethal gamma-ray burst , a geomagnetic storm from a coronal mass ejection destroying electronic equipment, natural long-term climate change , hostile extraterrestrial life , or the Sun transforming into a red giant star and engulfing the Earth billions of years in the future .

[ 18 ] Arrangement of global catastrophic risks into three sets according to whether they are largely human-caused, human influences upon nature, or purely natural Anthropogenic risks are those caused by humans and include those related to technology, governance, and climate change. Technological risks include the creation of artificial intelligence misaligned with human goals, biotechnology , and nanotechnology . Insufficient or malign global governance creates risks in the social and political domain, such as global war and nuclear holocaust , [ 19 ] biological warfare and bioterrorism using genetically modified organisms , cyberwarfare and cyberterrorism destroying critical infrastructure like the electrical grid , or radiological warfare using weapons such as large cobalt bombs . Other global catastrophic risks include climate change, environmental degradation , extinction of species , famine as a result of non-equitable resource distribution, human overpopulation or underpopulation , crop failures , and non- sustainable agriculture .

Methodological challenges [ edit ] Research into the nature and mitigation of global catastrophic risks and existential risks is subject to a unique set of challenges and, as a result, is not easily subjected to the usual standards of scientific rigour.

[ 14 ] For instance, it is neither feasible nor ethical to study these risks experimentally.

Carl Sagan expressed this with regards to nuclear war: "Understanding the long-term consequences of nuclear war is not a problem amenable to experimental verification".

[ 20 ] Moreover, many catastrophic risks change rapidly as technology advances and background conditions, such as geopolitical conditions, change. Another challenge is the general difficulty of accurately predicting the future over long timescales, especially for anthropogenic risks which depend on complex human political, economic and social systems.

[ 14 ] In addition to known and tangible risks, unforeseeable black swan extinction events may occur, presenting an additional methodological problem.

[ 14 ] [ 21 ] Lack of historical precedent [ edit ] Humanity has never suffered an existential catastrophe and if one were to occur, it would necessarily be unprecedented.

[ 14 ] Therefore, existential risks pose unique challenges to prediction, even more than other long-term events, because of observation selection effects .

[ 22 ] Unlike with most events, the failure of a complete extinction event to occur in the past is not evidence against their likelihood in the future, because every world that has experienced such an extinction event has gone unobserved by humanity. Regardless of civilization collapsing events' frequency, no civilization observes existential risks in its history.

[ 22 ] These anthropic issues may partly be avoided by looking at evidence that does not have such selection effects, such as asteroid impact craters on the Moon, or directly evaluating the likely impact of new technology.

[ 5 ] To understand the dynamics of an unprecedented, unrecoverable global civilizational collapse (a type of existential risk), it may be instructive to study the various local civilizational collapses that have occurred throughout human history.

[ 23 ] For instance, civilizations such as the Roman Empire have ended in a loss of centralized governance and a major civilization-wide loss of infrastructure and advanced technology. However, these examples demonstrate that societies appear to be fairly resilient to catastrophe; for example, Medieval Europe survived the Black Death without suffering anything resembling a civilization collapse despite losing 25 to 50 percent of its population.

[ 24 ] Incentives and coordination [ edit ] There are economic reasons that can explain why so little effort is going into global catastrophic risk reduction.  First, it is speculative and may never happen, so many people focus on other more pressing issues.  It is also a global public good , so we should expect it to be undersupplied by markets.

[ 5 ] Even if a large nation invested in risk mitigation measures, that nation would enjoy only a small fraction of the benefit of doing so. Furthermore, global catastrophic risk reduction can be thought of as an intergenerational global public good.  Since most of the hypothetical benefits of the reduction would be enjoyed by future generations, and though these future people would perhaps be willing to pay substantial sums for risk reduction, no mechanism for such a transaction exists.

[ 5 ] Cognitive biases [ edit ] Numerous cognitive biases can influence people's judgment of the importance of existential risks, including scope insensitivity , hyperbolic discounting , the availability heuristic , the conjunction fallacy , the affect heuristic , and the overconfidence effect .

[ 25 ] Scope insensitivity influences how bad people consider the extinction of the human race to be. For example, when people are motivated to donate money to altruistic causes, the quantity they are willing to give does not increase linearly with the magnitude of the issue: people are roughly as willing to prevent the deaths of 200,000 or 2,000 birds.

[ 26 ] Similarly, people are often more concerned about threats to individuals than to larger groups.

[ 25 ] Eliezer Yudkowsky theorizes that scope neglect plays a role in public perception of existential risks: [ 27 ] [ 28 ] Substantially larger numbers, such as 500 million deaths, and especially qualitatively different scenarios such as the extinction of the entire human species, seem to trigger a different mode of thinking... People who would never dream of hurting a child hear of existential risk, and say, "Well, maybe the human species doesn't really deserve to survive".

All past predictions of human extinction have proven to be false. To some, this makes future warnings seem less credible.

Nick Bostrom argues that the absence of human extinction in the past is weak evidence that there will be no human extinction in the future, due to survivor bias and other anthropic effects .

[ 29 ] Sociobiologist E. O. Wilson argued that: "The reason for this myopic fog, evolutionary biologists contend, is that it was actually advantageous during all but the last few millennia of the two million years of existence of the genus Homo... A premium was placed on close attention to the near future and early reproduction, and little else. Disasters of a magnitude that occur only once every few centuries were forgotten or transmuted into myth." [ 30 ] Proposed mitigation [ edit ] Multi-layer defense [ edit ] Defense in depth is a useful framework for categorizing risk mitigation measures into three layers of defense: [ 31 ] Prevention : Reducing the probability of a catastrophe occurring in the first place. Example: Measures to prevent outbreaks of new highly infectious diseases.

Response : Preventing the scaling of a catastrophe to the global level. Example: Measures to prevent escalation of a small-scale nuclear exchange into an all-out nuclear war.

Resilience : Increasing humanity's resilience (against extinction) when faced with global catastrophes. Example: Measures to increase food security during a nuclear winter.

[ 32 ] Human extinction is most likely when all three defenses are weak, that is, "by risks we are unlikely to prevent, unlikely to successfully respond to, and unlikely to be resilient against".

[ 31 ] The unprecedented nature of existential risks poses a special challenge in designing risk mitigation measures since humanity will not be able to learn from a track record of previous events.

[ 14 ] Funding [ edit ] Some researchers argue that both research and other initiatives relating to existential risk are underfunded. Nick Bostrom states that more research has been done on Star Trek , snowboarding , or dung beetles than on existential risks. Bostrom's comparisons have been criticized as "high-handed".

[ 33 ] [ 34 ] As of 2020, the Biological Weapons Convention organization had an annual budget of US$1.4 million.

[ 35 ] Survival planning [ edit ] Some scholars propose the establishment on Earth of one or more self-sufficient, remote, permanently occupied settlements specifically created for the purpose of surviving a global disaster.

[ 36 ] [ 37 ] [ 38 ] Economist Robin Hanson argues that a refuge permanently housing as few as 100 people would significantly improve the chances of human survival during a range of global catastrophes.

[ 36 ] [ 39 ] Food storage has been proposed globally, but the monetary cost would be high. Furthermore, it would likely contribute to the current millions of deaths per year due to malnutrition .

[ 40 ] In 2022, a team led by David Denkenberger modeled the cost-effectiveness of resilient foods to artificial general intelligence (AGI) safety and found "~98-99% confidence" for a higher marginal impact of work on resilient foods.

[ 41 ] Some survivalists stock survival retreats with multiple-year food supplies.

The Svalbard Global Seed Vault is buried 400 feet (120 m) inside a mountain on an island in the Arctic . It is designed to hold 2.5 billion seeds from more than 100 countries as a precaution to preserve the world's crops. The surrounding rock is −6 °C (21 °F) (as of 2015) but the vault is kept at −18 °C (0 °F) by refrigerators powered by locally sourced coal.

[ 42 ] [ 43 ] More speculatively, if society continues to function and if the biosphere remains habitable, calorie needs for the present human population might in theory be met during an extended absence of sunlight, given sufficient advance planning. Conjectured solutions include growing mushrooms on the dead plant biomass left in the wake of the catastrophe, converting cellulose to sugar, or feeding natural gas to methane-digesting bacteria.

[ 44 ] [ 45 ] Global catastrophic risks and global governance [ edit ] Insufficient global governance creates risks in the social and political domain, but the governance mechanisms develop more slowly than technological and social change. There are concerns from governments, the private sector, and the general public about the lack of governance mechanisms to efficiently deal with risks, negotiate and adjudicate between diverse and conflicting interests. This is further underlined by an understanding of the interconnectedness of global systemic risks.

[ 46 ] In absence or anticipation of global governance, national governments can act individually to better understand, mitigate and prepare for global catastrophes.

[ 47 ] Climate emergency plans [ edit ] In 2018, the Club of Rome called for greater climate change action and published its Climate Emergency Plan, which proposes ten action points to limit global average temperature increase to 1.5 degrees Celsius.

[ 48 ] Further, in 2019, the Club published the more comprehensive Planetary Emergency Plan.

[ 49 ] There is evidence to suggest that collectively engaging with the emotional experiences that emerge during contemplating the vulnerability of the human species within the context of climate change allows for these experiences to be adaptive. When collective engaging with and processing emotional experiences is supportive, this can lead to growth in resilience, psychological flexibility, tolerance of emotional experiences, and community engagement.

[ 50 ] Space colonization [ edit ] Main article: Space and survival Space colonization is a proposed alternative to improve the odds of surviving an extinction scenario.

[ 51 ] Solutions of this scope may require megascale engineering .

Astrophysicist Stephen Hawking advocated colonizing other planets within the Solar System once technology progresses sufficiently, in order to improve the chance of human survival from planet-wide events such as global thermonuclear war.

[ 52 ] [ 53 ] Organizations [ edit ] The Bulletin of the Atomic Scientists (est. 1945) is one of the oldest global risk organizations, founded after the public became alarmed by the potential of atomic warfare in the aftermath of WWII. It studies risks associated with nuclear war and energy and famously maintains the Doomsday Clock established in 1947. The Foresight Institute (est. 1986) examines the risks of nanotechnology and its benefits. It was one of the earliest organizations to study the unintended consequences of otherwise harmless technology gone haywire at a global scale. It was founded by K. Eric Drexler who postulated " grey goo ".

[ 54 ] [ 55 ] Beginning after 2000, a growing number of scientists, philosophers and tech billionaires created organizations devoted to studying global risks both inside and outside of academia.

[ 56 ] Independent non-governmental organizations (NGOs) include the Machine Intelligence Research Institute (est. 2000), which aims to reduce the risk of a catastrophe caused by artificial intelligence, [ 57 ] with donors including Peter Thiel and Jed McCaleb .

[ 58 ] The Nuclear Threat Initiative (est. 2001) seeks to reduce global threats from nuclear, biological and chemical threats, and containment of damage after an event.

[ 59 ] It maintains a nuclear material security index.

[ 60 ] The Lifeboat Foundation (est. 2009) funds research into preventing a technological catastrophe.

[ 61 ] Most of the research money funds projects at universities.

[ 62 ] The Global Catastrophic Risk Institute (est. 2011) is a US-based non-profit, non-partisan think tank founded by Seth Baum and Tony Barrett. GCRI does research and policy work across various risks, including artificial intelligence, nuclear war, climate change, and asteroid impacts.

[ 63 ] The Global Challenges Foundation (est. 2012), based in Stockholm and founded by Laszlo Szombatfalvy , releases a yearly report on the state of global risks.

[ 64 ] [ 65 ] The Future of Life Institute (est. 2014) works to reduce extreme, large-scale risks from transformative technologies, as well as steer the development and use of these technologies to benefit all life, through grantmaking, policy advocacy in the United States, European Union and United Nations, and educational outreach.

[ 66 ] Elon Musk , Vitalik Buterin and Jaan Tallinn are some of its biggest donors.

[ 67 ] University-based organizations included the Future of Humanity Institute (est. 2005) which researched the questions of humanity's long-term future, particularly existential risk.

[ 68 ] It was founded by Nick Bostrom and was based at Oxford University.

[ 68 ] The Centre for the Study of Existential Risk (est. 2012) is a Cambridge University-based organization which studies four major technological risks: artificial intelligence, biotechnology, global warming and warfare.

[ 69 ] All are man-made risks, as Huw Price explained to the AFP news agency, "It seems a reasonable prediction that some time in this or the next century intelligence will escape from the constraints of biology". He added that when this happens "we're no longer the smartest things around," and will risk being at the mercy of "machines that are not malicious, but machines whose interests don't include us." [ 70 ] Stephen Hawking was an acting adviser. The Millennium Alliance for Humanity and the Biosphere is a Stanford University-based organization focusing on many issues related to global catastrophe by bringing together members of academia in the humanities.

[ 71 ] [ 72 ] It was founded by Paul Ehrlich , among others.

[ 73 ] Stanford University also has the Center for International Security and Cooperation focusing on political cooperation to reduce global catastrophic risk.

[ 74 ] The Center for Security and Emerging Technology was established in January 2019 at Georgetown's Walsh School of Foreign Service and will focus on policy research of emerging technologies with an initial emphasis on artificial intelligence.

[ 75 ] They received a grant of 55M USD from Good Ventures as suggested by Open Philanthropy .

[ 75 ] Other risk assessment groups are based in or are part of governmental organizations. The World Health Organization (WHO) includes a division called the Global Alert and Response (GAR) which monitors and responds to global epidemic crisis.

[ 76 ] GAR helps member states with training and coordination of response to epidemics.

[ 77 ] The United States Agency for International Development (USAID) has its Emerging Pandemic Threats Program which aims to prevent and contain naturally generated pandemics at their source.

[ 78 ] The Lawrence Livermore National Laboratory has a division called the Global Security Principal Directorate which researches on behalf of the government issues such as bio-security and counter-terrorism.

[ 79 ] See also [ edit ] Outer space portal Philosophy portal Science portal Society portal Spaceflight portal Technology portal World portal Artificial intelligence arms race – Type of international competition Climate engineering – Deliberate and large-scale intervention in Earth's climate system Pages displaying short descriptions of redirect targets Community resilience – Concept in crisis management Extreme risk – Low-probability risk of very bad outcomes Fermi paradox – Discrepancy of the lack of evidence for alien life despite its apparent likelihood Foresight (psychology) – Behavior-based backcasting & forecasting factors Future of Earth – Long-term extrapolated geological and biological changes of planet Earth Future of the Solar System Global Risks Report – Publication of the World Economic Forum Great Filter – Hypothesis of barriers to forming interstellar civilizations Holocene extinction – Ongoing extinction event caused by human activity Impact event – Collision of two astronomical objects List of global issues – List of environmental and other issues affecting life on Earth Nuclear proliferation – Spread of nuclear weapons Outside Context Problem – 1996 Book by Iain M. Banks Pages displaying short descriptions of redirect targets Planetary boundaries – Limits not to be exceeded if humanity is to survive in a safe ecosystem Rare events - Events that occurs with low frequency, often with a widespread effect which might destabilize systems Risk of astronomical suffering – Scenarios of large amounts of future suffering Societal collapse – Fall of a complex human society Speculative evolution – Science fiction genre Survivalism – Movement of individuals or households preparing for emergencies and natural disasters Tail risk – Risk of statistically extreme events The Precipice: Existential Risk and the Future of Humanity – 2020 book by Toby Ord The Sixth Extinction: An Unnatural History – 2014 nonfiction book by Elizabeth Kolbert Timeline of the far future – Scientific projections regarding the far future Triple planetary crisis – Three intersecting global environmental crises Vulnerable world hypothesis – Existential risk concept World Scientists' Warning to Humanity – 1992 document about human carbon footprint References [ edit ] ^ Schulte, P.; et al. (March 5, 2010).

"The Chicxulub Asteroid Impact and Mass Extinction at the Cretaceous-Paleogene Boundary" (PDF) .

Science .

327 (5970): 1214– 1218.

Bibcode : 2010Sci...327.1214S .

doi : 10.1126/science.1177265 .

PMID 20203042 .

^ Bostrom, Nick (2008).

Global Catastrophic Risks (PDF) . Oxford University Press. p. 1.

Bibcode : 2008gcr..book.....B .

^ Ripple WJ, Wolf C, Newsome TM, Galetti M, Alamgir M, Crist E, Mahmoud MI, Laurance WF (November 13, 2017).

"World Scientists' Warning to Humanity: A Second Notice" .

BioScience .

67 (12): 1026– 1028.

doi : 10.1093/biosci/bix125 .

hdl : 11336/71342 .

^ Bostrom, Nick (March 2002).

"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards" .

Journal of Evolution and Technology .

9 .

^ a b c d e f Bostrom, Nick (2013). "Existential Risk Prevention as Global Priority".

Global Policy .

4 (1): 15– 3.

doi : 10.1111/1758-5899.12002 .

^ Bostrom, Nick; Cirkovic, Milan (2008).

Global Catastrophic Risks . Oxford: Oxford University Press. p. 1.

ISBN 978-0-19-857050-9 .

^ Ziegler, Philip (2012).

The Black Death . Faber and Faber. p. 397.

ISBN 9780571287116 .

^ Muehlhauser, Luke (March 15, 2017).

"How big a deal was the Industrial Revolution?" .

lukemuelhauser.com . Retrieved August 3, 2020 .

^ Taubenberger, Jeffery; Morens, David (2006).

"1918 Influenza: the Mother of All Pandemics" .

Emerging Infectious Diseases .

12 (1): 15– 22.

doi : 10.3201/eid1201.050979 .

PMC 3291398 .

PMID 16494711 .

^ Posner, Richard A. (2006).

Catastrophe: Risk and Response . Oxford: Oxford University Press.

ISBN 978-0195306477 .

Introduction, "What is Catastrophe?" ^ Ord, Toby (2020).

The Precipice: Existential Risk and the Future of Humanity . New York: Hachette.

ISBN 9780316484916 .

This is an equivalent, though crisper statement of Nick Bostrom 's definition: "An existential risk is one that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development." Source: Bostrom, Nick (2013). "Existential Risk Prevention as Global Priority". Global Policy. 4:15-31.

^ Cotton-Barratt, Owen; Ord, Toby (2015), Existential risk and existential hope: Definitions (PDF) , Future of Humanity Institute – Technical Report #2015-1, pp.

1– 4 ^ Bostrom, Nick (2009). "Astronomical Waste: The opportunity cost of delayed technological development".

Utilitas .

15 (3): 308– 314.

doi : 10.1017/s0953820800004076 .

^ a b c d e f g h Ord, Toby (2020).

The Precipice: Existential Risk and the Future of Humanity . New York: Hachette.

ISBN 9780316484916 .

^ a b Bryan Caplan (2008). " The totalitarian threat ".

Global Catastrophic Risks , eds. Bostrom & Cirkovic (Oxford University Press): 504–519.

ISBN 9780198570509 ^ Glover, Dennis (June 1, 2017).

"Did George Orwell secretly rewrite the end of Nineteen Eighty-Four as he lay dying?" .

The Sydney Morning Herald . Retrieved November 21, 2021 .

Winston's creator, George Orwell, believed that freedom would eventually defeat the truth-twisting totalitarianism portrayed in Nineteen Eighty-Four.

^ Orwell, George (1949).

Nineteen Eighty-Four. A novel . London: Secker & Warburg.

[ page needed ] ^ Baum, Seth D. (2023).

"Assessing natural global catastrophic risks" .

Natural Hazards .

115 (3): 2699– 2719.

Bibcode : 2023NatHa.115.2699B .

doi : 10.1007/s11069-022-05660-w .

PMC 9553633 .

PMID 36245947 .

^ Scouras, James (2019).

"Nuclear War as a Global Catastrophic Risk" .

Journal of Benefit-Cost Analysis .

10 (2): 274– 295.

doi : 10.1017/bca.2019.16 .

^ Sagan, Carl (Winter 1983).

"Nuclear War and Climatic Catastrophe: Some Policy Implications" .

Foreign Affairs . Council on Foreign Relations.

doi : 10.2307/20041818 .

JSTOR 20041818 . Retrieved August 4, 2020 .

^ Jebari, Karim (2014).

"Existential Risks: Exploring a Robust Risk Reduction Strategy" .

Science and Engineering Ethics .

21 (3): 541– 54.

doi : 10.1007/s11948-014-9559-3 .

PMID 24891130 .

^ a b Cirkovic, Milan M.

; Bostrom, Nick ; Sandberg, Anders (2010). "Anthropic Shadow: Observation Selection Effects and Human Extinction Risks".

Risk Analysis .

30 (10): 1495– 1506.

Bibcode : 2010RiskA..30.1495C .

doi : 10.1111/j.1539-6924.2010.01460.x .

PMID 20626690 .

^ Kemp, Luke (February 2019).

"Are we on the road to civilization collapse?" .

BBC . Retrieved August 12, 2021 .

^ Ord, Toby (2020).

The Precipice: Existential Risk and the Future of Humanity . Hachette Books.

ISBN 9780316484893 .

Europe survived losing 25 to 50 percent of its population in the Black Death, while keeping civilization firmly intact ^ a b Yudkowsky, Eliezer (2008). "Cognitive Biases Potentially Affecting Judgment of Global Risks".

Global Catastrophic Risks : 91– 119.

Bibcode : 2008gcr..book...86Y .

^ Desvousges, William H.; Johnson, F. Reed; Dunford, Richard W.; Hudson, Sara P.; Wilson, K. Nicole; Boyle, Kevin J. (1993). "Measuring Natural Resource Damages with Contingent Valuation: Tests of Validity and Reliability".

Contingent Valuation - A Critical Assessment . Contributions to Economic Analysis. Vol. 220. pp.

91– 164.

doi : 10.1016/B978-0-444-81469-2.50009-2 .

ISBN 978-0-444-81469-2 .

^ Bostrom 2013 .

^ Yudkowsky, Eliezer (2008). "Cognitive biases potentially affecting judgement of global risks".

Global Catastrophic Risks .

doi : 10.1093/oso/9780198570509.003.0009 .

ISBN 978-0-19-857050-9 .

^ "We're Underestimating the Risk of Human Extinction" . The Atlantic. March 6, 2012 . Retrieved July 1, 2016 .

^ Wilson, Edward O. (May 30, 1993).

"IS HUMANITY SUICIDAL?" .

The New York Times .

Also published as: Wilson, Edward O. (January 1993). "Is humanity suicidal?".

Biosystems .

31 ( 2– 3): 235– 242.

Bibcode : 1993BiSys..31..235W .

doi : 10.1016/0303-2647(93)90052-E .

PMID 8155855 .

^ a b Cotton-Barratt, Owen; Daniel, Max; Sandberg, Anders (2020).

"Defence in Depth Against Human Extinction: Prevention, Response, Resilience, and Why They All Matter" .

Global Policy .

11 (3): 271– 282.

doi : 10.1111/1758-5899.12786 .

PMC 7228299 .

PMID 32427180 .

^ García Martínez, Juan B.; Behr, Jeffray; Pearce, Joshua; Denkenberger, David (2025).

"Resilient foods for preventing global famine: a review of food supply interventions for global catastrophic food shocks including nuclear winter and infrastructure collapse" .

Critical Reviews in Food Science and Nutrition .

0 : 1– 27.

doi : 10.1080/10408398.2024.2431207 .

PMID 39932463 .

^ "Could science destroy the world? These scholars want to save us from a modern-day Frankenstein".

Science . March 28, 2021.

doi : 10.1126/science.aas9440 .

^ "Oxford Institute Forecasts The Possible Doom Of Humanity" .

Popular Science . 2013 . Retrieved April 20, 2020 .

^ Toby Ord (2020).

The precipice: Existential risk and the future of humanity . Hachette Books.

ISBN 9780316484893 .

The international body responsible for the continued prohibition of bioweapons (the Biological Weapons Convention) has an annual budget of $1.4 million - less than the average McDonald's restaurant ^ a b Matheny, Jason Gaverick (2007). "Reducing the Risk of Human Extinction".

Risk Analysis .

27 (5): 1335– 1344.

Bibcode : 2007RiskA..27.1335M .

doi : 10.1111/j.1539-6924.2007.00960.x .

PMID 18076500 .

^ Wells, Willard. (2009).

Apocalypse when?

. Praxis.

ISBN 978-0387098364 .

^ Wells, Willard. (2017).

Prospects for Human Survival . Lifeboat Foundation.

ISBN 978-0998413105 .

^ Hanson, Robin (2008). "Catastrophe, social collapse, and human extinction".

Global Catastrophic Risks .

doi : 10.1093/oso/9780198570509.003.0023 .

ISBN 978-0-19-857050-9 .

^ Smil, Vaclav (2003).

The Earth's Biosphere: Evolution, Dynamics, and Change .

MIT Press . p. 25.

ISBN 978-0-262-69298-4 .

^ Denkenberger, David C.; Sandberg, Anders; Tieman, Ross John; Pearce, Joshua M. (2022).

"Long term cost-effectiveness of resilient foods for global catastrophes compared to artificial general intelligence safety" .

International Journal of Disaster Risk Reduction .

73 102798.

Bibcode : 2022IJDRR..7302798D .

doi : 10.1016/j.ijdrr.2022.102798 .

^ Lewis Smith (February 27, 2008).

"Doomsday vault for world's seeds is opened under Arctic mountain" .

The Times Online . London. Archived from the original on May 12, 2008.

^ Suzanne Goldenberg (May 20, 2015).

"The doomsday vault: the seeds that could save a post-apocalyptic world" .

The Guardian . Retrieved June 30, 2017 .

^ "Here's how the world could end—and what we can do about it".

Science . July 24, 2021.

doi : 10.1126/science.aag0664 .

^ Denkenberger, David C.; Pearce, Joshua M. (September 2015).

"Feeding everyone: Solving the food crisis in event of global catastrophes that kill crops or obscure the sun" (PDF) .

Futures .

72 : 57– 68.

doi : 10.1016/j.futures.2014.11.008 .

^ "Global Challenges Foundation | Understanding Global Systemic Risk" .

globalchallenges.org . Archived from the original on August 16, 2017 . Retrieved August 15, 2017 .

^ "Global Catastrophic Risk Policy" .

gcrpolicy.com . Archived from the original on August 11, 2019 . Retrieved August 11, 2019 .

^ Club of Rome (2018).

"The Climate Emergency Plan" . Retrieved August 17, 2020 .

^ Club of Rome (2019).

"The Planetary Emergency Plan" . Retrieved August 17, 2020 .

^ Kieft, J.; Bendell, J (2021).

"The responsibility of communicating difficult truths about climate influenced societal disruption and collapse: an introduction to psychological research" .

Institute for Leadership and Sustainability (IFLAS) Occasional Papers .

7 : 1– 39.

^ "Mankind must abandon earth or face extinction: Hawking" , physorg.com , August 9, 2010 , retrieved January 23, 2012 ^ Malik, Tariq (April 13, 2013).

"Stephen Hawking: Humanity Must Colonize Space to Survive" .

Space.com . Retrieved July 1, 2016 .

^ Shukman, David (January 19, 2016).

"Hawking: Humans at risk of lethal 'own goal' " .

BBC News . Retrieved July 1, 2016 .

^ Fred Hapgood (November 1986).

"Nanotechnology: Molecular Machines that Mimic Life" (PDF) .

Omni . Archived from the original (PDF) on July 27, 2013 . Retrieved June 5, 2015 .

^ Giles, Jim (2004).

"Nanotech takes small step towards burying 'grey goo' " .

Nature .

429 (6992): 591.

Bibcode : 2004Natur.429..591G .

doi : 10.1038/429591b .

PMID 15190320 .

^ Sophie McBain (September 25, 2014).

"Apocalypse soon: the scientists preparing for the end times" .

New Statesman . Retrieved June 5, 2015 .

^ "Reducing Long-Term Catastrophic Risks from Artificial Intelligence" .

Machine Intelligence Research Institute . Retrieved June 5, 2015 .

The Machine Intelligence Research Institute aims to reduce the risk of a catastrophe, should such an event eventually occur.

^ Angela Chen (September 11, 2014).

"Is Artificial Intelligence a Threat?" .

The Chronicle of Higher Education . Retrieved June 5, 2015 .

^ "Nuclear Threat Initiative" .

Nuclear Threat Initiative . Retrieved June 5, 2015 .

^ Alexander Sehmar (May 31, 2015).

"Isis could obtain nuclear weapon from Pakistan, warns India" .

The Independent . Archived from the original on June 2, 2015 . Retrieved June 5, 2015 .

^ "About the Lifeboat Foundation" . The Lifeboat Foundation . Retrieved April 26, 2013 .

^ Ashlee, Vance (July 20, 2010).

"The Lifeboat Foundation: Battling Asteroids, Nanobots and A.I." New York Times . Retrieved June 5, 2015 .

^ "Global Catastrophic Risk Institute" .

gcrinstitute.org . Retrieved March 22, 2022 .

^ Meyer, Robinson (April 29, 2016).

"Human Extinction Isn't That Unlikely" .

The Atlantic . Boston, Massachusetts: Emerson Collective . Retrieved April 30, 2016 .

^ "Global Challenges Foundation website" .

globalchallenges.org . Retrieved April 30, 2016 .

^ "The Future of Life Institute" .

Future of Life Institute . Retrieved May 5, 2014 .

^ Nick Bilton (May 28, 2015).

"Ava of 'Ex Machina' Is Just Sci-Fi (for Now)" .

New York Times . Retrieved June 5, 2015 .

^ a b "About FHI" .

Future of Humanity Institute . Retrieved August 12, 2021 .

^ "About us" .

Centre for the Study of Existential Risk . Retrieved August 12, 2021 .

^ Hui, Sylvia (November 25, 2012).

"Cambridge to study technology's risks to humans" . Associated Press. Archived from the original on December 1, 2012 . Retrieved January 30, 2012 .

^ Scott Barrett (2014).

Environment and Development Economics: Essays in Honour of Sir Partha Dasgupta . Oxford University Press. p. 112.

ISBN 9780199677856 . Retrieved June 5, 2015 .

^ "Millennium Alliance for Humanity & The Biosphere" .

Millennium Alliance for Humanity & The Biosphere . Retrieved June 5, 2015 .

^ Guruprasad Madhavan (2012).

Practicing Sustainability . Springer Science & Business Media. p. 43.

ISBN 9781461443483 . Retrieved June 5, 2015 .

^ "Center for International Security and Cooperation" . Center for International Security and Cooperation . Retrieved June 5, 2015 .

^ a b Anderson, Nick (February 28, 2019).

"Georgetown launches think tank on security and emerging technology" .

Washington Post . Retrieved March 12, 2019 .

^ "Global Alert and Response (GAR)" .

World Health Organization . Archived from the original on February 16, 2003 . Retrieved June 5, 2015 .

^ Kelley Lee (2013).

Historical Dictionary of the World Health Organization . Rowman & Littlefield. p. 92.

ISBN 9780810878587 . Retrieved June 5, 2015 .

^ "USAID Emerging Pandemic Threats Program" .

USAID . Archived from the original on October 22, 2014 . Retrieved June 5, 2015 .

^ "Global Security" .

Lawrence Livermore National Laboratory . Archived from the original on December 27, 2007 . Retrieved June 5, 2015 .

Further reading [ edit ] Avin, Shahar; Wintle, Bonnie C.; Weitzdörfer, Julius; ó Héigeartaigh, Seán S.; Sutherland, William J.; Rees, Martin J. (2018).

"Classifying global catastrophic risks" .

Futures .

102 : 20– 26.

doi : 10.1016/j.futures.2018.02.001 .

Corey S. Powell (2000) "Twenty ways the world could end suddenly" Discover Magazine Currie, Adrian; Ó hÉigeartaigh, Seán (2018).

"Working together to face humanity's greatest threats: Introduction to the Future of Research on Catastrophic and Existential Risk" .

Futures .

102 : 1– 5.

doi : 10.1016/j.futures.2018.07.003 .

hdl : 10871/35764 .

Derrick Jensen (2006) Endgame ISBN 1-58322-730-X .

Donella Meadows (1972) The Limits to Growth ISBN 0-87663-165-0 .

Edward O. Wilson (2003) The Future of Life ISBN 0-679-76811-4 Holt, Jim (February 25, 2021).

"The Power of Catastrophic Thinking" .

The New York Review of Books . Vol. LXVIII, no. 3. pp.

26– 29. p. 28: Whether you are searching for a cure for cancer, or pursuing a scholarly or artistic career, or engaged in establishing more just institutions, a threat to the future of humanity is also a threat to the significance of what you do.

Huesemann, Michael H., and Joyce A. Huesemann (2011) Technofix: Why Technology Won't Save Us or the Environment , Chapter 6, "Sustainability or Collapse", New Society Publishers , Gabriola Island, British Columbia, Canada, 464 pages ISBN 0865717044 .

Jared Diamond (2005 and 2011) Collapse: How Societies Choose to Fail or Succeed Penguin Books ISBN 9780241958681 .

Jean-Francois Rischard (2003) High Noon 20 Global Problems, 20 Years to Solve Them ISBN 0-465-07010-8 Joel Garreau (2005) Radical Evolution ISBN 978-0385509657 .

John A. Leslie (1996) The End of the World ISBN 0-415-14043-9 .

Joseph Tainter (1990) The Collapse of Complex Societies , Cambridge University Press , Cambridge, UK ISBN 9780521386739 .

Marshall Brain (2020) The Doomsday Book: The Science Behind Humanity's Greatest Threats Union Square ISBN 9781454939962 Martin Rees (2004) Our Final Hour: A Scientist's warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future in This Century—On Earth and Beyond ISBN 0-465-06863-4 Rhodes, Catherine (2024).

Managing Extreme Technological Risk .

World Scientific .

doi : 10.1142/q0438 .

ISBN 978-1-80061-481-9 .

Roger-Maurice Bonnet and Lodewijk Woltjer (2008) Surviving 1,000 Centuries Can We Do It?

Springer-Praxis Books.

Taggart, Gabel (2023). "Taking stock of systems for organizing existential and global catastrophic risks: Implications for policy".

Global Policy .

14 (3): 489– 499.

doi : 10.1111/1758-5899.13230 .

Toby Ord (2020) The Precipice - Existential Risk and the Future of Humanity Bloomsbury Publishing ISBN 9781526600219 Turchin, Alexey; Denkenberger, David (2018).

"Global catastrophic and existential risks communication scale" .

Futures .

102 : 27– 38.

doi : 10.1016/j.futures.2018.01.003 .

Walsh, Bryan (2019).

End Times: A Brief Guide to the End of the World . Hachette Books.

ISBN 978-0275948023 .

External links [ edit ] Wikiquote has quotations related to Global catastrophic risk .

"Are we on the road to civilisation collapse?" .

BBC . February 19, 2019.

MacAskill, William (August 5, 2022).

"The Case for Longtermism" .

The New York Times .

"What a way to go" from The Guardian . Ten scientists name the biggest dangers to Earth and assess the chances they will happen. April 14, 2005.

Humanity under threat from perfect storm of crises – study .

The Guardian . February 6, 2020.

Annual Reports on Global Risk by the Global Challenges Foundation Center on Long-Term Risk Global Catastrophic Risk Policy [ usurped ] Stephen Petranek: 10 ways the world could end , a TED talk v t e Global catastrophic risks Future of the Earth Future of an expanding universe Ultimate fate of the universe Human extinction risk estimates Technological Chemical warfare Cyberattack Cyberwarfare Cyberterrorism Cybergeddon Ransomware Gray goo Nanoweapons Kinetic bombardment Kinetic energy weapon Nuclear warfare Mutual assured destruction Dead Hand Doomsday Clock Doomsday device Antimatter weapon Electromagnetic pulse (EMP) Safety of high-energy particle collision experiments Micro black hole Strangelet Synthetic intelligence / Artificial intelligence AI takeover Existential risk from artificial intelligence Technological singularity Transhumanism Sociological Anthropogenic hazard Collapsology Doomsday argument Self-indication assumption doomsday argument rebuttal Self-referencing doomsday argument rebuttal Economic collapse Malthusian catastrophe New World Order (conspiracy theory) Nuclear holocaust cobalt famine winter Riots Social crisis Societal collapse State collapse World War III Ecological Climate change Anoxic event Biodiversity loss Mass mortality event Cascade effect Cataclysmic pole shift hypothesis Deforestation Desertification Plant or animal species extinctions Civilizational collapse Tipping points Climate sensitivity Flood basalt Global dimming Global terrestrial stilling Global warming Hypercane Ice age Ecocide Ecological collapse Environmental degradation Habitat destruction Human impact on the environment coral reefs on marine life Land degradation Land consumption Land surface effects on climate Ocean acidification Ozone depletion Resource depletion Sea level rise Supervolcano winter Verneshot Water pollution Water scarcity Earth Overshoot Day Overexploitation Overpopulation Human overpopulation Biological Extinction Extinction event Holocene extinction Human extinction List of extinction events Genetic erosion Genetic pollution Others Biodiversity loss Decline in amphibian populations Decline in insect populations Biotechnology risk Biological agent Biological warfare Bioterrorism Colony collapse disorder Defaunation Dysgenics Interplanetary contamination Pandemic Pollinator decline Overfishing Astronomical Big Crunch Big Rip Coronal mass ejection Cosmological phase transition Geomagnetic storm False vacuum decay Gamma-ray burst Heat death of the universe Proton decay Virtual black hole Impact event Asteroid impact avoidance Asteroid impact prediction Potentially hazardous object Near-Earth object winter Rogue planet Rogue star Near-Earth supernova Hypernova Micronova Solar flare Stellar collision Eschatological Buddhist Maitreya Three Ages Hindu Kalki Kali Yuga Last Judgement Second Coming 1 Enoch Daniel Abomination of desolation Prophecy of Seventy Weeks Messiah Christian Futurism Historicism Interpretations of Revelation Idealism Preterism 2 Esdras 2 Thessalonians Man of sin Katechon Antichrist Book of Revelation Events Four Horsemen of the Apocalypse Seven bowls Seven seals The Beast Two witnesses War in Heaven Whore of Babylon Great Apostasy New Earth New Jerusalem Olivet Discourse Great Tribulation Son of perdition Sheep and Goats Islamic Al-Qa'im Beast of the Earth Dhu al-Qarnayn Dhul-Suwayqatayn Dajjal Israfil Mahdi Sufyani Jewish Messiah War of Gog and Magog Third Temple Norse Zoroastrian Saoshyant Others 2011 end times prediction 2012 phenomenon Apocalypse Apocalyptic literature Apocalypticism Armageddon Blood moon prophecy Earth Changes End time Gog and Magog List of dates predicted for apocalyptic events Messianism Messianic Age Millenarianism Millennialism Premillennialism Amillennialism Postmillennialism Nemesis (hypothetical star) Nibiru cataclysm Rapture Prewrath Posttribulation rapture Resurrection of the dead Vulnerable world hypothesis World to come Fictional Alien invasion Apocalyptic and post-apocalyptic fiction List of apocalyptic and post-apocalyptic fiction List of apocalyptic films Climate fiction Disaster films List of disaster films Zombie apocalypse Zombie Organizations Centre for the Study of Existential Risk Future of Humanity Institute Future of Life Institute Nuclear Threat Initiative General Disaster Depression Financial crisis Survivalism World portal Categories Apocalypticism Future problems Hazards Risk analysis Doomsday scenarios v t e Effective altruism Concepts Aid effectiveness Charity assessment Demandingness objection Disability-adjusted life year Disease burden Distributional cost-effectiveness analysis Earning to give Equal consideration of interests Incremental cost-effectiveness ratio Longtermism Marginal utility Moral circle expansion Psychological barriers to effective altruism Quality-adjusted life year Utilitarianism Venture philanthropy Key figures Sam Bankman-Fried Liv Boeree Nick Bostrom Hilary Greaves Holden Karnofsky William MacAskill Dustin Moskovitz Yew-Kwang Ng Toby Ord Derek Parfit Kelsey Piper Peter Singer Brian Tomasik Cari Tuna Eliezer Yudkowsky Organizations 80,000 Hours Against Malaria Foundation Animal Charity Evaluators Animal Ethics Centre for Effective Altruism Centre for Enabling EA Learning & Research Center for High Impact Philanthropy Centre for the Study of Existential Risk Development Media International Evidence Action Faunalytics Fistula Foundation Future of Humanity Institute Future of Life Institute Founders Pledge GiveDirectly GiveWell Giving Multiplier Giving What We Can Good Food Fund The Good Food Institute Good Ventures The Humane League Mercy for Animals Machine Intelligence Research Institute Malaria Consortium Open Philanthropy Raising for Effective Giving Sentience Institute Unlimit Health Wild Animal Initiative Focus areas Biotechnology risk Climate change Cultured meat Economic stability Existential risk from artificial general intelligence Global catastrophic risk Global health Global poverty Intensive animal farming Land use reform Life extension Malaria prevention Mass deworming Neglected tropical diseases Risk of astronomical suffering Wild animal suffering Literature Doing Good Better The End of Animal Farming Famine, Affluence, and Morality The Life You Can Save Living High and Letting Die The Most Good You Can Do Practical Ethics The Precipice Superintelligence: Paths, Dangers, Strategies What We Owe the Future Events Effective Altruism Global v t e Existential risk from artificial intelligence Concepts AGI AI alignment AI boom AI capability control AI safety AI takeover Consequentialism Effective accelerationism Ethics of artificial intelligence Existential risk from artificial intelligence Friendly artificial intelligence Instrumental convergence Vulnerable world hypothesis Intelligence explosion Longtermism Machine ethics Suffering risks Superintelligence Technological singularity Organizations Alignment Research Center Center for AI Safety Center for Applied Rationality Center for Human-Compatible Artificial Intelligence Centre for the Study of Existential Risk EleutherAI Future of Humanity Institute Future of Life Institute Google DeepMind Humanity+ Institute for Ethics and Emerging Technologies Leverhulme Centre for the Future of Intelligence Machine Intelligence Research Institute OpenAI Safe Superintelligence People Scott Alexander Sam Altman Yoshua Bengio Nick Bostrom Paul Christiano Eric Drexler Sam Harris Stephen Hawking Dan Hendrycks Geoffrey Hinton Bill Joy Shane Legg Elon Musk Steve Omohundro Huw Price Martin Rees Stuart J. Russell Ilya Sutskever Jaan Tallinn Max Tegmark Frank Wilczek Roman Yampolskiy Eliezer Yudkowsky Other Artificial Intelligence Act Do You Trust This Computer?

Human Compatible Open letter on artificial intelligence (2015) Our Final Invention Roko's basilisk Statement on AI risk of extinction Superintelligence: Paths, Dangers, Strategies The Precipice Category v t e Risk management Risk type & source Risk type Business risks Reputational damage Personal risk Health risk Psychosocial hazard Natural risk Natural disaster Anthropogenic hazard Political risk Technology risk IT risk AI Macro risk / External risk Extreme risk Global catastrophic risk Safety hazard Security risk Vulnerability (computing) Threat Accident Operational risk Execution risk Model risk Reputational risk Country risk Legal risk Financial risk Credit risk Liquidity risk Interest rate risk Exchange rate risk Market risk Profit risk Systemic risk Strategic risk Residual risk Risk source Hazard Conflict Uncertainty Vulnerability Countermeasures Enterprise risk management Corporate governance Regulatory compliance GRC Internal control Personal risk management Health insurance Stress management Disease management Operational risk management Supply chain Project Quality Security management Identity and access management Vulnerability management Incident management Business continuity planning Disaster risk reduction Financial risk management Diversification Hedge Risk pool Strategic management Risk communication Warning system Precautionary principle Insurance Crisis management Disaster management Occupational safety and health Swiss cheese model Risk assessment Exposure assessment Hazard analysis Scenario planning Contingency plan Brainstorming Structured or semi-structured interviews Delphi method Checklist Preliminary hazard analysis (PHA) Hazard and operability study (HAZOP) Hazard analysis and critical control points (HACCP) Threat assessment Toxicity assessment Structured What If Technique (SWIFT) Scenario analysis Business impact analysis Root cause analysis Failure mode and effects analysis (FMEA) / FMECA Fault tree analysis Event tree analysis Cause and consequence analysis Cause-and-effect analysis Layers of protection analysis (LOPA) Decision tree Human reliability analysis (HRA) Bow tie analysis Reliability centered maintenance Sneak circuit analysis Markov analysis Monte Carlo simulation Bayesian statistics and Bayes nets FN curve Risk index Risk Matrix Cost/benefit analysis Risk–benefit ratio Multi-criteria decision analysis (MCDA) Related concepts ISO 31000 ISO/IEC 31010 COSO Risk appetite Hazard map Rare events Problem solving Security Opportunity cost Crisis management v t e Sustainability Outline Index Principles Anthropocene Environmentalism Global governance Human impact on the environment Planetary boundaries Development Consumption Anthropization Anti-consumerism Circular economy Durable good Earth Overshoot Day Ecological footprint Ethical Green consumption Micro-sustainability Over-consumption Product stewardship Simple living Social return on investment Steady-state economy Sustainability Advertising Brand Marketing myopia Sustainable Consumer behaviour Market Systemic change resistance Tragedy of the commons World population Control Demographic transition Dependency ratio List Family planning Intergenerational equity Population ageing Sustainable population Technology Appropriate Environmental technology Natural building Sustainable architecture Sustainable design Sustainable industries Sustainable packaging Biodiversity Biosecurity Biosphere Conservation biology Endangered species Holocene extinction Invasive species Energy Carbon footprint Renewable energy Sustainable energy Food Civic agriculture Climate-smart agriculture Community-supported agriculture Cultured meat Sustainable agriculture Sustainable diet Sustainable fishery Water Air well (condenser) Bioretention Bioswale Blue roof Catchwater Constructed wetland Detention basin Dew pond Footprint Hydroelectricity Hydropower Infiltration basin Irrigation tank Marine energy Micro hydro Ocean thermal energy conversion Pico hydro Rain garden Rainwater harvesting Rainwater tank Reclaimed water Retention basin Run-of-the-river hydroelectricity Scarcity Security Small hydro Sustainable drainage system Tidal power Tidal stream generator Tree box filter Water conservation Water heat recycling Water recycling shower Water-sensitive urban design Accountability Corporate environmental responsibility Corporate social responsibility Environmental accounting Environmental full-cost accounting Environmental planning Generational accounting Sustainability Accounting Measurement Metrics and indices Reporting Standards and certification Sustainable yield Economic Debt Sustainability Analysis Fiscal sustainability Applications Advertising Art Business City Cultural sustainability Climate finance Community Disinvestment Eco-capitalism Eco-cities Eco-investing Eco-socialism Ecovillage Environmental finance Green economy Construction Fashion Finance Gardening Geopark Green Development Infrastructure Marketing Green roof Greening Impact investing Landscape Livelihood Living Market Organic movement Organizations Procurement Refurbishment Socially responsible business Socially responsible marketing Sanitation Sourcing Space Sustainability organization Tourism Transport Urban drainage systems Urban infrastructure Sustainable management Environmental Fisheries Forest Humanistic capitalism Landscape Materials Natural resource Planetary Recycling Waste Agreements and conferences UN Conference on the Human Environment (Stockholm 1972) Brundtlandt Commission Report (1983) Our Common Future (1987) Earth Summit (1992) Rio Declaration on Environment and Development (1992) Agenda 21 (1992) Convention on Biological Diversity (1992) Lisbon Principles (1997) Earth Charter (2000) UN Millennium Declaration (2000) Earth Summit 2002 (Rio+10, Johannesburg) UN Conference on Sustainable Development (Rio+20, 2012) Sustainable Development Goals (2015) UNESCO MONDIACULT conferences Category Lists Science Studies Degrees NewPP limit report
Parsed by mw‐web.codfw.main‐7c956d68b4‐nm4kn
Cached time: 20250817135413
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.534 seconds
Real time usage: 1.818 seconds
Preprocessor visited node count: 9992/1000000
Revision size: 53997/2097152 bytes
Post‐expand include size: 310457/2097152 bytes
Template argument size: 3624/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 17/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 384542/5000000 bytes
Lua time usage: 1.017/10.000 seconds
Lua memory usage: 26649852/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00% 1524.489      1 -total
 41.37%  630.656      1 Template:Reflist
 18.97%  289.162     27 Template:Annotated_link
 16.19%  246.765     24 Template:Cite_journal
  9.39%  143.159     29 Template:Cite_web
  7.99%  121.777     20 Template:Cite_book
  5.11%   77.849      1 Template:Futures_studies
  4.99%   76.120      1 Template:Sidebar
  4.69%   71.434      8 Template:Navbox
  4.37%   66.559      1 Template:Short_description Saved in parser cache with key enwiki:pcache:21221594:|#|:idhash:canonical and timestamp 20250817135413 and revision id 1303638338. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Global_catastrophic_risk&oldid=1303638338 " Categories : Existential risk Apocalyptic fiction Post-apocalyptic fiction Science fiction themes Survivalism Hidden categories: Wikipedia articles needing page number citations from May 2025 CS1: unfit URL Articles with short description Short description is different from Wikidata Use American English from August 2021 All Wikipedia articles written in American English Use mdy dates from March 2025 Pages displaying short descriptions of redirect targets via Module:Annotated link TED talk template with ID not in Wikidata This page was last edited on 1 August 2025, at 05:07 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Global catastrophic risk 32 languages Add topic

