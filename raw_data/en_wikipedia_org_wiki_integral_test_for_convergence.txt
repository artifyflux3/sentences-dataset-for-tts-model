Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Statement of the test Toggle Statement of the test subsection 1.1 Remark 2 Proof 3 Applications 4 Borderline between divergence and convergence 5 See also 6 References Toggle the table of contents Integral test for convergence 17 languages Bosanski Català Čeština Deutsch Français 한국어 Nederlands 日本語 Polski Português Română Русский Suomi Svenska Türkçe Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Test for infinite series of monotonous terms for convergence The integral test applied to the harmonic series .  Since the area under the curve y = 1/ x for x ∈ [1, ∞) is infinite, the total area of the rectangles must be infinite as well.

Part of a series of articles about Calculus ∫ ∫ a b f ′ ( t ) d t = f ( b ) − − f ( a ) {\displaystyle \int _{a}^{b}f'(t)\,dt=f(b)-f(a)} Fundamental theorem Limits Continuity Rolle's theorem Mean value theorem Inverse function theorem Differential Definitions Derivative ( generalizations ) Differential infinitesimal of a function total Concepts Differentiation notation Second derivative Implicit differentiation Logarithmic differentiation Related rates Taylor's theorem Rules and identities Sum Product Chain Power Quotient L'Hôpital's rule Inverse General Leibniz Faà di Bruno's formula Reynolds Integral Lists of integrals Integral transform Leibniz integral rule Definitions Antiderivative Integral ( improper ) Riemann integral Lebesgue integration Contour integration Integral of inverse functions Integration by Parts Discs Cylindrical shells Substitution ( trigonometric , tangent half-angle , Euler ) Euler's formula Partial fractions ( Heaviside's method ) Changing order Reduction formulae Differentiating under the integral sign Risch algorithm Series Geometric ( arithmetico-geometric ) Harmonic Alternating Power Binomial Taylor Convergence tests Summand limit (term test) Ratio Root Integral Direct comparison Limit comparison Alternating series Cauchy condensation Dirichlet Abel Vector Gradient Divergence Curl Laplacian Directional derivative Identities Theorems Gradient Green's Stokes' Divergence Generalized Stokes Helmholtz decomposition Multivariable Formalisms Matrix Tensor Exterior Geometric Definitions Partial derivative Multiple integral Line integral Surface integral Volume integral Jacobian Hessian Advanced Calculus on Euclidean space Generalized functions Limit of distributions Specialized Fractional Malliavin Stochastic Variations Miscellanea Precalculus History Glossary List of topics Integration Bee Mathematical analysis Nonstandard analysis v t e In mathematics , the integral test for convergence is a method used to test infinite series of monotonic terms for convergence . It was developed by Colin Maclaurin and Augustin-Louis Cauchy and is sometimes known as the Maclaurin–Cauchy test .

Statement of the test [ edit ] Consider an integer N and a function f defined on the unbounded interval [ N , ∞) , on which it is monotone decreasing . Then the infinite series ∑ ∑ n = N ∞ ∞ f ( n ) {\displaystyle \sum _{n=N}^{\infty }f(n)} converges to a real number if and only if the improper integral ∫ ∫ N ∞ ∞ f ( x ) d x {\displaystyle \int _{N}^{\infty }f(x)\,dx} is finite. In particular, if the integral diverges, then the series diverges as well.

Remark [ edit ] If the improper integral is finite, then the proof also gives the lower and upper bounds ∫ ∫ N ∞ ∞ f ( x ) d x ≤ ≤ ∑ ∑ n = N ∞ ∞ f ( n ) ≤ ≤ f ( N ) + ∫ ∫ N ∞ ∞ f ( x ) d x {\displaystyle \int _{N}^{\infty }f(x)\,dx\leq \sum _{n=N}^{\infty }f(n)\leq f(N)+\int _{N}^{\infty }f(x)\,dx} 1 for the infinite series.

Note that if the function f ( x ) {\displaystyle f(x)} is increasing, then the function − − f ( x ) {\displaystyle -f(x)} is decreasing and the above theorem applies.

Many textbooks require the function f {\displaystyle f} to be positive, [ 1 ] [ 2 ] [ 3 ] but this condition is not really necessary, since when f {\displaystyle f} is negative and decreasing both ∑ ∑ n = N ∞ ∞ f ( n ) {\displaystyle \sum _{n=N}^{\infty }f(n)} and ∫ ∫ N ∞ ∞ f ( x ) d x {\displaystyle \int _{N}^{\infty }f(x)\,dx} diverge.

[ 4 ] [ better source needed ] Proof [ edit ] The proof uses the comparison test , comparing the term f ( n ) {\displaystyle f(n)} with the integral of f {\displaystyle f} over the intervals [ n − − 1 , n ) {\displaystyle [n-1,n)} and [ n , n + 1 ) {\displaystyle [n,n+1)} respectively.

The monotonic function f {\displaystyle f} is continuous almost everywhere . To show this, let D = { x ∈ ∈ [ N , ∞ ∞ ) ∣ ∣ f is discontinuous at x } {\displaystyle D=\{x\in [N,\infty )\mid f{\text{ is discontinuous at }}x\}} For every x ∈ ∈ D {\displaystyle x\in D} , there exists by the density of Q {\displaystyle \mathbb {Q} } , a c ( x ) ∈ ∈ Q {\displaystyle c(x)\in \mathbb {Q} } so that c ( x ) ∈ ∈ [ lim y ↓ ↓ x f ( y ) , lim y ↑ ↑ x f ( y ) ] {\displaystyle c(x)\in \left[\lim _{y\downarrow x}f(y),\lim _{y\uparrow x}f(y)\right]} .

Note that this set contains an open non-empty interval precisely if f {\displaystyle f} is discontinuous at x {\displaystyle x} . We can uniquely identify c ( x ) {\displaystyle c(x)} as the rational number that has the least index in an enumeration N → → Q {\displaystyle \mathbb {N} \to \mathbb {Q} } and satisfies the above property. Since f {\displaystyle f} is monotone , this defines an injective mapping c : D → → Q , x ↦ ↦ c ( x ) {\displaystyle c:D\to \mathbb {Q} ,x\mapsto c(x)} and thus D {\displaystyle D} is countable . It follows that f {\displaystyle f} is continuous almost everywhere . This is sufficient for Riemann integrability .

[ 5 ] Since f is a monotone decreasing function, we know that f ( x ) ≤ ≤ f ( n ) for all x ∈ ∈ [ n , ∞ ∞ ) {\displaystyle f(x)\leq f(n)\quad {\text{for all }}x\in [n,\infty )} and f ( n ) ≤ ≤ f ( x ) for all x ∈ ∈ [ N , n ] .

{\displaystyle f(n)\leq f(x)\quad {\text{for all }}x\in [N,n].} Hence, for every integer n ≥ N , ∫ ∫ n n + 1 f ( x ) d x ≤ ≤ ∫ ∫ n n + 1 f ( n ) d x = f ( n ) {\displaystyle \int _{n}^{n+1}f(x)\,dx\leq \int _{n}^{n+1}f(n)\,dx=f(n)} 2 and, for every integer n ≥ N + 1 , f ( n ) = ∫ ∫ n − − 1 n f ( n ) d x ≤ ≤ ∫ ∫ n − − 1 n f ( x ) d x .

{\displaystyle f(n)=\int _{n-1}^{n}f(n)\,dx\leq \int _{n-1}^{n}f(x)\,dx.} 3 By summation over all n from N to some larger integer M , we get from ( 2 ) ∫ ∫ N M + 1 f ( x ) d x = ∑ ∑ n = N M ∫ ∫ n n + 1 f ( x ) d x ⏟ ⏟ ≤ ≤ f ( n ) ≤ ≤ ∑ ∑ n = N M f ( n ) {\displaystyle \int _{N}^{M+1}f(x)\,dx=\sum _{n=N}^{M}\underbrace {\int _{n}^{n+1}f(x)\,dx} _{\leq \,f(n)}\leq \sum _{n=N}^{M}f(n)} and from ( 3 ) ∑ ∑ n = N M f ( n ) = f ( N ) + ∑ ∑ n = N + 1 M f ( n ) ≤ ≤ f ( N ) + ∑ ∑ n = N + 1 M ∫ ∫ n − − 1 n f ( x ) d x ⏟ ⏟ ≥ ≥ f ( n ) = f ( N ) + ∫ ∫ N M f ( x ) d x .

{\displaystyle {\begin{aligned}\sum _{n=N}^{M}f(n)&=f(N)+\sum _{n=N+1}^{M}f(n)\\&\leq f(N)+\sum _{n=N+1}^{M}\underbrace {\int _{n-1}^{n}f(x)\,dx} _{\geq \,f(n)}\\&=f(N)+\int _{N}^{M}f(x)\,dx.\end{aligned}}} Combining these two estimates yields ∫ ∫ N M + 1 f ( x ) d x ≤ ≤ ∑ ∑ n = N M f ( n ) ≤ ≤ f ( N ) + ∫ ∫ N M f ( x ) d x .

{\displaystyle \int _{N}^{M+1}f(x)\,dx\leq \sum _{n=N}^{M}f(n)\leq f(N)+\int _{N}^{M}f(x)\,dx.} Letting M tend to infinity, the bounds in ( 1 ) and the result follow.

Applications [ edit ] The harmonic series ∑ ∑ n = 1 ∞ ∞ 1 n {\displaystyle \sum _{n=1}^{\infty }{\frac {1}{n}}} diverges because, using the natural logarithm , its antiderivative , and the fundamental theorem of calculus , we get ∫ ∫ 1 M 1 n d n = ln ⁡ ⁡ n | 1 M = ln ⁡ ⁡ M → → ∞ ∞ for M → → ∞ ∞ .

{\displaystyle \int _{1}^{M}{\frac {1}{n}}\,dn=\ln n{\Bigr |}_{1}^{M}=\ln M\to \infty \quad {\text{for }}M\to \infty .} On the other hand, the series ζ ζ ( 1 + ε ε ) = ∑ ∑ n = 1 ∞ ∞ 1 n 1 + ε ε {\displaystyle \zeta (1+\varepsilon )=\sum _{n=1}^{\infty }{\frac {1}{n^{1+\varepsilon }}}} (cf.

Riemann zeta function )
converges for every ε > 0 , because by the power rule ∫ ∫ 1 M 1 n 1 + ε ε d n = − − 1 ε ε n ε ε | 1 M = 1 ε ε ( 1 − − 1 M ε ε ) ≤ ≤ 1 ε ε < ∞ ∞ for all M ≥ ≥ 1.

{\displaystyle \int _{1}^{M}{\frac {1}{n^{1+\varepsilon }}}\,dn=\left.-{\frac {1}{\varepsilon n^{\varepsilon }}}\right|_{1}^{M}={\frac {1}{\varepsilon }}\left(1-{\frac {1}{M^{\varepsilon }}}\right)\leq {\frac {1}{\varepsilon }}<\infty \quad {\text{for all }}M\geq 1.} From ( 1 ) we get the upper estimate ζ ζ ( 1 + ε ε ) = ∑ ∑ n = 1 ∞ ∞ 1 n 1 + ε ε ≤ ≤ 1 + ε ε ε ε , {\displaystyle \zeta (1+\varepsilon )=\sum _{n=1}^{\infty }{\frac {1}{n^{1+\varepsilon }}}\leq {\frac {1+\varepsilon }{\varepsilon }},} which can be compared with some of the particular values of Riemann zeta function .

Borderline between divergence and convergence [ edit ] The above examples involving the harmonic series raise the question of whether there are monotone sequences such that f ( n ) decreases to 0 faster than 1/ n but slower than 1/ n 1+ ε in the sense that lim n → → ∞ ∞ f ( n ) 1 / n = 0 and lim n → → ∞ ∞ f ( n ) 1 / n 1 + ε ε = ∞ ∞ {\displaystyle \lim _{n\to \infty }{\frac {f(n)}{1/n}}=0\quad {\text{and}}\quad \lim _{n\to \infty }{\frac {f(n)}{1/n^{1+\varepsilon }}}=\infty } for every ε > 0 , and whether the corresponding series of the f ( n ) still diverges. Once such a sequence is found, a similar question can be asked with f ( n ) taking the role of 1/ n , and so on. In this way it is possible to investigate the borderline between divergence and convergence of infinite series.

Using the integral test for convergence, one can show (see below) that, for every natural number k , the series ∑ ∑ n = N k ∞ ∞ 1 n ln ⁡ ⁡ ( n ) ln 2 ⁡ ⁡ ( n ) ⋯ ⋯ ln k − − 1 ⁡ ⁡ ( n ) ln k ⁡ ⁡ ( n ) {\displaystyle \sum _{n=N_{k}}^{\infty }{\frac {1}{n\ln(n)\ln _{2}(n)\cdots \ln _{k-1}(n)\ln _{k}(n)}}} 4 still diverges (cf.

proof that the sum of the reciprocals of the primes diverges for k = 1 ) but ∑ ∑ n = N k ∞ ∞ 1 n ln ⁡ ⁡ ( n ) ln 2 ⁡ ⁡ ( n ) ⋯ ⋯ ln k − − 1 ⁡ ⁡ ( n ) ( ln k ⁡ ⁡ ( n ) ) 1 + ε ε {\displaystyle \sum _{n=N_{k}}^{\infty }{\frac {1}{n\ln(n)\ln _{2}(n)\cdots \ln _{k-1}(n)(\ln _{k}(n))^{1+\varepsilon }}}} 5 converges for every ε > 0 . Here ln k denotes the k -fold composition of the natural logarithm defined recursively by ln k ⁡ ⁡ ( x ) = { ln ⁡ ⁡ ( x ) for k = 1 , ln ⁡ ⁡ ( ln k − − 1 ⁡ ⁡ ( x ) ) for k ≥ ≥ 2.

{\displaystyle \ln _{k}(x)={\begin{cases}\ln(x)&{\text{for }}k=1,\\\ln(\ln _{k-1}(x))&{\text{for }}k\geq 2.\end{cases}}} Furthermore, let N k denote the smallest natural number such that the k -fold composition is well-defined and ln k ( N k ) ≥ 1 , i.e.

N k ≥ ≥ e e ⋅ ⋅ ⋅ ⋅ e ⏟ ⏟ k e s = e ↑ ↑ ↑ ↑ k {\displaystyle N_{k}\geq \underbrace {e^{e^{\cdot ^{\cdot ^{e}}}}} _{k\ e{\text{s}}}=e\uparrow \uparrow k} using tetration or Knuth's up-arrow notation .

To see the divergence of the series ( 4 ) using the integral test, note that by repeated application of the chain rule d d x ln k + 1 ⁡ ⁡ ( x ) = d d x ln ⁡ ⁡ ( ln k ⁡ ⁡ ( x ) ) = 1 ln k ⁡ ⁡ ( x ) d d x ln k ⁡ ⁡ ( x ) = ⋯ ⋯ = 1 x ln ⁡ ⁡ ( x ) ⋯ ⋯ ln k ⁡ ⁡ ( x ) , {\displaystyle {\frac {d}{dx}}\ln _{k+1}(x)={\frac {d}{dx}}\ln(\ln _{k}(x))={\frac {1}{\ln _{k}(x)}}{\frac {d}{dx}}\ln _{k}(x)=\cdots ={\frac {1}{x\ln(x)\cdots \ln _{k}(x)}},} hence ∫ ∫ N k ∞ ∞ d x x ln ⁡ ⁡ ( x ) ⋯ ⋯ ln k ⁡ ⁡ ( x ) = ln k + 1 ⁡ ⁡ ( x ) | N k ∞ ∞ = ∞ ∞ .

{\displaystyle \int _{N_{k}}^{\infty }{\frac {dx}{x\ln(x)\cdots \ln _{k}(x)}}=\ln _{k+1}(x){\bigr |}_{N_{k}}^{\infty }=\infty .} To see the convergence of the series ( 5 ), note that by the power rule , the chain rule, and the above result, − − d d x 1 ε ε ( ln k ⁡ ⁡ ( x ) ) ε ε = 1 ( ln k ⁡ ⁡ ( x ) ) 1 + ε ε d d x ln k ⁡ ⁡ ( x ) = ⋯ ⋯ = 1 x ln ⁡ ⁡ ( x ) ⋯ ⋯ ln k − − 1 ⁡ ⁡ ( x ) ( ln k ⁡ ⁡ ( x ) ) 1 + ε ε , {\displaystyle -{\frac {d}{dx}}{\frac {1}{\varepsilon (\ln _{k}(x))^{\varepsilon }}}={\frac {1}{(\ln _{k}(x))^{1+\varepsilon }}}{\frac {d}{dx}}\ln _{k}(x)=\cdots ={\frac {1}{x\ln(x)\cdots \ln _{k-1}(x)(\ln _{k}(x))^{1+\varepsilon }}},} hence ∫ ∫ N k ∞ ∞ d x x ln ⁡ ⁡ ( x ) ⋯ ⋯ ln k − − 1 ⁡ ⁡ ( x ) ( ln k ⁡ ⁡ ( x ) ) 1 + ε ε = − − 1 ε ε ( ln k ⁡ ⁡ ( x ) ) ε ε | N k ∞ ∞ < ∞ ∞ {\displaystyle \int _{N_{k}}^{\infty }{\frac {dx}{x\ln(x)\cdots \ln _{k-1}(x)(\ln _{k}(x))^{1+\varepsilon }}}=-{\frac {1}{\varepsilon (\ln _{k}(x))^{\varepsilon }}}{\biggr |}_{N_{k}}^{\infty }<\infty } and ( 1 ) gives bounds for the infinite series in ( 5 ).

See also [ edit ] Convergence tests Convergence (mathematics) Direct comparison test Dominated convergence theorem Euler-Maclaurin formula Limit comparison test Monotone convergence theorem References [ edit ] Knopp, Konrad , "Infinite Sequences and Series", Dover Publications , Inc.,  New York, 1956. (§ 3.3) ISBN 0-486-60153-6 Whittaker, E. T., and Watson, G. N., A Course in Modern Analysis , fourth edition, Cambridge University Press, 1963. (§ 4.43) ISBN 0-521-58807-3 Ferreira, Jaime Campos, Ed Calouste Gulbenkian, 1987, ISBN 972-31-0179-3 ^ Stewart, James; Clegg, Daniel; Watson, Saleem (2021).

Calculus: Metric Version (9 ed.). Cengage.

ISBN 9780357113462 .

^ Wade, William (2004).

An Introduction to Analysis (3 ed.). Pearson Education.

ISBN 9780131246836 .

^ Thomas, George; Hass, Joel; Heil, Christopher; Weir, Maurice; Zuleta, José Luis (2018).

Thomas' Calculus: Early Transcendentals (14 ed.). Pearson Education.

ISBN 9781292253114 .

^ savemycalculus.

"Why does it have to be positive and decreasing to apply the integral test?" .

Mathematics Stack Exchange . Retrieved 2020-03-11 .

^ Brown, A. B. (September 1936). "A Proof of the Lebesgue Condition for Riemann Integrability".

The American Mathematical Monthly .

43 (7): 396– 398.

doi : 10.2307/2301737 .

ISSN 0002-9890 .

JSTOR 2301737 .

v t e Calculus Precalculus Binomial theorem Concave function Continuous function Factorial Finite difference Free variables and bound variables Graph of a function Linear function Radian Rolle's theorem Secant Slope Tangent Limits Indeterminate form Limit of a function One-sided limit Limit of a sequence Order of approximation (ε, δ)-definition of limit Differential calculus Derivative Second derivative Partial derivative Differential Differential operator Mean value theorem Notation Leibniz's notation Newton's notation Rules of differentiation linearity Power Sum Chain L'Hôpital's Product General Leibniz's rule Quotient Other techniques Implicit differentiation Inverse functions and differentiation Logarithmic derivative Related rates Stationary points First derivative test Second derivative test Extreme value theorem Maximum and minimum Further applications Newton's method Taylor's theorem Differential equation Ordinary differential equation Partial differential equation Stochastic differential equation Integral calculus Antiderivative Arc length Riemann integral Basic properties Constant of integration Fundamental theorem of calculus Differentiating under the integral sign Integration by parts Integration by substitution trigonometric Euler Tangent half-angle substitution Partial fractions in integration Quadratic integral Trapezoidal rule Volumes Washer method Shell method Integral equation Integro-differential equation Vector calculus Derivatives Curl Directional derivative Divergence Gradient Laplacian Basic theorems Line integrals Green's Stokes' Gauss' Multivariable calculus Divergence theorem Geometric Hessian matrix Jacobian matrix and determinant Lagrange multiplier Line integral Matrix Multiple integral Partial derivative Surface integral Volume integral Advanced topics Differential forms Exterior derivative Generalized Stokes' theorem Tensor calculus Sequences and series Arithmetico-geometric sequence Types of series Alternating Binomial Fourier Geometric Harmonic Infinite Power Maclaurin Taylor Telescoping Tests of convergence Abel's Alternating series Cauchy condensation Direct comparison Dirichlet's Integral Limit comparison Ratio Root Term Special functions and numbers Bernoulli numbers e (mathematical constant) Exponential function Natural logarithm Stirling's approximation History of calculus Adequality Brook Taylor Colin Maclaurin Generality of algebra Gottfried Wilhelm Leibniz Infinitesimal Infinitesimal calculus Isaac Newton Fluxion Law of Continuity Leonhard Euler Method of Fluxions The Method of Mechanical Theorems Lists Integrals rational functions irrational algebraic functions exponential functions logarithmic functions hyperbolic functions inverse trigonometric functions inverse Secant Secant cubed List of limits List of derivatives Miscellaneous topics Complex calculus Contour integral Differential geometry Manifold Curvature of curves of surfaces Tensor Euler–Maclaurin formula Gabriel's horn Integration Bee Proof that 22/7 exceeds π Regiomontanus' angle maximization problem Steinmetz solid Retrieved from " https://en.wikipedia.org/w/index.php?title=Integral_test_for_convergence&oldid=1302410654 " Categories : Augustin-Louis Cauchy Integral calculus Convergence tests Hidden categories: Articles with short description Short description matches Wikidata Pages using sidebar with the child parameter All articles lacking reliable references Articles lacking reliable references from August 2024 Articles containing proofs This page was last edited on 25 July 2025, at 06:50 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Integral test for convergence 17 languages Add topic

