Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions Toggle Definitions subsection 1.1 Probability density function 1.2 Cumulative distribution function 2 Properties Toggle Properties subsection 2.1 Moments 2.2 Related distributions 2.3 Probability of a Laplace being greater than another 2.4 Relation to the exponential distribution 2.5 Sargan distributions 3 Statistical inference 4 Occurrence and applications 5 Random variate generation 6 History 7 See also 8 References 9 External links Toggle the table of contents Laplace distribution 18 languages العربية Català Deutsch Español فارسی Français Italiano עברית Nederlands 日本語 Polski Русский Shqip Slovenščina Српски / srpski Türkçe Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Probability distribution Laplace Probability density function Cumulative distribution function Parameters μ μ {\displaystyle \mu } location ( real ) b > 0 {\displaystyle b>0} scale (real) Support R {\displaystyle \mathbb {R} } PDF 1 2 b exp ⁡ ⁡ ( − − | x − − μ μ | b ) {\displaystyle {\frac {1}{2b}}\exp \left(-{\frac {|x-\mu |}{b}}\right)} CDF { 1 2 exp ⁡ ⁡ ( x − − μ μ b ) if x ≤ ≤ μ μ 1 − − 1 2 exp ⁡ ⁡ ( − − x − − μ μ b ) if x ≥ ≥ μ μ {\displaystyle {\begin{cases}{\frac {1}{2}}\exp \left({\frac {x-\mu }{b}}\right)&{\text{if }}x\leq \mu \\[8pt]1-{\frac {1}{2}}\exp \left(-{\frac {x-\mu }{b}}\right)&{\text{if }}x\geq \mu \end{cases}}} Quantile { μ μ + b ln ⁡ ⁡ ( 2 F ) if F ≤ ≤ 1 2 μ μ − − b ln ⁡ ⁡ ( 2 − − 2 F ) if F ≥ ≥ 1 2 {\displaystyle {\begin{cases}\mu +b\ln \left(2F\right)&{\text{if }}F\leq {\frac {1}{2}}\\[8pt]\mu -b\ln \left(2-2F\right)&{\text{if }}F\geq {\frac {1}{2}}\end{cases}}} Mean μ μ {\displaystyle \mu } Median μ μ {\displaystyle \mu } Mode μ μ {\displaystyle \mu } Variance 2 b 2 {\displaystyle 2b^{2}} MAD b ln ⁡ ⁡ 2 {\displaystyle b\ln 2} Skewness 0 {\displaystyle 0} Excess kurtosis 3 {\displaystyle 3} Entropy log ⁡ ⁡ ( 2 b e ) {\displaystyle \log(2be)} MGF exp ⁡ ⁡ ( μ μ t ) 1 − − b 2 t 2 for | t | < 1 / b {\displaystyle {\frac {\exp(\mu t)}{1-b^{2}t^{2}}}{\text{ for }}|t|<1/b} CF exp ⁡ ⁡ ( μ μ i t ) 1 + b 2 t 2 {\displaystyle {\frac {\exp(\mu it)}{1+b^{2}t^{2}}}} Expected shortfall { μ μ + b ( p 1 − − p ) ( 1 − − ln ⁡ ⁡ ( 2 p ) ) , p < .5 μ μ + b ( 1 − − ln ⁡ ⁡ ( 2 ( 1 − − p ) ) ) , p ≥ ≥ .5 {\displaystyle {\begin{cases}\mu +b\left({\frac {p}{1-p}}\right)(1-\ln(2p))&,p<.5\\\mu +b\left(1-\ln \left(2(1-p)\right)\right)&,p\geq .5\end{cases}}} [ 1 ] In probability theory and statistics , the Laplace distribution is a continuous probability distribution named after Pierre-Simon Laplace .  It is also sometimes called the double exponential distribution , because it can be thought of as two exponential distributions (with an additional location parameter) spliced together along the x-axis, [ 2 ] although the term is also sometimes used to refer to the Gumbel distribution .  The difference between two independent identically distributed exponential random variables is governed by a Laplace distribution, as is a Brownian motion evaluated at an exponentially distributed random time [ citation needed ] .  Increments of Laplace motion or a variance gamma process evaluated over the time scale also have a Laplace distribution.

Definitions [ edit ] Probability density function [ edit ] A random variable has a Laplace ⁡ ⁡ ( μ μ , b ) {\displaystyle \operatorname {Laplace} (\mu ,b)} distribution if its probability density function is f ( x ∣ ∣ μ μ , b ) = 1 2 b exp ⁡ ⁡ ( − − | x − − μ μ | b ) , {\displaystyle f(x\mid \mu ,b)={\frac {1}{2b}}\exp \left(-{\frac {|x-\mu |}{b}}\right),} where μ μ {\displaystyle \mu } is a location parameter , and b > 0 {\displaystyle b>0} , which is sometimes referred to as the "diversity", is a scale parameter . If μ μ = 0 {\displaystyle \mu =0} and b = 1 {\displaystyle b=1} , the positive half-line is exactly an exponential distribution scaled by 1/2.

[ 3 ] The probability density function of the Laplace distribution is also reminiscent of the normal distribution ; however, whereas the normal distribution is expressed in terms of the squared difference from the mean μ μ {\displaystyle \mu } , the Laplace density is expressed in terms of the absolute difference from the mean. Consequently, the Laplace distribution has fatter tails than the normal distribution. It is a special case of the generalized normal distribution and the hyperbolic distribution . Continuous symmetric distributions that have exponential tails, like the Laplace distribution, but which have probability density functions that are differentiable at the mode include the logistic distribution , hyperbolic secant distribution , and the Champernowne distribution .

Cumulative distribution function [ edit ] The Laplace distribution is easy to integrate (if one distinguishes two symmetric cases) due to the use of the absolute value function.  Its cumulative distribution function is as follows: F ( x ) = ∫ ∫ − − ∞ ∞ x f ( u ) d u = { 1 2 exp ⁡ ⁡ ( x − − μ μ b ) if x < μ μ 1 − − 1 2 exp ⁡ ⁡ ( − − x − − μ μ b ) if x ≥ ≥ μ μ = 1 2 + 1 2 sgn ⁡ ⁡ ( x − − μ μ ) ( 1 − − exp ⁡ ⁡ ( − − | x − − μ μ | b ) ) .

{\displaystyle {\begin{aligned}F(x)&=\int _{-\infty }^{x}\!\!f(u)\,\mathrm {d} u={\begin{cases}{\frac {1}{2}}\exp \left({\frac {x-\mu }{b}}\right)&{\mbox{if }}x<\mu \\1-{\frac {1}{2}}\exp \left(-{\frac {x-\mu }{b}}\right)&{\mbox{if }}x\geq \mu \end{cases}}\\&={\tfrac {1}{2}}+{\tfrac {1}{2}}\operatorname {sgn}(x-\mu )\left(1-\exp \left(-{\frac {|x-\mu |}{b}}\right)\right).\end{aligned}}} The inverse cumulative distribution function is given by F − − 1 ( p ) = μ μ − − b sgn ⁡ ⁡ ( p − − 0.5 ) ln ⁡ ⁡ ( 1 − − 2 | p − − 0.5 | ) .

{\displaystyle F^{-1}(p)=\mu -b\,\operatorname {sgn}(p-0.5)\,\ln(1-2|p-0.5|).} Properties [ edit ] Moments [ edit ] μ μ r ′ = ( 1 2 ) ∑ ∑ k = 0 r [ r !

( r − − k ) !

b k μ μ ( r − − k ) { 1 + ( − − 1 ) k } ] .

{\displaystyle \mu _{r}'={\bigg (}{\frac {1}{2}}{\bigg )}\sum _{k=0}^{r}{\bigg [}{\frac {r!}{(r-k)!}}b^{k}\mu ^{(r-k)}\{1+(-1)^{k}\}{\bigg ]}.} Related distributions [ edit ] If X ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X\sim {\textrm {Laplace}}(\mu ,b)} then k X + c ∼ ∼ Laplace ( k μ μ + c , | k | b ) {\displaystyle kX+c\sim {\textrm {Laplace}}(k\mu +c,|k|b)} .

If X ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle X\sim {\textrm {Laplace}}(0,1)} then b X ∼ ∼ Laplace ( 0 , b ) {\displaystyle bX\sim {\textrm {Laplace}}(0,b)} .

If X ∼ ∼ Laplace ( 0 , b ) {\displaystyle X\sim {\textrm {Laplace}}(0,b)} then | X | ∼ ∼ Exponential ( b − − 1 ) {\displaystyle \left|X\right|\sim {\textrm {Exponential}}\left(b^{-1}\right)} ( exponential distribution ).

If X , Y ∼ ∼ Exponential ( λ λ ) {\displaystyle X,Y\sim {\textrm {Exponential}}(\lambda )} then X − − Y ∼ ∼ Laplace ( 0 , λ λ − − 1 ) {\displaystyle X-Y\sim {\textrm {Laplace}}\left(0,\lambda ^{-1}\right)} ． If X ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X\sim {\textrm {Laplace}}(\mu ,b)} then | X − − μ μ | ∼ ∼ Exponential ( b − − 1 ) {\displaystyle \left|X-\mu \right|\sim {\textrm {Exponential}}(b^{-1})} .

If X ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X\sim {\textrm {Laplace}}(\mu ,b)} then X ∼ ∼ EPD ( μ μ , b , 1 ) {\displaystyle X\sim {\textrm {EPD}}(\mu ,b,1)} ( exponential power distribution ).

If X 1 , .

.

.

, X 4 ∼ ∼ N ( 0 , 1 ) {\displaystyle X_{1},...,X_{4}\sim {\textrm {N}}(0,1)} ( normal distribution ) then X 1 X 2 − − X 3 X 4 ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle X_{1}X_{2}-X_{3}X_{4}\sim {\textrm {Laplace}}(0,1)} and ( X 1 2 − − X 2 2 + X 3 2 − − X 4 2 ) / 2 ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle (X_{1}^{2}-X_{2}^{2}+X_{3}^{2}-X_{4}^{2})/2\sim {\textrm {Laplace}}(0,1)} .

If X i ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X_{i}\sim {\textrm {Laplace}}(\mu ,b)} then 2 b ∑ ∑ i = 1 n | X i − − μ μ | ∼ ∼ χ χ 2 ( 2 n ) {\displaystyle {\frac {\displaystyle 2}{b}}\sum _{i=1}^{n}|X_{i}-\mu |\sim \chi ^{2}(2n)} ( chi-squared distribution ).

If X , Y ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X,Y\sim {\textrm {Laplace}}(\mu ,b)} then | X − − μ μ | | Y − − μ μ | ∼ ∼ F ⁡ ⁡ ( 2 , 2 ) {\displaystyle {\tfrac {|X-\mu |}{|Y-\mu |}}\sim \operatorname {F} (2,2)} . ( F-distribution ) If X , Y ∼ ∼ U ( 0 , 1 ) {\displaystyle X,Y\sim {\textrm {U}}(0,1)} ( uniform distribution ) then log ⁡ ⁡ ( X / Y ) ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle \log(X/Y)\sim {\textrm {Laplace}}(0,1)} .

If X ∼ ∼ Exponential ( λ λ ) {\displaystyle X\sim {\textrm {Exponential}}(\lambda )} and Y ∼ ∼ Bernoulli ( 0.5 ) {\displaystyle Y\sim {\textrm {Bernoulli}}(0.5)} ( Bernoulli distribution ) independent of X {\displaystyle X} , then X ( 2 Y − − 1 ) ∼ ∼ Laplace ( 0 , λ λ − − 1 ) {\displaystyle X(2Y-1)\sim {\textrm {Laplace}}\left(0,\lambda ^{-1}\right)} .

If X ∼ ∼ Exponential ( λ λ ) {\displaystyle X\sim {\textrm {Exponential}}(\lambda )} and Y ∼ ∼ Exponential ( ν ν ) {\displaystyle Y\sim {\textrm {Exponential}}(\nu )} independent of X {\displaystyle X} , then λ λ X − − ν ν Y ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle \lambda X-\nu Y\sim {\textrm {Laplace}}(0,1)} ． If X {\displaystyle X} has a Rademacher distribution and Y ∼ ∼ Exponential ( λ λ ) {\displaystyle Y\sim {\textrm {Exponential}}(\lambda )} then X Y ∼ ∼ Laplace ( 0 , 1 / λ λ ) {\displaystyle XY\sim {\textrm {Laplace}}(0,1/\lambda )} .

If V ∼ ∼ Exponential ( 1 ) {\displaystyle V\sim {\textrm {Exponential}}(1)} and Z ∼ ∼ N ( 0 , 1 ) {\displaystyle Z\sim N(0,1)} independent of V {\displaystyle V} , then X = μ μ + b 2 V Z ∼ ∼ L a p l a c e ( μ μ , b ) {\displaystyle X=\mu +b{\sqrt {2V}}Z\sim \mathrm {Laplace} (\mu ,b)} .

If X ∼ ∼ GeometricStable ( 2 , 0 , λ λ , 0 ) {\displaystyle X\sim {\textrm {GeometricStable}}(2,0,\lambda ,0)} ( geometric stable distribution ) then X ∼ ∼ Laplace ( 0 , λ λ ) {\displaystyle X\sim {\textrm {Laplace}}(0,\lambda )} .

The Laplace distribution is a limiting case of the hyperbolic distribution .

If X | Y ∼ ∼ N ( μ μ , Y 2 ) {\displaystyle X|Y\sim {\textrm {N}}(\mu ,Y^{2})} with Y ∼ ∼ Rayleigh ( b ) {\displaystyle Y\sim {\textrm {Rayleigh}}(b)} ( Rayleigh distribution ) then X ∼ ∼ Laplace ( μ μ , b ) {\displaystyle X\sim {\textrm {Laplace}}(\mu ,b)} . Note that if Y ∼ ∼ Rayleigh ( b ) {\displaystyle Y\sim {\textrm {Rayleigh}}(b)} , then Y 2 ∼ ∼ Gamma ( 1 , 2 b 2 ) {\displaystyle Y^{2}\sim {\textrm {Gamma}}(1,2b^{2})} with E ( Y 2 ) = 2 b 2 {\displaystyle {\textrm {E}}(Y^{2})=2b^{2}} , which in turn equals the exponential distribution Exp ( 1 / ( 2 b 2 ) ) {\displaystyle {\textrm {Exp}}(1/(2b^{2}))} .

Given an integer n ≥ ≥ 1 {\displaystyle n\geq 1} , if X i , Y i ∼ ∼ Γ Γ ( 1 n , b ) {\displaystyle X_{i},Y_{i}\sim \Gamma \left({\frac {1}{n}},b\right)} ( gamma distribution , using k , θ θ {\displaystyle k,\theta } characterization), then ∑ ∑ i = 1 n ( μ μ n + X i − − Y i ) ∼ ∼ Laplace ( μ μ , b ) {\displaystyle \sum _{i=1}^{n}\left({\frac {\mu }{n}}+X_{i}-Y_{i}\right)\sim {\textrm {Laplace}}(\mu ,b)} ( infinite divisibility ) [ 4 ] If X has a Laplace distribution, then Y = e X has a log-Laplace distribution ; conversely, if X has a log-Laplace distribution, then its logarithm has a Laplace distribution.

Probability of a Laplace being greater than another [ edit ] Let X , Y {\displaystyle X,Y} be independent laplace random variables: X ∼ ∼ Laplace ( μ μ X , b X ) {\displaystyle X\sim {\textrm {Laplace}}(\mu _{X},b_{X})} and Y ∼ ∼ Laplace ( μ μ Y , b Y ) {\displaystyle Y\sim {\textrm {Laplace}}(\mu _{Y},b_{Y})} , and we want to compute P ( X > Y ) {\displaystyle P(X>Y)} .

The probability of P ( X > Y ) {\displaystyle P(X>Y)} can be reduced (using the properties below) to P ( μ μ + b Z 1 > Z 2 ) {\displaystyle P(\mu +bZ_{1}>Z_{2})} , where Z 1 , Z 2 ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle Z_{1},Z_{2}\sim {\textrm {Laplace}}(0,1)} . This probability is equal to P ( μ μ + b Z 1 > Z 2 ) = { b 2 e μ μ / b − − e μ μ 2 ( b 2 − − 1 ) , when μ μ < 0 1 − − b 2 e − − μ μ / b − − e − − μ μ 2 ( b 2 − − 1 ) , when μ μ > 0 {\displaystyle P(\mu +bZ_{1}>Z_{2})={\begin{cases}{\frac {b^{2}e^{\mu /b}-e^{\mu }}{2(b^{2}-1)}},&{\text{when }}\mu <0\\1-{\frac {b^{2}e^{-\mu /b}-e^{-\mu }}{2(b^{2}-1)}},&{\text{when }}\mu >0\\\end{cases}}} When b = 1 {\displaystyle b=1} , both expressions are replaced by their limit as b → → 1 {\displaystyle b\to 1} : P ( μ μ + Z 1 > Z 2 ) = { e μ μ ( 2 − − μ μ ) 4 , when μ μ < 0 1 − − e − − μ μ ( 2 + μ μ ) 4 , when μ μ > 0 {\displaystyle P(\mu +Z_{1}>Z_{2})={\begin{cases}e^{\mu }{\frac {(2-\mu )}{4}},&{\text{when }}\mu <0\\1-e^{-\mu }{\frac {(2+\mu )}{4}},&{\text{when }}\mu >0\\\end{cases}}} To compute the case for μ μ > 0 {\displaystyle \mu >0} , note that P ( μ μ + Z 1 > Z 2 ) = 1 − − P ( μ μ + Z 1 < Z 2 ) = 1 − − P ( − − μ μ − − Z 1 > − − Z 2 ) = 1 − − P ( − − μ μ + Z 1 > Z 2 ) {\displaystyle P(\mu +Z_{1}>Z_{2})=1-P(\mu +Z_{1}<Z_{2})=1-P(-\mu -Z_{1}>-Z_{2})=1-P(-\mu +Z_{1}>Z_{2})} since Z ∼ ∼ − − Z {\displaystyle Z\sim -Z} when Z ∼ ∼ Laplace ( 0 , 1 ) {\displaystyle Z\sim {\textrm {Laplace}}(0,1)} .

Relation to the exponential distribution [ edit ] A Laplace random variable can be represented as the difference of two independent and identically distributed ( iid ) exponential random variables.

[ 4 ] One way to show this is by using the characteristic function approach. For any set of independent continuous random variables, for any linear combination of those variables, its characteristic function (which uniquely determines the distribution) can be acquired by multiplying the corresponding characteristic functions.

Consider two i.i.d random variables X , Y ∼ ∼ Exponential ( λ λ ) {\displaystyle X,Y\sim {\textrm {Exponential}}(\lambda )} . The characteristic functions for X , − − Y {\displaystyle X,-Y} are λ λ − − i t + λ λ , λ λ i t + λ λ {\displaystyle {\frac {\lambda }{-it+\lambda }},\quad {\frac {\lambda }{it+\lambda }}} respectively. On multiplying these characteristic functions (equivalent to the characteristic function of the sum of the random variables X + ( − − Y ) {\displaystyle X+(-Y)} ), the result is λ λ 2 ( − − i t + λ λ ) ( i t + λ λ ) = λ λ 2 t 2 + λ λ 2 .

{\displaystyle {\frac {\lambda ^{2}}{(-it+\lambda )(it+\lambda )}}={\frac {\lambda ^{2}}{t^{2}+\lambda ^{2}}}.} This is the same as the characteristic function for Z ∼ ∼ Laplace ( 0 , 1 / λ λ ) {\displaystyle Z\sim {\textrm {Laplace}}(0,1/\lambda )} , which is 1 1 + t 2 λ λ 2 .

{\displaystyle {\frac {1}{1+{\frac {t^{2}}{\lambda ^{2}}}}}.} Sargan distributions [ edit ] Sargan distributions are a system of distributions of which the Laplace distribution is a core member. A p {\displaystyle p} th order Sargan distribution has density [ 5 ] [ 6 ] f p ( x ) = 1 2 exp ⁡ ⁡ ( − − α α | x | ) 1 + ∑ ∑ j = 1 p β β j α α j | x | j 1 + ∑ ∑ j = 1 p j !

β β j , {\displaystyle f_{p}(x)={\tfrac {1}{2}}\exp(-\alpha |x|){\frac {\displaystyle 1+\sum _{j=1}^{p}\beta _{j}\alpha ^{j}|x|^{j}}{\displaystyle 1+\sum _{j=1}^{p}j!\beta _{j}}},} for parameters α α ≥ ≥ 0 , β β j ≥ ≥ 0 {\displaystyle \alpha \geq 0,\beta _{j}\geq 0} . The Laplace distribution results for p = 0 {\displaystyle p=0} .

Statistical inference [ edit ] Given n {\displaystyle n} independent and identically distributed samples x 1 , x 2 , .

.

.

, x n {\displaystyle x_{1},x_{2},...,x_{n}} , the maximum likelihood (MLE) estimator of μ μ {\displaystyle \mu } is the sample median , [ 7 ] μ μ ^ ^ = m e d ( x ) .

{\displaystyle {\hat {\mu }}=\mathrm {med} (x).} The MLE estimator of b {\displaystyle b} is the mean absolute deviation from the median, [ citation needed ] b ^ ^ = 1 n ∑ ∑ i = 1 n | x i − − μ μ ^ ^ | .

{\displaystyle {\hat {b}}={\frac {1}{n}}\sum _{i=1}^{n}|x_{i}-{\hat {\mu }}|.} revealing a link between the Laplace distribution and least absolute deviations .
A correction for small samples can be applied as follows: b ^ ^ ∗ ∗ = b ^ ^ ⋅ ⋅ n / ( n − − 2 ) {\displaystyle {\hat {b}}^{*}={\hat {b}}\cdot n/(n-2)} (see: exponential distribution#Parameter estimation ).

Occurrence and applications [ edit ] The Laplacian distribution has been used in speech recognition to model priors on DFT coefficients [ 8 ] and in JPEG image compression to model AC coefficients [ 9 ] generated by a DCT .

The addition of noise drawn from a Laplacian distribution, with scaling parameter appropriate to a function's sensitivity, to the output of a statistical database query is the most common means to provide differential privacy in statistical databases.

Fitted Laplace distribution to maximum one-day rainfalls [ 10 ] In regression analysis , the least absolute deviations estimate arises as the maximum likelihood estimate if the errors have a Laplace distribution.

The Lasso can be thought of as a Bayesian regression with a Laplacian prior for the coefficients.

[ 11 ] In hydrology the Laplace distribution is applied to extreme events such as annual maximum one-day rainfalls and river discharges. The blue picture, made with CumFreq , illustrates an example of fitting the Laplace distribution to ranked annually maximum one-day rainfalls showing also the 90% confidence belt based on the binomial distribution . The rainfall data are represented by plotting positions as part of the cumulative frequency analysis .

The Laplace distribution has applications in finance.  For example, S.G. Kou developed a model for financial instrument prices incorporating a Laplace distribution (in some cases an asymmetric Laplace distribution ) to address problems of skewness , kurtosis and the volatility smile that often occur when using a normal distribution for pricing these instruments.

[ 12 ] [ 13 ] The Laplace distribution, being a composite or double distribution, is applicable in situations where the lower values originate under different external conditions than the higher ones so that they follow a different pattern.

[ 14 ] Random variate generation [ edit ] Further information: Non-uniform random variate generation Given a random variable U {\displaystyle U} drawn from the uniform distribution in the interval ( − − 1 / 2 , 1 / 2 ) {\displaystyle \left(-1/2,1/2\right)} , the random variable X = μ μ − − b sgn ⁡ ⁡ ( U ) ln ⁡ ⁡ ( 1 − − 2 | U | ) {\displaystyle X=\mu -b\,\operatorname {sgn}(U)\,\ln(1-2|U|)} has a Laplace distribution with parameters μ μ {\displaystyle \mu } and b {\displaystyle b} . This follows from the inverse cumulative distribution function given above.

A Laplace ( 0 , b ) {\displaystyle {\textrm {Laplace}}(0,b)} variate can also be generated as the difference of two i.i.d.

Exponential ( 1 / b ) {\displaystyle {\textrm {Exponential}}(1/b)} random variables. Equivalently, Laplace ( 0 , 1 ) {\displaystyle {\textrm {Laplace}}(0,1)} can also be generated as the logarithm of the ratio of two i.i.d.

uniform random variables.

History [ edit ] This distribution is often referred to as "Laplace's first law of errors". He published it in 1774, modeling the frequency of an error as an exponential function of its magnitude once its sign was disregarded. Laplace would later replace this model with his "second law of errors", based on the normal distribution, after the discovery of the central limit theorem .

[ 15 ] [ 16 ] Keynes published a paper in 1911 based on his earlier thesis wherein he showed that the Laplace distribution minimised the absolute deviation from the median.

[ 17 ] See also [ edit ] Generalized normal distribution#Symmetric version Multivariate Laplace distribution Besov measure , a generalisation of the Laplace distribution to function spaces Cauchy distribution , also called the "Lorentzian distribution", ie the Fourier transform of the Laplace Characteristic function (probability theory) References [ edit ] ^ a b Norton, Matthew; Khokhlov, Valentyn; Uryasev, Stan (2019).

"Calculating CVaR and bPOE for common probability distributions with application to portfolio optimization and density estimation" (PDF) .

Annals of Operations Research .

299 ( 1– 2). Springer: 1281– 1315.

arXiv : 1811.11301 .

doi : 10.1007/s10479-019-03373-1 . Archived from the original (PDF) on 2023-03-31 . Retrieved 2023-02-27 .

^ Chattamvelli, Rajan; Shanmugam, Ramalingam (2021), "Laplace Distribution" , Continuous Distributions in Engineering and the Applied Sciences – Part II , Cham: Springer International Publishing, pp.

189– 199, doi : 10.1007/978-3-031-02435-1_4 , ISBN 978-3-031-01307-2 , retrieved 2025-04-04 ^ Huang, Yunfei.; et al. (2022).

"Sparse inference and active learning of stochastic differential equations from data" .

Scientific Reports .

12 (1): 21691.

arXiv : 2203.11010 .

Bibcode : 2022NatSR..1221691H .

doi : 10.1038/s41598-022-25638-9 .

PMC 9755218 .

PMID 36522347 .

^ a b Kotz, Samuel; Kozubowski, Tomasz J.; Podgórski, Krzysztof (2001).

The Laplace distribution and generalizations: a revisit with applications to Communications, Economics, Engineering and Finance . Birkhauser. pp. 23 (Proposition 2.2.2, Equation 2.2.8).

ISBN 9780817641665 .

^ Everitt, B.S. (2002) The Cambridge Dictionary of Statistics , CUP.

ISBN 0-521-81099-X ^ Johnson, N.L., Kotz S., Balakrishnan, N. (1994) Continuous Univariate Distributions , Wiley.

ISBN 0-471-58495-9 . p. 60 ^ Robert M. Norton (May 1984). "The Double Exponential Distribution: Using Calculus to Find a Maximum Likelihood Estimator".

The American Statistician .

38 (2). American Statistical Association: 135– 136.

doi : 10.2307/2683252 .

JSTOR 2683252 .

^ Eltoft, T.; Taesu Kim; Te-Won Lee (2006).

"On the multivariate Laplace distribution" (PDF) .

IEEE Signal Processing Letters .

13 (5): 300– 303.

Bibcode : 2006ISPL...13..300E .

doi : 10.1109/LSP.2006.870353 .

S2CID 1011487 . Archived from the original (PDF) on 2013-06-06 . Retrieved 2012-07-04 .

^ Minguillon, J.; Pujol, J. (2001).

"JPEG standard uniform quantization error modeling with applications to sequential and progressive operation modes" (PDF) .

Journal of Electronic Imaging .

10 (2): 475– 485.

Bibcode : 2001JEI....10..475M .

doi : 10.1117/1.1344592 .

hdl : 10609/6263 .

^ CumFreq for probability distribution fitting ^ Pardo, Scott (2020).

Statistical Analysis of Empirical Data Methods for Applied Sciences . Springer. p. 58.

ISBN 978-3-030-43327-7 .

^ Kou, S.G. (August 8, 2002).

"A Jump-Diffusion Model for Option Pricing" .

Management Science .

48 (8): 1086– 1101.

doi : 10.1287/mnsc.48.8.1086.166 .

JSTOR 822677 . Retrieved 2022-03-01 .

^ Chen, Jian (2018).

General Equilibrium Option Pricing Method: Theoretical and Empirical Study . Springer. p. 70.

ISBN 9789811074288 .

^ A collection of composite distributions ^ Laplace, P-S. (1774). Mémoire sur la probabilité des causes par les évènements. Mémoires de l’Academie Royale des Sciences Presentés par Divers Savan, 6, 621–656 ^ Wilson, Edwin Bidwell (1923). "First and Second Laws of Error".

Journal of the American Statistical Association .

18 (143). Informa UK Limited: 841– 851.

doi : 10.1080/01621459.1923.10502116 .

ISSN 0162-1459 .

This article incorporates text from this source, which is in the public domain .

^ Keynes, J. M. (1911).

"The Principal Averages and the Laws of Error which Lead to Them" .

Journal of the Royal Statistical Society .

74 (3). JSTOR: 322– 331.

doi : 10.2307/2340444 .

ISSN 0952-8385 .

JSTOR 2340444 .

External links [ edit ] "Laplace distribution" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Laplace_distribution&oldid=1303458521 " Categories : Continuous distributions Compound probability distributions Pierre-Simon Laplace Exponential family distributions Location-scale family probability distributions Geometric stable distributions Infinitely divisible probability distributions Hidden categories: Source attribution Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from October 2023 Articles with unsourced statements from August 2022 This page was last edited on 31 July 2025, at 04:08 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Laplace distribution 18 languages Add topic

