Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions Toggle Definitions subsection 1.1 Probability density function 1.2 Cumulative distribution function 1.3 Generating functions 2 Properties Toggle Properties subsection 2.1 Moments 2.2 Entropy 2.3 Large n approximation 3 Related distributions 4 References 5 External links Toggle the table of contents Chi distribution 11 languages Català Deutsch Español فارسی Français Magyar Polski Русский Shqip Slovenščina Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Probability distribution This article needs additional citations for verification .

Please help improve this article by adding citations to reliable sources . Unsourced material may be challenged and removed.

Find sources: "Chi distribution" – news · newspapers · books · scholar · JSTOR ( October 2009 ) ( Learn how and when to remove this message ) chi Probability density function Cumulative distribution function Notation χ χ ( k ) {\displaystyle \chi (k)\;} or χ χ k {\displaystyle \chi _{k}\!} Parameters k > 0 {\displaystyle k>0\,} (degrees of freedom) Support x ∈ ∈ [ 0 , ∞ ∞ ) {\displaystyle x\in [0,\infty )} PDF 1 2 ( k / 2 ) − − 1 Γ Γ ( k / 2 ) x k − − 1 e − − x 2 / 2 {\displaystyle {\frac {1}{2^{(k/2)-1}\Gamma (k/2)}}\;x^{k-1}e^{-x^{2}/2}} CDF P ( k / 2 , x 2 / 2 ) {\displaystyle P(k/2,x^{2}/2)\,} Mean μ μ = 2 Γ Γ ( ( k + 1 ) / 2 ) Γ Γ ( k / 2 ) {\displaystyle \mu ={\sqrt {2}}\,{\frac {\Gamma ((k+1)/2)}{\Gamma (k/2)}}} Median ≈ ≈ k ( 1 − − 2 9 k ) 3 {\displaystyle \approx {\sqrt {k{\bigg (}1-{\frac {2}{9k}}{\bigg )}^{3}}}} Mode k − − 1 {\displaystyle {\sqrt {k-1}}\,} for k ≥ ≥ 1 {\displaystyle k\geq 1} Variance σ σ 2 = k − − μ μ 2 {\displaystyle \sigma ^{2}=k-\mu ^{2}\,} Skewness γ γ 1 = μ μ σ σ 3 ( 1 − − 2 σ σ 2 ) {\displaystyle \gamma _{1}={\frac {\mu }{\sigma ^{3}}}\,(1-2\sigma ^{2})} Excess kurtosis 2 σ σ 2 ( 1 − − μ μ σ σ γ γ 1 − − σ σ 2 ) {\displaystyle {\frac {2}{\sigma ^{2}}}(1-\mu \sigma \gamma _{1}-\sigma ^{2})} Entropy ln ⁡ ⁡ ( Γ Γ ( k / 2 ) ) + {\displaystyle \ln(\Gamma (k/2))+\,} 1 2 ( k − − ln ⁡ ⁡ ( 2 ) − − ( k − − 1 ) ψ ψ 0 ( k / 2 ) ) {\displaystyle {\frac {1}{2}}(k\!-\!\ln(2)\!-\!(k\!-\!1)\psi _{0}(k/2))} MGF Complicated (see text) CF Complicated (see text) In probability theory and statistics , the chi distribution is a continuous probability distribution over the non-negative real line. It is the distribution of the positive square root of a sum of squared independent Gaussian random variables . Equivalently, it is the distribution of the Euclidean distance between a multivariate Gaussian random variable and the origin. The chi distribution describes the positive square roots of a variable obeying a chi-squared distribution .

If Z 1 , … … , Z k {\displaystyle Z_{1},\ldots ,Z_{k}} are k {\displaystyle k} independent, normally distributed random variables with mean 0 and standard deviation 1, then the statistic Y = ∑ ∑ i = 1 k Z i 2 {\displaystyle Y={\sqrt {\sum _{i=1}^{k}Z_{i}^{2}}}} is distributed according to the chi distribution. The chi distribution has one positive integer parameter k {\displaystyle k} , which specifies the degrees of freedom (i.e. the number of random variables Z i {\displaystyle Z_{i}} ).

The most familiar examples are the Rayleigh distribution (chi distribution with two degrees of freedom ) and the Maxwell–Boltzmann distribution of the molecular speeds in an ideal gas (chi distribution with three degrees of freedom).

Definitions [ edit ] Probability density function [ edit ] The probability density function (pdf) of the chi-distribution is f ( x ; k ) = { x k − − 1 e − − x 2 / 2 2 k / 2 − − 1 Γ Γ ( k 2 ) , x ≥ ≥ 0 ; 0 , otherwise .

{\displaystyle f(x;k)={\begin{cases}{\dfrac {x^{k-1}e^{-x^{2}/2}}{2^{k/2-1}\Gamma \left({\frac {k}{2}}\right)}},&x\geq 0;\\0,&{\text{otherwise}}.\end{cases}}} where Γ Γ ( z ) {\displaystyle \Gamma (z)} is the gamma function .

Cumulative distribution function [ edit ] The cumulative distribution function is given by: F ( x ; k ) = P ( k / 2 , x 2 / 2 ) {\displaystyle F(x;k)=P(k/2,x^{2}/2)\,} where P ( k , x ) {\displaystyle P(k,x)} is the regularized gamma function .

Generating functions [ edit ] The moment-generating function is given by: M ( t ) = M ( k 2 , 1 2 , t 2 2 ) + t 2 Γ Γ ( ( k + 1 ) / 2 ) Γ Γ ( k / 2 ) M ( k + 1 2 , 3 2 , t 2 2 ) , {\displaystyle M(t)=M\left({\frac {k}{2}},{\frac {1}{2}},{\frac {t^{2}}{2}}\right)+t{\sqrt {2}}\,{\frac {\Gamma ((k+1)/2)}{\Gamma (k/2)}}M\left({\frac {k+1}{2}},{\frac {3}{2}},{\frac {t^{2}}{2}}\right),} where M ( a , b , z ) {\displaystyle M(a,b,z)} is Kummer's confluent hypergeometric function . The characteristic function is given by: φ φ ( t ; k ) = M ( k 2 , 1 2 , − − t 2 2 ) + i t 2 Γ Γ ( ( k + 1 ) / 2 ) Γ Γ ( k / 2 ) M ( k + 1 2 , 3 2 , − − t 2 2 ) .

{\displaystyle \varphi (t;k)=M\left({\frac {k}{2}},{\frac {1}{2}},{\frac {-t^{2}}{2}}\right)+it{\sqrt {2}}\,{\frac {\Gamma ((k+1)/2)}{\Gamma (k/2)}}M\left({\frac {k+1}{2}},{\frac {3}{2}},{\frac {-t^{2}}{2}}\right).} Properties [ edit ] Moments [ edit ] The raw moments are then given by: μ μ j = ∫ ∫ 0 ∞ ∞ f ( x ; k ) x j d x = 2 j / 2 Γ Γ ( 1 2 ( k + j ) ) Γ Γ ( 1 2 k ) {\displaystyle \mu _{j}=\int _{0}^{\infty }f(x;k)x^{j}\mathrm {d} x=2^{j/2}\ {\frac {\ \Gamma \left({\tfrac {1}{2}}(k+j)\right)\ }{\Gamma \left({\tfrac {1}{2}}k\right)}}} where Γ Γ ( z ) {\displaystyle \ \Gamma (z)\ } is the gamma function . Thus the first few raw moments are: μ μ 1 = 2 Γ Γ ( 1 2 ( k + 1 ) ) Γ Γ ( 1 2 k ) {\displaystyle \mu _{1}={\sqrt {2\ }}\ {\frac {\ \Gamma \left({\tfrac {1}{2}}(k+1)\right)\ }{\Gamma \left({\tfrac {1}{2}}k\right)}}} μ μ 2 = k , {\displaystyle \mu _{2}=k\ ,} μ μ 3 = 2 2 Γ Γ ( 1 2 ( k + 3 ) ) Γ Γ ( 1 2 k ) = ( k + 1 ) μ μ 1 , {\displaystyle \mu _{3}=2{\sqrt {2\ }}\ {\frac {\ \Gamma \left({\tfrac {1}{2}}(k+3)\right)\ }{\Gamma \left({\tfrac {1}{2}}k\right)}}=(k+1)\ \mu _{1}\ ,} μ μ 4 = ( k ) ( k + 2 ) , {\displaystyle \mu _{4}=(k)(k+2)\ ,} μ μ 5 = 4 2 Γ Γ ( 1 2 ( k + 5 ) ) Γ Γ ( 1 2 k ) = ( k + 1 ) ( k + 3 ) μ μ 1 , {\displaystyle \mu _{5}=4{\sqrt {2\ }}\ {\frac {\ \Gamma \left({\tfrac {1}{2}}(k\!+\!5)\right)\ }{\Gamma \left({\tfrac {1}{2}}k\right)}}=(k+1)(k+3)\ \mu _{1}\ ,} μ μ 6 = ( k ) ( k + 2 ) ( k + 4 ) , {\displaystyle \mu _{6}=(k)(k+2)(k+4)\ ,} where the rightmost expressions are derived using the recurrence relationship for the gamma function: Γ Γ ( x + 1 ) = x Γ Γ ( x ) .

{\displaystyle \Gamma (x+1)=x\ \Gamma (x)~.} From these expressions we may derive the following relationships: Mean: μ μ = 2 Γ Γ ( 1 2 ( k + 1 ) ) Γ Γ ( 1 2 k ) , {\displaystyle \mu ={\sqrt {2\ }}\ {\frac {\ \Gamma \left({\tfrac {1}{2}}(k+1)\right)\ }{\Gamma \left({\tfrac {1}{2}}k\right)}}\ ,} which is close to k − − 1 2 {\displaystyle {\sqrt {k-{\tfrac {1}{2}}\ }}\ } for large k .

Variance: V = k − − μ μ 2 , {\displaystyle V=k-\mu ^{2}\ ,} which approaches 1 2 {\displaystyle \ {\tfrac {1}{2}}\ } as k increases.

Skewness: γ γ 1 = μ μ σ σ 3 ( 1 − − 2 σ σ 2 ) .

{\displaystyle \gamma _{1}={\frac {\mu }{\ \sigma ^{3}\ }}\left(1-2\sigma ^{2}\right)~.} Kurtosis excess: γ γ 2 = 2 σ σ 2 ( 1 − − μ μ σ σ γ γ 1 − − σ σ 2 ) .

{\displaystyle \gamma _{2}={\frac {2}{\ \sigma ^{2}\ }}\left(1-\mu \ \sigma \ \gamma _{1}-\sigma ^{2}\right)~.} Entropy [ edit ] The entropy is given by: S = ln ⁡ ⁡ ( Γ Γ ( k / 2 ) ) + 1 2 ( k − − ln ⁡ ⁡ ( 2 ) − − ( k − − 1 ) ψ ψ 0 ( k / 2 ) ) {\displaystyle S=\ln(\Gamma (k/2))+{\frac {1}{2}}(k\!-\!\ln(2)\!-\!(k\!-\!1)\psi ^{0}(k/2))} where ψ ψ 0 ( z ) {\displaystyle \psi ^{0}(z)} is the polygamma function .

Large n approximation [ edit ] We find the large n=k+1 approximation of the mean and variance of chi distribution. This has application e.g. in finding the distribution of standard deviation of a sample of normally distributed population, where n is the sample size.

The mean is then: μ μ = 2 Γ Γ ( n / 2 ) Γ Γ ( ( n − − 1 ) / 2 ) {\displaystyle \mu ={\sqrt {2}}\,\,{\frac {\Gamma (n/2)}{\Gamma ((n-1)/2)}}} We use the Legendre duplication formula to write: 2 n − − 2 Γ Γ ( ( n − − 1 ) / 2 ) ⋅ ⋅ Γ Γ ( n / 2 ) = π π Γ Γ ( n − − 1 ) {\displaystyle 2^{n-2}\,\Gamma ((n-1)/2)\cdot \Gamma (n/2)={\sqrt {\pi }}\Gamma (n-1)} , so that: μ μ = 2 / π π 2 n − − 2 ( Γ Γ ( n / 2 ) ) 2 Γ Γ ( n − − 1 ) {\displaystyle \mu ={\sqrt {2/\pi }}\,2^{n-2}\,{\frac {(\Gamma (n/2))^{2}}{\Gamma (n-1)}}} Using Stirling's approximation for Gamma function, we get the following expression for the mean: μ μ = 2 / π π 2 n − − 2 ( 2 π π ( n / 2 − − 1 ) n / 2 − − 1 + 1 / 2 e − − ( n / 2 − − 1 ) ⋅ ⋅ [ 1 + 1 12 ( n / 2 − − 1 ) + O ( 1 n 2 ) ] ) 2 2 π π ( n − − 2 ) n − − 2 + 1 / 2 e − − ( n − − 2 ) ⋅ ⋅ [ 1 + 1 12 ( n − − 2 ) + O ( 1 n 2 ) ] {\displaystyle \mu ={\sqrt {2/\pi }}\,2^{n-2}\,{\frac {\left({\sqrt {2\pi }}(n/2-1)^{n/2-1+1/2}e^{-(n/2-1)}\cdot [1+{\frac {1}{12(n/2-1)}}+O({\frac {1}{n^{2}}})]\right)^{2}}{{\sqrt {2\pi }}(n-2)^{n-2+1/2}e^{-(n-2)}\cdot [1+{\frac {1}{12(n-2)}}+O({\frac {1}{n^{2}}})]}}} = ( n − − 2 ) 1 / 2 ⋅ ⋅ [ 1 + 1 4 n + O ( 1 n 2 ) ] = n − − 1 ( 1 − − 1 n − − 1 ) 1 / 2 ⋅ ⋅ [ 1 + 1 4 n + O ( 1 n 2 ) ] {\displaystyle =(n-2)^{1/2}\,\cdot \left[1+{\frac {1}{4n}}+O({\frac {1}{n^{2}}})\right]={\sqrt {n-1}}\,(1-{\frac {1}{n-1}})^{1/2}\cdot \left[1+{\frac {1}{4n}}+O({\frac {1}{n^{2}}})\right]} = n − − 1 ⋅ ⋅ [ 1 − − 1 2 n + O ( 1 n 2 ) ] ⋅ ⋅ [ 1 + 1 4 n + O ( 1 n 2 ) ] {\displaystyle ={\sqrt {n-1}}\,\cdot \left[1-{\frac {1}{2n}}+O({\frac {1}{n^{2}}})\right]\,\cdot \left[1+{\frac {1}{4n}}+O({\frac {1}{n^{2}}})\right]} = n − − 1 ⋅ ⋅ [ 1 − − 1 4 n + O ( 1 n 2 ) ] {\displaystyle ={\sqrt {n-1}}\,\cdot \left[1-{\frac {1}{4n}}+O({\frac {1}{n^{2}}})\right]} And thus the variance is: V = ( n − − 1 ) − − μ μ 2 = ( n − − 1 ) ⋅ ⋅ 1 2 n ⋅ ⋅ [ 1 + O ( 1 n ) ] {\displaystyle V=(n-1)-\mu ^{2}\,=(n-1)\cdot {\frac {1}{2n}}\,\cdot \left[1+O({\frac {1}{n}})\right]} Related distributions [ edit ] If X ∼ ∼ χ χ k {\displaystyle X\sim \chi _{k}} then X 2 ∼ ∼ χ χ k 2 {\displaystyle X^{2}\sim \chi _{k}^{2}} ( chi-squared distribution ) χ χ 1 ∼ ∼ H N ( 1 ) {\displaystyle \chi _{1}\sim \mathrm {HN} (1)\,} ( half-normal distribution ), i.e. if X ∼ ∼ N ( 0 , 1 ) {\displaystyle X\sim N(0,1)\,} then | X | ∼ ∼ χ χ 1 {\displaystyle |X|\sim \chi _{1}\,} , and if Y ∼ ∼ H N ( σ σ ) {\displaystyle Y\sim \mathrm {HN} (\sigma )\,} for any σ σ > 0 {\displaystyle \sigma >0\,} then Y σ σ ∼ ∼ χ χ 1 {\displaystyle {\tfrac {Y}{\sigma }}\sim \chi _{1}\,} χ χ 2 ∼ ∼ R a y l e i g h ( 1 ) {\displaystyle \chi _{2}\sim \mathrm {Rayleigh} (1)\,} ( Rayleigh distribution ) and if Y ∼ ∼ R a y l e i g h ( σ σ ) {\displaystyle Y\sim \mathrm {Rayleigh} (\sigma )\,} for any σ σ > 0 {\displaystyle \sigma >0\,} then Y σ σ ∼ ∼ χ χ 2 {\displaystyle {\tfrac {Y}{\sigma }}\sim \chi _{2}\,} χ χ 3 ∼ ∼ M a x w e l l ( 1 ) {\displaystyle \chi _{3}\sim \mathrm {Maxwell} (1)\,} ( Maxwell distribution ) and if Y ∼ ∼ M a x w e l l ( a ) {\displaystyle Y\sim \mathrm {Maxwell} (a)\,} for any a > 0 {\displaystyle a>0\,} then Y a ∼ ∼ χ χ 3 {\displaystyle {\tfrac {Y}{a}}\sim \chi _{3}\,} ‖ ‖ N i = 1 , … … , k ( 0 , 1 ) ‖ ‖ 2 ∼ ∼ χ χ k {\displaystyle \|{\boldsymbol {N}}_{i=1,\ldots ,k}{(0,1)}\|_{2}\sim \chi _{k}} , the Euclidean norm of a standard normal random vector of with k {\displaystyle k} dimensions, is distributed according to a chi distribution with k {\displaystyle k} degrees of freedom chi distribution is a special case of various distributions: generalized gamma , Nakagami , noncentral chi , etc.

lim k → → ∞ ∞ χ χ k − − μ μ k σ σ k → d N ( 0 , 1 ) {\displaystyle \lim _{k\to \infty }{\tfrac {\chi _{k}-\mu _{k}}{\sigma _{k}}}{\xrightarrow {d}}\ N(0,1)\,} ( Normal distribution ) The mean of the chi distribution (scaled by the square root of n − − 1 {\displaystyle n-1} ) yields the correction factor in the unbiased estimation of the standard deviation of the normal distribution .

Various chi and chi-squared distributions Name Statistic chi-squared distribution ∑ ∑ i = 1 k ( X i − − μ μ i σ σ i ) 2 {\displaystyle \sum _{i=1}^{k}\left({\frac {X_{i}-\mu _{i}}{\sigma _{i}}}\right)^{2}} noncentral chi-squared distribution ∑ ∑ i = 1 k ( X i σ σ i ) 2 {\displaystyle \sum _{i=1}^{k}\left({\frac {X_{i}}{\sigma _{i}}}\right)^{2}} chi distribution ∑ ∑ i = 1 k ( X i − − μ μ i σ σ i ) 2 {\displaystyle {\sqrt {\sum _{i=1}^{k}\left({\frac {X_{i}-\mu _{i}}{\sigma _{i}}}\right)^{2}}}} noncentral chi distribution ∑ ∑ i = 1 k ( X i σ σ i ) 2 {\displaystyle {\sqrt {\sum _{i=1}^{k}\left({\frac {X_{i}}{\sigma _{i}}}\right)^{2}}}} References [ edit ] Martha L. Abell, James P. Braselton, John Arthur Rafter, John A. Rafter, Statistics with Mathematica (1999), 237f.

Jan W. Gooch, Encyclopedic Dictionary of Polymers vol. 1 (2010), Appendix E, p. 972 .

External links [ edit ] http://mathworld.wolfram.com/ChiDistribution.html v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Chi_distribution&oldid=1259192969 " Categories : Continuous distributions Normal distribution Exponential family distributions Hidden categories: Articles with short description Short description matches Wikidata Articles needing additional references from October 2009 All articles needing additional references This page was last edited on 23 November 2024, at 21:53 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Chi distribution 11 languages Add topic

