Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Conventions 2 Mathematics Toggle Mathematics subsection 2.1 Definition 2.2 Representation 2.3 Expectation measure 2.4 Laplace functional 2.5 Moment measure 2.6 Stationarity 2.7 Transformations 3 Examples Toggle Examples subsection 3.1 Poisson point process 3.2 Cox point process 3.3 Determinantal point processes 3.4 Hawkes (self-exciting) processes 3.5 Geometric processes 4 Point processes on the real half-line Toggle Point processes on the real half-line subsection 4.1 Intensity of a point process 5 Related functions Toggle Related functions subsection 5.1 Papangelou intensity function 5.2 Likelihood function 6 Point processes in spatial statistics 7 See also 8 Notes 9 References Toggle the table of contents Point process 7 languages Català Deutsch فارسی Français Suomi 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Random set of points on a space with random number and random position In statistics and probability theory , a point process or point field is a set of a random number of mathematical points randomly located on a mathematical space such as the real line or Euclidean space .

[ 1 ] [ 2 ] Point processes on the real line form an important special case that is particularly amenable to study, [ 3 ] because the points are ordered in a natural way, and the whole point process can be described completely by the (random) intervals between the points. These point processes are frequently used as models for random events in time, such as the arrival of customers in a queue ( queueing theory ), of impulses in a neuron ( computational neuroscience ), particles in a Geiger counter , location of radio stations in a telecommunication network [ 4 ] or of searches on the world-wide web .

General point processes on a Euclidean space can be used for spatial data analysis , [ 5 ] [ 6 ] which is of interest in such diverse disciplines as forestry, plant ecology, epidemiology, geography, seismology, materials science, astronomy, telecommunications, computational neuroscience, [ 7 ] economics [ 8 ] and others.

Conventions [ edit ] Since point processes were historically developed by different communities, there are different mathematical interpretations of a point process, such as a random counting measure or a random set, [ 9 ] [ 10 ] and different notations. The notations are described in detail on the point process notation page.

Some authors regard a point process and stochastic process as two different objects such that a point process is a random object that arises from or is associated with a stochastic process, [ 11 ] [ 12 ] though it has been remarked that the difference between point processes and stochastic processes is not clear.

[ 12 ] Others consider a point process as a stochastic process, where the process is indexed by sets of the underlying space [ a ] on which it is defined, such as the real line or n {\displaystyle n} -dimensional Euclidean space.

[ 15 ] [ 16 ] Other stochastic processes such as renewal and counting processes are studied in the theory of point processes.

[ 17 ] [ 12 ] Sometimes the term "point process" is not preferred, as historically the word "process" denoted an evolution of some system in time, so point process is also called a random point field.

[ 18 ] Mathematics [ edit ] In mathematics, a point process is a random element whose values are "point patterns" on a set S . While in the exact mathematical definition a point pattern is specified as a locally finite counting measure , it is sufficient for more applied purposes to think of a point pattern as a countable subset of S that has no limit points .

[ clarification needed ] Definition [ edit ] To define general point processes, we start with a probability space ( Ω Ω , F , P ) {\displaystyle (\Omega ,{\mathcal {F}},P)} ,
and a measurable space ( S , S ) {\displaystyle (S,{\mathcal {S}})} where S {\displaystyle S} is a locally compact second countable Hausdorff space and S {\displaystyle {\mathcal {S}}} is its Borel σ-algebra . Consider now an integer-valued locally finite kernel ξ ξ {\displaystyle \xi } from ( Ω Ω , F ) {\displaystyle (\Omega ,{\mathcal {F}})} into ( S , S ) {\displaystyle (S,{\mathcal {S}})} , that is, a mapping Ω Ω × × S ↦ ↦ Z + {\displaystyle \Omega \times {\mathcal {S}}\mapsto \mathbb {Z} _{+}} such that: For every ω ω ∈ ∈ Ω Ω {\displaystyle \omega \in \Omega } , ξ ξ ( ω ω , ⋅ ⋅ ) {\displaystyle \xi (\omega ,\cdot )} is a (integer-valued) locally finite measure on S {\displaystyle S} .

For every B ∈ ∈ S {\displaystyle B\in {\mathcal {S}}} , ξ ξ ( ⋅ ⋅ , B ) : Ω Ω → → Z + {\displaystyle \xi (\cdot ,B):\Omega \to \mathbb {Z} _{+}} is a random variable over Z + {\displaystyle \mathbb {Z} _{+}} .

This kernel defines a random measure in the following way. We would like to think of ξ ξ {\displaystyle \xi } as defining a mapping which maps ω ω ∈ ∈ Ω Ω {\displaystyle \omega \in \Omega } to a measure ξ ξ ω ω ∈ ∈ M ( S ) {\displaystyle \xi _{\omega }\in {\mathcal {M}}({\mathcal {S}})} (namely, Ω Ω ↦ ↦ M ( S ) {\displaystyle \Omega \mapsto {\mathcal {M}}({\mathcal {S}})} ),
where M ( S ) {\displaystyle {\mathcal {M}}({\mathcal {S}})} is the set of all locally finite measures on S {\displaystyle S} .
Now, to make this mapping measurable, we need to define a σ σ {\displaystyle \sigma } -field over M ( S ) {\displaystyle {\mathcal {M}}({\mathcal {S}})} .
This σ σ {\displaystyle \sigma } -field is constructed as the minimal algebra so that all evaluation maps of the form π π B : μ μ ↦ ↦ μ μ ( B ) {\displaystyle \pi _{B}:\mu \mapsto \mu (B)} , where B ∈ ∈ S {\displaystyle B\in {\mathcal {S}}} is relatively compact ,
are measurable. Equipped with this σ σ {\displaystyle \sigma } -field, then ξ ξ {\displaystyle \xi } is a random element, where for every ω ω ∈ ∈ Ω Ω {\displaystyle \omega \in \Omega } , ξ ξ ω ω {\displaystyle \xi _{\omega }} is a locally finite measure over S {\displaystyle S} .

Now, by a point process on S {\displaystyle S} we simply mean an integer-valued random measure (or equivalently, integer-valued
kernel) ξ ξ {\displaystyle \xi } constructed as above.
The most common example for the state space S is the Euclidean space R n or a subset thereof, where a particularly interesting special case is given by the real half-line [0,∞). However, point processes are not limited to these examples and may among other things also be used if the points are themselves compact subsets of R n , in which case ξ is usually referred to as a particle process .

Despite the name point process since S might not be a subset of the real line, as it might suggest that ξ is a stochastic process .

Representation [ edit ] Every instance (or event) of a point process ξ can be represented as ξ ξ = ∑ ∑ i = 1 n δ δ X i , {\displaystyle \xi =\sum _{i=1}^{n}\delta _{X_{i}},} where δ δ {\displaystyle \delta } denotes the Dirac measure , n is an integer-valued random variable and X i {\displaystyle X_{i}} are random elements of S . If X i {\displaystyle X_{i}} 's are almost surely distinct (or equivalently, almost surely ξ ξ ( x ) ≤ ≤ 1 {\displaystyle \xi (x)\leq 1} for all x ∈ ∈ R d {\displaystyle x\in \mathbb {R} ^{d}} ), then the point process is known as simple .

Another different but useful representation of an event (an event in the event space, i.e. a series of points) is the counting notation, where each instance is represented as an N ( t ) {\displaystyle N(t)} function, a continuous function which takes integer values: N : R → → Z 0 + {\displaystyle N:{\mathbb {R} }\rightarrow {\mathbb {Z} _{0}^{+}}} : N ( t 1 , t 2 ) = ∫ ∫ t 1 t 2 ξ ξ ( t ) d t {\displaystyle N(t_{1},t_{2})=\int _{t_{1}}^{t_{2}}\xi (t)\,dt} which is the number of events in the observation interval ( t 1 , t 2 ] {\displaystyle (t_{1},t_{2}]} . It is sometimes denoted by N t 1 , t 2 {\displaystyle N_{t_{1},t_{2}}} , and N T {\displaystyle N_{T}} or N ( T ) {\displaystyle N(T)} mean N 0 , T {\displaystyle N_{0,T}} .

Expectation measure [ edit ] Main article: Intensity measure The expectation measure Eξ (also known as mean measure ) of a point process ξ is a measure on S that assigns to every Borel subset B of S the expected number of points of ξ in B . That is, E ξ ξ ( B ) := E ( ξ ξ ( B ) ) for every B ∈ ∈ B .

{\displaystyle E\xi (B):=E{\bigl (}\xi (B){\bigr )}\quad {\text{for every }}B\in {\mathcal {B}}.} Laplace functional [ edit ] The Laplace functional Ψ Ψ N ( f ) {\displaystyle \Psi _{N}(f)} of a point process N is a
map from the set of all positive valued functions f on the state space of N , to [ 0 , ∞ ∞ ) {\displaystyle [0,\infty )} defined as follows: Ψ Ψ N ( f ) = E [ exp ⁡ ⁡ ( − − N ( f ) ) ] {\displaystyle \Psi _{N}(f)=E[\exp(-N(f))]} They play a similar role as the characteristic functions for random variable . One important theorem says that: two point processes have the same law if their Laplace functionals are equal.

Moment measure [ edit ] Main article: Moment measure The n {\displaystyle n} th power of a point process, ξ ξ n , {\displaystyle \xi ^{n},} is defined on the product space S n {\displaystyle S^{n}} as follows : ξ ξ n ( A 1 × × ⋯ ⋯ × × A n ) = ∏ ∏ i = 1 n ξ ξ ( A i ) {\displaystyle \xi ^{n}(A_{1}\times \cdots \times A_{n})=\prod _{i=1}^{n}\xi (A_{i})} By monotone class theorem , this uniquely defines the product measure on ( S n , B ( S n ) ) .

{\displaystyle (S^{n},B(S^{n})).} The expectation E ξ ξ n ( ⋅ ⋅ ) {\displaystyle E\xi ^{n}(\cdot )} is called
the n {\displaystyle n} th moment measure . The first moment measure is the mean measure.

Let S = R d {\displaystyle S=\mathbb {R} ^{d}} . The joint intensities of a point process ξ ξ {\displaystyle \xi } w.r.t. the Lebesgue measure are functions ρ ρ ( k ) : ( R d ) k → → [ 0 , ∞ ∞ ) {\displaystyle \rho ^{(k)}:(\mathbb {R} ^{d})^{k}\to [0,\infty )} such that for any disjoint bounded Borel subsets B 1 , … … , B k {\displaystyle B_{1},\ldots ,B_{k}} E ( ∏ ∏ i ξ ξ ( B i ) ) = ∫ ∫ B 1 × × ⋯ ⋯ × × B k ρ ρ ( k ) ( x 1 , … … , x k ) d x 1 ⋯ ⋯ d x k .

{\displaystyle E\left(\prod _{i}\xi (B_{i})\right)=\int _{B_{1}\times \cdots \times B_{k}}\rho ^{(k)}(x_{1},\ldots ,x_{k})\,dx_{1}\cdots dx_{k}.} Joint intensities do not always exist for point processes. Given that moments of a random variable determine the random variable in many cases, a similar result is to be expected for joint intensities. Indeed, this has been shown in many cases.

[ 2 ] Stationarity [ edit ] A point process ξ ξ ⊂ ⊂ R d {\displaystyle \xi \subset \mathbb {R} ^{d}} is said to be stationary if ξ ξ + x := ∑ ∑ i = 1 N δ δ X i + x {\displaystyle \xi +x:=\sum _{i=1}^{N}\delta _{X_{i}+x}} has the same distribution as ξ ξ {\displaystyle \xi } for all x ∈ ∈ R d .

{\displaystyle x\in \mathbb {R} ^{d}.} For a stationary point process, the mean measure E ξ ξ ( ⋅ ⋅ ) = λ λ ‖ ‖ ⋅ ⋅ ‖ ‖ {\displaystyle E\xi (\cdot )=\lambda \|\cdot \|} for some constant λ λ ≥ ≥ 0 {\displaystyle \lambda \geq 0} and where ‖ ‖ ⋅ ⋅ ‖ ‖ {\displaystyle \|\cdot \|} stands for the Lebesgue measure. This λ λ {\displaystyle \lambda } is called the intensity of the point process. A stationary point process on R d {\displaystyle \mathbb {R} ^{d}} has almost surely either 0 or an infinite number of points in total. For more on stationary point processes and random measure, refer to Chapter 12 of Daley & Vere-Jones.

[ 2 ] Stationarity has been defined and studied for point processes in more general spaces than R d {\displaystyle \mathbb {R} ^{d}} .

Transformations [ edit ] Main article: Point process operation A point process transformation is a function that maps a point process to another point process.

Examples [ edit ] We shall see some examples of point processes in R d .

{\displaystyle \mathbb {R} ^{d}.} Poisson point process [ edit ] Main article: Poisson point process The simplest and most ubiquitous example of a point process is the Poisson point process , which is a spatial generalisation of the Poisson process . A Poisson (counting) process on the line can be characterised by two properties : the number of points (or events) in disjoint intervals are independent and have a Poisson distribution . A Poisson point process can also be defined using these two properties. Namely, we say that a point process ξ ξ {\displaystyle \xi } is a Poisson point process if the following two conditions hold 1) ξ ξ ( B 1 ) , … … , ξ ξ ( B n ) {\displaystyle \xi (B_{1}),\ldots ,\xi (B_{n})} are independent for disjoint subsets B 1 , … … , B n .

{\displaystyle B_{1},\ldots ,B_{n}.} 2) For any bounded subset B {\displaystyle B} , ξ ξ ( B ) {\displaystyle \xi (B)} has a Poisson distribution with parameter λ λ ‖ ‖ B ‖ ‖ , {\displaystyle \lambda \|B\|,} where ‖ ‖ ⋅ ⋅ ‖ ‖ {\displaystyle \|\cdot \|} denotes the Lebesgue measure .

The two conditions can be combined and written as follows : For any disjoint bounded subsets B 1 , … … , B n {\displaystyle B_{1},\ldots ,B_{n}} and non-negative integers k 1 , … … , k n {\displaystyle k_{1},\ldots ,k_{n}} we have that Pr [ ξ ξ ( B i ) = k i , 1 ≤ ≤ i ≤ ≤ n ] = ∏ ∏ i e − − λ λ ‖ ‖ B i ‖ ‖ ( λ λ ‖ ‖ B i ‖ ‖ ) k i k i !

.

{\displaystyle \Pr[\xi (B_{i})=k_{i},1\leq i\leq n]=\prod _{i}e^{-\lambda \|B_{i}\|}{\frac {(\lambda \|B_{i}\|)^{k_{i}}}{k_{i}!}}.} The constant λ λ {\displaystyle \lambda } is called the intensity of the Poisson point process. Note that the Poisson point process is characterised by the single parameter λ λ .

{\displaystyle \lambda .} It is a simple, stationary point process.
To be more specific one calls the above point process a homogeneous Poisson point process. An inhomogeneous Poisson process is defined as above but by replacing λ λ ‖ ‖ B ‖ ‖ {\displaystyle \lambda \|B\|} with ∫ ∫ B λ λ ( x ) d x {\displaystyle \int _{B}\lambda (x)\,dx} where λ λ {\displaystyle \lambda } is a non-negative function on R d .

{\displaystyle \mathbb {R} ^{d}.} Cox point process [ edit ] A Cox process (named after Sir David Cox ) is a generalisation of the Poisson point process, in that we use random measures in place of λ λ ‖ ‖ B ‖ ‖ {\displaystyle \lambda \|B\|} . More formally, let Λ Λ {\displaystyle \Lambda } be a random measure . A Cox point process driven by the random measure Λ Λ {\displaystyle \Lambda } is the point process ξ ξ {\displaystyle \xi } with the following two properties : Given Λ Λ ( ⋅ ⋅ ) {\displaystyle \Lambda (\cdot )} , ξ ξ ( B ) {\displaystyle \xi (B)} is Poisson distributed with parameter Λ Λ ( B ) {\displaystyle \Lambda (B)} for any bounded subset B .

{\displaystyle B.} For any finite collection of disjoint subsets B 1 , … … , B n {\displaystyle B_{1},\ldots ,B_{n}} and conditioned on Λ Λ ( B 1 ) , … … , Λ Λ ( B n ) , {\displaystyle \Lambda (B_{1}),\ldots ,\Lambda (B_{n}),} we have that ξ ξ ( B 1 ) , … … , ξ ξ ( B n ) {\displaystyle \xi (B_{1}),\ldots ,\xi (B_{n})} are independent.

It is easy to see that Poisson point process (homogeneous and inhomogeneous) follow as special cases of Cox point processes. The mean measure of a Cox point process is E ξ ξ ( ⋅ ⋅ ) = E Λ Λ ( ⋅ ⋅ ) {\displaystyle E\xi (\cdot )=E\Lambda (\cdot )} and thus in the special case of a Poisson point process, it is λ λ ‖ ‖ ⋅ ⋅ ‖ ‖ .

{\displaystyle \lambda \|\cdot \|.} For a Cox point process, Λ Λ ( ⋅ ⋅ ) {\displaystyle \Lambda (\cdot )} is called the intensity measure . Further, if Λ Λ ( ⋅ ⋅ ) {\displaystyle \Lambda (\cdot )} has a (random) density ( Radon–Nikodym derivative ) λ λ ( ⋅ ⋅ ) {\displaystyle \lambda (\cdot )} i.e., Λ Λ ( B ) = a.s.

∫ ∫ B λ λ ( x ) d x , {\displaystyle \Lambda (B)\,{\stackrel {\text{a.s.}}{=}}\,\int _{B}\lambda (x)\,dx,} then λ λ ( ⋅ ⋅ ) {\displaystyle \lambda (\cdot )} is called the intensity field of the Cox point process. Stationarity of the intensity measures or intensity fields imply the stationarity of the corresponding Cox point processes.

There have been many specific classes of Cox point processes that have been studied in detail such as: Log-Gaussian Cox point processes: [ 19 ] λ λ ( y ) = exp ⁡ ⁡ ( X ( y ) ) {\displaystyle \lambda (y)=\exp(X(y))} for a Gaussian random field X ( ⋅ ⋅ ) {\displaystyle X(\cdot )} Shot noise Cox point processes:, [ 20 ] λ λ ( y ) = ∑ ∑ X ∈ ∈ Φ Φ h ( X , y ) {\displaystyle \lambda (y)=\sum _{X\in \Phi }h(X,y)} for a Poisson point process Φ Φ ( ⋅ ⋅ ) {\displaystyle \Phi (\cdot )} and kernel h ( ⋅ ⋅ , ⋅ ⋅ ) {\displaystyle h(\cdot ,\cdot )} Generalised shot noise Cox point processes: [ 21 ] λ λ ( y ) = ∑ ∑ X ∈ ∈ Φ Φ h ( X , y ) {\displaystyle \lambda (y)=\sum _{X\in \Phi }h(X,y)} for a point process Φ Φ ( ⋅ ⋅ ) {\displaystyle \Phi (\cdot )} and kernel h ( ⋅ ⋅ , ⋅ ⋅ ) {\displaystyle h(\cdot ,\cdot )} Lévy based Cox point processes: [ 22 ] λ λ ( y ) = ∫ ∫ h ( x , y ) L ( d x ) {\displaystyle \lambda (y)=\int h(x,y)L(dx)} for a Lévy basis L ( ⋅ ⋅ ) {\displaystyle L(\cdot )} and kernel h ( ⋅ ⋅ , ⋅ ⋅ ) {\displaystyle h(\cdot ,\cdot )} , and Permanental Cox point processes: [ 23 ] λ λ ( y ) = X 1 2 ( y ) + ⋯ ⋯ + X k 2 ( y ) {\displaystyle \lambda (y)=X_{1}^{2}(y)+\cdots +X_{k}^{2}(y)} for k independent Gaussian random fields X i ( ⋅ ⋅ ) {\displaystyle X_{i}(\cdot )} 's Sigmoidal Gaussian Cox point processes: [ 24 ] λ λ ( y ) = λ λ ⋆ ⋆ / ( 1 + exp ⁡ ⁡ ( − − X ( y ) ) ) {\displaystyle \lambda (y)=\lambda ^{\star }/(1+\exp(-X(y)))} for a Gaussian random field X ( ⋅ ⋅ ) {\displaystyle X(\cdot )} and random λ λ ⋆ ⋆ > 0 {\displaystyle \lambda ^{\star }>0} By Jensen's inequality, one can verify that Cox point processes satisfy the following inequality: for all bounded Borel subsets B {\displaystyle B} , Var ⁡ ⁡ ( ξ ξ ( B ) ) ≥ ≥ Var ⁡ ⁡ ( ξ ξ α α ( B ) ) , {\displaystyle \operatorname {Var} (\xi (B))\geq \operatorname {Var} (\xi _{\alpha }(B)),} where ξ ξ α α {\displaystyle \xi _{\alpha }} stands for a Poisson point process with intensity measure α α ( ⋅ ⋅ ) := E ξ ξ ( ⋅ ⋅ ) = E Λ Λ ( ⋅ ⋅ ) .

{\displaystyle \alpha (\cdot ):=E\xi (\cdot )=E\Lambda (\cdot ).} Thus points are distributed with greater variability in a Cox point process compared to a Poisson point process. This is sometimes called clustering or attractive property of the Cox point process.

Determinantal point processes [ edit ] An important class of point processes, with applications to physics , random matrix theory , and combinatorics , is that of determinantal point processes .

[ 25 ] Hawkes (self-exciting) processes [ edit ] Main article: Hawkes process A Hawkes process N t {\displaystyle N_{t}} , also known as a self-exciting counting process, is a simple point process whose conditional intensity can be expressed as λ λ ( t ) = μ μ ( t ) + ∫ ∫ − − ∞ ∞ t ν ν ( t − − s ) d N s = μ μ ( t ) + ∑ ∑ T k < t ν ν ( t − − T k ) {\displaystyle {\begin{aligned}\lambda (t)&=\mu (t)+\int _{-\infty }^{t}\nu (t-s)\,dN_{s}\\[5pt]&=\mu (t)+\sum _{T_{k}<t}\nu (t-T_{k})\end{aligned}}} where ν ν : R + → → R + {\displaystyle \nu :\mathbb {R} ^{+}\rightarrow \mathbb {R} ^{+}} is a kernel function which expresses the positive influence of past events T i {\displaystyle T_{i}} on the current value of the intensity process λ λ ( t ) {\displaystyle \lambda (t)} , μ μ ( t ) {\displaystyle \mu (t)} is a possibly non-stationary function representing the expected, predictable, or deterministic part of the intensity, and { T i : T i < T i + 1 } ∈ ∈ R {\displaystyle \{T_{i}:T_{i}<T_{i+1}\}\in \mathbb {R} } is the time of occurrence of the i -th event of the process.

[ 26 ] Geometric processes [ edit ] Given a sequence of non-negative random variables { X k , k = 1 , 2 , … … } {\textstyle \{X_{k},k=1,2,\dots \}} , if they are independent and the cdf of X k {\displaystyle X_{k}} is given by F ( a k − − 1 x ) {\displaystyle F(a^{k-1}x)} for k = 1 , 2 , … … {\displaystyle k=1,2,\dots } , where a {\displaystyle a} is a positive constant, then { X k , k = 1 , 2 , … … } {\displaystyle \{X_{k},k=1,2,\ldots \}} is called a geometric process (GP).

[ 27 ] The geometric process has several extensions, including the α- series process [ 28 ] and the doubly geometric process .

[ 29 ] Point processes on the real half-line [ edit ] Historically the first point processes that were studied had the real half line R + = [0,∞) as their state space, which in this context is usually interpreted as time. These studies were motivated by the wish to model telecommunication systems, [ 30 ] in which the points represented events in time, such as calls to a telephone exchange.

Point processes on R + are typically described by giving the sequence of their (random) inter-event times ( T 1 , T 2 , ...), from which the actual sequence ( X 1 , X 2 , ...) of event times can be obtained as X k = ∑ ∑ j = 1 k T j for k ≥ ≥ 1.

{\displaystyle X_{k}=\sum _{j=1}^{k}T_{j}\quad {\text{for }}k\geq 1.} If the inter-event times are independent and identically distributed, the point process obtained is called a renewal process .

Intensity of a point process [ edit ] The intensity λ ( t | H t )  of a point process on the real half-line with respect to a filtration H t is defined as λ λ ( t ∣ ∣ H t ) = lim Δ Δ t → → 0 1 Δ Δ t Pr ( One event occurs in the time-interval [ t , t + Δ Δ t ] ∣ ∣ H t ) , {\displaystyle \lambda (t\mid H_{t})=\lim _{\Delta t\to 0}{\frac {1}{\Delta t}}\Pr({\text{One event occurs in the time-interval}}\,[t,t+\Delta t]\mid H_{t}),} H t can denote the history of event-point times preceding time t but can also correspond to other filtrations (for example in the case of a Cox process).

In the N ( t ) {\displaystyle N(t)} -notation, this can be written in a more compact form: λ λ ( t ∣ ∣ H t ) = lim Δ Δ t → → 0 1 Δ Δ t Pr ( N ( t + Δ Δ t ) − − N ( t ) = 1 ∣ ∣ H t ) .

{\displaystyle \lambda (t\mid H_{t})=\lim _{\Delta t\to 0}{\frac {1}{\Delta t}}\Pr(N(t+\Delta t)-N(t)=1\mid H_{t}).} The compensator of a point process, also known as the dual-predictable projection , is the integrated conditional intensity function defined by Λ Λ ( s , u ) = ∫ ∫ s u λ λ ( t ∣ ∣ H t ) d t {\displaystyle \Lambda (s,u)=\int _{s}^{u}\lambda (t\mid H_{t})\,\mathrm {d} t} Related functions [ edit ] Papangelou intensity function [ edit ] The Papangelou intensity function of a point process N {\displaystyle N} in the n {\displaystyle n} -dimensional Euclidean space R n {\displaystyle \mathbb {R} ^{n}} is defined as λ λ p ( x ) = lim δ δ → → 0 1 | B δ δ ( x ) | P { One event occurs in B δ δ ( x ) ∣ ∣ σ σ [ N ( R n ∖ ∖ B δ δ ( x ) ) ] } , {\displaystyle \lambda _{p}(x)=\lim _{\delta \to 0}{\frac {1}{|B_{\delta }(x)|}}{P}\{{\text{One event occurs in }}\,B_{\delta }(x)\mid \sigma [N(\mathbb {R} ^{n}\setminus B_{\delta }(x))]\},} where B δ δ ( x ) {\displaystyle B_{\delta }(x)} is the ball centered at x {\displaystyle x} of a radius δ δ {\displaystyle \delta } , and σ σ [ N ( R n ∖ ∖ B δ δ ( x ) ) ] {\displaystyle \sigma [N(\mathbb {R} ^{n}\setminus B_{\delta }(x))]} denotes  the information of the point process N {\displaystyle N} outside B δ δ ( x ) {\displaystyle B_{\delta }(x)} .

Likelihood function [ edit ] The logarithmic likelihood of a parameterized simple point process conditional upon some observed data is written as ln ⁡ ⁡ L ( N ( t ) t ∈ ∈ [ 0 , T ] ) = ∫ ∫ 0 T ( 1 − − λ λ ( s ) ) d s + ∫ ∫ 0 T ln ⁡ ⁡ λ λ ( s ) d N s {\displaystyle \ln {\mathcal {L}}(N(t)_{t\in [0,T]})=\int _{0}^{T}(1-\lambda (s))\,ds+\int _{0}^{T}\ln \lambda (s)\,dN_{s}} [ 31 ] Point processes in spatial statistics [ edit ] The analysis of point pattern data in a compact subset S of R n is a major object of study within spatial statistics . Such data appear in a broad range of disciplines, [ 32 ] amongst which are forestry and plant ecology (positions of trees or plants in general) epidemiology (home locations of infected patients) zoology (burrows or nests of animals) geography (positions of human settlements, towns or cities) seismology (epicenters of earthquakes) materials science (positions of defects in industrial materials) astronomy (locations of stars or galaxies) computational neuroscience (spikes of neurons).

The need to use point processes to model these kinds of data lies in their inherent spatial structure. Accordingly, a first question of interest is often whether the given data exhibit complete spatial randomness (i.e. are a realization of a spatial Poisson process ) as opposed to exhibiting either spatial aggregation or spatial inhibition.

In contrast, many datasets considered in classical multivariate statistics consist of independently generated datapoints that may be governed by one or several covariates (typically non-spatial).

Apart from the applications in spatial statistics, point processes are one of the fundamental objects in stochastic geometry . Research has also focussed extensively on various models built on point processes such as Voronoi tessellations , random geometric graphs , and Boolean models .

See also [ edit ] Empirical measure Random measure Point process notation Point process operation Poisson process Renewal theory Invariant measure Transfer operator Koopman operator Shift operator Notes [ edit ] ^ In the context of point processes, the term "state space" can mean the space on which the point process is defined such as the real line, [ 13 ] [ 14 ] which corresponds to the index set in stochastic process terminology.

References [ edit ] ^ Kallenberg, O.

(1986).

Random Measures , 4th edition. Academic Press, New York, London; Akademie-Verlag, Berlin.

ISBN 0-12-394960-2 , MR 0854102 .

^ a b c Daley, D.J, Vere-Jones, D. (1988).

An Introduction to the Theory of Point Processes . Springer, New York.

ISBN 0-387-96666-8 , MR 0950166 .

^ Last, G., Brandt, A. (1995).

Marked point processes on the real line: The dynamic approach.

Probability and its Applications. Springer, New York.

ISBN 0-387-94547-4 , MR 1353912 ^ Gilbert E.N.

(1961). "Random plane networks".

Journal of the Society for Industrial and Applied Mathematics .

9 (4): 533– 543.

doi : 10.1137/0109045 .

^ Diggle, P. (2003).

Statistical Analysis of Spatial Point Patterns , 2nd edition. Arnold, London.

ISBN 0-340-74070-1 .

^ Baddeley, A. (2006). Spatial point processes and their applications.
In A. Baddeley, I. Bárány, R. Schneider, and W. Weil, editors, Stochastic Geometry: Lectures given at the C.I.M.E. Summer School held in Martina Franca, Italy, September 13–18, 2004 , Lecture Notes in Mathematics 1892, Springer.

ISBN 3-540-38174-0 , pp. 1–75 ^ Brown E. N., Kass R. E., Mitra P. P. (2004). "Multiple neural spike train data analysis: state-of-the-art and future challenges".

Nature Neuroscience .

7 (5): 456– 461.

doi : 10.1038/nn1228 .

PMID 15114358 .

S2CID 562815 .

{{ cite journal }} :  CS1 maint: multiple names: authors list ( link ) ^ Engle Robert F., Lunde Asger (2003).

"Trades and Quotes: A Bivariate Point Process" (PDF) .

Journal of Financial Econometrics .

1 (2): 159– 188.

doi : 10.1093/jjfinec/nbg011 .

^ Sung Nok Chiu; Dietrich Stoyan; Wilfrid S. Kendall; Joseph Mecke (27 June 2013).

Stochastic Geometry and Its Applications . John Wiley & Sons. p. 108.

ISBN 978-1-118-65825-3 .

^ Martin Haenggi (2013).

Stochastic Geometry for Wireless Networks . Cambridge University Press. p. 10.

ISBN 978-1-107-01469-5 .

^ D.J. Daley; D. Vere-Jones (10 April 2006).

An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods . Springer Science & Business Media. p. 194.

ISBN 978-0-387-21564-8 .

^ a b c Cox, D. R.

; Isham, Valerie (1980).

Point Processes . CRC Press.

p. 3 .

ISBN 978-0-412-21910-8 .

^ J. F. C. Kingman (17 December 1992).

Poisson Processes . Clarendon Press. p. 8.

ISBN 978-0-19-159124-2 .

^ Jesper Moller; Rasmus Plenge Waagepetersen (25 September 2003).

Statistical Inference and Simulation for Spatial Point Processes . CRC Press. p. 7.

ISBN 978-0-203-49693-0 .

^ Samuel Karlin; Howard E. Taylor (2 December 2012).

A First Course in Stochastic Processes . Academic Press. p. 31.

ISBN 978-0-08-057041-9 .

^ Volker Schmidt (24 October 2014).

Stochastic Geometry, Spatial Statistics and Random Fields: Models and Algorithms . Springer. p. 99.

ISBN 978-3-319-10064-7 .

^ D.J. Daley; D. Vere-Jones (10 April 2006).

An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods . Springer Science & Business Media.

ISBN 978-0-387-21564-8 .

^ Sung Nok Chiu; Dietrich Stoyan; Wilfrid S. Kendall; Joseph Mecke (27 June 2013).

Stochastic Geometry and Its Applications . John Wiley & Sons. p. 109.

ISBN 978-1-118-65825-3 .

^ Moller, J.; Syversveen, A. R.; Waagepetersen, R. P. (1998). "Log Gaussian Cox Processes".

Scandinavian Journal of Statistics .

25 (3): 451.

CiteSeerX 10.1.1.71.6732 .

doi : 10.1111/1467-9469.00115 .

S2CID 120543073 .

^ Moller, J. (2003) Shot noise Cox processes, Adv. Appl. Prob.

, 35 .

[ page needed ] ^ Moller, J. and Torrisi, G.L. (2005) "Generalised Shot noise Cox processes", Adv. Appl. Prob.

, 37 .

^ Hellmund, G., Prokesova, M. and Vedel Jensen, E.B.

(2008)
"Lévy-based Cox point processes", Adv. Appl. Prob.

, 40 .

[ page needed ] ^ Mccullagh,P. and Moller, J. (2006) "The permanental processes", Adv. Appl. Prob.

, 38 .

[ page needed ] ^ Adams, R. P., Murray, I. MacKay, D. J. C. (2009) "Tractable inference in Poisson processes with Gaussian process intensities", Proceedings of the 26th International Conference on Machine Learning doi : 10.1145/1553374.1553376 ^ Hough, J. B., Krishnapur, M., Peres, Y., and Virág, B., Zeros of Gaussian analytic functions and determinantal point processes. University Lecture Series, 51. American Mathematical Society, Providence, RI, 2009.

^ Patrick J. Laub, Young Lee, Thomas Taimre, The Elements of Hawkes Processes , Springer, 2022.

^ Lin, Ye (Lam Yeh) (1988). "Geometric processes and replacement problem".

Acta Mathematicae Applicatae Sinica .

4 (4): 366– 377.

doi : 10.1007/BF02007241 .

S2CID 123338120 .

^ Braun, W. John; Li, Wei; Zhao, Yiqiang Q. (2005). "Properties of the geometric and related processes".

Naval Research Logistics .

52 (7): 607– 616.

CiteSeerX 10.1.1.113.9550 .

doi : 10.1002/nav.20099 .

S2CID 7745023 .

^ Wu, Shaomin (2018).

"Doubly geometric processes and applications" (PDF) .

Journal of the Operational Research Society .

69 : 66– 77.

doi : 10.1057/s41274-017-0217-4 .

S2CID 51889022 .

^ Palm, C. (1943). Intensitätsschwankungen im Fernsprechverkehr (German).

Ericsson Technics no. 44, (1943).

MR 0011402 ^ Rubin, I. (Sep 1972). "Regular point processes and their detection".

IEEE Transactions on Information Theory .

18 (5): 547– 557.

doi : 10.1109/tit.1972.1054897 .

^ Baddeley, A., Gregori, P., Mateu, J., Stoica, R., and Stoyan, D., editors (2006).

Case Studies in Spatial Point Pattern Modelling , Lecture Notes in Statistics No. 185. Springer, New York.

ISBN 0-387-28311-0 .

v t e Stochastic processes Discrete time Bernoulli process Branching process Chinese restaurant process Galton–Watson process Independent and identically distributed random variables Markov chain Moran process Random walk Loop-erased Self-avoiding Biased Maximal entropy Continuous time Additive process Airy process Bessel process Birth–death process pure birth Brownian motion Bridge Dyson Excursion Fractional Geometric Meander Cauchy process Contact process Continuous-time random walk Cox process Diffusion process Empirical process Feller process Fleming–Viot process Gamma process Geometric process Hawkes process Hunt process Interacting particle systems Itô diffusion Itô process Jump diffusion Jump process Lévy process Local time Markov additive process McKean–Vlasov process Ornstein–Uhlenbeck process Poisson process Compound Non-homogeneous Quasimartingale Schramm–Loewner evolution Semimartingale Sigma-martingale Stable process Superprocess Telegraph process Variance gamma process Wiener process Wiener sausage Both Branching process Gaussian process Hidden Markov model (HMM) Markov process Martingale Differences Local Sub- Super- Random dynamical system Regenerative process Renewal process Stochastic chains with memory of variable length White noise Fields and other Dirichlet process Gaussian random field Gibbs measure Hopfield model Ising model Potts model Boolean network Markov random field Percolation Pitman–Yor process Point process Cox Determinantal Poisson Random field Random graph Time series models Autoregressive conditional heteroskedasticity (ARCH) model Autoregressive integrated moving average (ARIMA) model Autoregressive (AR) model Autoregressive–moving-average (ARMA) model Generalized autoregressive conditional heteroskedasticity (GARCH) model Moving-average (MA) model Financial models Binomial options pricing model Black–Derman–Toy Black–Karasinski Black–Scholes Chan–Karolyi–Longstaff–Sanders (CKLS) Chen Constant elasticity of variance (CEV) Cox–Ingersoll–Ross (CIR) Garman–Kohlhagen Heath–Jarrow–Morton (HJM) Heston Ho–Lee Hull–White Korn-Kreer-Lenssen LIBOR market Rendleman–Bartter SABR volatility Vašíček Wilkie Actuarial models Bühlmann Cramér–Lundberg Risk process Sparre–Anderson Queueing models Bulk Fluid Generalized queueing network M/G/1 M/M/1 M/M/c Properties Càdlàg paths Continuous Continuous paths Ergodic Exchangeable Feller-continuous Gauss–Markov Markov Mixing Piecewise-deterministic Predictable Progressively measurable Self-similar Stationary Time-reversible Limit theorems Central limit theorem Donsker's theorem Doob's martingale convergence theorems Ergodic theorem Fisher–Tippett–Gnedenko theorem Large deviation principle Law of large numbers (weak/strong) Law of the iterated logarithm Maximal ergodic theorem Sanov's theorem Zero–one laws ( Blumenthal , Borel–Cantelli , Engelbert–Schmidt , Hewitt–Savage , Kolmogorov , Lévy ) Inequalities Burkholder–Davis–Gundy Doob's martingale Doob's upcrossing Kunita–Watanabe Marcinkiewicz–Zygmund Tools Cameron–Martin formula Convergence of random variables Doléans-Dade exponential Doob decomposition theorem Doob–Meyer decomposition theorem Doob's optional stopping theorem Dynkin's formula Feynman–Kac formula Filtration Girsanov theorem Infinitesimal generator Itô integral Itô's lemma Karhunen–Loève theorem Kolmogorov continuity theorem Kolmogorov extension theorem Lévy–Prokhorov metric Malliavin calculus Martingale representation theorem Optional stopping theorem Prokhorov's theorem Quadratic variation Reflection principle Skorokhod integral Skorokhod's representation theorem Skorokhod space Snell envelope Stochastic differential equation Tanaka Stopping time Stratonovich integral Uniform integrability Usual hypotheses Wiener space Classical Abstract Disciplines Actuarial mathematics Control theory Econometrics Ergodic theory Extreme value theory (EVT) Large deviations theory Mathematical finance Mathematical statistics Probability theory Queueing theory Renewal theory Ruin theory Signal processing Statistics Stochastic analysis Time series analysis Machine learning List of topics Category NewPP limit report
Parsed by mw‐api‐ext.codfw.main‐b666f4b‐lz27t
Cached time: 20250815150114
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.625 seconds
Real time usage: 0.850 seconds
Preprocessor visited node count: 3404/1000000
Revision size: 29730/2097152 bytes
Post‐expand include size: 86239/2097152 bytes
Template argument size: 3368/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 118142/5000000 bytes
Lua time usage: 0.272/10.000 seconds
Lua memory usage: 6545480/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  428.887      1 -total
 54.95%  235.677      2 Template:Reflist
 15.74%   67.488      1 Template:Stochastic_processes
 15.28%   65.516      1 Template:Navbox
 15.12%   64.839      8 Template:Cite_journal
 13.15%   56.403      1 Template:Short_description
 12.46%   53.450     10 Template:Cite_book
 11.93%   51.182      6 Template:Isbn
  9.21%   39.485      2 Template:Pagetype
  7.88%   33.791      3 Template:Page_needed Saved in parser cache with key enwiki:pcache:2147685:|#|:idhash:canonical and timestamp 20250815150114 and revision id 1306036492. Rendering was triggered because: unknown Retrieved from " https://en.wikipedia.org/w/index.php?title=Point_process&oldid=1306036492 " Categories : Statistical data types Point processes Spatial processes Hidden categories: CS1 maint: multiple names: authors list Wikipedia articles needing page number citations from October 2011 Wikipedia articles needing page number citations from June 2011 Articles with short description Short description is different from Wikidata Wikipedia articles needing clarification from October 2011 This page was last edited on 15 August 2025, at 15:00 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Point process 7 languages Add topic

