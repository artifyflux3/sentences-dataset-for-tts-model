Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions 2 Euclidean vector spaces 3 Orthogonal functions 4 Examples Toggle Examples subsection 4.1 Orthogonal polynomials 5 Combinatorics 6 Completely orthogonal 7 See also 8 References Toggle the table of contents Orthogonality (mathematics) 1 language Galego Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Term in geometry mathematics For other uses, see Orthogonality .

In mathematics , orthogonality is the generalization of the geometric notion of perpendicularity to linear algebra of bilinear forms .

Two elements u and v of a vector space with bilinear form B {\displaystyle B} are orthogonal when B ( u , v ) = 0 {\displaystyle B(\mathbf {u} ,\mathbf {v} )=0} .  Depending on the bilinear form, the vector space may contain null vectors , non-zero self-orthogonal vectors, in which case perpendicularity is replaced with hyperbolic orthogonality .

In the case of function spaces , families of functions are used to form an orthogonal basis , such as in the contexts of orthogonal polynomials , orthogonal functions , and combinatorics .

Orthogonality and rotation of coordinate systems compared between left: Euclidean space through circular angle ϕ , right: in Minkowski spacetime through hyperbolic angle ϕ (red lines labelled c denote the worldlines of a light signal, a vector is orthogonal to itself if it lies on this line).

[ 1 ] Definitions [ edit ] In geometry , two Euclidean vectors are orthogonal if they are perpendicular , i.e.

they form a right angle .

Two vectors u and v in an inner product space V {\displaystyle V} are orthogonal if their inner product ⟨ ⟨ u , v ⟩ ⟩ {\displaystyle \langle \mathbf {u} ,\mathbf {v} \rangle } is zero.

[ 2 ] This relationship is denoted u ⊥ ⊥ v {\displaystyle \mathbf {u} \perp \mathbf {v} } .

A set of vectors in an inner product space is called pairwise orthogonal if each pairing of them is orthogonal. Such a set is called an orthogonal set (or orthogonal system ). If the vectors are normalized, they form an orthonormal system .

An orthogonal matrix is a matrix whose column vectors are orthonormal to each other.

An orthonormal basis is a basis whose vectors are both orthogonal and normalized (they are unit vectors ).

A conformal linear transformation preserves angles and distance ratios, meaning that transforming orthogonal vectors by the same conformal linear transformation will keep those vectors orthogonal .

Two vector subspaces A {\displaystyle A} and B {\displaystyle B} of an inner product space V {\displaystyle V} are called orthogonal subspaces if each vector in A {\displaystyle A} is orthogonal to each vector in B {\displaystyle B} .  The largest subspace of V {\displaystyle V} that is orthogonal to a given subspace is its orthogonal complement .

Given a module M {\displaystyle M} and its dual M ∗ ∗ {\displaystyle M^{*}} , an element m ′ {\displaystyle m'} of M ∗ ∗ {\displaystyle M^{*}} and an element m {\displaystyle m} of M {\displaystyle M} are orthogonal if their natural pairing is zero, i.e.

⟨ ⟨ m ′ , m ⟩ ⟩ = 0 {\displaystyle \langle m',m\rangle =0} . Two sets S ′ ⊆ ⊆ M ∗ ∗ {\displaystyle S'\subseteq M^{*}} and S ⊆ ⊆ M {\displaystyle S\subseteq M} are orthogonal if each element of S ′ {\displaystyle S'} is orthogonal to each element of S {\displaystyle S} .

[ 3 ] A term rewriting system is said to be orthogonal if it is left-linear and is non-ambiguous. Orthogonal term rewriting systems are confluent .

In certain cases, the word normal is used to mean orthogonal , particularly in the geometric sense as in the normal to a surface . For example, the y -axis is normal to the curve y = x 2 {\displaystyle y=x^{2}} at the origin.  However, normal may also refer to the magnitude of a vector. In particular, a set is called orthonormal (orthogonal plus normal) if it is an orthogonal set of unit vectors . As a result, use of the term normal to mean "orthogonal" is often avoided. The word "normal" also has a different meaning in probability and statistics .

A vector space with a bilinear form generalizes the case of an inner product. When the bilinear form applied to two vectors results in zero, then they are orthogonal . The case of a pseudo-Euclidean plane uses the term hyperbolic orthogonality . In the diagram, axes x′ and t′ are hyperbolic-orthogonal for any given ϕ ϕ {\displaystyle \phi } .

Euclidean vector spaces [ edit ] In Euclidean space , two vectors are orthogonal if and only if their dot product is zero, i.e. they make an angle of 90° ( π π 2 {\textstyle {\frac {\pi }{2}}} radians ), or one of the vectors is zero.

[ 4 ] Hence orthogonality of vectors is an extension of the concept of perpendicular vectors to spaces of any dimension.

The orthogonal complement of a subspace is the space of all vectors that are orthogonal to every vector in the subspace. In a three-dimensional Euclidean vector space, the orthogonal complement of a line through the origin is the plane through the origin perpendicular to it, and vice versa.

[ 5 ] Note that the geometric concept of two planes being perpendicular does not correspond to the orthogonal complement, since in three dimensions a pair of vectors, one from each of a pair of perpendicular planes, might meet at any angle.

In four-dimensional Euclidean space, the orthogonal complement of a line is a hyperplane and vice versa, and that of a plane is a plane.

[ 5 ] Orthogonal functions [ edit ] Main article: Orthogonal functions By using integral calculus , it is common to use the following to define the inner product of two functions f {\displaystyle f} and g {\displaystyle g} with respect to a nonnegative weight function w {\displaystyle w} over an interval [ a , b ] {\displaystyle [a,b]} : ⟨ ⟨ f , g ⟩ ⟩ w = ∫ ∫ a b f ( x ) g ( x ) w ( x ) d x .

{\displaystyle \langle f,g\rangle _{w}=\int _{a}^{b}f(x)g(x)w(x)\,dx.} In simple cases, w ( x ) = 1 {\displaystyle w(x)=1} .

We say that functions f {\displaystyle f} and g {\displaystyle g} are orthogonal if their inner product (equivalently, the value of this integral) is zero: ⟨ ⟨ f , g ⟩ ⟩ w = 0.

{\displaystyle \langle f,g\rangle _{w}=0.} Orthogonality of two functions with respect to one inner product does not imply orthogonality with respect to another inner product.

We write the norm with respect to this inner product as ‖ ‖ f ‖ ‖ w = ⟨ ⟨ f , f ⟩ ⟩ w {\displaystyle \|f\|_{w}={\sqrt {\langle f,f\rangle _{w}}}} The members of a set of functions f i ∣ ∣ i ∈ ∈ N {\displaystyle {f_{i}\mid i\in \mathbb {N} }} are orthogonal with respect to w {\displaystyle w} on the interval [ a , b ] {\displaystyle [a,b]} if ⟨ ⟨ f i , f j ⟩ ⟩ w = 0 ∣ ∣ i ≠ ≠ j .

{\displaystyle \langle f_{i},f_{j}\rangle _{w}=0\mid i\neq j.} The members of such a set of functions are orthonormal with respect to w {\displaystyle w} on the interval [ a , b ] {\displaystyle [a,b]} if ⟨ ⟨ f i , f j ⟩ ⟩ w = δ δ i j , {\displaystyle \langle f_{i},f_{j}\rangle _{w}=\delta _{ij},} where δ δ i j = { 1 , i = j 0 , i ≠ ≠ j {\displaystyle \delta _{ij}=\left\{{\begin{matrix}1,&&i=j\\0,&&i\neq j\end{matrix}}\right.} is the Kronecker delta .

In other words, every pair of them (excluding pairing of a function with itself) is orthogonal, and the norm of each is 1. See in particular the orthogonal polynomials .

Examples [ edit ] The vectors ( 1 , 3 , 2 ) T , ( 3 , − − 1 , 0 ) T , ( 1 , 3 , − − 5 ) T {\displaystyle (1,3,2)^{\text{T}},(3,-1,0)^{\text{T}},(1,3,-5)^{\text{T}}} are orthogonal to each other, since ( 1 ) ( 3 ) + ( 3 ) ( − − 1 ) + ( 2 ) ( 0 ) = 0 , {\displaystyle (1)(3)+(3)(-1)+(2)(0)=0\ ,} ( 3 ) ( 1 ) + ( − − 1 ) ( 3 ) + ( 0 ) ( − − 5 ) = 0 , {\displaystyle \ (3)(1)+(-1)(3)+(0)(-5)=0\ ,} and ( 1 ) ( 1 ) + ( 3 ) ( 3 ) + ( 2 ) ( − − 5 ) = 0 {\displaystyle (1)(1)+(3)(3)+(2)(-5)=0} .

The vectors ( 1 , 0 , 1 , 0 , … … ) T {\displaystyle (1,0,1,0,\ldots )^{\text{T}}} and ( 0 , 1 , 0 , 1 , … … ) T {\displaystyle (0,1,0,1,\ldots )^{\text{T}}} are orthogonal to each other. The dot product of these vectors is zero. We can then make the generalization to consider the vectors in Z 2 n {\displaystyle \mathbb {Z} _{2}^{n}} : v k = ∑ ∑ i = 0 a i + k < n n / a e i {\displaystyle \mathbf {v} _{k}=\sum _{i=0 \atop ai+k<n}^{n/a}\mathbf {e} _{i}} for some positive integer a {\displaystyle a} , and for 1 ≤ ≤ k ≤ ≤ a − − 1 {\displaystyle 1\leq k\leq a-1} , these vectors are orthogonal, for example [ 1 0 0 1 0 0 1 0 ] {\displaystyle {\begin{bmatrix}1&0&0&1&0&0&1&0\end{bmatrix}}} , [ 0 1 0 0 1 0 0 1 ] {\displaystyle {\begin{bmatrix}0&1&0&0&1&0&0&1\end{bmatrix}}} , [ 0 0 1 0 0 1 0 0 ] {\displaystyle {\begin{bmatrix}0&0&1&0&0&1&0&0\end{bmatrix}}} are orthogonal.

The functions 2 t + 3 {\displaystyle 2t+3} and 45 t 2 + 9 t − − 17 {\displaystyle 45t^{2}+9t-17} are orthogonal with respect to a unit weight function on the interval from −1 to 1: ∫ ∫ − − 1 1 ( 2 t + 3 ) ( 45 t 2 + 9 t − − 17 ) d t = 0 {\displaystyle \int _{-1}^{1}\left(2t+3\right)\left(45t^{2}+9t-17\right)\,dt=0} The functions 1 , sin ⁡ ⁡ ( n x ) , cos ⁡ ⁡ ( n x ) ∣ ∣ n ∈ ∈ N {\displaystyle 1,\sin {(nx)},\cos {(nx)}\mid n\in \mathbb {N} } are orthogonal with respect to Riemann integration on the intervals [ 0 , 2 π π ] , [ − − π π , π π ] {\displaystyle [0,2\pi ],[-\pi ,\pi ]} , or any other closed interval of length 2 π π {\displaystyle 2\pi } . This fact is a central one in Fourier series .

Orthogonal polynomials [ edit ] Various polynomial sequences named for mathematicians of the past are sequences of orthogonal polynomials . In particular: The Hermite polynomials are orthogonal with respect to the Gaussian distribution with zero mean value.

The Legendre polynomials are orthogonal with respect to the uniform distribution on the interval [ − − 1 , 1 ] {\displaystyle [-1,1]} .

The Laguerre polynomials are orthogonal with respect to the exponential distribution . Somewhat more general Laguerre polynomial sequences are orthogonal with respect to gamma distributions .

The Chebyshev polynomials of the first kind are orthogonal with respect to the measure 1 1 − − x 2 .

{\textstyle {\frac {1}{\sqrt {1-x^{2}}}}.} The Chebyshev polynomials of the second kind are orthogonal with respect to the Wigner semicircle distribution .

Combinatorics [ edit ] In combinatorics , two n × × n {\displaystyle n\times n} Latin squares are said to be orthogonal if their superimposition yields all possible n 2 {\displaystyle n^{2}} combinations of entries.

[ 6 ] Completely orthogonal [ edit ] Two flat planes A {\displaystyle A} and B {\displaystyle B} of a Euclidean four-dimensional space are called completely orthogonal if and only if every line in A {\displaystyle A} is orthogonal to every line in B {\displaystyle B} .

[ 7 ] In that case the planes A {\displaystyle A} and B {\displaystyle B} intersect at a single point O {\displaystyle O} , so that if a line in A {\displaystyle A} intersects with a line in B {\displaystyle B} , they intersect at O {\displaystyle O} .

A {\displaystyle A} and B {\displaystyle B} are perpendicular and Clifford parallel .

In 4 dimensional space we can construct 4 perpendicular axes and 6 perpendicular planes through a point. Without loss of generality, we may take these to be the axes and orthogonal central planes of a ( w , x , y , z ) {\displaystyle (w,x,y,z)} Cartesian coordinate system. In 4 dimensions we have the same 3 orthogonal planes ( x y , x z , y z ) {\displaystyle (xy,xz,yz)} that we have in 3 dimensions, and also 3 others ( w x , w y , w z ) {\displaystyle (wx,wy,wz)} . Each of the 6 orthogonal planes shares an axis with 4 of the others, and is completely orthogonal to just one of the others: the only one with which it does not share an axis. Thus there are 3 pairs of completely orthogonal planes: x y {\displaystyle xy} and w z {\displaystyle wz} intersect only at the origin; x z {\displaystyle xz} and w y {\displaystyle wy} intersect only at the origin; y z {\displaystyle yz} and w x {\displaystyle wx} intersect only at the origin.

More generally, two flat subspaces S 1 {\displaystyle S_{1}} and S 2 {\displaystyle S_{2}} of dimensions M {\displaystyle M} and N {\displaystyle N} of a Euclidean space S {\displaystyle S} of at least M + N {\displaystyle M+N} dimensions are called completely orthogonal if every line in S 1 {\displaystyle S_{1}} is orthogonal to every line in S 2 {\displaystyle S_{2}} . If dim ⁡ ⁡ ( S ) = M + N {\displaystyle \dim(S)=M+N} then S 1 {\displaystyle S_{1}} and S 2 {\displaystyle S_{2}} intersect at a single point O {\displaystyle O} . If dim ⁡ ⁡ ( S ) > M + N {\displaystyle \dim(S)>M+N} then S 1 {\displaystyle S_{1}} and S 2 {\displaystyle S_{2}} may or may not intersect. If dim ⁡ ⁡ ( S ) = M + N {\displaystyle \dim(S)=M+N} then a line in S 1 {\displaystyle S_{1}} and a line in S 2 {\displaystyle S_{2}} may or may not intersect; if they intersect then they intersect at O {\displaystyle O} .

[ 8 ] See also [ edit ] Look up orthogonal in Wiktionary, the free dictionary.

Imaginary number Orthogonal complement Orthogonal group Orthogonal matrix Orthogonal polynomials Orthogonal polyhedron Orthogonal trajectory Orthogonalization Gram–Schmidt process Orthonormal basis Orthonormality Pan-orthogonality occurs in coquaternions Up tack References [ edit ] ^ J.A. Wheeler; C. Misner; K.S. Thorne (1973).

Gravitation . W.H. Freeman & Co. p. 58.

ISBN 0-7167-0344-0 .

^ "Wolfram MathWorld" .

^ Bourbaki, "ch. II §2.4", Algebra I , p. 234 ^ Trefethen, Lloyd N. & Bau, David (1997).

Numerical linear algebra . SIAM. p. 13.

ISBN 978-0-89871-361-9 .

^ a b R. Penrose (2007).

The Road to Reality . Vintage books. pp.

417– 419.

ISBN 978-0-679-77631-4 .

^ Hedayat, A.; et al. (1999).

Orthogonal arrays: theory and applications . Springer. p. 168.

ISBN 978-0-387-98766-8 .

^ Coxeter, H.S.M.

(1973) [1948].

Regular Polytopes (3rd ed.). New York: Dover. p. 124.

^ P.H.Schoute : Mehrdimensionale Geometrie . Leipzig: G.J.Göschensche Verlagshandlung. Volume 1 (Sammlung Schubert XXXV): Die linearen Räume, 1902.

[ page needed ] v t e Linear algebra Outline Glossary Basic concepts Scalar Vector Vector space Scalar multiplication Vector projection Linear span Linear map Linear projection Linear independence Linear combination Multilinear map Basis Change of basis Row and column vectors Row and column spaces Kernel Eigenvalues and eigenvectors Transpose Linear equations Matrices Block Decomposition Invertible Minor Multiplication Rank Transformation Cramer's rule Gaussian elimination Productive matrix Gram matrix Bilinear Orthogonality Dot product Hadamard product Inner product space Outer product Kronecker product Gram–Schmidt process Multilinear algebra Determinant Cross product Triple product Seven-dimensional cross product Geometric algebra Exterior algebra Bivector Multivector Tensor Outermorphism Vector space constructions Dual Direct sum Function space Quotient Subspace Tensor product Numerical Floating-point Numerical stability Basic Linear Algebra Subprograms Sparse matrix Comparison of linear algebra libraries Category NewPP limit report
Parsed by mw‐web.codfw.main‐645954cd9f‐tcrhn
Cached time: 20250815165733
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.476 seconds
Real time usage: 0.781 seconds
Preprocessor visited node count: 1794/1000000
Revision size: 14018/2097152 bytes
Post‐expand include size: 30109/2097152 bytes
Template argument size: 1466/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 39011/5000000 bytes
Lua time usage: 0.233/10.000 seconds
Lua memory usage: 5819835/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  389.459      1 -total
 43.81%  170.638      1 Template:Reflist
 25.15%   97.957      5 Template:Cite_book
 22.22%   86.555      1 Template:Linear_algebra
 21.71%   84.545      1 Template:Navbox
 17.67%   68.809      1 Template:Short_description
 10.95%   42.651      2 Template:Pagetype
 10.66%   41.511      1 Template:Page_needed
  9.28%   36.152      1 Template:Fix
  6.33%   24.637      1 Template:Wiktionary Saved in parser cache with key enwiki:pcache:71675950:|#|:idhash:canonical and timestamp 20250815165733 and revision id 1288590394. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Orthogonality_(mathematics)&oldid=1288590394 " Categories : Abstract algebra Linear algebra Orthogonality Hidden categories: Wikipedia articles needing page number citations from March 2024 Articles with short description Short description is different from Wikidata This page was last edited on 3 May 2025, at 16:59 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Orthogonality (mathematics) 1 language Add topic

