Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 List of metrics Toggle List of metrics subsection 1.1 Additional variations of h -index 2 Criticism 3 See also 4 References 5 Further reading Toggle the table of contents Author-level metrics 3 languages العربية Español Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Metrics of the bibliometric impact of individual authors Part of a series on Citation metrics Author-level Composite index Eigenfactor Erdős number g-index h-index Kardashian index Science-wide author databases Citation Analysis Academic journal publishing reform DORA Leiden Manifesto I4OC Altmetrics Article-level Bibliographic coupling Bibliometrics Cartel Co-citation Proximity Analysis Coercive Dynamics Index Graph Scientometrics Journal-level CiteScore Impact factor SCImago v t e Author-level metrics are citation metrics that measure the bibliometric impact of individual authors, researchers, academics, and scholars. Many metrics have been developed that take into account varying numbers of factors (from only considering the total number of citations, to looking at their distribution across papers or journals using statistical or graph-theoretic principles).

These quantitative comparisons between researchers are mostly done to distribute resources (such as money and academic positions). However, there is still debate in the academic world about how effectively author-level metrics accomplish this objective.

[ 1 ] [ 2 ] [ 3 ] Author-level metrics differ from journal-level metrics , which attempt to measure the bibliometric impact of academic journals rather than individuals, and from article-level metrics , which attempt to measure the impact of individual articles. However, metrics originally developed for academic journals can be reported at researcher level, such as the author-level eigenfactor [ 4 ] and the author impact factor.

[ 5 ] List of metrics [ edit ] Name Description h -index The h -index asks "What is the largest h such that the author has at least h publications with at least h citations?" Formally, if f is the function that corresponds to the number of citations for each publication, the h -index is computed as follows. First, we order the values of f from the largest to the lowest value. Then, we look for the last position in which f is greater than or equal to the position (we call h this position). For example, if we have a researcher with 5 publications A, B, C, D, and E with 10, 8, 5, 4, and 3 citations, respectively, the h -index is equal to 4 because the 4th publication has 4 citations and the 5th has only 3. In contrast, if the same publications have 25, 8, 5, 3, and 3 citations, then the index is 3 because the fourth paper has only 3 citations.

[ 1 ] Individual h -index An individual h -index normalized by the number of authors has been proposed: h I = h 2 / N a ( T ) {\displaystyle h_{I}=h^{2}/N_{a}^{(T)}} , with N a ( T ) {\displaystyle N_{a}^{(T)}} being the number of authors considered in the h {\displaystyle h} papers.

[ 6 ] It was found that the distribution of the h -index, although it depends on the field, can be normalized by a simple rescaling factor. For example, assuming as standard the h s for biology, the distribution of h for mathematics collapses with it if this h is multiplied by three, that is, a mathematician with h = 3 is equivalent to a biologist with h = 9. This method has not been readily adopted, perhaps because of its complexity.

Fractional h -index To avoid incentivizing hyperauthorship, one may divide citation counts by the number of authors before ordering the papers and obtaining the fractional h-index , as originally suggested by Hirsch. This index, also called h-frac, is not highly correlated with h -index, and in 2021 was shown to correlate with scientific awards.

[ 7 ] h 2 Three additional metrics have been proposed: h 2 lower, h 2 center, and h 2 upper, to give a more accurate representation of the distribution shape. The three h 2 metrics measure the relative area within a scientist's citation distribution in the low impact area, h 2 lower, the area captured by the h -index, h 2 center, and the area from publications with the highest visibility, h 2 upper. Scientists with high h 2 upper percentages are perfectionists, whereas scientists with high h 2 lower percentages are mass producers. As these metrics are percentages, they are intended to give a qualitative description to supplement the quantitative h -index.

[ 8 ] Field-weighted Citation Impact Field-weighted Citation Impact (FWCI) is an author-level metric introduced and applied by Scopus SciVal.

[ 9 ] FWCI equals to the total citations actually received divided by the total citations that would be expected based on the average of the considered field. FWCI of 1 means that the output performs just as expected for the global average. More than 1 means that the author outperforms the average, and less than 1 means that the author underperforms. For instance, 1.55 {\displaystyle 1.55} means 55 {\displaystyle 55} % more likely to be cited.

[ 10 ] [ 11 ] Normalized h -index The h -index has been shown to have a strong discipline bias. However, a simple normalization h / ⟨ ⟨ h ⟩ ⟩ d {\displaystyle h/\langle h\rangle _{d}} by the average h of scholars in a discipline d is an effective way to mitigate this bias, obtaining a universal impact metric that allows comparison of scholars across different disciplines.

[ 12 ] Author-level Eigenfactor Author-level Eigenfactor is a version of Eigenfactor for single authors.

[ 13 ] Eigenfactor regards authors as nodes in a network of citations. The score of an author according to this metric is his or her eigenvector centrality in the network.

Erdős number It has been argued that "For an individual researcher, a measure such as Erdős number captures the structural properties of the network whereas the h -index captures the citation impact of the publications. One can be easily convinced that ranking in coauthorship networks should take into account both measures to generate a realistic and acceptable ranking." Several author ranking systems have been proposed already, for instance the Phys Author Rank Algorithm.

[ 14 ] i-10-index The i-10 index indicates the number of academic publications an author has written that have been cited by at least 10 sources. It was introduced in July 2011 by Google as part of their work on Google Scholar .

[ 15 ] RG Score ResearchGate Score or RG Score is an author-level metric introduced by ResearchGate in 2012.

[ 16 ] According to ResearchGate's CEO Dr.

Ijad Madisch , “[t]he RG Score allows real-time feedback from the people who matter: the scientists themselves.” [ 17 ] RG Score has been reported to be correlated with existing author-level metrics and has an undisclosed calculation methodology.

[ 18 ] [ 19 ] [ 20 ] [ 21 ] Two studies reported that RG Score seems to incorporate the journal impact factors into the calculation.

[ 20 ] [ 21 ] The RG Score was found to be negatively correlated with network centrality – users that are the most active on ResearchGate usually do not have high RG scores.

[ 22 ] It was also found to be strongly positively correlated with Quacquarelli Symonds university rankings at the institutional level, but only weakly with Elsevier SciVal rankings of individual authors.

[ 23 ] While it was found to be correlated with different university rankings, the correlation in between these rankings themselves was higher.

[ 18 ] m -index The m -index is defined as h / n , where h is the h -index and n is the number of years since the first published paper of the scientist; [ 1 ] also called m -quotient.

[ 24 ] [ 25 ] g -index For g -index is introduced in 2006 as largest number of top g {\displaystyle g} articles, which have received together at least g 2 {\displaystyle g^{2}} citations.

[ 26 ] e -index The e -index, the square root of surplus citations for the h -set beyond h 2 , complements the h -index for ignored citations, and therefore is especially useful for highly cited scientists and for comparing those with the same h -index (iso- h -index group).

[ 27 ] [ 28 ] c -index The c -index accounts not only for the citations but for the quality of the citations in terms of the collaboration distance between citing and cited authors. A scientist has c -index n if n of [his/her] N citations are from authors which are at collaboration distance at least n , and the other ( N − n ) citations are from authors which are at collaboration distance at most n .

[ 29 ] o -index The o -index corresponds to the geometric mean of the h -index and the most cited paper of a researcher.

[ 30 ] Hr -index Rivesed H -index Q = H / N {\displaystyle Q=H/{\sqrt {N}}} , or Q = H / N {\displaystyle Q=H/N} where H is H -index and N is the total number of publications of a researcher.

[ 31 ] A more sophisticated version is Q = H / N 0.68 {\displaystyle Q=H/N^{0.68}} which is fitted from the average Q of a list of the top 2% scholars in all fields of science based on comprehensive metrics at Jeroen Baas, Kevin Boyack, John P.A. Ioannidis (19 October 2021).

"August 2021 data-update for "Updated science-wide author databases of standardized citation indicators" " . Elsevier BV.

doi : 10.17632/btchxktzyw.3 . Retrieved 15 March 2025 .

{{ cite web }} :  CS1 maint: multiple names: authors list ( link ) [ 32 ] The Hr -index or q -index is an intensive index that measures the average quality of the papers in citation published by a researcher.

RA-index The RA-index accommodates improving the sensitivity of the h -index on the number of highly cited papers and has many cited paper and uncited paper under the h -core. This improvement can enhance the measurement sensitivity of the h -index.

[ 33 ] L -index L -index combines the number of citations, the number of coauthors, the age of publications into a single value, which is independent of the number of publications and conveniently ranges from 0.0 to 9.9.

[ 34 ] With c as number of citations, a as number of authors and y as number of years, L -index is defined by the formula: L = ln ⁡ ⁡ ( ∑ ∑ i c i a i y i ) + 1 {\displaystyle L=\ln \left({\sum _{i}{\frac {c_{i}}{a_{i}y_{i}}}}\right)+1} L -index is automatically calculated by the Exaly database.

[ 35 ] s -index An s -index, accounting for the non-entropic distribution of citations, has been proposed and it has been shown to be in a very good correlation with h .

[ 36 ] w -index w -index is defined as follow: if w of a researcher's papers have at least 10 w {\displaystyle 10w} citations each and the other papers have fewer than 10 ( w + 1 ) {\displaystyle 10(w+1)} citations, that researcher's w -index is w .

[ 37 ] Author Impact Factor Author Impact Factor (AIF) is the Impact Factor applied to authors.

[ 5 ] The AIF of an author X {\displaystyle X} in year y {\displaystyle y} is the mean number of citations given by papers published in year y {\displaystyle y} to papers published by X {\displaystyle X} in a period of Δ Δ y {\displaystyle \Delta y} years before year y {\displaystyle y} . Unlike the h-index, AIF is able to capture trends and variations of the impact of the scientific output of scientists over time,  which is a growing measure taking into account the whole career path.

Disruptive and Consolidating Metrics A set of metrics based on citation network analysis, distinguishing disruptive and consolidating impact: SDC (Scientists' Disruptive Citation) sums citations reflecting divergence from prior work; SCC (Scientists' Consolidating Citation) sums citations building on existing research; D h-index is the maximum number of papers with at least that number of disruptive citations; C h-index is the maximum number of papers with at least that number of consolidating citations.

[ 38 ] [ 39 ] [ 40 ] Additional variations of h -index [ edit ] There are a number of models proposed to incorporate the relative contribution of each author to a paper, for instance by accounting for the rank in the sequence of authors.

[ 41 ] A generalization of the h -index and some other indices that gives additional information about the shape of the author's citation function (heavy-tailed, flat/peaked, etc.) has been proposed.

[ 42 ] Because the h -index was never meant to measure future publication success, recently, a group of researchers has investigated the features that are most predictive of future h -index. It is possible to try the predictions using an online tool.

[ 43 ] However, later work has shown that since h -index is a cumulative measure, it contains intrinsic auto-correlation that led to significant overestimation of its predictability. Thus, the true predictability of future h -index is much lower than what has been claimed before.

[ 44 ] The h -index can be timed to analyze its evolution during one's career, employing different time windows.

[ 45 ] Criticism [ edit ] Some academics, such as physicist Jorge E. Hirsch , have praised author-level metrics as a "useful yardstick with which to compare, in an unbiased way, different individuals competing for the same resource when an important evaluation criterion is scientific achievement." [ 1 ] However, other members of the scientific community, and even Hirsch himself, [ 46 ] have criticized them as particularly susceptible to gaming the system .

[ 2 ] [ 3 ] [ 47 ] Work in bibliometrics has demonstrated multiple techniques for the manipulation of popular author-level metrics. The most used metric h -index can be manipulated through self-citations, [ 48 ] [ 49 ] [ 50 ] and even computer-generated nonsense documents can be used for that purpose, for example using SCIgen .

[ 51 ] Metrics can also be manipulated by coercive citation , a practice in which an editor of a journal forces authors to add spurious citations to their own articles before the journal will agree to publish it.

[ 52 ] [ 53 ] Additionally, if the h -index is considered as a decision criterion for research funding agencies, the game-theoretic solution to this competition implies increasing the average length of coauthors' lists .

[ 54 ] A study analyzing >120 million papers in the specific field of biology showed that the validity of citation-based measures is being compromised and their usefulness is lessening.

[ 55 ] As predicted by Goodhart's law , quantity of publications is not a good metric anymore as a result of shorter papers and longer author lists.

Leo Szilard , the inventor of the nuclear chain reaction , also expressed criticism of the decision-making system for scientific funding in his book "The Voice of the Dolphins and Other Stories".

[ 56 ] Senator J. Lister Hill read excerpts of this criticism in a 1962 senate hearing on the slowing of government-funded cancer research .

[ 57 ] Szilard's work focuses on metrics slowing scientific progress, rather than on specific methods of gaming: "As a matter of fact, I think it would be quite easy. You could set up a foundation, with an annual endowment of thirty million dollars. Research workers in need of funds could apply for grants, if they could mail out a convincing case. Have ten committees, each committee, each composed of twelve scientists, appointed to pass on these applications. Take the most active scientists out of the laboratory and make them members of these committees. And the very best men in the field should be appointed as chairman at salaries of fifty thousand dollars each. Also have about twenty prizes of one hundred thousand dollars each for the best scientific papers of the year. This is just about all you would have to do. Your lawyers could easily prepare a charter for the foundation. As a matter of fact, any of the National Science Foundation bills which were introduced in the Seventy-ninth and Eightieth Congress could perfectly well serve as a model." "First of all, the best scientists would be removed from their laboratories and kept busy on committees passing on applications for funds. Secondly the scientific workers in need of funds would concentrate on problems which were considered promising and were pretty certain to lead to publishable results. For a few years there might be a great increase in scientific output; but by going after the obvious, pretty soon science would dry out. Science would become something like a parlor game. Somethings would be considered interesting, others not. There would be fashions. Those who followed the fashions would get grants. Those who wouldn’t would not, and pretty soon they would learn to follow the fashion, too." [ 56 ] See also [ edit ] Academic age Goodhart's law Scientometrics References [ edit ] ^ a b c d Hirsch, J. E. (7 November 2005).

"An index to quantify an individual's scientific research output" .

Proceedings of the National Academy of Sciences .

102 (46): 16569– 16572.

arXiv : physics/0508025 .

Bibcode : 2005PNAS..10216569H .

doi : 10.1073/pnas.0507655102 .

PMC 1283832 .

PMID 16275915 .

^ a b Peter A., Lawrence (2007).

"The mismeasurement of science" (PDF) .

Current Biology .

17 (15): R583 – R585 .

Bibcode : 2007CBio...17.R583L .

doi : 10.1016/j.cub.2007.06.014 .

PMID 17686424 .

S2CID 30518724 .

^ a b Şengör, Celâl. AM (2014).

"How scientometry is killing science" (PDF) .

GSA Today .

24 (12): 44– 45.

doi : 10.1130/GSATG226GW.1 .

^ West, Jevin D.; Jensen, Michael C.; Dandrea, Ralph J.; Gordon, Gregory J.; Bergstrom, Carl T. (2013). "Author-level Eigenfactor metrics: Evaluating the influence of authors, institutions, and countries within the social science research network community".

Journal of the American Society for Information Science and Technology .

64 (4): 787– 801.

doi : 10.1002/asi.22790 .

^ a b Pan, Raj Kumar; Fortunato, Santo (2014).

"Author Impact Factor: Tracking the dynamics of individual scientific impact" .

Scientific Reports .

4 4880.

arXiv : 1312.2650 .

Bibcode : 2014NatSR...4.4880P .

doi : 10.1038/srep04880 .

PMC 4017244 .

PMID 24814674 .

^ Batista P. D.; et al. (2006). "Is it possible to compare researchers with different scientific interests?".

Scientometrics .

68 (1): 179– 89.

arXiv : physics/0509048 .

doi : 10.1007/s11192-006-0090-4 .

S2CID 119068816 .

^ Koltun, V; Hafner, D (2021).

"The h-index is no longer an effective correlate of scientific reputation" .

PLOS ONE .

16 (6): e0253397.

arXiv : 2102.03234 .

Bibcode : 2021PLoSO..1653397K .

doi : 10.1371/journal.pone.0253397 .

PMC 8238192 .

PMID 34181681 .

^ Bornmann, Lutz; Mutz, Rüdiger; Daniel, Hans-Dieter (2010). "The h index research output measurement: Two approaches to enhance its accuracy".

Journal of Informetrics .

4 (3): 407– 14.

doi : 10.1016/j.joi.2010.03.005 .

^ Cooke, Bec.

"Guides: Research Metrics: Field-Weighted Citation Impact" .

libguides.usc.edu.au .

^ "Snowball Metrics Recipe Book" (PDF) . 2012.

^ Tauro, Kiera.

"Subject Guides: 6. Measure Impact: Field-Weighted Citation Impact" .

canterbury.libguides.com .

^ Kaur, Jasleen; Radicchi, Filippo; Menczer, Filippo (2013). "Universality of scholarly impact metrics".

Journal of Informetrics .

7 (4): 924– 32.

arXiv : 1305.6339 .

doi : 10.1016/j.joi.2013.09.002 .

S2CID 7415777 .

^ West, Jevin D.; Jensen, Michael C.; Dandrea, Ralph J.; Gordon, Gregory J.; Bergstrom, Carl T. (April 2013). "Author-level Eigenfactor metrics: Evaluating the influence of authors, institutions, and countries within the social science research network community".

Journal of the American Society for Information Science and Technology .

64 (4): 787– 801.

doi : 10.1002/asi.22790 .

^ Kashyap Dixit; S Kameshwaran; Sameep Mehta; Vinayaka Pandit; N Viswanadham (February 2009).

"Towards simultaneously exploiting structure and outcomes in interaction networks for node ranking" (PDF) .

IBM Research Report R109002 .

; see also Kameshwaran, Sampath; Pandit, Vinayaka; Mehta, Sameep; Viswanadham, Nukala; Dixit, Kashyap (2010). "Outcome aware ranking in interaction networks".

Proceedings of the 19th ACM international conference on Information and knowledge management – CIKM '10 . p. 229.

doi : 10.1145/1871437.1871470 .

ISBN 9781450300995 .

^ Connor, James; Google Scholar Blog.

"Google Scholar Citations Open To All" , Google, 16 November 2011, retrieved 24 November 2011 ^ " "Professoren der nächsten Generation" | NZZ" .

Neue Zürcher Zeitung (in German) . Retrieved 25 May 2020 .

^ Knowles, Jamillah (10 August 2012).

"ResearchGate Releases RG Score - Klout for Boffins" .

The Next Web . Retrieved 26 May 2020 .

^ a b Thelwall, M.; Kousha, K. (2014).

"ResearchGate: Disseminating, communicating, and measuring Scholarship?" (PDF) .

Journal of the Association for Information Science and Technology .

66 (5): 876– 889.

CiteSeerX 10.1.1.589.5396 .

doi : 10.1002/asi.23236 .

S2CID 8974197 .

Archived (PDF) from the original on 2018-02-18 . Retrieved 2018-07-30 .

^ Yu, Min-Chun (February 2016). "ResearchGate: An effective altmetric indicator for active researchers?".

Computers in Human Behavior .

55 : 1001– 1006.

doi : 10.1016/j.chb.2015.11.007 .

^ a b Kraker, Peter; Lex, Elisabeth (2015).

"A Critical Look at the ResearchGate Score as a Measure of Scientific Reputation" .

Proceedings of the Quantifying and Analysing Scholarly Communication on the Web Workshop (ASCW'15) .

^ a b Jordan, Katy (2015).

Exploring the ResearchGate score as an academic metric: Reflections and implications for practice . Quantifying and Analysing Scholarly Communication on the Web (ASCW'15).

^ Hoffmann, C. P.; Lutz, C.; Meckel, M. (2016).

"A relational altmetric? Network centrality on ResearchGate as an indicator of scientific impact" (PDF) .

Journal of the Association for Information Science and Technology .

67 (4): 765– 775.

doi : 10.1002/asi.23423 .

S2CID 7769870 .

^ Yu, Min-Chun (February 2016). "ResearchGate: An effective altmetric indicator for active researchers?".

Computers in Human Behavior .

55 : 1001– 1006.

doi : 10.1016/j.chb.2015.11.007 .

^ Anne-Wil Harzing (2008-04-23).

"Reflections on the h -index" . Retrieved 2013-07-18 .

^ von Bohlen und Halbach O (2011). "How to judge a book by its cover? How useful are bibliometric indices for the evaluation of "scientific quality" or "scientific productivity"?".

Annals of Anatomy .

193 (3): 191– 96.

doi : 10.1016/j.aanat.2011.03.011 .

PMID 21507617 .

^ Egghe, Leo (2006). "Theory and practise of the g -index".

Scientometrics .

69 (1): 131– 152.

doi : 10.1007/s11192-006-0144-7 .

hdl : 1942/981 .

S2CID 207236267 .

^ Zhang, Chun-Ting (2009). Joly, Etienne (ed.).

"The e-Index, Complementing the h -Index for Excess Citations" .

PLOS ONE .

4 (5): e5429.

Bibcode : 2009PLoSO...4.5429Z .

doi : 10.1371/journal.pone.0005429 .

PMC 2673580 .

PMID 19415119 .

^ Dodson, M.V. (2009). "Citation analysis: Maintenance of h -index and use of e-index".

Biochemical and Biophysical Research Communications .

387 (4): 625– 26.

Bibcode : 2009BBRC..387..625D .

doi : 10.1016/j.bbrc.2009.07.091 .

PMID 19632203 .

^ Bras-Amorós, M.; Domingo-Ferrer, J.; Torra, V (2011). "A bibliometric index based on the collaboration distance between cited and citing authors".

Journal of Informetrics .

5 (2): 248– 64.

doi : 10.1016/j.joi.2010.11.001 .

hdl : 10261/138172 .

^ Dorogovtsev, S.N.

; Mendes, J.F.F. (2015). "Ranking Scientists".

Nature Physics .

11 (11): 882– 84.

arXiv : 1511.01545 .

Bibcode : 2015NatPh..11..882D .

doi : 10.1038/nphys3533 .

S2CID 12533449 .

^ Mao, M.; Chen, J (2023). "Quality Research Follows the Power Law".

Journal of Scientometric Research .

12 (3): 570– 576.

doi : 10.5530/jscires.12.3.054 .

^ John P. A. Ioannidis, Jeroen Baas, Richard Klavans, Kevin W. Boyack (2019).

"A standardized citation metrics author database annotated for scientific field" .

PLOS Biology .

17 (8): e3000384.

doi : 10.1371/journal.pbio.3000384 .

PMC 6699798 .

PMID 31404057 .

{{ cite journal }} :  CS1 maint: multiple names: authors list ( link ) ^ Fatchur Rochim, Adian (November 2018).

"Improving fairness of h -index: RA-index" .

DESIDOC Journal of Library & Information Technology .

38 (6): 378– 386.

doi : 10.14429/djlit.38.6.12937 .

^ Belikov, Aleksey V.; Belikov, Vitaly V. (22 September 2015).

"A citation-based, author- and age-normalized, logarithmic index for evaluation of individual researchers independently of publication counts" .

F1000Research .

4 : 884.

doi : 10.12688/f1000research.7070.1 .

PMC 4654436 .

PMID 40462768 .

^ Engine, exaly Search.

"exaly Search Engine" .

Free database of papers and journals . Retrieved 20 May 2022 .

^ Silagadze, Z. K. (2010). "Citation entropy and research impact estimation".

Acta Phys. Pol. B .

41 (2010): 2325– 33.

arXiv : 0905.1039 .

Bibcode : 2009arXiv0905.1039S .

^ Wu, Qiang (2009). "The w-index: A measure to assess scientific impact by focusing on widely cited papers".

Journal of the American Society for Information Science and Technology .

61 (3): 609– 614.

arXiv : 0805.4650 .

doi : 10.1002/asi.21276 .

S2CID 119293304 .

^ Yang, Alex J.; et al. (2023). "From consolidation to disruption: A novel way to measure the impact of scientists and identify laureates".

Information Processing & Management .

60 (5) 103420.

doi : 10.1016/j.ipm.2023.103420 .

^ Yang, Alex J.; Deng, Siyu (2024).

"Dynamic patterns of the disruptive and consolidating knowledge flows in Nobel-winning scientific breakthroughs" .

Quantitative Science Studies .

5 (4): 1070– 1086.

doi : 10.1162/qss_a_00323 .

^ Yang, Alex J.; et al. (2025). "Are disruptive papers more likely to impact technology and society?".

Journal of the Association for Information Science and Technology .

76 (3): 563– 579.

doi : 10.1002/asi.24947 .

^ Tscharntke, T.; Hochberg, M. E.; Rand, T. A.; Resh, V. H.; Krauss, J. (2007).

"Author Sequence and Credit for Contributions in Multiauthored Publications" .

PLOS Biology .

5 (1): e18.

doi : 10.1371/journal.pbio.0050018 .

PMC 1769438 .

PMID 17227141 .

^ Gągolewski, M.; Grzegorzewski, P. (2009). "A geometric approach to the construction of scientific impact indices".

Scientometrics .

81 (3): 617– 34.

doi : 10.1007/s11192-008-2253-y .

S2CID 466433 .

^ Acuna, Daniel E.; Allesina, Stefano; Kording, Konrad P.

(2012).

"Future impact: Predicting scientific success" .

Nature .

489 (7415): 201– 02.

Bibcode : 2012Natur.489..201A .

doi : 10.1038/489201a .

PMC 3770471 .

PMID 22972278 .

^ Penner, Orion; Pan, Raj K.; Petersen, Alexander M.; Kaski, Kimmo; Fortunato, Santo (2013).

"On the Predictability of Future Impact in Science" .

Scientific Reports .

3 (3052): 3052.

arXiv : 1306.0114 .

Bibcode : 2013NatSR...3.3052P .

doi : 10.1038/srep03052 .

PMC 3810665 .

PMID 24165898 .

^ Schreiber, Michael (2015). "Restricting the h -index to a publication and citation time window: A case study of a timed Hirsch index".

Journal of Informetrics .

9 : 150– 55.

arXiv : 1412.5050 .

doi : 10.1016/j.joi.2014.12.005 .

S2CID 12320545 .

^ Hirsch, Jorge E. (2020). "Superconductivity, What the H? The Emperor Has No Clothes".

Physics and Society .

49 : 5– 9.

arXiv : 2001.09496 .

I proposed the H-index hoping it would be an objective measure of scientific achievement. By and large, I think this is believed to be the case. But I have now come to believe that it can also fail spectacularly and have severe unintended negative consequences. I can understand how the sorcerer's apprentice must have felt. (p.5) ^ Seppelt, Ralf (2018).

"The Art of Scientific Performance" .

Trends in Ecology and Evolution .

11 (33): 805– 809.

Bibcode : 2018TEcoE..33..805S .

doi : 10.1016/j.tree.2018.08.003 .

PMID 30270172 .

S2CID 52890068 .

^ Gálvez RH (March 2017). "Assessing author self-citation as a mechanism of relevant knowledge diffusion".

Scientometrics .

111 (3): 1801– 1812.

doi : 10.1007/s11192-017-2330-1 .

S2CID 6863843 .

^ Christoph Bartneck & Servaas Kokkelmans; Kokkelmans (2011).

"Detecting h -index manipulation through self-citation analysis" .

Scientometrics .

87 (1): 85– 98.

doi : 10.1007/s11192-010-0306-5 .

PMC 3043246 .

PMID 21472020 .

^ Emilio Ferrara & Alfonso Romero; Romero (2013). "Scientific impact evaluation and the effect of self-citations: Mitigating the bias by discounting the h -index".

Journal of the American Society for Information Science and Technology .

64 (11): 2332– 39.

arXiv : 1202.3119 .

doi : 10.1002/asi.22976 .

S2CID 12693511 .

^ Labbé, Cyril (2010).

Ike Antkare one of the great stars in the scientific firmament (PDF) .

Laboratoire d'Informatique de Grenoble RR-LIG-2008 (technical report) (Report).

Joseph Fourier University .

^ Wilhite, A. W.; Fong, E. A. (2012). "Coercive Citation in Academic Publishing".

Science .

335 (6068): 542– 3.

Bibcode : 2012Sci...335..542W .

doi : 10.1126/science.1212540 .

PMID 22301307 .

S2CID 30073305 .

^ Noorden, Richard Van (February 6, 2020).

"Highly cited researcher banned from journal board for citation abuse" .

Nature .

578 (7794): 200– 201.

Bibcode : 2020Natur.578..200V .

doi : 10.1038/d41586-020-00335-7 .

PMID 32047304 .

^ Rustam Tagiew; Dmitry I. Ignatov (2017).

"Behavior mining in h-index ranking game" (PDF) .

CEUR Workshop Proceedings .

1968 : 52– 61.

^ Fire, Michael; Guestrin, Carlos (1 June 2019).

"Over-optimization of academic publishing metrics: observing Goodhart's Law in action" .

GigaScience .

8 (6).

arXiv : 1809.07841 .

doi : 10.1093/gigascience/giz053 .

PMC 6541803 .

PMID 31144712 .

^ a b The Voice of the Dolphins and Other Stories . New York: Simon and Schuster. 1961.

^ Committee, United States Congress Senate Appropriations (1961).

Labor-Health, Education, and Welfare Appropriations for 1962, Hearings Before the Subcommittee of ... , 87-1 on H.R. 7035 . p. 1498.

Further reading [ edit ] Bartling, Sönke; Friesike, Sascha (2013-12-16).

Opening Science: The Evolving Guide on How the Internet is Changing Research ...

Springer.

ISBN 978-3319000251 . Retrieved 2015-08-16 .

Sally Morris; Ed Barnas; Douglas LaFrenier; Margaret Reich (2013-02-21).

The Handbook of Journal Publishing . Cambridge University Press.

ISBN 978-1107653603 . Retrieved 2015-08-16 .

Welpe, Isabell M.; Wollersheim, Jutta; Ringelhan, Stefanie; Osterloh, Margit (7 November 2014).

Incentives and Performance: Governance of Research Organizations . Springer.

ISBN 978-3319097848 . Retrieved 2015-08-16 .

Ding, Ying; Rousseau, Ronald; Wolfram, Dietmar (6 November 2014).

Measuring Scholarly Impact: Methods and Practice . Springer.

ISBN 978-3319103761 . Retrieved 2015-08-16 .

v t e Academic publishing Journals Academic journal Public health Papers Paper Abstract Review article Position paper Literature review Grey literature Working paper White paper Technical report Annual report Pamphlet Essay Lab notes Other publication types Thesis Collection of articles Patent Biological Chemical Book Monograph Chapter Treatise Poster session Proceedings Impact and ranking Acknowledgment index Altmetrics Article-level metrics Author-level metrics Bibliometrics C-score Journal ranking Eigenfactor g-index h -index Impact factor Rankings of academic publishers Science-wide author databases of standardized citation indicators Scientometrics SCImago Journal Rank Citation cartel Reform and access Academic journal publishing reform Open access Citation advantage Serials crisis Sci-Hub #ICanHazPDF Versioning Preprint Postprint Version of record Erratum Retraction Indexes and search engines Google Scholar AMiner BASE CORE Semantic Scholar Scopus Web of Science Paperity OpenAlex Index Copernicus ERIH PLUS Sherpa Romeo OpenAIRE Related topics Imprint Scientific writing Peer review Scholarly communication Scientific literature Learned society Open research Open scientific data ORCID Electronic publishing Ingelfinger rule Least publishable unit " Publish or perish " Lists Academic databases and search engines Academic journals Copyright policies Highly Cited Researchers Open-access journals Preprint policies Scientific journals Style/formatting guides University presses Retrieved from " https://en.wikipedia.org/w/index.php?title=Author-level_metrics&oldid=1301552677 " Categories : Author-level metrics Academic publishing Citation metrics Cheating in science Hidden categories: CS1 German-language sources (de) CS1 maint: multiple names: authors list Articles with short description Short description is different from Wikidata This page was last edited on 20 July 2025, at 12:35 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Author-level metrics 3 languages Add topic

