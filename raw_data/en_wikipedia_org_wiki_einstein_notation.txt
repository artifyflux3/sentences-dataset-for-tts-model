Title: Einstein notation

URL Source: https://en.wikipedia.org/wiki/Einstein_notation

Published Time: 2003-03-12T23:18:21Z

Markdown Content:
From Wikipedia, the free encyclopedia

In [mathematics](https://en.wikipedia.org/wiki/Mathematics "Mathematics"), especially the usage of [linear algebra](https://en.wikipedia.org/wiki/Linear_algebra "Linear algebra") in [mathematical physics](https://en.wikipedia.org/wiki/Mathematical_physics "Mathematical physics") and [differential geometry](https://en.wikipedia.org/wiki/Differential_geometry "Differential geometry"), **Einstein notation** (also known as the **Einstein summation convention** or **Einstein summation notation**) is a notational convention that implies [summation](https://en.wikipedia.org/wiki/Summation "Summation") over a set of indexed terms in a formula, thus achieving brevity. As part of mathematics it is a notational subset of [Ricci calculus](https://en.wikipedia.org/wiki/Ricci_calculus "Ricci calculus"); however, it is often used in physics applications that do not distinguish between [tangent](https://en.wikipedia.org/wiki/Tangent_space "Tangent space") and [cotangent spaces](https://en.wikipedia.org/wiki/Cotangent_space "Cotangent space"). It was introduced to physics by [Albert Einstein](https://en.wikipedia.org/wiki/Albert_Einstein "Albert Einstein") in 1916.[[1]](https://en.wikipedia.org/wiki/Einstein_notation#cite_note-Ein1916-1)

### Statement of convention

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=2 "Edit section: Statement of convention")]

According to this convention, when an index variable appears twice in a single [term](https://en.wikipedia.org/wiki/Addend "Addend") and is not otherwise defined (see [Free and bound variables](https://en.wikipedia.org/wiki/Free_and_bound_variables "Free and bound variables")), it implies summation of that term over all the values of the index. So where the indices can range over the [set](https://en.wikipedia.org/wiki/Set_(mathematics) "Set (mathematics)"){1, 2, 3}, ![Image 1: {\displaystyle y=\sum _{i=1}^{3}x^{i}e_{i}=x^{1}e_{1}+x^{2}e_{2}+x^{3}e_{3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8937bb52ffa0d2a19cd4c3676fa7e45e50719613) is simplified by the convention to: ![Image 2: {\displaystyle y=x^{i}e_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e8cc1afcdff28e780d2ab87181e40c055e06ce70)

The upper indices are not [exponents](https://en.wikipedia.org/wiki/Exponentiation "Exponentiation") but are indices of coordinates, [coefficients](https://en.wikipedia.org/wiki/Coefficient "Coefficient") or [basis vectors](https://en.wikipedia.org/wiki/Basis_vector "Basis vector"). That is, in this context _x_ 2 should be understood as the second component of _x_ rather than the square of _x_ (this can occasionally lead to ambiguity). The upper index position in _x_ _i_ is because, typically, an index occurs once in an upper (superscript) and once in a lower (subscript) position in a term (see _[§Application](https://en.wikipedia.org/wiki/Einstein\_notation#Application)_ below). Typically, (_x_ 1 _x_ 2 _x_ 3) would be equivalent to the traditional (_x_ _y_ _z_).

In [general relativity](https://en.wikipedia.org/wiki/General_relativity "General relativity"), a common convention is that

*   the [Greek alphabet](https://en.wikipedia.org/wiki/Greek_alphabet "Greek alphabet") is used for space and time components, where indices take on values 0, 1, 2, or 3 (frequently used letters are _μ_, _ν_, ...),
*   the [Latin alphabet](https://en.wikipedia.org/wiki/Latin_alphabet "Latin alphabet") is used for spatial components only, where indices take on values 1, 2, or 3 (frequently used letters are _i_, _j_, ...),

In general, indices can range over any [indexing set](https://en.wikipedia.org/wiki/Indexed_family "Indexed family"), including an [infinite set](https://en.wikipedia.org/wiki/Infinite_set "Infinite set"). This should not be confused with a typographically similar convention used to distinguish between [tensor index notation](https://en.wikipedia.org/wiki/Tensor_index_notation "Tensor index notation") and the closely related but distinct basis-independent [abstract index notation](https://en.wikipedia.org/wiki/Abstract_index_notation "Abstract index notation").

An index that is summed over is a _summation index_, in this case "_i_". It is also called a [dummy index](https://en.wikipedia.org/wiki/Bound_variable "Bound variable") since any symbol can replace "_i_" without changing the meaning of the expression (provided that it does not collide with other index symbols in the same term).

An index that is not summed over is a [_free index_](https://en.wikipedia.org/wiki/Free_variable "Free variable") and should appear only once per term. If such an index does appear, it usually also appears in every other term in an equation. An example of a free index is the "_i_" in the equation ![Image 3: {\displaystyle v_{i}=a_{i}b_{j}x^{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/62f1286dd5bdef843cb47525b8fe7fd5cc02d126), which is equivalent to the equation ![Image 4: {\textstyle v_{i}=\sum _{j}(a_{i}b_{j}x^{j})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5256167dced454c324891e7b57a2c4f9aef5e673).

Einstein notation can be applied in slightly different ways. Typically, each index occurs once in an upper (superscript) and once in a lower (subscript) position in a term; however, the convention can be applied more generally to any repeated indices within a term.[[2]](https://en.wikipedia.org/wiki/Einstein_notation#cite_note-wolfram-2) When dealing with [covariant and contravariant](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors "Covariance and contravariance of vectors") vectors, where the position of an index indicates the type of vector, the first case usually applies; a covariant vector can only be contracted with a contravariant vector, corresponding to summation of the products of coefficients. On the other hand, when there is a fixed coordinate basis (or when not considering coordinate vectors), one may choose to use only subscripts; see _[§Superscripts and subscripts versus only subscripts](https://en.wikipedia.org/wiki/Einstein\_notation#Superscripts\_and\_subscripts\_versus\_only\_subscripts)_ below.

Vector representations
----------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=4 "Edit section: Vector representations")]

### Superscripts and subscripts versus only subscripts

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=5 "Edit section: Superscripts and subscripts versus only subscripts")]

In terms of [covariance and contravariance of vectors](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors "Covariance and contravariance of vectors"),

*   upper indices represent components of [contravariant vectors](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors "Covariance and contravariance of vectors") ([vectors](https://en.wikipedia.org/wiki/Coordinate_vector "Coordinate vector")),
*   lower indices represent components of [covariant](https://en.wikipedia.org/wiki/Covariant_vector "Covariant vector") vectors ([covectors](https://en.wikipedia.org/wiki/Covector "Covector")).

They transform contravariantly or covariantly, respectively, with respect to [change of basis](https://en.wikipedia.org/wiki/Change_of_basis "Change of basis").

In recognition of this fact, the following notation uses the same symbol both for a vector or covector and its _components_, as in: ![Image 5: {\displaystyle {\begin{aligned}v=v^{i}e_{i}={\begin{bmatrix}e_{1}&e_{2}&\cdots &e_{n}\end{bmatrix}}{\begin{bmatrix}v^{1}\\v^{2}\\\vdots \\v^{n}\end{bmatrix}}\\w=w_{i}e^{i}={\begin{bmatrix}w_{1}&w_{2}&\cdots &w_{n}\end{bmatrix}}{\begin{bmatrix}e^{1}\\e^{2}\\\vdots \\e^{n}\end{bmatrix}}\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/de08a1260cdfd8ec1618ee43b04549a1dc48a31a)

where ![Image 6: {\displaystyle v}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597) is the vector and ![Image 7: {\displaystyle v^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a593908199cba4c17cea2fc670fdc171f83f537d) are its components (not the ![Image 8: {\displaystyle i}](https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20)th covector ![Image 9: {\displaystyle v}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597)), ![Image 10: {\displaystyle w}](https://wikimedia.org/api/rest_v1/media/math/render/svg/88b1e0c8e1be5ebe69d18a8010676fa42d7961e6) is the covector and ![Image 11: {\displaystyle w_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fe22f0329d3ecb2e1880d44d191aba0e5475db68) are its components. The basis vector elements ![Image 12: {\displaystyle e_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ebdc3a9cb1583d3204eff8918b558c293e0d2cf3) are each column vectors, and the covector basis elements ![Image 13: {\displaystyle e^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b410dd911800d0baf0c9bc3ab949d910cb216a4d) are each row covectors. (See also [§Abstract description](https://en.wikipedia.org/wiki/Einstein_notation#Abstract_description); [duality](https://en.wikipedia.org/wiki/Dual_basis "Dual basis"), below and the [examples](https://en.wikipedia.org/wiki/Dual_basis#Examples "Dual basis"))

In the presence of a [non-degenerate form](https://en.wikipedia.org/wiki/Degenerate_bilinear_form "Degenerate bilinear form") (an [isomorphism](https://en.wikipedia.org/wiki/Isomorphism "Isomorphism")_V_ → _V_∗, for instance a [Riemannian metric](https://en.wikipedia.org/wiki/Riemannian_metric "Riemannian metric") or [Minkowski metric](https://en.wikipedia.org/wiki/Minkowski_metric "Minkowski metric")), one can [raise and lower indices](https://en.wikipedia.org/wiki/Raising_and_lowering_indices "Raising and lowering indices").

A basis gives such a form (via the [dual basis](https://en.wikipedia.org/wiki/Dual_basis "Dual basis")), hence when working on **R**_n_ with a [Euclidean metric](https://en.wikipedia.org/wiki/Euclidean_metric "Euclidean metric") and a fixed [orthonormal basis](https://en.wikipedia.org/wiki/Orthonormal_basis "Orthonormal basis"), one has the option to work with only subscripts.

However, if one changes coordinates, the way that coefficients change depends on the variance of the object, and one cannot ignore the distinction; see [Covariance and contravariance of vectors](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors "Covariance and contravariance of vectors").

In the above example, vectors are represented as _n_ × 1[matrices](https://en.wikipedia.org/wiki/Matrix_(mathematics) "Matrix (mathematics)") (column vectors), while covectors are represented as 1 × _n_ matrices (row covectors).

When using the column vector convention:

### Abstract description

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=7 "Edit section: Abstract description")]

The virtue of Einstein notation is that it represents the [invariant](https://en.wikipedia.org/wiki/Invariant_(mathematics) "Invariant (mathematics)") quantities with a simple notation.

In physics, a [scalar](https://en.wikipedia.org/wiki/Scalar_(physics) "Scalar (physics)") is invariant under transformations of basis. In particular, a [Lorentz scalar](https://en.wikipedia.org/wiki/Lorentz_scalar "Lorentz scalar") is invariant under a [Lorentz transformation](https://en.wikipedia.org/wiki/Lorentz_transformation "Lorentz transformation"). The individual terms in the sum are not. When the basis is changed, the _components_ of a vector change by a [linear transformation](https://en.wikipedia.org/wiki/Linear_transformation "Linear transformation") described by a matrix. This led Einstein to propose the convention that repeated indices imply the summation is to be done.

As for covectors, they change by the [inverse matrix](https://en.wikipedia.org/wiki/Inverse_matrix "Inverse matrix"). This is designed to guarantee that the linear function associated with the covector, the sum above, is the same no matter what the basis is.

The value of the Einstein convention is that it applies to other [vector spaces](https://en.wikipedia.org/wiki/Vector_space "Vector space") built from _V_ using the [tensor product](https://en.wikipedia.org/wiki/Tensor_product "Tensor product") and [duality](https://en.wikipedia.org/wiki/Dual_space "Dual space"). For example, _V_ ⊗ _V_, the tensor product of _V_ with itself, has a basis consisting of tensors of the form **e**_ij_ = **e**_i_ ⊗ **e**_j_. Any tensor **T** in _V_ ⊗ _V_ can be written as: ![Image 14: {\displaystyle \mathbf {T} =T^{ij}\mathbf {e} _{ij}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e2d6bd99c1bc64bf07d82ad1cdf30ca941b464fa)

_V_ *, the dual of _V_, has a basis **e**1, **e**2, ..., **e**_n_ which obeys the rule ![Image 15: {\displaystyle \mathbf {e} ^{i}(\mathbf {e} _{j})=\delta _{j}^{i}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/22c1be23cce8e9ff1932b481caebd64e44775252) where _δ_ is the [Kronecker delta](https://en.wikipedia.org/wiki/Kronecker_delta "Kronecker delta"). As ![Image 16: {\displaystyle \operatorname {Hom} (V,W)=V^{*}\otimes W}](https://wikimedia.org/api/rest_v1/media/math/render/svg/962d74b21376d96cf1a242ec2117079d26d657e9) the row/column coordinates on a matrix correspond to the upper/lower indices on the tensor product.

Common operations in this notation
----------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=8 "Edit section: Common operations in this notation")]

In Einstein notation, the usual element reference ![Image 17: {\displaystyle A_{mn}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bfe7e0664cb18690807c8213c6b473701816cd91) for the ![Image 18: {\displaystyle m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc)-th row and ![Image 19: {\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b)-th column of matrix ![Image 20: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3) becomes ![Image 21: {\displaystyle {A^{m}}_{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/23f97fdc93f406dc25ee939a4e4c72c63aff85af). We can then write the following operations in Einstein notation as follows.

The [inner product](https://en.wikipedia.org/wiki/Inner_product "Inner product") of two vectors is the sum of the products of their corresponding components, with the indices of one vector lowered (see [#Raising and lowering indices](https://en.wikipedia.org/wiki/Einstein_notation#Raising_and_lowering_indices)): ![Image 22: {\displaystyle \langle \mathbf {u} ,\mathbf {v} \rangle =\langle \mathbf {e} _{i},\mathbf {e} _{j}\rangle u^{i}v^{j}=u_{j}v^{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9f25e145d99572e1e7fb23b8b9abe2e366e7085e) In the case of an [orthonormal basis](https://en.wikipedia.org/wiki/Orthonormal_basis "Orthonormal basis"), we have ![Image 23: {\displaystyle u^{j}=u_{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/af137b1ad4e2ebdcc8e5aa4bd8d3584631571a01), and the expression simplifies to: ![Image 24: {\displaystyle \langle \mathbf {u} ,\mathbf {v} \rangle =\sum _{j}u^{j}v^{j}=u_{j}v^{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/708797fb742f0e13ca0f04fcf5ab92866c907ac5)

### Vector cross product

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=10 "Edit section: Vector cross product")]

In three dimensions, the [cross product](https://en.wikipedia.org/wiki/Cross_product "Cross product") of two vectors with respect to a [positively oriented](https://en.wikipedia.org/wiki/Orientation_(vector_space) "Orientation (vector space)") orthonormal basis, meaning that ![Image 25: {\displaystyle \mathbf {e} _{1}\times \mathbf {e} _{2}=\mathbf {e} _{3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a0594d8771ce98d117ff3307160bf7cbad00fbde), can be expressed as: ![Image 26: {\displaystyle \mathbf {u} \times \mathbf {v} =\varepsilon _{\,jk}^{i}u^{j}v^{k}\mathbf {e} _{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cb05decc104b0e89fbe58e6def8120e5d3f1e252)

Here, ![Image 27: {\displaystyle \varepsilon _{\,jk}^{i}=\varepsilon _{ijk}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ea4adc41d1236df5a01dd52e731c61a19d914400) is the [Levi-Civita symbol](https://en.wikipedia.org/wiki/Levi-Civita_symbol "Levi-Civita symbol"). Since the basis is orthonormal, raising the index ![Image 28: {\displaystyle i}](https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20) does not alter the value of ![Image 29: {\displaystyle \varepsilon _{ijk}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/21525193117bdfc0f3ac71b8ec46e3b6d0637daf), when treated as a tensor.

### Matrix-vector multiplication

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=11 "Edit section: Matrix-vector multiplication")]

The product of a matrix _A ij_ with a column vector _v j_ is: ![Image 30: {\displaystyle \mathbf {u} _{i}=(\mathbf {A} \mathbf {v} )_{i}=\sum _{j=1}^{N}A_{ij}v_{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d9e6d0c4aade9dab4ff1d2dd0fa8b5b0791de2c1) equivalent to ![Image 31: {\displaystyle u^{i}={A^{i}}_{j}v^{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2cb4b2708a1cbe2b7a304f431e64b14d2eb7c740)

This is a special case of matrix multiplication.

### Matrix multiplication

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=12 "Edit section: Matrix multiplication")]

The [matrix product](https://en.wikipedia.org/wiki/Matrix_multiplication "Matrix multiplication") of two matrices _A ij_ and _B jk_ is: ![Image 32: {\displaystyle \mathbf {C} _{ik}=(\mathbf {A} \mathbf {B} )_{ik}=\sum _{j=1}^{N}A_{ij}B_{jk}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3eef6c6a6078bfedb659bff81a3ffd410672ef36)

equivalent to ![Image 33: {\displaystyle {C^{i}}_{k}={A^{i}}_{j}{B^{j}}_{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a738c66775ec9ac262a0e17f3d3b0c18c165a93f)

For a [square matrix](https://en.wikipedia.org/wiki/Square_matrix "Square matrix")_A i j_, the [trace](https://en.wikipedia.org/wiki/Trace_(linear_algebra) "Trace (linear algebra)") is the sum of the diagonal elements, hence the sum over a common index _A i i_.

The [outer product](https://en.wikipedia.org/wiki/Outer_product "Outer product") of the column vector _u i_ by the row vector _v j_ yields an _m_ × _n_ matrix **A**: ![Image 34: {\displaystyle {A^{i}}_{j}=u^{i}v_{j}={(uv)^{i}}_{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/62e1beeb2b4e0d32ee29cbf82c58fbfef5ced19d)

Since _i_ and _j_ represent two _different_ indices, there is no summation and the indices are not eliminated by the multiplication.

### Raising and lowering indices

[[edit](https://en.wikipedia.org/w/index.php?title=Einstein_notation&action=edit&section=15 "Edit section: Raising and lowering indices")]

Given a [tensor](https://en.wikipedia.org/wiki/Tensor "Tensor"), one can [raise an index or lower an index](https://en.wikipedia.org/wiki/Raising_and_lowering_indices "Raising and lowering indices") by contracting the tensor with the [metric tensor](https://en.wikipedia.org/wiki/Metric_tensor "Metric tensor"), _g μν_. For example, taking the tensor _T α β_, one can lower an index: ![Image 35: {\displaystyle g_{\mu \sigma }{T^{\sigma }}_{\beta }=T_{\mu \beta }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d829c6442626cbb47749d8a823212d4f223c0e16)

Or one can raise an index: ![Image 36: {\displaystyle g^{\mu \sigma }{T_{\sigma }}^{\alpha }=T^{\mu \alpha }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e640e91b26c5837292c8f2b38cbcfd37c095a6c0)

*   [Tensor](https://en.wikipedia.org/wiki/Tensor "Tensor")
*   [Abstract index notation](https://en.wikipedia.org/wiki/Abstract_index_notation "Abstract index notation")
*   [Bra–ket notation](https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation "Bra–ket notation")
*   [Penrose graphical notation](https://en.wikipedia.org/wiki/Penrose_graphical_notation "Penrose graphical notation")
*   [Levi-Civita symbol](https://en.wikipedia.org/wiki/Levi-Civita_symbol "Levi-Civita symbol")
*   [DeWitt notation](https://en.wikipedia.org/wiki/DeWitt_notation "DeWitt notation")

1.    This applies only for numerical indices. The situation is the opposite for [abstract indices](https://en.wikipedia.org/wiki/Abstract_indices "Abstract indices"). Then, vectors themselves carry upper abstract indices and covectors carry lower abstract indices, as per the example in the [introduction](https://en.wikipedia.org/wiki/Einstein_notation#Introduction) of this article. Elements of a basis of vectors may carry a lower _numerical_ index and an upper _abstract_ index.

1.   **[^](https://en.wikipedia.org/wiki/Einstein_notation#cite_ref-Ein1916_1-0)**[Einstein, Albert](https://en.wikipedia.org/wiki/Albert_Einstein "Albert Einstein") (1916). ["The Foundation of the General Theory of Relativity"](https://web.archive.org/web/20060829045130/http://www.alberteinstein.info/gallery/gtext3.html). _Annalen der Physik_. **354** (7): 769. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1916AnP...354..769E](https://ui.adsabs.harvard.edu/abs/1916AnP...354..769E). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1002/andp.19163540702](https://doi.org/10.1002%2Fandp.19163540702). Archived from [the original](http://www.alberteinstein.info/gallery/gtext3.html)([PDF](https://en.wikipedia.org/wiki/PDF "PDF")) on 2006-08-29. Retrieved 2006-09-03.
2.   **[^](https://en.wikipedia.org/wiki/Einstein_notation#cite_ref-wolfram_2-0)**["Einstein Summation"](http://mathworld.wolfram.com/EinsteinSummation.html). Wolfram Mathworld. Retrieved 13 April 2011.

*   Kuptsov, L. P. (2001) [1994], ["Einstein rule"](https://www.encyclopediaofmath.org/index.php?title=Einstein_rule), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society").

[![Image 37](https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/40px-Wikibooks-logo-en-noslogan.svg.png)](https://en.wikipedia.org/wiki/File:Wikibooks-logo-en-noslogan.svg)

*   Rawlings, Steve (2007-02-01). ["Lecture 10 – Einstein Summation Convention and Vector Identities"](https://web.archive.org/web/20170106185911/http://www-astro.physics.ox.ac.uk/~sr/lectures/vectors/lecture10final.pdfc). Oxford University. Archived from [the original](http://www-astro.physics.ox.ac.uk/~sr/lectures/vectors/lecture10final.pdfc) on 2017-01-06. Retrieved 2008-07-02.
*   ["Vector Calculation in Index Notation (Einstein's Summation Convention)"](https://www.goldsilberglitzer.at/Rezepte/Rezept004E.pdf)(PDF).
*   ["Understanding NumPy's einsum"](https://stackoverflow.com/a/33641428). _Stack Overflow_.
