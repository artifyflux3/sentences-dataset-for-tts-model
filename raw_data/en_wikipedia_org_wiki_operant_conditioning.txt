Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Origins 2 History Toggle History subsection 2.1 Thorndike's law of effect 2.2 B. F. Skinner 3 Concepts and procedures Toggle Concepts and procedures subsection 3.1 Origins of operant behavior: operant variability 3.2 Modifying operant behavior: reinforcement and punishment 3.2.1 Schedules of reinforcement 3.2.2 Factors that alter the effectiveness of reinforcement and punishment 3.2.3 Shaping 3.2.4 Noncontingent reinforcement 3.3 Stimulus control of operant behavior 3.3.1 Discrimination, generalization & context 3.4 Behavioral sequences: conditioned reinforcement and chaining 3.5 Escape and avoidance 3.5.1 Discriminated avoidance learning 3.5.2 Free-operant avoidance learning 3.5.3 Two-process theory of avoidance 3.5.4 Operant or "one-factor" theory 3.6 Operant hoarding 4 Neurobiological correlates 5 Questions about the law of effect 6 Applications Toggle Applications subsection 6.1 Biological basis 6.2 Tools 6.3 Addiction and dependence 6.4 Animal training 6.5 Applied behavior analysis 6.6 Child behavior – parent management training 6.7 Economics 6.8 Gambling – variable ratio scheduling 6.9 Military psychology 6.10 Nudge theory 6.11 Praise 6.12 Video games 6.13 Defensive medicine 7 See also 8 References 9 External links Toggle the table of contents Operant conditioning 34 languages العربية 閩南語 / Bân-lâm-gí Български Català Čeština Deutsch Eesti Español Esperanto فارسی Français Gaeilge 한국어 हिन्दी Bahasa Indonesia Íslenska Italiano עברית Bahasa Melayu Nederlands 日本語 Norsk bokmål Polski Português Русский Shqip Simple English Slovenščina Српски / srpski Suomi Svenska Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Type of associative learning process for behavioral modification This article needs more reliable medical references for verification or relies too heavily on primary sources .

Please review the contents of the article and add the appropriate references if you can. Unsourced or poorly sourced material may be challenged and removed .

Find sources: "Operant conditioning" – news · newspapers · books · scholar · JSTOR ( July 2025 ) Operant conditioning , also called instrumental conditioning , is a learning process in which voluntary behaviors are modified by association with the addition (or removal) of reward or aversive stimuli. The frequency or duration of the behavior may increase through reinforcement or decrease through punishment or extinction .

Origins [ edit ] Operant conditioning originated with Edward Thorndike , whose law of effect theorised that behaviors arise as a result of consequences as satisfying or discomforting. In the 20th century, operant conditioning was studied by behavioral psychologists , who believed that much of mind and behaviour is explained through environmental conditioning. Reinforcements are environmental stimuli that increase behaviors, whereas punishments are stimuli that decrease behaviors. Both kinds of stimuli can be further categorised into positive and negative stimuli, which respectively involve the addition or removal of environmental stimuli.

Operant conditioning differs from classical conditioning in both mechanism and outcome. While classical conditioning pairs stimuli to produce involuntary, reflexive behaviors (like salivating at food), operant conditioning shapes voluntary behaviors through their consequences. Actions followed by rewards tend to be repeated, while those followed by negative outcomes diminish.

The study of animal learning in the 20th century was dominated by the analysis of these two sorts of learning, [ 1 ] and they are still at the core of behavior analysis. They have also been applied to the study of social psychology , helping to clarify certain phenomena such as the false consensus effect .

[ 2 ] Operant conditioning Extinction Reinforcement Increase behavior Punishment Decrease behavior Positive reinforcement Add appetitive stimulus following correct behavior Negative reinforcement Positive punishment Add noxious stimulus following behavior Negative punishment Remove appetitive stimulus following behavior Escape Remove noxious stimulus following correct behavior Active avoidance Behavior avoids noxious stimulus History [ edit ] Edward Lee Thorndike in 1912 Thorndike's law of effect [ edit ] Main article: Law of effect Operant conditioning, sometimes called instrumental learning , was first extensively studied by Edward L. Thorndike (1874–1949), who observed the behavior of cats trying to escape from home-made puzzle boxes.

[ 3 ] A cat could escape from the box by a simple response such as pulling a cord or pushing a pole, but when first constrained, the cats took a long time to get out. With repeated trials ineffective responses occurred less frequently and successful responses occurred more frequently, so the cats escaped more and more quickly.

[ 3 ] Thorndike generalized this finding in his law of effect , which states that behaviors followed by satisfying consequences tend to be repeated and those that produce unpleasant consequences are less likely to be repeated. In short, some consequences strengthen behavior and some consequences weaken behavior. By plotting escape time against trial number Thorndike produced the first known animal learning curves through this procedure.

[ 4 ] Humans appear to learn many simple behaviors through the sort of process studied by Thorndike, now called operant conditioning. That is, responses are retained when they lead to a successful outcome and discarded when they do not, or when they produce aversive effects. This usually happens without being planned by any "teacher", but operant conditioning has been used by parents in teaching their children for thousands of years.

[ 5 ] B. F. Skinner [ edit ] B.F. Skinner at the Harvard Psychology Department, circa 1950 Main article: B. F. Skinner B.F. Skinner (1904–1990) is referred to as the Father of operant conditioning, and his work is frequently cited in connection with this topic. His 1938 book "The Behavior of Organisms: An Experimental Analysis", [ 6 ] initiated his lifelong study of operant conditioning and its application to human and animal behavior. Following the ideas of Ernst Mach , Skinner rejected Thorndike's reference to unobservable mental states such as satisfaction, building his analysis on observable behavior and its equally observable consequences.

[ 7 ] Skinner believed that classical conditioning was too simplistic to be used to describe something as complex as human behavior. Operant conditioning, in his opinion, better described human behavior as it examined causes and effects of intentional behavior.

To implement his empirical approach, Skinner invented the operant conditioning chamber , or " Skinner Box ", in which subjects such as pigeons and rats were isolated and could be exposed to carefully controlled stimuli. Unlike Thorndike's puzzle box, this arrangement allowed the subject to make one or two simple, repeatable responses, and the rate of such responses became Skinner's primary behavioral measure.

[ 8 ] Another invention, the cumulative recorder, produced a graphical record from which these response rates could be estimated. These records were the primary data that Skinner and his colleagues used to explore the effects on response rate of various reinforcement schedules.

[ 9 ] A reinforcement schedule may be defined as "any procedure that delivers reinforcement to an organism according to some well-defined rule".

[ 10 ] The effects of schedules became, in turn, the basic findings from which Skinner developed his account of operant conditioning. He also drew on many less formal observations of human and animal behavior.

[ 11 ] Many of Skinner's writings are devoted to the application of operant conditioning to human behavior.

[ 12 ] In 1948 he published Walden Two , a fictional account of a peaceful, happy, productive community organized around his conditioning principles.

[ 13 ] In 1957, Skinner published Verbal Behavior , [ 14 ] which extended the principles of operant conditioning to language, a form of human behavior that had previously been analyzed quite differently by linguists and others. Skinner defined new functional relationships such as "mands" and "tacts" to capture some essentials of language, but he introduced no new principles, treating verbal behavior like any other behavior controlled by its consequences, which included the reactions of the speaker's audience.

Concepts and procedures [ edit ] Origins of operant behavior: operant variability [ edit ] Operant behavior is said to be "emitted"; that is, initially it is not elicited by any particular stimulus. Thus one may ask why it happens in the first place.  The answer to this question is like Darwin's answer to the question of the origin of a "new" bodily structure, namely, variation and selection. Similarly, the behavior of an individual varies from moment to moment, in such aspects as the specific motions involved, the amount of force applied, or the timing of the response. Variations that lead to reinforcement are strengthened, and if reinforcement is consistent, the behavior tends to remain stable. However, behavioral variability can itself be altered through the manipulation of certain variables.

[ 15 ] Modifying operant behavior: reinforcement and punishment [ edit ] Main articles: Reinforcement and Punishment (psychology) Reinforcement and punishment are the core tools through which operant behavior is modified. These terms are defined by their effect on behavior. "Positive" and "negative" refer to whether a stimulus was added or removed, respectively. Similarly, "reinforcement" and "punishment" refer to the future frequency of the behavior. Reinforcement describes a consequence that makes a behavior occur more often in the future, whereas punishment is a consequence that makes a behavior occur less often.

[ 16 ] There are a total of four consequences: Positive reinforcement occurs when a behavior (response) results in a desired stimulus being added and increases the frequency of that behavior in the future.

[ 17 ] Example : if a rat in a Skinner box gets food when it presses a lever, its rate of pressing will go up. Pressing the lever was positively reinforced.

Negative reinforcement (a.k.a. escape) occurs when a behavior (response) is followed by the removal of an aversive stimulus, thereby increasing the original behavior's frequency.

Example : A child is afraid of loud noises at a fireworks display. They put on a pair of headphones, and they can no longer hear the fireworks. The next time the child sees fireworks, they put on a pair of headphones. Putting on headphones was negatively reinforced.

Positive punishment (also referred to as "punishment by contingent stimulation") occurs when a behavior (response) is followed by an aversive stimulus which makes the behavior less likely to occur in the future.

Example: A child touches a hot stove and burns his hand. The next time he sees a stove, he does not touch it. Touching the stove was positively punished.

Negative punishment (penalty) (also called "punishment by contingent withdrawal") occurs when a behavior (response) is followed by the removal of a stimulus, and the behavior is less likely to occur in the future.

Example : When an employee puts their lunch in a communal refrigerator, it gets stolen before break time. The next time the employee brings a lunch to work, they do not put it in the refrigerator. Putting the lunch in the refrigerator was negatively punished.

Extinction is a consequence strategy that occurs when a previously reinforced behavior is no longer reinforced with either positive or negative reinforcement. During extinction the behavior becomes less probable. Occasional reinforcement can lead to an even longer delay before behavior extinction due to the learning factor of repeated instances becoming necessary to get reinforcement, when compared with reinforcement being given at each opportunity before extinction.

[ 18 ] A study suggests that tactile feedback, such as haptic vibrations from mobile devices, can function as secondary reinforcers (i.e., learned rewards that acquire reinforcing value through association), strengthening consumer behaviors such as online purchasing.

[ 19 ] Schedules of reinforcement [ edit ] Schedules of reinforcement are rules that control the delivery of reinforcement. The rules specify either the time that reinforcement is to be made available, or the number of responses to be made, or both. Many rules are possible, but the following are the most basic and commonly used [ 20 ] [ 9 ] Fixed interval schedule: Reinforcement occurs following the first response after a fixed time has elapsed after the previous reinforcement. This schedule yields a "break-run" pattern of response; that is, after training on this schedule, the organism typically pauses after reinforcement, and then begins to respond rapidly as the time for the next reinforcement approaches.

Variable interval schedule: Reinforcement occurs following the first response after a variable time has elapsed from the previous reinforcement. This schedule typically yields a relatively steady rate of response that varies with the average time between reinforcements.

Fixed ratio schedule: Reinforcement occurs after a fixed number of responses have been emitted since the previous reinforcement. An organism trained on this schedule typically pauses for a while after a reinforcement and then responds at a high rate. If the response requirement is low there may be no pause; if the response requirement is high the organism may quit responding altogether.

Variable ratio schedule: Reinforcement occurs after a variable number of responses have been emitted since the previous reinforcement. This schedule typically yields a very high, persistent rate of response.

Continuous reinforcement: Reinforcement occurs after each response. Organisms typically respond as rapidly as they can, given the time taken to obtain and consume reinforcement, until they are satiated.

Factors that alter the effectiveness of reinforcement and punishment [ edit ] The effectiveness of reinforcement and punishment can be changed.

Satiation/Deprivation : The effectiveness of a positive or "appetitive" stimulus will be reduced if the individual has received enough of that stimulus to satisfy his/her appetite. The opposite effect will occur if the individual becomes deprived of that stimulus: the effectiveness of a consequence will then increase. A subject with a full stomach wouldn't feel as motivated as a hungry one.

[ 21 ] Immediacy : An immediate consequence is more effective than a delayed one. If one gives a dog a treat for sitting within five seconds, the dog will learn faster than if the treat is given after thirty seconds.

[ 22 ] Contingency : To be most effective, reinforcement should occur consistently after responses and not at other times. Learning may be slower if reinforcement is intermittent, that is, following only some instances of the same response. Responses reinforced intermittently are usually slower to extinguish than are responses that have always been reinforced.

[ 21 ] Size : The size, or amount, of a stimulus often affects its potency as a reinforcer. Humans and animals engage in cost-benefit analysis. If a lever press brings ten food pellets, lever pressing may be learned more rapidly than if a press brings only one pellet.   A pile of quarters from a slot machine may keep a gambler pulling the lever longer than a single quarter.

Most of these factors serve biological functions.  For example, the process of satiation helps the organism maintain a stable internal environment ( homeostasis ). When an organism has been deprived of sugar, for example, the taste of sugar is an effective reinforcer. When the organism's blood sugar reaches or exceeds an optimum level the taste of sugar becomes less effective or even aversive.

Shaping [ edit ] Main article: Shaping (psychology) Shaping is a conditioning method often used in animal training and in teaching nonverbal humans. It depends on operant variability and reinforcement, as described above. The trainer starts by identifying the desired final (or "target") behavior. Next, the trainer chooses a behavior that the animal or person already emits with some probability. The form of this behavior is then gradually changed across successive trials by reinforcing behaviors that approximate the target behavior more and more closely. When the target behavior is finally emitted, it may be strengthened and maintained by the use of a schedule of reinforcement.

Noncontingent reinforcement [ edit ] Noncontingent reinforcement is the delivery of reinforcing stimuli regardless of the organism's behavior. Noncontingent reinforcement may be used in an attempt to reduce an undesired target behavior by reinforcing multiple alternative responses while extinguishing the target response.

[ 23 ] As no measured behavior is identified as being strengthened, there is controversy surrounding the use of the term noncontingent "reinforcement".

[ 24 ] Stimulus control of operant behavior [ edit ] Main article: Stimulus control Though initially operant behavior is emitted without an identified reference to a particular stimulus, during operant conditioning operants come under the control of stimuli that are present when behavior is reinforced. Such stimuli are called "discriminative stimuli." A so-called " three-term contingency " is the result. That is, discriminative stimuli set the occasion for responses that produce reward or punishment. Example: a rat may be trained to press a lever only when a light comes on; a dog rushes to the kitchen when it hears the rattle of his/her food bag; a child reaches for candy when s/he sees it on a table.

Discrimination, generalization & context [ edit ] Most behavior is under stimulus control. Several aspects of this may be distinguished: Discrimination typically occurs when a response is reinforced only in the presence of a specific stimulus. For example, a pigeon might be fed for pecking at a red light and not at a green light; in consequence, it pecks at red and stops pecking at green.  Many complex combinations of stimuli and other conditions have been studied; for example an organism might be reinforced on an interval schedule in the presence of one stimulus and on a ratio schedule in the presence of another.

Generalization is the tendency to respond to stimuli that are similar to a previously trained discriminative stimulus. For example, having been trained to peck at "red" a pigeon might also peck at "pink", though usually less strongly.

Context refers to stimuli that are continuously present in a situation, like the walls, tables, chairs, etc. in a room, or the interior of an operant conditioning chamber. Context stimuli may come to control behavior as do discriminative stimuli, though usually more weakly.  Behaviors learned in one context may be absent, or altered, in another.  This may cause difficulties for behavioral therapy, because behaviors learned in the therapeutic setting may fail to occur in other situations.

Behavioral sequences: conditioned reinforcement and chaining [ edit ] Most behavior cannot easily be described in terms of individual responses reinforced one by one. The scope of operant analysis is expanded through the idea of behavioral chains, which are sequences of responses bound together by the three-term contingencies defined above.  Chaining is based on the fact, experimentally demonstrated, that a discriminative stimulus not only sets the occasion for subsequent behavior, but it can also reinforce a behavior that precedes it. That is, a discriminative stimulus is also a "conditioned reinforcer". For example, the light that sets the occasion for lever pressing may be used to reinforce "turning around" in the presence of a noise. This results in the sequence "noise – turn-around – light – press lever – food". Much longer chains can be built by adding more stimuli and responses.

Escape and avoidance [ edit ] In escape learning, a behavior terminates an (aversive) stimulus. For example, shielding one's eyes from sunlight terminates the (aversive) stimulation of bright light in one's eyes.  (This is an example of negative reinforcement, defined above.) Behavior that is maintained by preventing a stimulus is called "avoidance,"  as, for example, putting on sun glasses before going outdoors.  Avoidance behavior raises the so-called "avoidance paradox", for, it may be asked, how can the non-occurrence of a stimulus serve as a reinforcer? This question is addressed by several theories of avoidance (see below).

Two kinds of experimental settings are commonly used: discriminated and free-operant avoidance learning.

Discriminated avoidance learning [ edit ] A discriminated avoidance experiment involves a series of trials in which a neutral stimulus such as a light is followed by an aversive stimulus such as a shock. After the neutral stimulus appears an operant response such as a lever press prevents or terminate the aversive stimulus. In early trials, the subject does not make the response until the aversive stimulus has come on, so these early trials are called "escape" trials. As learning progresses, the subject begins to respond during the neutral stimulus and thus prevents the aversive stimulus from occurring. Such trials are called "avoidance trials." This experiment is said to involve classical conditioning because a neutral CS (conditioned stimulus) is paired with the aversive US (unconditioned stimulus); this idea underlies the two-factor theory of avoidance learning described below.

Free-operant avoidance learning [ edit ] In free-operant avoidance a subject periodically receives an aversive stimulus (often an electric shock) unless an operant response is made; the response delays the onset of the shock. In this situation, unlike discriminated avoidance, no prior stimulus signals the shock. Two crucial time intervals determine the rate of avoidance learning. This first is the S-S (shock-shock) interval. This is time between successive shocks in the absence of a response. The second interval is the R-S (response-shock) interval. This specifies the time by which an operant response delays the onset of the next shock. Each time the subject performs the operant response, the R-S interval without shock begins anew.

Two-process theory of avoidance [ edit ] This theory was originally proposed in order to explain discriminated avoidance learning, in which an organism learns to avoid an aversive stimulus by escaping from a signal for that stimulus. Two processes are involved: classical conditioning of the signal followed by operant conditioning of the escape response: a) Classical conditioning of fear.

Initially the organism experiences the pairing of a CS with an aversive US. The theory assumes that this pairing creates an association between the CS and the US through classical conditioning and, because of the aversive nature of the US, the CS comes to elicit a conditioned emotional reaction (CER) – "fear." b) Reinforcement of the operant response by fear-reduction.

As a result of the first process, the CS now signals fear; this unpleasant emotional reaction serves to motivate operant responses, and responses that terminate the CS are reinforced by fear termination. The theory does not say that the organism "avoids" the US in the sense of anticipating it, but rather that the organism "escapes" an aversive internal state that is caused by the CS.
Several experimental findings seem to run counter to two-factor theory. For example, avoidance behavior often extinguishes very slowly even when the initial CS-US pairing never occurs again, so the fear response might be expected to extinguish (see Classical conditioning ). Further, animals that have learned to avoid often show little evidence of fear, suggesting that escape from fear is not necessary to maintain avoidance behavior.

[ 25 ] Operant or "one-factor" theory [ edit ] Some theorists suggest that avoidance behavior may simply be a special case of operant behavior maintained by its consequences. In this view the idea of "consequences" is expanded to include sensitivity to a pattern of events. Thus, in avoidance, the consequence of a response is a reduction in the rate of aversive stimulation. Indeed, experimental evidence suggests that a "missed shock" is detected as a stimulus, and can act as a reinforcer. Cognitive theories of avoidance take this idea a step farther. For example, a rat comes to "expect" shock if it fails to press a lever and to "expect no shock" if it presses it, and avoidance behavior is strengthened if these expectancies are confirmed.

[ 25 ] Operant hoarding [ edit ] Operant hoarding refers to the observation that rats reinforced in a certain way may allow food pellets to accumulate in a food tray instead of retrieving those pellets. In this procedure, retrieval of the pellets always instituted a one-minute period of extinction during which no additional food pellets were available but those that had been accumulated earlier could be consumed. This finding appears to contradict the usual finding that rats behave impulsively in situations in which there is a choice between a smaller food object right away and a larger food object after some delay. See schedules of reinforcement .

[ 26 ] Neurobiological correlates [ edit ] Further information: Reward system The first scientific studies identifying neurons that responded in ways that suggested they encode for conditioned stimuli came from work by Mahlon deLong [ 27 ] [ 28 ] and by R.T. Richardson.

[ 28 ] They showed that nucleus basalis neurons, which release acetylcholine broadly throughout the cerebral cortex , are activated shortly after a conditioned stimulus, or after a primary reward if no conditioned stimulus exists. These neurons are equally active for positive and negative reinforcers, and have been shown to be related to neuroplasticity in many cortical regions.

[ 29 ] Evidence also exists that dopamine is activated at similar times.

[ 30 ] There is considerable evidence that dopamine participates in both reinforcement and aversive learning.

[ 31 ] Dopamine pathways project much more densely onto frontal cortex regions.

Cholinergic projections, in contrast, are dense even in the posterior cortical regions like the primary visual cortex . A study of patients with Parkinson's disease , a condition attributed to the insufficient action of dopamine, further illustrates the role of dopamine in positive reinforcement.

[ 32 ] It showed that while off their medication, patients learned more readily with aversive consequences than with positive reinforcement. Patients who were on their medication showed the opposite to be the case, positive reinforcement proving to be the more effective form of learning when dopamine activity is high.

A neurochemical process involving dopamine has been suggested to underlie reinforcement.  When an organism experiences a reinforcing stimulus, dopamine pathways in the brain are activated. This network of pathways "releases a short pulse of dopamine onto many dendrites , thus broadcasting a global reinforcement signal to postsynaptic neurons ." [ 33 ] This allows recently activated synapses to increase their sensitivity to efferent (conducting outward) signals, thus increasing the probability of occurrence for the recent responses that preceded the reinforcement. These responses are, statistically, the most likely to have been the behavior responsible for successfully achieving reinforcement. But when the application of reinforcement is either less immediate or less contingent (less consistent), the ability of dopamine to act upon the appropriate synapses is reduced.

Questions about the law of effect [ edit ] A number of observations seem to show that operant behavior can be established without reinforcement in the sense defined above. Most cited is the phenomenon of autoshaping (sometimes called "sign tracking"), in which a stimulus is repeatedly followed by reinforcement, and in consequence the animal begins to respond to the stimulus. For example, a response key is lighted and then food is presented. When this is repeated a few times a pigeon subject begins to peck the key even though food comes whether the bird pecks or not. Similarly, rats begin to handle small objects, such as a lever, when food is presented nearby.

[ 34 ] [ 35 ] Strikingly, pigeons and rats persist in this behavior even when pecking the key or pressing the lever leads to less food (omission training).

[ 36 ] [ 37 ] Another apparent operant behavior that appears without reinforcement is contrafreeloading .

These observations and others appear to contradict the law of effect , and they have prompted some researchers to propose new conceptualizations of operant reinforcement  (e.g.

[ 38 ] [ 39 ] [ 40 ] )  A more general view is that autoshaping is an instance of classical conditioning ; the autoshaping procedure has, in fact, become one of the most common ways to measure classical conditioning.  In this view, many behaviors can be influenced by both classical contingencies (stimulus-response) and operant contingencies (response-reinforcement), and the experimenter's task is to work out how these interact.

[ 41 ] Applications [ edit ] Reinforcement and punishment are ubiquitous in human social interactions, and a great many applications of operant principles have been suggested and implemented.

Biological basis [ edit ] Operant conditioning bridges the field of neurobiology and the field of psychology. It’s able to do this by demonstrating how exterior behavioral principles correspond with internal processes. While psychologist describe learning in terms of observable behaviors that can be shaped by consequences, neurobiologist share a different sentiment. neurobiologist analyze how these behaviors are underpinned by neural circuits.

Both positive and negative reinforcement has been shown to activate a reward system in the brain. this is able to take place because of the release of dopamine in specific areas such as the nucleus accumbens.

[ 42 ] Tools [ edit ] Tools such as point systems, charts of behavior and token economies are principles that are grounded in operant conditioning. These systems function as conditioned reinforcers, which means that they can be exchanged for primary reinforcers such as a tangible reward.

Addiction and dependence [ edit ] Positive and negative reinforcement play central roles in the development and maintenance of addiction and drug dependence . An addictive drug is intrinsically rewarding ; that is, it functions as a primary positive reinforcer of drug use. The brain's reward system assigns it incentive salience (i.e., it is "wanted" or "desired"), [ 43 ] [ 44 ] [ 45 ] so as an addiction develops, deprivation of the drug leads to craving.  In addition, stimuli associated with drug use – e.g., the sight of a syringe, and the location of use – become associated with the intense reinforcement induced by the drug.

[ 43 ] [ 44 ] [ 45 ] These previously neutral stimuli acquire several properties: their appearance can induce craving, and they can become conditioned positive reinforcers of continued use.

[ 43 ] [ 44 ] [ 45 ] Thus, if an addicted individual encounters one of these drug cues, a craving for the associated drug may reappear. For example, anti-drug agencies previously used posters with images of drug paraphernalia as an attempt to show the dangers of drug use. However, such posters are no longer used because of the effects of incentive salience in causing relapse upon sight of the stimuli illustrated in the posters.

In drug dependent individuals, negative reinforcement occurs when a drug is self-administered in order to alleviate or "escape" the symptoms of physical dependence (e.g., tremors and sweating) and/or psychological dependence (e.g., anhedonia , restlessness, irritability, and anxiety) that arise during the state of drug withdrawal .

[ 43 ] Animal training [ edit ] Main article: Animal training Animal trainers and pet owners were applying the principles and practices of operant conditioning long before these ideas were named and studied, and animal training still provides one of the clearest and most convincing examples of operant control. Of the concepts and procedures described in this article, a few of the most salient are the following: 
(a) availability of primary reinforcement (e.g. a bag of dog yummies); 
(b) the use of secondary reinforcement, (e.g. sounding a clicker immediately after a desired response, then giving yummy); 
(c) contingency, assuring that reinforcement (e.g. the clicker) follows the desired behavior and not something else; 
(d) shaping,  as in gradually getting a dog to jump higher and higher; 
(e) intermittent reinforcement, as in gradually reducing the frequency of reinforcement to induce persistent behavior without satiation; 
(f) chaining, where a complex behavior is gradually constructed from smaller units.

[ 46 ] Applied behavior analysis [ edit ] Main article: Applied behavior analysis Applied behavior analysis (ABA) is the discipline initiated [ vague ] by B. F. Skinner that applies the principles of conditioning to the modification of socially significant [ definition needed ] human behavior. It uses the basic concepts of conditioning theory, including conditioned stimulus (S C ), discriminative stimulus (S d ), response (R), and reinforcing stimulus (S rein or S r for reinforcers, sometimes S ave for aversive stimuli).

[ 25 ] ABA practitioners bring these procedures, and many variations and developments of them, to bear on a variety of socially significant behaviors and issues.

[ clarification needed ] In many cases, practitioners use operant techniques to develop constructive, socially acceptable behaviors to replace aberrant behaviors.  The techniques of ABA have been effectively applied to such things as early intensive behavioral interventions for autistic children, [ 47 ] [ better source needed ] research on the principles influencing criminal behavior , [ citation needed ] HIV prevention, [ 48 ] [ better source needed ] conservation of natural resources, [ 49 ] [ better source needed ] education, [ 50 ] gerontology , [ 51 ] [ better source needed ] health and exercise , [ 52 ] [ better source needed ] industrial safety , [ 53 ] [ better source needed ] language acquisition , [ 54 ] [ better source needed ] littering, [ 55 ] [ better source needed ] medical procedures , [ 56 ] [ better source needed ] parenting, [ 57 ] [ better source needed ] psychotherapy , [ citation needed ] seatbelt use, [ 58 ] [ better source needed ] severe mental disorders , [ 59 ] [ better source needed ] sports, [ 60 ] [ better source needed ] substance abuse , [ citation needed ] phobias , [ citation needed ] pediatric feeding disorders, [ citation needed ] and zoo management and care of animals .

[ 61 ] [ better source needed ] Some of these applications are among those described below.

Child behavior – parent management training [ edit ] Main article: Parent management training Providing positive reinforcement for appropriate child behaviors is a major focus of parent management training. Typically, parents learn to reward appropriate behavior through social rewards (such as praise, smiles, and hugs) as well as concrete rewards (such as stickers or points towards a larger reward as part of an incentive system created collaboratively with the child).

[ 62 ] In addition, parents learn to select simple behaviors as an initial focus and reward each of the small steps that their child achieves towards reaching a larger goal (this concept is called "successive approximations").

[ 62 ] [ 63 ] Economics [ edit ] Main article: Behavioral economics Further information: Consumer demand tests (animals) Both psychologists and economists have become interested in applying operant concepts and findings to the behavior of humans in the marketplace. An example 
is the analysis of consumer demand, as indexed by the amount of a commodity that is purchased. In economics, the degree to which price influences consumption is called "the price elasticity of demand." Certain commodities are more elastic than others; for example, a change in price of certain foods may have a large effect on the amount bought, while gasoline and other everyday consumables may be less affected by price changes. In terms of operant analysis, such effects may be interpreted in terms of motivations of consumers and the relative value of the commodities as reinforcers.

[ 64 ] Gambling – variable ratio scheduling [ edit ] Main article: Gambling As stated earlier in this article, a variable ratio schedule yields reinforcement after the emission of an unpredictable number of responses.  This schedule typically generates rapid, persistent responding. Slot machines pay off on a variable ratio schedule, and they produce just this sort of persistent lever-pulling behavior in gamblers. The variable ratio payoff from slot machines and other forms of gambling has often been cited as a factor underlying gambling addiction.

[ 65 ] Military psychology [ edit ] Main article: Military psychology Human beings have an innate resistance to killing and are reluctant to act in a direct, aggressive way towards members of their own species, even to save life.  This resistance to killing has caused infantry to be remarkably inefficient throughout the history of military warfare.

[ 66 ] This phenomenon was not understood until S.L.A. Marshall (Brigadier General and military historian) undertook interview studies of WWII infantry immediately following combat engagement. Marshall's well-known and controversial book, Men Against Fire; The Problem of Battle Command in Future Wars , revealed that only 15% of soldiers fired their rifles with the purpose of killing in combat.

[ 67 ] Following acceptance of Marshall's research by the US Army in 1946, the Human Resources Research Office of the US Army began implementing new training protocols which resemble operant conditioning methods.  Subsequent applications of such methods increased the percentage of soldiers able to kill to around 50% in Korea and over 90% in Vietnam.

[ 66 ] Revolutions in training included replacing traditional pop-up firing ranges with three-dimensional, man-shaped, pop-up targets which collapsed when hit.  This provided immediate feedback and acted as positive reinforcement for a soldier's behavior.

[ 68 ] Other improvements to military training methods have included the timed firing course; more realistic training; high repetitions; praise from superiors; marksmanship rewards; and group recognition. Negative reinforcement includes peer accountability or the requirement to retake courses.

Modern military training conditions mid-brain response to combat pressure by closely simulating actual combat, using mainly Pavlovian classical conditioning and Skinnerian operant conditioning (both forms of behaviorism ).

[ 66 ] Modern marksmanship training is such an excellent example of behaviorism that it has been used for years in the introductory psychology course taught to all cadets at the US Military Academy at West Point as a classic example of operant conditioning. In the 1980s, during a visit to West Point, B.F. Skinner identified modern military marksmanship training as a near-perfect application of operant conditioning.

[ 68 ] Lt. Col. Dave Grossman states about operant conditioning and US Military training that: It is entirely possible that no one intentionally sat down to use operant conditioning or behavior modification techniques to train soldiers in this area…But from the standpoint of a psychologist who is also a historian and a career soldier, it has become increasingly obvious to me that this is exactly what has been achieved.

[ 66 ] Nudge theory [ edit ] Main article: Nudge theory Nudge theory (or nudge) is a concept in behavioural science , political theory and economics which argues that indirect suggestions to try to achieve non-forced compliance can influence the motives, incentives and decision making of groups and individuals, at least as effectively – if not more effectively – than direct instruction, legislation, or enforcement.

[ citation needed ] Praise [ edit ] Main article: Praise The concept of praise as a means of behavioral reinforcement is rooted in B.F. Skinner's model of operant conditioning. Through this lens, praise has been viewed as a means of positive reinforcement, wherein an observed behavior is made more likely to occur by contingently praising said behavior.

[ 69 ] Hundreds of studies have demonstrated the effectiveness of praise in promoting positive behaviors, notably in the study of teacher and parent use of praise on child in promoting improved behavior and academic performance, [ 70 ] [ 71 ] but also in the study of work performance.

[ 72 ] Praise has also been demonstrated to reinforce positive behaviors in non-praised adjacent individuals (such as a classmate of the praise recipient) through vicarious reinforcement.

[ 73 ] Praise may be more or less effective in changing behavior depending on its form, content and delivery. In order for praise to effect positive behavior change, it must be contingent on the positive behavior (i.e., only administered after the targeted behavior is enacted), must specify the particulars of the behavior that is to be reinforced, and must be delivered sincerely and credibly.

[ 74 ] Acknowledging the effect of praise as a positive reinforcement strategy, numerous behavioral and cognitive behavioral interventions have incorporated the use of praise in their protocols.

[ 75 ] [ 76 ] The strategic use of praise is recognized as an evidence-based practice in both classroom management [ 75 ] and parenting training interventions, [ 71 ] though praise is often subsumed in intervention research into a larger category of positive reinforcement, which includes strategies such as strategic attention and behavioral rewards.

Several studies have been done on the effect cognitive-behavioral therapy and operant-behavioral therapy have on different medical conditions. When patients developed cognitive and behavioral techniques that changed their behaviors, attitudes, and emotions; their pain severity decreased. The results of these studies showed an influence of cognitions on pain perception and impact presented explained the general efficacy of Cognitive-Behavioral therapy (CBT) and Operant-Behavioral therapy (OBT).

[ citation needed ] Video games [ edit ] Main article: Compulsion loop The majority [ citation needed ] of video games are designed around a compulsion loop , adding a type of positive reinforcement through a variable rate schedule to keep the player playing. This can lead to the pathology of video game addiction .

[ 77 ] Main article: Loot box As part of a trend in the monetization of video games during the 2010s, some games offered loot boxes as rewards or as items purchasable by real world funds. Boxes contains a random selection of in-game items. The practice has been tied to the same methods that slot machines and other gambling devices dole out rewards, as it follows a variable rate schedule. While the general perception that loot boxes are a form of gambling, the practice is only classified as such in a few countries. However, methods to use those items as virtual currency for online gambling or trading for real world money has created a skin gambling market that is under legal evaluation.

[ 78 ] Defensive medicine [ edit ] One of the many reasons proposed for the dramatic costs associated with healthcare is the practice of defensive medicine.  Prabhu reviews the article by Cole and discusses how the responses of two groups of neurosurgeons are classic operant behavior.  One group practice in a state with restrictions on medical lawsuits and the other group with no restrictions.  The group of neurosurgeons were queried anonymously on their practice patterns.  The physicians changed their practice in response to a negative feedback (fear from lawsuit) in the group that practiced in a state with no restrictions on medical lawsuits.

[ 79 ] See also [ edit ] Psychology portal Abusive power and control Animal testing Behavioral contrast Behaviorism (branch of psychology referring to methodological and radical behaviorism) Behavior modification (old expression for ABA; modifies behavior either through consequences without incorporating stimulus control or involves the use of flooding —also referred to as prolonged exposure therapy ) Carrot and stick Child grooming Classical conditioning Cognitivism (psychology) (theory of internal mechanisms without reference to behavior) Conditioned avoidance response test Consumer demand tests (animals) Educational psychology Educational technology Experimental analysis of behavior (experimental research principles in operant and respondent conditioning) Exposure therapy (also called desensitization) Graduated exposure therapy (also called systematic desensitization ) Habituation Jerzy Konorski Learned industriousness Matching law Negative (positive) contrast effect Radical behaviorism (conceptual theory of behavior analysis that expands behaviorism to also encompass private events (thoughts and feelings) as forms of behavior) Reinforcement Pavlovian-instrumental transfer Preference tests (animals) Premack principle Sensitization Social conditioning Society for Quantitative Analysis of Behavior Spontaneous recovery v t e Learning Non-associative learning Habituation Sensitization Associative learning Classical conditioning Imprinting Observational learning Operant conditioning Insight learning Abductive reasoning Deductive reasoning Inductive reasoning v t e Conformity Enforcement Proscription Damnatio memoriae Dissident / Dissenter Exile Émigré Homo sacer Ostracism Blacklisting Cancel culture Censorship Deplatforming Outcast Outlaw Civil death Vogelfrei Persona non grata Public enemy Enemy of the people Enemy of the state Scapegoating Shunning Governmental pressure Authoritarianism Harmonisation of law Nationalism Left-wing nationalism National conservatism Totalitarianism Tyranny of the majority Group pressure Bandwagon effect Brainwashing Closure (sociology) Collectivism Consensus reality Culture shock Dogma Echo chamber False consensus effect Fear of missing out Groupthink Hazing Herd mentality Identification (psychology) Indoctrination Invented tradition Memory conformity Mere-exposure effect Milieu control Mobbing Normalization Normative social influence Passing (sociology) Patriotism Peer pressure Pluralistic ignorance Propaganda Psychosocial issue Purity spiral Operant conditioning Rally 'round the flag effect Social construction of gender Social contagion Addiction Behavioral Crime Hysterical Suicide Emotional Social influence Social integration Socialization Spiral of silence Teasing Toxic positivity Untouchability Individual pressure Authoritarian personality Authoritarian leadership style Right-wing authoritarianism Control freak Obsessive–compulsive personality disorder Conformity Compliance Communal reinforcement Countersignaling Creeping normality Herd behavior Internalization Normalization of deviance Obedience Preference falsification Social proof Social reality Experiments Asch conformity experiments Breaching experiment Milgram experiment Stanford prison experiment Anticonformity Alternative media Anti-authoritarianism Anti-social behaviour Self-segregation Civil disobedience Cosmopolitanism Counterculture Culture jamming Deviance Devil's advocate Dissent / Defection Political Eccentricity Eclecticism Hermit Idiosyncrasy Individualism Insubordination Pueblo clown Rebellion Red team Satire Shock value Authority control databases National Germany United States France BnF data Israel Other Yale LUX References [ edit ] ^ Jenkins, H. M. "Animal Learning & Behavior Theory" Ch. 5 in Hearst, E. "The First Century of Experimental Psychology"  Hillsdale N. J.,  Earlbaum, 1979 ^ Tarantola, Tor; Kumaran, Dharshan; Dayan, Peters; De Martino, Benedetto (10 October 2017).

"Prior preferences beneficially influence social and non-social learning" .

Nature Communications .

8 (1): 817.

Bibcode : 2017NatCo...8..817T .

doi : 10.1038/s41467-017-00826-8 .

ISSN 2041-1723 .

PMC 5635122 .

PMID 29018195 .

^ a b Thorndike, E.L. (1901). "Animal intelligence: An experimental study of the associative processes in animals".

Psychological Review Monograph Supplement .

2 : 1– 109.

^ Miltenberger, R. G. "Behavioral Modification: Principles and Procedures".

Thomson/Wadsworth , 2008. p. 9.

^ Miltenberger, R. G., & Crosland, K. A. (2014). Parenting. The wiley blackwell handbook of operant and classical conditioning. (pp. 509–531) Wiley-Blackwell.

doi : 10.1002/9781118468135.ch20 ^ Skinner, B. F. (1938).

The Behavior of Organisms: An experimental Analysis . New York: Appleton-Century-Crofts.

^ Skinner, B. F. (1950). "Are theories of learning necessary?".

Psychological Review .

57 (4): 193– 216.

doi : 10.1037/h0054367 .

PMID 15440996 .

S2CID 17811847 .

^ Schacter, Daniel L., Daniel T. Gilbert, and Daniel M. Wegner. "B. F. Skinner: The role of reinforcement and Punishment", subsection in: Psychology; Second Edition. New York: Worth, Incorporated, 2011, 278–288.

^ a b Ferster, C. B. & Skinner, B. F.  "Schedules of Reinforcement", 1957 New York: Appleton-Century-Crofts ^ Staddon, J. E. R; D. T Cerutti (February 2003).

"Operant Conditioning" .

Annual Review of Psychology .

54 (1): 115– 144.

doi : 10.1146/annurev.psych.54.101601.145124 .

PMC 1473025 .

PMID 12415075 .

^ Mecca Chiesa (2004) Radical Behaviorism: The philosophy and the science ^ Skinner, B. F. "Science and Human Behavior", 1953. New York: MacMillan ^ Skinner, B.F. (1948). Walden Two. Indianapolis: Hackett ^ Skinner, B. F. "Verbal Behavior", 1957. New York: Appleton-Century-Crofts ^ Neuringer, A (2002).

"Operant variability: Evidence, functions, and theory" .

Psychonomic Bulletin & Review .

9 (4): 672– 705.

doi : 10.3758/bf03196324 .

PMID 12613672 .

^ Cooper, JO; Heron, TE; Heward, WL (2019).

Applied Behavior Analysis (3rd ed.). Pearson Education (US). p. 33.

ISBN 978-0134752556 .

^ Schultz W (2015).

"Neuronal reward and decision signals: from theories to data" .

Physiological Reviews .

95 (3): 853– 951.

doi : 10.1152/physrev.00023.2014 .

PMC 4491543 .

PMID 26109341 .

Rewards in operant conditioning are positive reinforcers. ... Operant behavior gives a good definition for rewards. Anything that makes an individual come back for more is a positive reinforcer and therefore a reward. Although it provides a good definition, positive reinforcement is only one of several reward functions. ... Rewards are attractive. They are motivating and make us exert an effort. ... Rewards induce approach behavior, also called appetitive or preparatory behavior, and consummatory behavior. ... Thus any stimulus, object, event, activity, or situation that has the potential to make us approach and consume it is by definition a reward.

^ Skinner, B.F. (2014).

Science and Human Behavior (PDF) . Cambridge, MA: The B.F. Skinner Foundation. p. 70 . Retrieved 13 March 2019 .

^ Hampton, W., & Morrin, M. (2025). "When Touch Drives Purchase: Haptic Rewards as Reinforcers of Online Buying." Journal of Consumer Research.

https://doi.org/10.1093/jcr/ucaf025 ^ Schacter et al.2011 Psychology 2nd ed. pg.280–284 Reference for entire section Principles version 130317 ^ a b Miltenberger, R. G. "Behavioral Modification: Principles and Procedures".

Thomson/Wadsworth , 2008. p. 84.

^ Miltenberger, R. G. "Behavioral Modification: Principles and Procedures".

Thomson/Wadsworth , 2008. p. 86.

^ Tucker, M.; Sigafoos, J.; Bushell, H. (1998). "Use of noncontingent reinforcement in the treatment of challenging behavior".

Behavior Modification .

22 (4): 529– 547.

doi : 10.1177/01454455980224005 .

PMID 9755650 .

S2CID 21542125 .

^ Poling, A.; Normand, M. (1999).

"Noncontingent reinforcement: an inappropriate description of time-based schedules that reduce behavior" .

Journal of Applied Behavior Analysis .

32 (2): 237– 238.

doi : 10.1901/jaba.1999.32-237 .

PMC 1284187 .

^ a b c Pierce & Cheney (2004) Behavior Analysis and Learning ^ Cole, M.R. (1990).

"Operant hoarding: A new paradigm for the study of self-control" .

Journal of the Experimental Analysis of Behavior .

53 (2): 247– 262.

doi : 10.1901/jeab.1990.53-247 .

PMC 1323010 .

PMID 2324665 .

^ "Activity of pallidal neurons during movement" [ permanent dead link ] , M.R. DeLong, J. Neurophysiol.

, 34:414–27, 1971 ^ a b Richardson RT, DeLong MR (1991): Electrophysiological studies of the function of the nucleus basalis in primates. In Napier TC, Kalivas P, Hamin I (eds), The Basal Forebrain: Anatomy to Function ( Advances in Experimental Medicine and Biology ), vol. 295. New York, Plenum, pp. 232–252 ^ PNAS 93:11219-24 1996, Science 279:1714–8 1998 ^ Rozenfeld, Eyal; Parnas, Moshe (6 December 2024).

"Neuronal circuit mechanisms of competitive interaction between action-based and coincidence learning" .

Science Advances .

10 (49): eadq3016.

Bibcode : 2024SciA...10.3016R .

doi : 10.1126/sciadv.adq3016 .

PMC 11623277 .

PMID 39642217 .

^ Neuron 63:244–253, 2009, Frontiers in Behavioral Neuroscience, 3: Article 13, 2009 ^ Michael J. Frank, Lauren C. Seeberger, and Randall C. O'Reilly (2004) "By Carrot or by Stick: Cognitive Reinforcement Learning in Parkinsonism," Science 4, November 2004 ^ Schultz, Wolfram (1998).

"Predictive Reward Signal of Dopamine Neurons" .

The Journal of Neurophysiology .

80 (1): 1– 27.

doi : 10.1152/jn.1998.80.1.1 .

PMID 9658025 .

S2CID 52857162 .

^ Timberlake, W (1983).

"Rats' responses to a moving object related to food or water: A behavior-systems analysis" .

Animal Learning & Behavior .

11 (3): 309– 320.

doi : 10.3758/bf03199781 .

^ Neuringer, A.J. (1969). "Animals respond for food in the presence of free food".

Science .

166 (3903): 399– 401.

Bibcode : 1969Sci...166..399N .

doi : 10.1126/science.166.3903.399 .

PMID 5812041 .

S2CID 35969740 .

^ Williams, D.R.; Williams, H. (1969).

"Auto-maintenance in the pigeon: sustained pecking despite contingent non-reinforcement" .

Journal of the Experimental Analysis of Behavior .

12 (4): 511– 520.

doi : 10.1901/jeab.1969.12-511 .

PMC 1338642 .

PMID 16811370 .

^ Peden, B.F.; Brown, M.P.; Hearst, E. (1977). "Persistent approaches to a signal for food despite food omission for approaching".

Journal of Experimental Psychology: Animal Behavior Processes .

3 (4): 377– 399.

doi : 10.1037/0097-7403.3.4.377 .

^ Gardner, R.A.; Gardner, B.T. (1988). "Feedforward vs feedbackward: An ethological alternative to the law of effect".

Behavioral and Brain Sciences .

11 (3): 429– 447.

doi : 10.1017/s0140525x00058258 .

S2CID 143876403 .

^ Gardner, R. A. & Gardner B.T. (1998) The structure of learning from sign stimuli to sign language. Mahwah NJ: Lawrence Erlbaum Associates.

^ Baum, W. M. (2012).

"Rethinking reinforcement: Allocation, induction and contingency" .

Journal of the Experimental Analysis of Behavior .

97 (1): 101– 124.

doi : 10.1901/jeab.2012.97-101 .

PMC 3266735 .

PMID 22287807 .

^ Locurto, C. M., Terrace, H. S., & Gibbon, J. (1981) Autoshaping and conditioning theory. New York: Academic Press.

^ Staddon, J. E. R.; Cerutti, D. T. (2003).

"Operant conditioning" .

Annual Review of Psychology .

54 : 115– 144.

doi : 10.1146/annurev.psych.54.101601.145124 .

ISSN 0066-4308 .

PMC 1473025 .

PMID 12415075 .

^ a b c d Edwards S (2016). "Reinforcement principles for addiction medicine; from recreational drug use to psychiatric disorder".

Neuroscience for Addiction Medicine: From Prevention to Rehabilitation - Constructs and Drugs . Progress in Brain Research. Vol. 223. pp.

63– 76.

doi : 10.1016/bs.pbr.2015.07.005 .

ISBN 9780444635457 .

PMID 26806771 .

Abused substances (ranging from alcohol to psychostimulants) are initially ingested at regular occasions according to their positive reinforcing properties. Importantly, repeated exposure to rewarding substances sets off a chain of secondary reinforcing events, whereby cues and contexts associated with drug use may themselves become reinforcing and thereby contribute to the continued use and possible abuse of the substance(s) of choice. ...

An important dimension of reinforcement highly relevant to the addiction process (and particularly relapse) is secondary reinforcement (Stewart, 1992). Secondary reinforcers (in many cases also considered conditioned reinforcers) likely drive the majority of reinforcement processes in humans. In the specific case of drug [addiction], cues and contexts that are intimately and repeatedly associated with drug use will often themselves become reinforcing ... A fundamental piece of Robinson and Berridge's incentive-sensitization theory of addiction posits that the incentive value or attractive nature of such secondary reinforcement processes, in addition to the primary reinforcers themselves, may persist and even become sensitized over time in league with the development of drug addiction (Robinson and Berridge, 1993). ...

Negative reinforcement is a special condition associated with a strengthening of behavioral responses that terminate some ongoing (presumably aversive) stimulus. In this case we can define a negative reinforcer as a motivational stimulus that strengthens such an "escape" response. Historically, in relation to drug addiction, this phenomenon has been consistently observed in humans whereby drugs of abuse are self-administered to quench a motivational need in the state of withdrawal (Wikler, 1952).

{{ cite book }} : |journal= ignored ( help ) ^ a b c Berridge KC (April 2012).

"From prediction error to incentive salience: mesolimbic computation of reward motivation" .

Eur. J. Neurosci .

35 (7): 1124– 1143.

doi : 10.1111/j.1460-9568.2012.07990.x .

PMC 3325516 .

PMID 22487042 .

When a Pavlovian CS+ is attributed with incentive salience it not only triggers 'wanting' for its UCS, but often the cue itself becomes highly attractive – even to an irrational degree. This cue attraction is another signature feature of incentive salience. The CS becomes hard not to look at (Wiers & Stacy, 2006; Hickey et al., 2010a; Piech et al., 2010; Anderson et al., 2011). The CS even takes on some incentive properties similar to its UCS. An attractive CS often elicits behavioral motivated approach, and sometimes an individual may even attempt to 'consume' the CS somewhat as its UCS (e.g., eat, drink, smoke, have sex with, take as drug). 'Wanting' of a CS can turn also turn the formerly neutral stimulus into an instrumental conditioned reinforcer, so that an individual will work to obtain the cue (however, there exist alternative psychological mechanisms for conditioned reinforcement too).

^ a b c Berridge KC, Kringelbach ML (May 2015).

"Pleasure systems in the brain" .

Neuron .

86 (3): 646– 664.

doi : 10.1016/j.neuron.2015.02.018 .

PMC 4425246 .

PMID 25950633 .

An important goal in future for addiction neuroscience is to understand how intense motivation becomes narrowly focused on a particular target. Addiction has been suggested to be partly due to excessive incentive salience produced by sensitized or hyper-reactive dopamine systems that produce intense 'wanting' (Robinson and Berridge, 1993). But why one target becomes more 'wanted' than all others has not been fully explained. In addicts or agonist-stimulated patients, the repetition of dopamine-stimulation of incentive salience becomes attributed to particular individualized pursuits, such as taking the addictive drug or the particular compulsions. In Pavlovian reward situations, some cues for reward become more 'wanted' more than others as powerful motivational magnets, in ways that differ across individuals (Robinson et al., 2014b; Saunders and Robinson, 2013). ... However, hedonic effects might well change over time. As a drug was taken repeatedly, mesolimbic dopaminergic sensitization could consequently occur in susceptible individuals to amplify 'wanting' (Leyton and Vezina, 2013; Lodge and Grace, 2011; Wolf and Ferrario, 2010), even if opioid hedonic mechanisms underwent down-regulation due to continual drug stimulation, producing 'liking' tolerance. Incentive-sensitization would produce addiction, by selectively magnifying cue-triggered 'wanting' to take the drug again, and so powerfully cause motivation even if the drug became less pleasant (Robinson and Berridge, 1993).

^ McGreevy, P & Boakes, R."Carrots and Sticks: Principles of Animal Training".(Sydney: "Sydney University Press"., 2011) ^ Dillenburger, K.; Keenan, M. (2009). "None of the As in ABA stand for autism: dispelling the myths".

J Intellect Dev Disabil .

34 (2): 193– 95.

doi : 10.1080/13668250902845244 .

PMID 19404840 .

S2CID 1818966 .

^ DeVries, J.E.; Burnette, M.M.; Redmon, W.K. (1991).

"AIDS prevention: Improving nurses' compliance with glove wearing through performance feedback" .

Journal of Applied Behavior Analysis .

24 (4): 705– 11.

doi : 10.1901/jaba.1991.24-705 .

PMC 1279627 .

PMID 1797773 .

^ Brothers, K.J.; Krantz, P.J.; McClannahan, L.E. (1994).

"Office paper recycling: A function of container proximity" .

Journal of Applied Behavior Analysis .

27 (1): 153– 60.

doi : 10.1901/jaba.1994.27-153 .

PMC 1297784 .

PMID 16795821 .

^ Dardig, Jill C.; Heward, William L.; Heron, Timothy E.; Nancy A. Neef; Peterson, Stephanie; Diane M. Sainato; Cartledge, Gwendolyn; Gardner, Ralph; Peterson, Lloyd R.; Susan B. Hersh (2005).

Focus on behavior analysis in education: achievements, challenges, and opportunities . Upper Saddle River, NJ: Pearson/Merrill/Prentice Hall.

ISBN 978-0-13-111339-8 .

^ Gallagher, S.M.; Keenan M. (2000).

"Independent use of activity materials by the elderly in a residential setting" .

Journal of Applied Behavior Analysis .

33 (3): 325– 28.

doi : 10.1901/jaba.2000.33-325 .

PMC 1284256 .

PMID 11051575 .

^ De Luca, R.V.; Holborn, S.W. (1992).

"Effects of a variable-ratio reinforcement schedule with changing criteria on exercise in obese and nonobese boys" .

Journal of Applied Behavior Analysis .

25 (3): 671– 79.

doi : 10.1901/jaba.1992.25-671 .

PMC 1279749 .

PMID 1429319 .

^ Fox, D.K.; Hopkins, B.L.; Anger, W.K. (1987).

"The long-term effects of a token economy on safety performance in open-pit mining" .

Journal of Applied Behavior Analysis .

20 (3): 215– 24.

doi : 10.1901/jaba.1987.20-215 .

PMC 1286011 .

PMID 3667473 .

^ Drasgow, E.; Halle, J.W.; Ostrosky, M.M. (1998).

"Effects of differential reinforcement on the generalization of a replacement mand in three children with severe language delays" .

Journal of Applied Behavior Analysis .

31 (3): 357– 74.

doi : 10.1901/jaba.1998.31-357 .

PMC 1284128 .

PMID 9757580 .

^ Powers, R.B.; Osborne, J.G.; Anderson, E.G. (1973).

"Positive reinforcement of litter removal in the natural environment" .

Journal of Applied Behavior Analysis .

6 (4): 579– 86.

doi : 10.1901/jaba.1973.6-579 .

PMC 1310876 .

PMID 16795442 .

^ Hagopian, L.P.; Thompson, R.H. (1999).

"Reinforcement of compliance with respiratory treatment in a child with cystic fibrosis" .

Journal of Applied Behavior Analysis .

32 (2): 233– 36.

doi : 10.1901/jaba.1999.32-233 .

PMC 1284184 .

PMID 10396778 .

^ Kuhn, S.A.C.; Lerman, D.C.; Vorndran, C.M. (2003).

"Pyramidal training for families of children with problem behavior" .

Journal of Applied Behavior Analysis .

36 (1): 77– 88.

doi : 10.1901/jaba.2003.36-77 .

PMC 1284418 .

PMID 12723868 .

^ Van Houten, R.; Malenfant, J.E.L.; Austin, J.; Lebbon, A. (2005). Vollmer, Timothy (ed.).

"The effects of a seatbelt-gearshift delay prompt on the seatbelt use of motorists who do not regularly wear seatbelts" .

Journal of Applied Behavior Analysis .

38 (2): 195– 203.

doi : 10.1901/jaba.2005.48-04 .

PMC 1226155 .

PMID 16033166 .

^ Wong, S.E.; Martinez-Diaz, J.A.; Massel, H.K.; Edelstein, B.A.; Wiegand, W.; Bowen, L.; Liberman, R.P. (1993). "Conversational skills training with schizophrenic inpatients: A study of generalization across settings and conversants".

Behavior Therapy .

24 (2): 285– 304.

doi : 10.1016/S0005-7894(05)80270-9 .

^ Brobst, B.; Ward, P. (2002).

"Effects of public posting, goal setting, and oral feedback on the skills of female soccer players" .

Journal of Applied Behavior Analysis .

35 (3): 247– 57.

doi : 10.1901/jaba.2002.35-247 .

PMC 1284383 .

PMID 12365738 .

^ Forthman, D.L.; Ogden, J.J. (1992).

"The role of applied behavior analysis in zoo management: Today and tomorrow" .

Journal of Applied Behavior Analysis .

25 (3): 647– 52.

doi : 10.1901/jaba.1992.25-647 .

PMC 1279745 .

PMID 16795790 .

^ a b Kazdin AE (2010). Problem-solving skills training and parent management training for oppositional defiant disorder and conduct disorder.

Evidence-based psychotherapies for children and adolescents (2nd ed.), 211–226. New York: Guilford Press.

^ Forgatch MS, Patterson GR (2010). Parent management training — Oregon model: An intervention for antisocial behavior in children and adolescents.

Evidence-based psychotherapies for children and adolescents (2nd ed.), 159–78. New York: Guilford Press.

^ Domjan, M. (2009). The Principles of Learning & Behavior. Wadsworth Publishing Company. 6th Edition. pages 244–249.

^ Bleda, Miguel Ángel Pérez; Nieto, José Héctor Lozano (2012). "Impulsivity, Intelligence, and Discriminating Reinforcement Contingencies in a Fixed-Ratio 3 Schedule".

The Spanish Journal of Psychology .

3 (15): 922– 929.

doi : 10.5209/rev_SJOP.2012.v15.n3.39384 .

PMID 23156902 .

S2CID 144193503 .

ProQuest 1439791203 .

^ a b c d Grossman, Dave (1995).

On Killing: the Psychological Cost of Learning to Kill in War and Society . Boston: Little Brown.

ISBN 978-0316040938 .

^ Marshall, S.L.A. (1947).

Men Against Fire: the Problem of Battle Command in Future War . Washington: Infantry Journal.

ISBN 978-0-8061-3280-8 .

{{ cite book }} : ISBN / Date incompatibility ( help ) ^ a b Murray KA, Grossman D, Kentridge RW (21 October 2018).

"Behavioral Psychology" .

killology.com/behavioral-psychology .

^ Kazdin, Alan (1978).

History of behavior modification: Experimental foundations of contemporary research . Baltimore: University Park Press.

ISBN 9780839112051 .

^ Strain, Phillip S.; Lambert, Deborah L.; Kerr, Mary Margaret; Stagg, Vaughan; Lenkner, Donna A. (1983).

"Naturalistic assessment of children's compliance to teachers' requests and consequences for compliance" .

Journal of Applied Behavior Analysis .

16 (2): 243– 249.

doi : 10.1901/jaba.1983.16-243 .

PMC 1307879 .

PMID 16795665 .

^ a b Garland, Ann F.; Hawley, Kristin M.; Brookman-Frazee, Lauren; Hurlburt, Michael S. (May 2008). "Identifying Common Elements of Evidence-Based Psychosocial Treatments for Children's Disruptive Behavior Problems".

Journal of the American Academy of Child & Adolescent Psychiatry .

47 (5): 505– 514.

doi : 10.1097/CHI.0b013e31816765c2 .

PMID 18356768 .

^ Crowell, Charles R.; Anderson, D. Chris; Abel, Dawn M.; Sergio, Joseph P. (1988).

"Task clarification, performance feedback, and social praise: Procedures for improving the customer service of bank tellers" .

Journal of Applied Behavior Analysis .

21 (1): 65– 71.

doi : 10.1901/jaba.1988.21-65 .

PMC 1286094 .

PMID 16795713 .

^ Kazdin, Alan E. (1973).

"The effect of vicarious reinforcement on attentive behavior in the classroom" .

Journal of Applied Behavior Analysis .

6 (1): 71– 78.

doi : 10.1901/jaba.1973.6-71 .

PMC 1310808 .

PMID 16795397 .

^ Brophy, Jere (1981). "On praising effectively".

The Elementary School Journal .

81 (5): 269– 278.

doi : 10.1086/461229 .

JSTOR 1001606 .

S2CID 144444174 .

^ a b Simonsen, Brandi; Fairbanks, Sarah; Briesch, Amy; Myers, Diane; Sugai, George (2008). "Evidence-based Practices in Classroom Management: Considerations for Research to Practice".

Education and Treatment of Children .

31 (1): 351– 380.

doi : 10.1353/etc.0.0007 .

S2CID 145087451 .

^ Weisz, John R.; Kazdin, Alan E. (2010).

Evidence-based psychotherapies for children and adolescents . Guilford Press.

^ John Hopson: Behavioral Game Design , Gamasutra , 27 April 2001 ^ Hood, Vic (12 October 2017).

"Are loot boxes gambling?" .

Eurogamer . Retrieved 12 October 2017 .

^ Operant Conditioning and the Practice of Defensive Medicine.   Vikram C. Prabhu World Neurosurgery, 2016-07-01, Volume 91, Pages 603–605 External links [ edit ] Wikimedia Commons has media related to Operant conditioning .

Look up operant in Wiktionary, the free dictionary.

Library resources about Operant conditioning Resources in your library Resources in other libraries Operant conditioning article in Scholarpedia Journal of Applied Behavior Analysis Journal of the Experimental Analysis of Behavior Negative reinforcement scienceofbehavior.com Archived 2 October 2011 at the Wayback Machine NewPP limit report
Parsed by mw‐web.codfw.main‐8487bf5649‐94b9m
Cached time: 20250814015926
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.201 seconds
Real time usage: 1.395 seconds
Preprocessor visited node count: 9694/1000000
Revision size: 72746/2097152 bytes
Post‐expand include size: 283659/2097152 bytes
Template argument size: 22679/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 29/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 269803/5000000 bytes
Lua time usage: 0.763/10.000 seconds
Lua memory usage: 9570267/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00% 1220.898      1 -total
 40.30%  492.005      1 Template:Reflist
 28.86%  352.315     41 Template:Cite_journal
 11.21%  136.842     24 Template:Fix
  8.34%  101.846      3 Template:Navbox
  7.87%   96.091      1 Template:Learning
  7.01%   85.619     14 Template:Better_source_needed
  6.44%   78.629      1 Template:Short_description
  5.08%   62.059      8 Template:Citation_needed
  4.88%   59.625      1 Template:More_medical_citations_needed Saved in parser cache with key enwiki:pcache:128027:|#|:idhash:canonical and timestamp 20250814015926 and revision id 1305778826. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Operant_conditioning&oldid=1305778826 " Categories : Educational technology Behaviorism Experimental psychology Behavioral concepts History of psychology Hidden categories: All articles with dead external links Articles with dead external links from August 2025 Articles with permanently dead external links CS1 errors: periodical ignored CS1 errors: ISBN date Articles with short description Short description is different from Wikidata Use dmy dates from November 2018 Articles needing additional medical references from July 2025 All articles needing additional references Articles requiring reliable medical sources All Wikipedia articles needing clarification Wikipedia articles needing clarification from July 2025 All articles lacking reliable references Articles lacking reliable references from July 2025 All articles with unsourced statements Articles with unsourced statements from July 2025 Articles with unsourced statements from January 2018 Articles with unsourced statements from January 2023 Articles with unsourced statements from September 2018 Commons category link is on Wikidata Webarchive template wayback links This page was last edited on 14 August 2025, at 01:58 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Operant conditioning 34 languages Add topic

