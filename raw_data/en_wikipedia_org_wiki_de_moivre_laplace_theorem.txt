Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Theorem Toggle Theorem subsection 1.1 Proof 1.2 Alternative proof 2 See also 3 Notes Toggle the table of contents De Moivre–Laplace theorem 12 languages Čeština Deutsch Español Euskara Français עברית Nederlands Piemontèis Polski Русский தமிழ் Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Convergence in distribution of binomial to normal distribution Within a system whose bins are filled according to the binomial distribution (such as Galton's " bean machine ", shown here), given a sufficient number of trials (here the rows of pins, each of which causes a dropped "bean" to fall toward the left or right), a shape representing the probability distribution of k successes in n trials (see bottom of Fig. 7) matches approximately the Gaussian distribution with expectation np and variance np (1− p ), assuming the trials are independent and successes occur with probability p .

Consider tossing a set of n coins a very large number of times and counting the number of "heads" that result each time. The possible number of heads on each toss, k , runs from 0 to n along the horizontal axis, while the vertical axis represents the relative frequency of occurrence of the outcome k heads. The height of each dot is thus the probability of observing k heads when tossing n coins (a binomial distribution based on n trials). According to the de Moivre–Laplace theorem, as n grows large, the shape of the discrete distribution converges to the continuous Gaussian curve of the normal distribution .

Not to be confused with De Moivre's formula .

In probability theory , the de Moivre–Laplace theorem , which is a special case of the central limit theorem , states that the normal distribution may be used as an approximation to the binomial distribution under certain conditions.  In particular, the theorem shows that the probability mass function of the random number of "successes" observed in a series of n {\displaystyle n} independent Bernoulli trials , each having probability p {\displaystyle p} of success (a binomial distribution with n {\displaystyle n} trials), converges to the probability density function of the normal distribution with expectation n p {\displaystyle np} and standard deviation n p ( 1 − − p ) {\textstyle {\sqrt {np(1-p)}}} , as n {\displaystyle n} grows large, assuming p {\displaystyle p} is not 0 {\displaystyle 0} or 1 {\displaystyle 1} .

The theorem appeared in the second edition of The Doctrine of Chances by Abraham de Moivre , published in 1738.  Although de Moivre did not use the term "Bernoulli trials", he wrote about the probability distribution of the number of times "heads" appears when a coin is tossed 3600 times.

[ 1 ] This is one derivation of the particular Gaussian function used in the normal distribution.

It is a special case of the central limit theorem because a Bernoulli process can be thought of as the drawing of independent random variables from a bimodal discrete distribution with non-zero probability only for values 0 and 1. In this case, the binomial distribution models the number of successes (i.e., the number of 1s), whereas the central limit theorem states that, given sufficiently large n , the distribution of the sample means will be approximately normal. However, because in this case the fraction of successes (i.e., the number of 1s divided by the number of trials, n ) is equal to the sample mean , the distribution of the fractions of successes (described by the binomial distribution divided by the constant n ) and the distribution of the sample means (approximately normal with large n due to the central limit theorem) are equivalent.

Theorem [ edit ] As n grows large, for k in the neighborhood of np we can approximate [ 2 ] [ 3 ] ( n k ) p k q n − − k ≃ ≃ 1 2 π π n p q e − − ( k − − n p ) 2 2 n p q , p + q = 1 , p , q > 0 {\displaystyle {n \choose k}\,p^{k}q^{n-k}\simeq {\frac {1}{\sqrt {2\pi npq}}}\,e^{-{\frac {(k-np)^{2}}{2npq}}},\qquad p+q=1,\ p,q>0} in the sense that the ratio of the left-hand side to the right-hand side converges to 1 as n → ∞.

Proof [ edit ] The theorem can be more rigorously stated as follows: ( X − − n p ) / n p q {\displaystyle \left(X\!\,-\!\,np\right)\!/\!{\sqrt {npq}}} , with X {\displaystyle \textstyle X} a binomially distributed random variable, approaches the standard normal as n → → ∞ ∞ {\displaystyle n\!\to \!\infty } , with the ratio of the probability mass of X {\displaystyle X} to the limiting normal density being 1. This can be shown for an arbitrary nonzero and finite point c {\displaystyle c} . On the unscaled curve for X {\displaystyle X} , this would be a point k {\displaystyle k} given by k = n p + c n p q {\displaystyle k=np+c{\sqrt {npq}}} For example, with c {\displaystyle c} at 3, k {\displaystyle k} stays 3 standard deviations from the mean in the unscaled curve.

The normal distribution with mean μ μ {\displaystyle \mu } and standard deviation σ σ {\displaystyle \sigma } is defined by the differential equation (DE) f ′ ( x ) = − − x − − μ μ σ σ 2 f ( x ) {\displaystyle f'\!(x)\!=\!-\!\,{\frac {x-\mu }{\sigma ^{2}}}f(x)} with an initial condition set by the probability axiom ∫ ∫ − − ∞ ∞ ∞ ∞ f ( x ) d x = 1 {\displaystyle \int _{-\infty }^{\infty }\!f(x)\,dx\!=\!1} .

The binomial distribution limit approaches the normal if the binomial satisfies this DE. As the binomial is discrete the equation starts as a difference equation whose limit morphs to a DE. Difference equations use the discrete derivative , p ( k + 1 ) − − p ( k ) {\displaystyle \textstyle p(k\!+\!1)\!-\!p(k)} , the change for step size 1. As k → → ∞ ∞ {\displaystyle \textstyle k\!\to \!\infty } , the discrete derivative becomes the continuous derivative . Hence the proof need show only that, for the unscaled binomial distribution, p ( n , k + 1 ) − − p ( n , k ) p ( n , k ) ⋅ ⋅ ( − − σ σ 2 k − − μ μ ) → → 1 {\displaystyle {\frac {p(n,k+1)-p(n,k)}{p(n,k)}}\!\cdot \!\left(-{\frac {\sigma ^{2}}{k-\mu }}\right)\!\to \!1} as n → → ∞ ∞ {\displaystyle n\!\to \!\infty } , where p ( n , k ) = ( n k ) p k q n − − k {\displaystyle p(n,k)={n \choose k}\,p^{k}q^{n-k}} , μ μ = n p {\displaystyle \mu =np} , and σ σ = n p q {\displaystyle \sigma ={\sqrt {npq}}} .

The required result can be shown directly: p ( n , k + 1 ) − − p ( n , k ) p ( n , k ) n p q n p − − k = n p − − k − − q k q + q n p q − − c = − − c n p q − − q n p q + c q n p q + q n p q − − c → → 1 {\displaystyle {\begin{aligned}{\frac {p\left(n,k+1\right)-p\left(n,k\right)}{p\left(n,k\right)}}{\frac {npq}{np\!\,-\!\,k}}\!&={\frac {np-k-q}{kq+q}}{\frac {\sqrt {npq}}{-c}}\\&={\frac {-c{\sqrt {npq}}-q}{npq+cq{\sqrt {npq}}+q}}{\frac {\sqrt {npq}}{-c}}\\&\to 1\end{aligned}}} The last holds because the term − − c n p q {\displaystyle -cnpq} dominates both the denominator and the numerator as n → → ∞ ∞ {\displaystyle n\!\to \!\infty } .

As k {\displaystyle \textstyle k} takes just integral values, the constant c {\displaystyle \textstyle c} is subject to a rounding error. However, the maximum of this error, 0.5 / n p q {\displaystyle \textstyle {0.5}/\!{\sqrt {npq}}} , is a vanishing value.

[ 4 ] Alternative proof [ edit ] The proof consists of transforming the left-hand side (in the statement of the theorem) to the right-hand side by three approximations.

First, according to Stirling's formula , the factorial of a large number n can be replaced with the approximation n !

≃ ≃ n n e − − n 2 π π n as n → → ∞ ∞ .

{\displaystyle n!\simeq n^{n}e^{-n}{\sqrt {2\pi n}}\qquad {\text{as }}n\to \infty .} Thus ( n k ) p k q n − − k = n !

k !

( n − − k ) !

p k q n − − k ≃ ≃ n n e − − n 2 π π n k k e − − k 2 π π k ( n − − k ) n − − k e − − ( n − − k ) 2 π π ( n − − k ) p k q n − − k = n 2 π π k ( n − − k ) n n k k ( n − − k ) n − − k p k q n − − k = n 2 π π k ( n − − k ) ( n p k ) k ( n q n − − k ) n − − k {\displaystyle {\begin{aligned}{n \choose k}p^{k}q^{n-k}&={\frac {n!}{k!(n-k)!}}p^{k}q^{n-k}\\&\simeq {\frac {n^{n}e^{-n}{\sqrt {2\pi n}}}{k^{k}e^{-k}{\sqrt {2\pi k}}(n-k)^{n-k}e^{-(n-k)}{\sqrt {2\pi (n-k)}}}}p^{k}q^{n-k}\\&={\sqrt {\frac {n}{2\pi k\left(n-k\right)}}}{\frac {n^{n}}{k^{k}\left(n-k\right)^{n-k}}}p^{k}q^{n-k}\\&={\sqrt {\frac {n}{2\pi k\left(n-k\right)}}}\left({\frac {np}{k}}\right)^{k}\left({\frac {nq}{n-k}}\right)^{n-k}\end{aligned}}} Next, the approximation k n → → p {\displaystyle {\tfrac {k}{n}}\to p} is used to match the square root above to the desired square root on the right-hand side.

( n k ) p k q n − − k ≃ ≃ 1 2 π π n k n ( 1 − − k n ) ( n p k ) k ( n q n − − k ) n − − k ≃ ≃ 1 2 π π n p q ( n p k ) k ( n q n − − k ) n − − k p + q = 1 {\displaystyle {\begin{aligned}{n \choose k}p^{k}q^{n-k}&\simeq {\sqrt {\frac {1}{2\pi n{\frac {k}{n}}\left(1-{\frac {k}{n}}\right)}}}\left({\frac {np}{k}}\right)^{k}\left({\frac {nq}{n-k}}\right)^{n-k}\\&\simeq {\frac {1}{\sqrt {2\pi npq}}}\left({\frac {np}{k}}\right)^{k}\left({\frac {nq}{n-k}}\right)^{n-k}\qquad p+q=1\\\end{aligned}}} Finally, the expression is rewritten as an exponential, x = k − − n p n p q {\displaystyle x={\frac {k-np}{\sqrt {npq}}}} (the standardized value for k ) is introduced, and the Taylor Series approximation for ln(1+w) is used: ln ⁡ ⁡ ( 1 + w ) ≃ ≃ w − − w 2 2 + w 3 3 − − ⋯ ⋯ {\displaystyle \ln \left(1+w\right)\simeq w-{\frac {w^{2}}{2}}+{\frac {w^{3}}{3}}-\cdots } Then ( n k ) p k q n − − k ≃ ≃ 1 2 π π n p q exp ⁡ ⁡ { ln ⁡ ⁡ ( ( n p k ) k ) + ln ⁡ ⁡ ( ( n q n − − k ) n − − k ) } = 1 2 π π n p q exp ⁡ ⁡ { − − k ln ⁡ ⁡ ( k n p ) + ( k − − n ) ln ⁡ ⁡ ( n − − k n q ) } = 1 2 π π n p q exp ⁡ ⁡ { − − k ln ⁡ ⁡ ( n p + x n p q n p ) + ( k − − n ) ln ⁡ ⁡ ( n − − n p − − x n p q n q ) } = 1 2 π π n p q exp ⁡ ⁡ { − − k ln ⁡ ⁡ ( 1 + x q n p ) + ( k − − n ) ln ⁡ ⁡ ( 1 − − x p n q ) } p + q = 1 = 1 2 π π n p q exp ⁡ ⁡ { − − k ( x q n p − − x 2 q 2 n p + ⋯ ⋯ ) + ( k − − n ) ( − − x p n q − − x 2 p 2 n q − − ⋯ ⋯ ) } = 1 2 π π n p q exp ⁡ ⁡ { ( − − n p − − x n p q ) ( x q n p − − x 2 q 2 n p + ⋯ ⋯ ) + ( n p + x n p q − − n ) ( − − x p n q − − x 2 p 2 n q − − ⋯ ⋯ ) } = 1 2 π π n p q exp ⁡ ⁡ { ( − − n p − − x n p q ) ( x q n p − − x 2 q 2 n p + ⋯ ⋯ ) − − ( n q − − x n p q ) ( − − x p n q − − x 2 p 2 n q − − ⋯ ⋯ ) } = 1 2 π π n p q exp ⁡ ⁡ { ( − − x n p q + 1 2 x 2 q − − x 2 q + ⋯ ⋯ ) + ( x n p q + 1 2 x 2 p − − x 2 p − − ⋯ ⋯ ) } = 1 2 π π n p q exp ⁡ ⁡ { − − 1 2 x 2 q − − 1 2 x 2 p − − ⋯ ⋯ } = 1 2 π π n p q exp ⁡ ⁡ { − − 1 2 x 2 ( p + q ) − − ⋯ ⋯ } ≃ ≃ 1 2 π π n p q exp ⁡ ⁡ { − − 1 2 x 2 } = 1 2 π π n p q e − − ( k − − n p ) 2 2 n p q {\displaystyle {\begin{aligned}{n \choose k}p^{k}q^{n-k}&\simeq {\frac {1}{\sqrt {2\pi npq}}}\exp \left\{\ln \left(\left({\frac {np}{k}}\right)^{k}\right)+\ln \left(\left({\frac {nq}{n-k}}\right)^{n-k}\right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-k\ln \left({\frac {k}{np}}\right)+(k-n)\ln \left({\frac {n-k}{nq}}\right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-k\ln \left({\frac {np+x{\sqrt {npq}}}{np}}\right)+(k-n)\ln \left({\frac {n-np-x{\sqrt {npq}}}{nq}}\right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-k\ln \left({1+x{\sqrt {\frac {q}{np}}}}\right)+(k-n)\ln \left({1-x{\sqrt {\frac {p}{nq}}}}\right)\right\}\qquad p+q=1\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-k\left({x{\sqrt {\frac {q}{np}}}}-{\frac {x^{2}q}{2np}}+\cdots \right)+(k-n)\left({-x{\sqrt {\frac {p}{nq}}}-{\frac {x^{2}p}{2nq}}}-\cdots \right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{\left(-np-x{\sqrt {npq}}\right)\left({x{\sqrt {\frac {q}{np}}}}-{\frac {x^{2}q}{2np}}+\cdots \right)+\left(np+x{\sqrt {npq}}-n\right)\left(-x{\sqrt {\frac {p}{nq}}}-{\frac {x^{2}p}{2nq}}-\cdots \right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{\left(-np-x{\sqrt {npq}}\right)\left(x{\sqrt {\frac {q}{np}}}-{\frac {x^{2}q}{2np}}+\cdots \right)-\left(nq-x{\sqrt {npq}}\right)\left(-x{\sqrt {\frac {p}{nq}}}-{\frac {x^{2}p}{2nq}}-\cdots \right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{\left(-x{\sqrt {npq}}+{\frac {1}{2}}x^{2}q-x^{2}q+\cdots \right)+\left(x{\sqrt {npq}}+{\frac {1}{2}}x^{2}p-x^{2}p-\cdots \right)\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-{\frac {1}{2}}x^{2}q-{\frac {1}{2}}x^{2}p-\cdots \right\}\\&={\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-{\frac {1}{2}}x^{2}(p+q)-\cdots \right\}\\&\simeq {\frac {1}{\sqrt {2\pi npq}}}\exp \left\{-{\frac {1}{2}}x^{2}\right\}\\&={\frac {1}{\sqrt {2\pi npq}}}e^{\frac {-(k-np)^{2}}{2npq}}\\\end{aligned}}} Each " ≃ ≃ {\displaystyle \simeq } " in the above argument is a statement that two quantities are asymptotically equivalent as n increases, in the same sense as in the original statement of the theorem—i.e., that the ratio of each pair of quantities approaches 1 as n → ∞.

See also [ edit ] Poisson limit theorem an alternative approximation of the binomial distribution for large values of n .

Notes [ edit ] ^ Walker, Helen M (1985).

"De Moivre on the law of normal probability" (PDF) . In Smith, David Eugene (ed.).

A source book in mathematics . Dover. p.

78 .

ISBN 0-486-64690-4 .

But altho' the taking an infinite number of Experiments be not practicable, yet the preceding Conclusions may very well be applied to finite numbers, provided they be great, for Instance, if 3600 Experiments be taken, make n = 3600, hence ½ n will be = 1800, and ½√ n 30, then the Probability of the Event's neither appearing oftner than 1830 times, nor more rarely than 1770, will be 0.682688.

^ Papoulis, Athanasios ; Pillai, S. Unnikrishna (2002).

Probability, Random Variables, and Stochastic Processes (4th ed.). Boston: McGraw-Hill.

ISBN 0-07-122661-3 .

^ Feller, W.

(1968).

An Introduction to Probability Theory and Its Applications . Vol. 1. Wiley. Section VII.3.

ISBN 0-471-25708-7 .

^ Thamattoor, Ajoy (2018). "Normal limit of the binomial via the discrete derivative".

The College Mathematics Journal .

49 (3): 216– 217.

doi : 10.1080/07468342.2018.1440872 .

S2CID 125977913 .

Retrieved from " https://en.wikipedia.org/w/index.php?title=De_Moivre–Laplace_theorem&oldid=1291235741 " Categories : 1738 introductions Central limit theorem Abraham de Moivre Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 19 May 2025, at 23:01 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents De Moivre–Laplace theorem 12 languages Add topic

