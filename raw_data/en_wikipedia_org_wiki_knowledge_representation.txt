Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 History 2 Overview 3 Characteristics 4 Ontology engineering 5 See also 6 References 7 Further reading 8 External links Toggle the table of contents Knowledge representation and reasoning 33 languages Afrikaans العربية Azərbaycanca Български Català Čeština Deutsch Español فارسی 한국어 हिन्दी Hrvatski Bahasa Indonesia Interlingue Italiano עברית Кыргызча Magyar 日本語 Norsk nynorsk پښتو Polski Português Qaraqalpaqsha Русский සිංහල Српски / srpski ไทย Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Knowledge representation ) Field of artificial intelligence Knowledge representation ( KR ) aims to model information in a structured manner to formally represent it as knowledge in knowledge-based systems whereas knowledge representation and reasoning ( KRR , KR&R , or KR² ) also aims to understand, reason, and interpret knowledge. KRR is widely used in the field of artificial intelligence (AI) with the goal to represent information about the world in a form that a computer system can use to solve complex tasks, such as diagnosing a medical condition or having a natural-language dialog . KR incorporates findings from psychology [ 1 ] about how humans solve problems and represent knowledge, in order to design formalisms that make complex systems easier to design and build. KRR also incorporates findings from logic to automate various kinds of reasoning .

Traditional KRR focuses more on the declarative representation of knowledge. Related knowledge representation formalisms mainly include vocabularies , thesaurus , semantic networks , axiom systems , frames , rules , logic programs , and ontologies . Examples of automated reasoning engines include inference engines , theorem provers , model generators , and classifiers .

In a broader sense, parameterized models in machine learning — including neural network architectures such as convolutional neural networks and transformers — can also be regarded as a family of knowledge representation formalisms. The question of which formalism is most appropriate for knowledge-based systems has long been a subject of extensive debate. For instance, Frank van Harmelen et al. discussed the suitability of logic as a knowledge representation formalism and reviewed arguments presented by anti-logicists.

[ 2 ] Paul Smolensky criticized the limitations of symbolic formalisms and explored the possibilities of integrating it with connectionist approaches.

[ 3 ] More recently, Heng Zhang et al. have demonstrated that all universal (or equally expressive and natural) knowledge representation formalisms are recursively isomorphic.

[ 4 ] This finding indicates a theoretical equivalence among mainstream knowledge representation formalisms with respect to their capacity for supporting artificial general intelligence (AGI). They further argue that while diverse technical approaches may draw insights from one another via recursive isomorphisms, the fundamental challenges remain inherently shared.

History [ edit ] Part of a series on Artificial intelligence (AI) Major goals Artificial general intelligence Intelligent agent Recursive self-improvement Planning Computer vision General game playing Knowledge representation Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Software development Translation Military Physics Projects Philosophy Artificial consciousness Chinese room Friendly AI Control problem / Takeover Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom Glossary Glossary v t e The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959 and the Advice Taker proposed by John McCarthy also in 1959. GPS featured data structures for planning and decomposition. The system would begin with a goal. It would then decompose that goal into sub-goals and then set out to construct strategies that could accomplish each subgoal. The Advisor Taker, on the other hand, proposed the use of the predicate calculus to implement common sense reasoning .

Many of the early approaches to knowledge representation in Artificial Intelligence (AI) used graph representations and semantic networks , similar to knowledge graphs today. In such approaches, problem solving was a form of graph traversal [ 5 ] or path-finding, as in the A* search algorithm . Typical applications included robot plan-formation and game-playing.

Other researchers focused on developing automated theorem-provers for first-order logic, motivated by the use of mathematical logic to formalise mathematics and to automate the proof of mathematical theorems. A major step in this direction was the development of the resolution method by John Alan Robinson .

In the meanwhile, John McCarthy and Pat Hayes developed the situation calculus as a logical representation of common sense knowledge about the laws of cause and effect.

Cordell Green , in turn, showed how to do robot plan-formation by applying resolution to the situation calculus. He also showed how to use resolution for question-answering and automatic programming .

[ 6 ] In contrast, researchers at Massachusetts Institute of Technology (MIT) rejected the resolution uniform proof procedure paradigm and advocated the procedural embedding of knowledge instead.

[ 7 ] The resulting conflict between the use of logical representations and the use of procedural representations was resolved in the early 1970s with the development of logic programming and Prolog , using SLD resolution to treat Horn clauses as goal-reduction procedures.

The early development of logic programming was largely a European phenomenon. In North America, AI researchers such as Ed Feigenbaum and Frederick Hayes-Roth advocated the representation of domain-specific knowledge rather than general-purpose reasoning.

[ 8 ] These efforts led to the cognitive revolution in psychology and to the phase of AI focused on knowledge representation that resulted in expert systems in the 1970s and 80s, production systems , frame languages , etc. Rather than general problem solvers, AI changed its focus to expert systems that could match human competence on a specific task, such as medical diagnosis.

[ 9 ] Expert systems gave us the terminology still in use today where AI systems are divided into a knowledge base , which includes facts and rules about a problem domain, and an inference engine , which applies the knowledge in the knowledge base to answer questions and solve problems in the domain. In these early systems the facts in the knowledge base tended to be a fairly flat structure, essentially assertions about the values of variables used by the rules.

[ 10 ] Meanwhile, Marvin Minsky developed the concept of frame in the mid-1970s.

[ 11 ] A frame is similar to an object class: It is an abstract description of a category describing things in the world, problems, and potential solutions. Frames were originally used on systems geared toward human interaction, e.g.

understanding natural language and the social settings in which various default expectations such as ordering food in a restaurant narrow the search space and allow the system to choose appropriate responses to dynamic situations.

It was not long before the frame communities and the rule-based researchers realized that there was a synergy between their approaches. Frames were good for representing the real world, described as classes, subclasses, slots (data values) with various constraints on possible values. Rules were good for representing and utilizing complex logic such as the process to make a medical diagnosis. Integrated systems were developed that combined frames and rules. One of the most powerful and well known was the 1983 Knowledge Engineering Environment (KEE) from Intellicorp . KEE had a complete rule engine with forward and backward chaining . It also had a complete frame-based knowledge base with triggers, slots (data values), inheritance, and message passing. Although message passing originated in the object-oriented community rather than AI it was quickly embraced by AI researchers as well in environments such as KEE and in the operating systems for Lisp machines from Symbolics , Xerox , and Texas Instruments .

[ 12 ] The integration of frames, rules, and object-oriented programming was significantly driven by commercial ventures such as KEE and Symbolics spun off from various research projects. At the same time, there was another strain of research that was less commercially focused and was driven by mathematical logic and automated theorem proving.

[ citation needed ] One of the most influential languages in this research was the KL-ONE language of the mid-'80s. KL-ONE was a frame language that had a rigorous semantics, formal definitions for concepts such as an Is-A relation .

[ 13 ] KL-ONE and languages that were influenced by it such as Loom had an automated reasoning engine that was based on formal logic rather than on IF-THEN rules. This reasoner is called the classifier. A classifier can analyze a set of declarations and infer new assertions, for example, redefine a class to be a subclass or superclass of some other class that wasn't formally specified. In this way the classifier can function as an inference engine, deducing new facts from an existing knowledge base. The classifier can also provide consistency checking on a knowledge base (which in the case of KL-ONE languages is also referred to as an Ontology).

[ 14 ] Another area of knowledge representation research was the problem of common-sense reasoning . One of the first realizations learned from trying to make software that can function with human natural language was that humans regularly draw on an extensive foundation of knowledge about the real world that we simply take for granted but that is not at all obvious to an artificial agent, such as basic principles of common-sense physics, causality, intentions, etc. An example is the frame problem , that in an event driven logic there need to be axioms that state things maintain position from one moment to the next unless they are moved by some external force. In order to make a true artificial intelligence agent that can converse with humans using natural language and can process basic statements and questions about the world, it is essential to represent this kind of knowledge.

[ 15 ] In addition to McCarthy and Hayes' situation calculus, one of the most ambitious programs to tackle this problem was Doug Lenat's Cyc project. Cyc established its own Frame language and had large numbers of analysts document various areas of common-sense reasoning in that language. The knowledge recorded in Cyc included common-sense models of time, causality, physics, intentions, and many others.

[ 16 ] The starting point for knowledge representation is the knowledge representation hypothesis first formalized by Brian C. Smith in 1985: [ 17 ] Any mechanically embodied intelligent process will be comprised of structural ingredients that a) we as external observers naturally take to represent a propositional account of the knowledge that the overall process exhibits, and b) independent of such external semantic attribution, play a formal but causal and essential role in engendering the behavior that manifests that knowledge.

One of the most active areas of knowledge representation research is the Semantic Web .

[ citation needed ] The Semantic Web seeks to add a layer of semantics (meaning) on top of the current Internet. Rather than indexing web sites and pages via keywords, the Semantic Web creates large ontologies of concepts. Searching for a concept will be more effective than traditional text only searches. Frame languages and automatic classification play a big part in the vision for the future Semantic Web. The automatic classification gives developers technology to provide order on a constantly evolving network of knowledge. Defining ontologies that are static and incapable of evolving on the fly would be very limiting for Internet-based systems. The classifier technology provides the ability to deal with the dynamic environment of the Internet.

Recent projects funded primarily by the Defense Advanced Research Projects Agency (DARPA) have integrated frame languages and classifiers with markup languages based on XML. The Resource Description Framework (RDF) provides the basic capability to define classes, subclasses, and properties of objects. The Web Ontology Language (OWL) provides additional levels of semantics and enables integration with classification engines.

[ 18 ] [ 19 ] Overview [ edit ] Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used for solving complex problems.

The justification for knowledge representation is that conventional procedural code is not the best formalism to use to solve complex problems. Knowledge representation makes complex software easier to define and maintain than procedural code and can be used in expert systems .

For example, talking to experts in terms of business rules rather than code lessens the semantic gap between users and developers and makes development of complex systems more practical.

Knowledge representation goes hand in hand with automated reasoning because one of the main purposes of explicitly representing knowledge is to be able to reason about that knowledge, to make inferences, assert new knowledge, etc. Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.

[ 20 ] A key trade-off in the design of knowledge representation formalisms is that between expressivity and tractability.

[ 21 ] First Order Logic (FOL), with its high expressive power and ability to formalise much of mathematics, is a standard for comparing the expressibility of  knowledge representation languages.

Arguably, FOL has two drawbacks as a knowledge representation formalism in its own right, namely ease of use and efficiency of implementation. Firstly, because of its high expressive power, FOL allows many ways of expressing the same information, and this can make it hard for users to formalise or even to understand knowledge expressed in complex, mathematically-oriented ways. Secondly, because of its complex proof procedures, it can be difficult for users to understand complex proofs and explanations, and it can be hard for implementations to be efficient. As a consequence, unrestricted FOL can be intimidating for many software developers.

One of the key discoveries of AI research in the 1970s was that languages that do not have the full expressive power of FOL can still provide close to the same expressive power of FOL, but can be easier for both the average developer and for the computer to understand. Many of the early AI knowledge representation formalisms, from databases to semantic nets to production systems, can be viewed as making various design decisions about how to balance expressive power with naturalness of expression and efficiency.

[ 22 ] In particular, this balancing act was a driving motivation for the development of IF-THEN rules in rule-based expert systems.

A similar balancing act was also a motivation for the development of logic programming (LP) and the logic programming language Prolog . Logic programs have a rule-based syntax, which is easily confused with the IF-THEN syntax of production rules . But logic programs have a well-defined logical semantics, whereas production systems do not.

The earliest form of logic programming was based on the Horn clause subset of FOL. But later extensions of LP included the negation as failure inference rule, which turns LP into a non-monotonic logic for default reasoning . The resulting extended semantics of LP is a variation of the standard semantics of Horn clauses and FOL, and is a form of database semantics, [ 23 ] which includes the unique name assumption and a form of closed world assumption . These assumptions are much harder to state and reason with explicitly using the standard semantics of FOL.

In a key 1993 paper on the topic, Randall Davis of MIT outlined five distinct roles to analyze a knowledge representation framework: [ 24 ] "A knowledge representation (KR) is most fundamentally a surrogate, a substitute for the thing itself, used to enable an entity to determine consequences by thinking rather than acting," [ 24 ] i.e., "by reasoning about the world rather than taking action in it." [ 24 ] "It is a set of ontological commitments", [ 24 ] i.e., "an answer to the question: In what terms should I think about the world?" [ 24 ] "It is a fragmentary theory of intelligent reasoning, expressed in terms of three components: (i) the representation's fundamental conception of intelligent reasoning; (ii) the set of inferences the representation sanctions; and (iii) the set of inferences it recommends." [ 24 ] "It is a medium for pragmatically efficient computation", [ 24 ] i.e., "the computational environment in which thinking is accomplished. One contribution to this pragmatic efficiency is supplied by the guidance a representation provides for organizing information" [ 24 ] so as "to facilitate making the recommended inferences." [ 24 ] "It is a medium of human expression", [ 24 ] i.e., "a language in which we say things about the world." [ 24 ] Knowledge representation and reasoning are a key enabling technology for the Semantic Web . Languages based on the Frame model with automatic classification provide a layer of semantics on top of the existing Internet. Rather than searching via text strings as is typical today, it will be possible to define logical queries and find pages that map to those queries.

[ 18 ] The automated reasoning component in these systems is an engine known as the classifier. Classifiers focus on the subsumption relations in a knowledge base rather than rules. A classifier can infer new classes and dynamically change the ontology as new information becomes available. This capability is ideal for the ever-changing and evolving information space of the Internet.

[ 25 ] The Semantic Web integrates concepts from knowledge representation and reasoning with markup languages based on XML.  The Resource Description Framework (RDF) provides the basic capabilities to define knowledge-based objects on the Internet with basic features such as Is-A relations and object properties. The Web Ontology Language (OWL) adds additional semantics and integrates with automatic classification reasoners.

[ 19 ] Characteristics [ edit ] In 1985, Ron Brachman categorized the core issues for knowledge representation as follows: [ 26 ] Primitives. What is the underlying framework used to represent knowledge?

Semantic networks were one of the first knowledge representation primitives. Also, data structures and algorithms for general fast search. In this area, there is a strong overlap with research in data structures and algorithms in computer science. In early systems, the Lisp programming language, which was modeled after the lambda calculus , was often used as a form of functional knowledge representation. Frames and Rules were the next kind of primitive. Frame languages had various mechanisms for expressing and enforcing constraints on frame data. All data in frames are stored in slots. Slots are analogous to relations in entity-relation modeling and to object properties in object-oriented modeling. Another technique for primitives is to define languages that are modeled after First Order Logic (FOL). The most well known example is Prolog , but there are also many special-purpose theorem-proving environments. These environments can validate logical models and can deduce new theories from existing models. Essentially they automate the process a logician would go through in analyzing a model. Theorem-proving technology had some specific practical applications in the areas of software engineering. For example, it is possible to prove that a software program rigidly adheres to a formal logical specification.

Meta-representation. This is also known as the issue of reflection in computer science. It refers to the ability of a formalism to have access to information about its own state. An example is the meta-object protocol in Smalltalk and CLOS that gives developers runtime access to the class objects and enables them to dynamically redefine the structure of the knowledge base even at runtime. Meta-representation means the knowledge representation language is itself expressed in that language. For example, in most Frame based environments all frames would be instances of a frame class. That class object can be inspected at runtime, so that the object can understand and even change its internal structure or the structure of other parts of the model. In rule-based environments, the rules were also usually instances of rule classes. Part of the meta protocol for rules were the meta rules that prioritized rule firing.

Incompleteness . Traditional logic requires additional axioms and constraints to deal with the real world as opposed to the world of mathematics. Also, it is often useful to associate degrees of confidence with a statement, i.e., not simply say "Socrates is Human" but rather "Socrates is Human with confidence 50%". This was one of the early innovations from expert systems research which migrated to some commercial tools, the ability to associate certainty factors with rules and conclusions. Later research in this area is known as fuzzy logic .

[ 27 ] Definitions and universals vs. facts and defaults. Universals are general statements about the world such as "All humans are mortal". Facts are specific examples of universals such as "Socrates is a human and therefore mortal". In logical terms definitions and universals are about universal quantification while facts and defaults are about existential quantifications . All forms of knowledge representation must deal with this aspect and most do so with some variant of set theory, modeling universals as sets and subsets and definitions as elements in those sets.

Non-monotonic reasoning . Non-monotonic reasoning allows various kinds of hypothetical reasoning. The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability is known as a truth maintenance system .

[ 28 ] Expressive adequacy . The standard that Brachman and most AI researchers use to measure expressive adequacy is usually First Order Logic (FOL). Theoretical limitations mean that a full implementation of FOL is not practical. Researchers should be clear about how expressive (how much of full FOL expressive power) they intend their representation to be.

[ 29 ] Reasoning efficiency. This refers to the runtime efficiency of a system: The ability of the knowledge base to be updated and the reasoner to develop new inferences in a reasonable time. In some ways, this is the flip side of expressive adequacy. In general, the more powerful a representation, the more it has expressive adequacy, the less efficient its automated reasoning engine will be. Efficiency was often an issue, especially for early applications of knowledge representation technology. They were usually implemented in interpreted environments such as Lisp, which were slow compared to more traditional platforms of the time.

Ontology engineering [ edit ] Main articles: Ontology engineering and Ontology language In the early years of knowledge-based systems the knowledge-bases were fairly small. The knowledge-bases that were meant to actually solve real problems rather than do proof of concept demonstrations needed to focus on well defined problems. So for example, not just medical diagnosis as a whole topic, but medical diagnosis of certain kinds of diseases.

As knowledge-based technology scaled up, the need for larger knowledge bases and for modular knowledge bases that could communicate and integrate with each other became apparent. This gave rise to the discipline of ontology engineering, designing and building large knowledge bases that could be used by multiple projects. One of the leading research projects in this area was the Cyc project. Cyc was an attempt to build a huge encyclopedic knowledge base that would contain not just expert knowledge but common-sense knowledge. In designing an artificial intelligence agent, it was soon realized that representing common-sense knowledge, knowledge that humans simply take for granted, was essential to make an AI that could interact with humans using natural language. Cyc was meant to address this problem. The language they defined was known as CycL .

After CycL, a number of ontology languages have been developed. Most are declarative languages , and are either frame languages , or are based on first-order logic . Modularity—the ability to define boundaries around specific domains and problem spaces—is essential for these languages because as stated by Tom Gruber , "Every ontology is a treaty–a social agreement among people with common motive in sharing." There are always many competing and differing views that make any general-purpose ontology impossible. A general-purpose ontology would have to be applicable in any domain and different areas of knowledge need to be unified.

[ 30 ] There is a long history of work attempting to build ontologies for a variety of task domains, e.g., an ontology for liquids, [ 31 ] the lumped element model widely used in representing electronic circuits (e.g.

[ 32 ] ), as well as ontologies for time, belief, and even programming itself. Each of these offers a way to see some part of the world.

The lumped element model, for instance, suggests that we think of circuits in terms of components with connections between them, with signals flowing instantaneously along the connections. This is a useful view, but not the only possible one. A different ontology arises if we need to attend to the electrodynamics in the device: Here signals propagate at finite speed and an object (like a resistor) that was previously viewed as a single component with an I/O behavior may now have to be thought of as an extended medium through which an electromagnetic wave flows.

Ontologies can of course be written down in a wide variety of languages and notations (e.g., logic, LISP, etc.); the essential information is not the form of that language but the content, i.e., the set of concepts offered as a way of thinking about the world. Simply put, the important part is notions like connections and components, not the choice between writing them as predicates or LISP constructs.

The commitment made selecting one or another ontology can produce a sharply different view of the task at hand. Consider the difference that arises in selecting the lumped element view of a circuit rather than the electrodynamic view of the same device. As a second example, medical diagnosis viewed in terms of rules (e.g., MYCIN ) looks substantially different from the same task viewed in terms of frames (e.g., INTERNIST). Where MYCIN sees the medical world as made up of empirical associations connecting symptom to disease, INTERNIST sees a set of prototypes, in particular prototypical diseases, to be matched against the case at hand.

See also [ edit ] Alphabet of human thought – Hypothetical language created by Gottfried Wilhelm Leibniz Belief revision – Process of changing beliefs to take into account a new piece of information Chunking (psychology) – Cognitive psychology process Commonsense knowledge base – Facts assumed to be known to all humans Conceptual graph – Formalism for knowledge representation DIKW pyramid – Data, information, knowledge, wisdom hierarchy DATR , a language for lexical knowledge representation FO(.) , a KR language based on first-order logic Knowledge graph – Type of knowledge base Knowledge management – Processing of knowledge to accomplish organizational goals Logic programming – Programming paradigm based on formal logic Logico-linguistic modeling Mind map – Diagram to visually organize information Semantic technology – Technology to help machines understand data Valuation-based system References [ edit ] ^ Schank, Roger; Abelson, Robert (1977).

Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures . Lawrence Erlbaum Associates, Inc.

^ Porter, Bruce; Lifschitz, Vladimir; Van Harmelen, Frank (2008).

Handbook of knowledge representation . Foundations of artificial intelligence (1st ed.). Amsterdam Boston: Elsevier.

ISBN 978-0-444-52211-5 .

^ Smolensky, Paul (March 1988).

"On the proper treatment of connectionism" .

Behavioral and Brain Sciences .

11 (1): 1– 23.

doi : 10.1017/S0140525X00052432 .

ISSN 0140-525X .

^ Zhang, Heng; Jiang, Guifei; Quan, Donghui (2025-04-11).

"A Theory of Formalisms for Representing Knowledge" .

Proceedings of the AAAI Conference on Artificial Intelligence .

39 (14): 15257– 15264.

arXiv : 2412.11855 .

doi : 10.1609/aaai.v39i14.33674 .

ISSN 2374-3468 .

^ Doran, J. E.; Michie, D. (1966-09-20). "Experiments with the Graph Traverser program".

Proc. R. Soc. Lond. A .

294 (1437): 235– 259.

Bibcode : 1966RSPSA.294..235D .

doi : 10.1098/rspa.1966.0205 .

S2CID 21698093 .

^ Green, Cordell.

Application of Theorem Proving to Problem Solving (PDF) . IJCAI 1969.

^ Hewitt, C., 2009. Inconsistency robustness in logic programs. arXiv preprint arXiv:0904.3036.

^ Kowalski, Robert (1986).

"The limitation of logic" .

Proceedings of the 1986 ACM fourteenth annual conference on Computer science - CSC '86 . pp.

7– 13.

doi : 10.1145/324634.325168 .

ISBN 0-89791-177-6 .

S2CID 17211581 .

^ Nilsson, Nils (1995). "Eye on the Prize".

AI Magazine .

16 : 2.

^ Hayes-Roth, Frederick; Waterman, Donald; Lenat, Douglas (1983).

Building Expert Systems . Addison-Wesley.

ISBN 978-0-201-10686-2 .

^ Marvin Minsky, A Framework for Representing Knowledge Archived 2021-01-07 at the Wayback Machine , MIT-AI Laboratory Memo 306, June, 1974 ^ Mettrey, William (1987).

"An Assessment of Tools for Building Large Knowledge-Based Systems" .

AI Magazine .

8 (4). Archived from the original on 2013-11-10 . Retrieved 2013-12-24 .

^ Brachman, Ron (1978).

"A Structural Paradigm for Representing Knowledge" (PDF) .

Bolt, Beranek, and Neumann Technical Report (3605).

Archived (PDF) from the original on April 30, 2020.

^ MacGregor, Robert (June 1991). "Using a description classifier to enhance knowledge representation".

IEEE Expert .

6 (3): 41– 46.

doi : 10.1109/64.87683 .

S2CID 29575443 .

^ McCarthy, J., and Hayes, P. J. 1969.

"Some philosophical problems from the standpoint of artificial intelligence" (PDF) . Archived from the original on August 25, 2013 . Retrieved January 18, 2024 .

{{ cite web }} :  CS1 maint: bot: original URL status unknown ( link ) . In Meltzer, B., and Michie, D., eds., Machine Intelligence 4. Edinburgh: Edinburgh University Press. 463–502.

^ Lenat, Doug; R. V. Guha (January 1990).

Building Large Knowledge-Based Systems: Representation and Inference in the Cyc Project . Addison-Wesley.

ISBN 978-0201517521 .

^ Smith, Brian C. (1985).

"Prologue to Reflections and Semantics in a Procedural Language" . In Ronald Brachman and Hector J. Levesque (ed.).

Readings in Knowledge Representation . Morgan Kaufmann. pp.

31–40 .

ISBN 978-0-934613-01-9 .

^ a b Berners-Lee, Tim; Hendler, James; Lassila, Ora (May 17, 2001).

"The Semantic Web – A new form of Web content that is meaningful to computers will unleash a revolution of new possibilities" .

Scientific American .

284 (5): 34– 43.

doi : 10.1038/scientificamerican0501-34 . Archived from the original on April 24, 2013.

^ a b Knublauch, Holger; Oberle, Daniel; Tetlow, Phil; Wallace, Evan (2006-03-09).

"A Semantic Web Primer for Object-Oriented Software Developers" .

W3C .

Archived from the original on 2018-01-06 . Retrieved 2008-07-30 .

^ Hayes-Roth, Frederick; Waterman, Donald; Lenat, Douglas (1983).

Building Expert Systems . Addison-Wesley. pp.

6–7 .

ISBN 978-0-201-10686-2 .

^ Levesque, H.J. and Brachman, R.J., 1987. Expressiveness and tractability in knowledge representation and reasoning 1. Computational intelligence, 3(1), pp.78-93.

^ Levesque, Hector; Brachman, Ronald (1985).

"A Fundamental Tradeoff in Knowledge Representation and Reasoning" . In Ronald Brachman and Hector J. Levesque (ed.).

Readings in Knowledge Representation . Morgan Kaufmann. p.

49 .

ISBN 978-0-934613-01-9 .

The good news in reducing KR service to theorem proving is that we now have a very clear, very specific notion of what the KR system should do; the bad new is that it is also clear that the services can not be provided... deciding whether or not a sentence in FOL is a theorem... is unsolvable.

^ Russell, Stuart J.

; Norvig, Peter.

(2021).

Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. p. 282.

ISBN 978-0134610993 .

LCCN 20190474 .

^ a b c d e f g h i j k Davis, Randall; Shrobe, Howard; Szolovits, Peter (Spring 1993).

"What Is a Knowledge Representation?" .

AI Magazine .

14 (1): 17– 33.

Archived from the original on 2012-04-06 . Retrieved 2011-03-23 .

^ Macgregor, Robert (August 13, 1999).

"Retrospective on Loom" .

isi.edu . Information Sciences Institute. Archived from the original on 25 October 2013 . Retrieved 10 December 2013 .

^ Brachman, Ron (1985). "Introduction". In Brachman, Ronald; Levesque, Hector J. (eds.).

Readings in Knowledge Representation . Morgan Kaufmann. pp.

XVI– XVII.

ISBN 978-0-934613-01-9 .

^ Bih, Joseph (2006).

"Paradigm Shift: An Introduction to Fuzzy Logic" (PDF) .

IEEE Potentials .

25 (1): 6– 21.

Bibcode : 2006IPot...25a...6B .

doi : 10.1109/MP.2006.1635021 .

S2CID 15451765 .

Archived (PDF) from the original on 12 June 2014 . Retrieved 24 December 2013 .

^ Zlatarva, Nellie (1992). "Truth Maintenance Systems and their Application for Verifying Expert System Knowledge Bases".

Artificial Intelligence Review .

6 : 67– 110.

doi : 10.1007/bf00155580 .

S2CID 24696160 .

^ Levesque, Hector; Brachman, Ronald (1985).

"A Fundamental Tradeoff in Knowledge Representation and Reasoning" . In Ronald Brachman and Hector J. Levesque (ed.).

Readings in Knowledge Representation . Morgan Kaufmann. pp.

41–70 .

ISBN 978-0-934613-01-9 .

^ Russell, Stuart J.; Norvig, Peter (2010), Artificial Intelligence: A Modern Approach (3rd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-604259-7 , p. 437-439 ^ Hayes P, Naive physics I: Ontology for liquids. University of Essex report, 1978, Essex, UK.

^ Davis R, Shrobe H E, Representing Structure and Behavior of Digital Hardware, IEEE Computer, Special Issue on Knowledge Representation, 16(10):75-82.

Further reading [ edit ] Ronald J. Brachman ; What IS-A is and isn't. An Analysis of Taxonomic Links in Semantic Networks ; IEEE Computer, 16 (10); October 1983 Ronald J. Brachman , Hector J. Levesque Knowledge Representation and Reasoning , Morgan Kaufmann, 2004 ISBN 978-1-55860-932-7 Ronald J. Brachman , Hector J. Levesque (eds) Readings in Knowledge Representation , Morgan Kaufmann, 1985, ISBN 0-934613-01-X Chein, M., Mugnier, M.-L. (2009), Graph-based Knowledge Representation: Computational Foundations of Conceptual Graphs , Springer, 2009, ISBN 978-1-84800-285-2 .

Randall Davis, Howard Shrobe, and Peter Szolovits; What Is a Knowledge Representation?

AI Magazine, 14(1):17-33,1993 Ronald Fagin , Joseph Y. Halpern , Yoram Moses , Moshe Y. Vardi Reasoning About Knowledge , MIT Press, 1995, ISBN 0-262-06162-7 Jean-Luc Hainaut, Jean-Marc Hick, Vincent Englebert, Jean Henrard, Didier Roland: Understanding Implementations of IS-A Relations . ER 1996: 42-57 Hermann Helbig: Knowledge Representation and the Semantics of Natural Language , Springer, Berlin, Heidelberg, New York 2006 Frank van Harmelen, Vladimir Lifschitz and Bruce Porter: Handbook of Knowledge Representation 2007.

Arthur B. Markman: Knowledge Representation Lawrence Erlbaum Associates, 1998 John F. Sowa : Knowledge Representation : Logical, Philosophical, and Computational Foundations. Brooks/Cole: New York, 2000 Adrian Walker, Michael McCord, John F. Sowa , and Walter G. Wilson: Knowledge Systems and Prolog , Second Edition, Addison-Wesley, 1990 Mary-Anne Williams and Hans Rott: "Frontiers in Belief Revision, Kluwer", 2001.

External links [ edit ] Wikimedia Commons has media related to Knowledge representation .

What is a Knowledge Representation?

by Randall Davis and others Introduction to Knowledge Modeling by Pejman Makhfi Introduction to Description Logics course by Enrico Franconi, Faculty of Computer Science, Free University of Bolzano, Italy DATR Lexical knowledge representation language Loom Project Home Page Principles of Knowledge Representation and Reasoning Incorporated Description Logic in Practice: A CLASSIC Application The Rule Markup Initiative Nelements KOS [ usurped ] - a non-free 3d knowledge representation system v t e Knowledge representation and reasoning Backward chaining Case-based reasoning Commonsense reasoning Forward chaining Model-based reasoning Inference engines Proof assistants Knowledge engineering Expert systems CLIPS Connectionist expert systems Expert systems for mortgages Legal expert systems Reasoning systems Theorem provers Constraint solvers Deductive classifiers Logic programs Procedural reasoning systems Rule engines Ontology languages Attempto Controlled English CycL F-logic FO(.) Knowledge Interchange Format Web Ontology Language Theorem provers CARINE E Nqthm Otter Paradox Prover9 SPASS TPS Z3 Constraint satisfaction Constraint programming Constraint logic programming Local consistency SMT solvers Automated planning Motion planning Multi-agent planning Partial-order planning Preference-based planning Reactive planning State-space planning v t e Computer science Note: This template roughly follows the 2012 ACM Computing Classification System .

Hardware Printed circuit board Peripheral Integrated circuit Very-large-scale integration System on a chip (SoC) Energy consumption (green computing) Electronic design automation Hardware acceleration Processor Size / Form Computer systems organization Computer architecture Computational complexity Dependability Embedded system Real-time computing Cyber-physical system Fault tolerance Wireless sensor network Networks Network architecture Network protocol Network components Network scheduler Network performance evaluation Network service Software organization Interpreter Middleware Virtual machine Operating system Software quality Software notations and tools Programming paradigm Programming language Compiler Domain-specific language Modeling language Software framework Integrated development environment Software configuration management Software library Software repository Software development Control variable Software development process Requirements analysis Software design Software construction Software deployment Software engineering Software maintenance Programming team Open-source model Theory of computation Model of computation Stochastic Formal language Automata theory Computability theory Computational complexity theory Logic Semantics Algorithms Algorithm design Analysis of algorithms Algorithmic efficiency Randomized algorithm Computational geometry Mathematics of computing Discrete mathematics Probability Statistics Mathematical software Information theory Mathematical analysis Numerical analysis Theoretical computer science Information systems Database management system Information storage systems Enterprise information system Social information systems Geographic information system Decision support system Process control system Multimedia information system Data mining Digital library Computing platform Digital marketing World Wide Web Information retrieval Security Cryptography Formal methods Security hacker Security services Intrusion detection system Hardware security Network security Information security Application security Human–centered computing Interaction design Augmented reality Virtual reality Social computing Ubiquitous computing Visualization Accessibility Human–computer interaction Mobile computing Concurrency Concurrent computing Parallel computing Distributed computing Multithreading Multiprocessing Artificial intelligence Natural language processing Knowledge representation and reasoning Computer vision Automated planning and scheduling Search methodology Control method Philosophy of artificial intelligence Distributed artificial intelligence Machine learning Supervised learning Unsupervised learning Reinforcement learning Multi-task learning Cross-validation Graphics Animation Rendering Photograph manipulation Graphics processing unit Image compression Solid modeling Applied computing Quantum computing E-commerce Enterprise software Computational mathematics Computational physics Computational chemistry Computational biology Computational social science Computational engineering Differentiable computing Computational healthcare Digital art Electronic publishing Cyberwarfare Electronic voting Video games Word processing Operations research Educational technology Document management Category Outline Glossaries Authority control databases National Germany United States France BnF data Israel Other Yale LUX Retrieved from " https://en.wikipedia.org/w/index.php?title=Knowledge_representation_and_reasoning&oldid=1303587197 " Categories : Knowledge representation Intelligence assessment Scientific modelling Programming paradigms Automated reasoning Hidden categories: Webarchive template wayback links CS1 maint: bot: original URL status unknown Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from February 2021 Commons category link is on Wikidata This page was last edited on 31 July 2025, at 21:31 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Knowledge representation and reasoning 33 languages Add topic

