Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Construction 2 Adjunction and universal property 3 Non-commutative polynomials 4 Quotients 5 Coalgebra Toggle Coalgebra subsection 5.1 Coproduct 5.2 Counit 6 Bialgebra Toggle Bialgebra subsection 6.1 Multiplication 6.2 Unit 6.3 Compatibility 7 Hopf algebra Toggle Hopf algebra subsection 7.1 Compatibility 8 Cofree cocomplete coalgebra 9 See also 10 References Toggle the table of contents Tensor algebra 15 languages العربية Català Deutsch Español Français 한국어 עברית Nederlands 日本語 Português Русский Svenska Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Universal construction in multilinear algebra In mathematics , the tensor algebra of a vector space V , denoted T ( V ) or T • ( V ), is the algebra of tensors on V (of any rank) with multiplication being the tensor product . It is the free algebra on V , in the sense of being left adjoint to the forgetful functor from algebras to vector spaces: it is the "most general" algebra containing V , in the sense of the corresponding universal property (see below ).

The tensor algebra is important because many other algebras arise as quotient algebras of T ( V ).  These include the exterior algebra , the symmetric algebra , Clifford algebras , the Weyl algebra and universal enveloping algebras .

The tensor algebra also has two coalgebra structures; one simple one, which does not make it a bi-algebra, but does lead to the concept of a cofree coalgebra , and a more complicated one, which yields a bialgebra , and can be extended by giving an antipode to create a Hopf algebra structure.

Note : In this article, all algebras are assumed to be unital and associative . The unit is explicitly required to define the coproduct .

Construction [ edit ] Let V be a vector space over a field K . For any nonnegative integer k , we define the k th tensor power of V to be the tensor product of V with itself k times: T k V = V ⊗ ⊗ k = V ⊗ ⊗ V ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ V .

{\displaystyle T^{k}V=V^{\otimes k}=V\otimes V\otimes \cdots \otimes V.} That is, T k V consists of all tensors on V of order k . By convention T 0 V is the ground field K (as a one-dimensional vector space over itself).

We then construct T ( V ) as the direct sum of T k V for k = 0,1,2,… T ( V ) = ⨁ ⨁ k = 0 ∞ ∞ T k V = K ⊕ ⊕ V ⊕ ⊕ ( V ⊗ ⊗ V ) ⊕ ⊕ ( V ⊗ ⊗ V ⊗ ⊗ V ) ⊕ ⊕ ⋯ ⋯ .

{\displaystyle T(V)=\bigoplus _{k=0}^{\infty }T^{k}V=K\oplus V\oplus (V\otimes V)\oplus (V\otimes V\otimes V)\oplus \cdots .} The multiplication in T ( V ) is determined by the canonical isomorphism T k V ⊗ ⊗ T ℓ ℓ V → → T k + ℓ ℓ V {\displaystyle T^{k}V\otimes T^{\ell }V\to T^{k+\ell }V} given by the tensor product, which is then extended by linearity to all of T ( V ). This multiplication rule implies that the tensor algebra T ( V ) is naturally a graded algebra with T k V serving as the grade- k subspace. This grading can be extended to a Z -grading by appending subspaces T k V = { 0 } {\displaystyle T^{k}V=\{0\}} for negative integers k .

The construction generalizes in a straightforward manner to the tensor algebra of any module M over a commutative ring . If R is a non-commutative ring , one can still perform the construction for any R - R bimodule M . (It does not work for ordinary R -modules because the iterated tensor products cannot be formed.) Adjunction and universal property [ edit ] The tensor algebra T ( V ) is also called the free algebra on the vector space V , and is functorial ; this means that the map V ↦ ↦ T ( V ) {\displaystyle V\mapsto T(V)} extends to linear maps for forming a functor from the category of K -vector spaces to the category of associative algebras . Similarly with other free constructions , the functor T is left adjoint to the forgetful functor that sends each associative K -algebra to its underlying vector space.

Explicitly, the tensor algebra satisfies the following universal property , which formally expresses the statement that it is the most general algebra containing V : Any linear map f : V → → A {\displaystyle f:V\to A} from V to an associative algebra A over K can be uniquely extended to an algebra homomorphism from T ( V ) to A as indicated by the following commutative diagram : Universal property of the tensor algebra Here i is the canonical inclusion of V into T ( V ) . As for other universal properties, the tensor algebra T ( V ) can be defined as the unique algebra satisfying this property (specifically, it is unique up to a unique isomorphism), but this definition requires to prove that an object satisfying this property exists.

The above universal property implies that T is a functor from  the category of vector spaces over K , to the category of K -algebras. This means that any linear map between K -vector spaces U and W extends uniquely to a K -algebra homomorphism from T ( U ) to T ( W ) .

Non-commutative polynomials [ edit ] If V has finite dimension n , another way of looking at the tensor algebra is as the "algebra of polynomials over K in n non-commuting variables". If we take basis vectors for V , those become non-commuting variables (or indeterminates ) in T ( V ), subject to no constraints beyond associativity , the distributive law and K -linearity.

Note that the algebra of polynomials on V is not T ( V ) {\displaystyle T(V)} , but rather T ( V ∗ ∗ ) {\displaystyle T(V^{*})} : a (homogeneous) linear function on V is an element of V ∗ ∗ , {\displaystyle V^{*},} for example coordinates x 1 , … … , x n {\displaystyle x^{1},\dots ,x^{n}} on a vector space are covectors , as they take in a vector and give out a scalar (the given coordinate of the vector).

Quotients [ edit ] Because of the generality of the tensor algebra, many other algebras of interest can be constructed by starting with the tensor algebra and then imposing certain relations on the generators, i.e. by constructing certain quotient algebras of T ( V ).  Examples of this are the exterior algebra , the symmetric algebra , Clifford algebras , the Weyl algebra and universal enveloping algebras .

Coalgebra [ edit ] The tensor algebra has two different coalgebra structures. One is compatible with the tensor product, and thus can be extended to a bialgebra , and can be further be extended with an antipode to a Hopf algebra structure. The other structure, although simpler, cannot be extended to a bialgebra. The first structure is developed immediately below; the second structure is given in the section on the cofree coalgebra , further down.

The development provided below can be equally well applied to the exterior algebra , using the wedge symbol ∧ ∧ {\displaystyle \wedge } in place of the tensor symbol ⊗ ⊗ {\displaystyle \otimes } ; a sign must also be kept track of, when permuting elements of the exterior algebra. This correspondence also lasts through the definition of the bialgebra, and on to the definition of a Hopf algebra. That is, the exterior algebra can also be given a Hopf algebra structure.

Similarly, the symmetric algebra can also be given the structure of a Hopf algebra, in exactly the same fashion, by replacing everywhere the tensor product ⊗ ⊗ {\displaystyle \otimes } by the symmetrized tensor product ⊗ ⊗ S y m {\displaystyle \otimes _{\mathrm {Sym} }} , i.e. that product where v ⊗ ⊗ S y m w = w ⊗ ⊗ S y m v .

{\displaystyle v\otimes _{\mathrm {Sym} }w=w\otimes _{\mathrm {Sym} }v.} In each case, this is possible because the alternating product ∧ ∧ {\displaystyle \wedge } and the symmetric product ⊗ ⊗ S y m {\displaystyle \otimes _{\mathrm {Sym} }} obey the required consistency conditions for the definition of a bialgebra and Hopf algebra; this can be explicitly checked in the manner below. Whenever one has a product obeying these consistency conditions, the construction goes through; insofar as such a product gave rise to a quotient space, the quotient space inherits the Hopf algebra structure.

In the language of category theory , one says that there is a functor T from the category of K -vector spaces to the category of K -associative algebras. But there is also a functor Λ taking vector spaces to the category of exterior algebras, and a functor Sym taking vector spaces to symmetric algebras. There is a natural map from T to each of these. Verifying that quotienting preserves the Hopf algebra structure is the same as verifying that the maps are indeed natural.

Coproduct [ edit ] The coalgebra is obtained by defining a coproduct or diagonal operator Δ Δ : T V → → T V ⊠ ⊠ T V {\displaystyle \Delta :TV\to TV\boxtimes TV} Here, T V {\displaystyle TV} is used as a short-hand for T ( V ) {\displaystyle T(V)} to avoid an explosion of parentheses. The ⊠ ⊠ {\displaystyle \boxtimes } symbol is used to denote the "external" tensor product, needed for the definition of a coalgebra.  It is being used to distinguish it from the "internal" tensor product ⊗ ⊗ {\displaystyle \otimes } , which is already being used to denote multiplication in the tensor algebra (see the section Multiplication , below, for further clarification on this issue). In order to avoid confusion between these two symbols, most texts will replace ⊗ ⊗ {\displaystyle \otimes } by a plain dot, or even drop it altogether, with the understanding that it is implied from context. This then allows the ⊗ ⊗ {\displaystyle \otimes } symbol to be used in place of the ⊠ ⊠ {\displaystyle \boxtimes } symbol. This is not done below, and the two symbols are used independently and explicitly, so as to show the proper location of each.  The result is a bit more verbose, but should be easier to comprehend.

The definition of the operator Δ Δ {\displaystyle \Delta } is most easily built up in stages, first by defining it for elements v ∈ ∈ V ⊂ ⊂ T V {\displaystyle v\in V\subset TV} and then by homomorphically extending it to the whole algebra.  A suitable choice for the coproduct is then Δ Δ : v ↦ ↦ v ⊠ ⊠ 1 + 1 ⊠ ⊠ v {\displaystyle \Delta :v\mapsto v\boxtimes 1+1\boxtimes v} and Δ Δ : 1 ↦ ↦ 1 ⊠ ⊠ 1 {\displaystyle \Delta :1\mapsto 1\boxtimes 1} where 1 ∈ ∈ K = T 0 V ⊂ ⊂ T V {\displaystyle 1\in K=T^{0}V\subset TV} is the unit of the field K {\displaystyle K} . By linearity, one obviously has Δ Δ ( k ) = k ( 1 ⊠ ⊠ 1 ) = k ⊠ ⊠ 1 = 1 ⊠ ⊠ k {\displaystyle \Delta (k)=k(1\boxtimes 1)=k\boxtimes 1=1\boxtimes k} for all k ∈ ∈ K .

{\displaystyle k\in K.} It is straightforward to verify that this definition satisfies the axioms of a coalgebra: that is, that ( i d T V ⊠ ⊠ Δ Δ ) ∘ ∘ Δ Δ = ( Δ Δ ⊠ ⊠ i d T V ) ∘ ∘ Δ Δ {\displaystyle (\mathrm {id} _{TV}\boxtimes \Delta )\circ \Delta =(\Delta \boxtimes \mathrm {id} _{TV})\circ \Delta } where i d T V : x ↦ ↦ x {\displaystyle \mathrm {id} _{TV}:x\mapsto x} is the identity map on T V {\displaystyle TV} .  Indeed, one gets ( ( i d T V ⊠ ⊠ Δ Δ ) ∘ ∘ Δ Δ ) ( v ) = v ⊠ ⊠ 1 ⊠ ⊠ 1 + 1 ⊠ ⊠ v ⊠ ⊠ 1 + 1 ⊠ ⊠ 1 ⊠ ⊠ v {\displaystyle ((\mathrm {id} _{TV}\boxtimes \Delta )\circ \Delta )(v)=v\boxtimes 1\boxtimes 1+1\boxtimes v\boxtimes 1+1\boxtimes 1\boxtimes v} and likewise for the other side. At this point, one could invoke a lemma, and say that Δ Δ {\displaystyle \Delta } extends trivially, by linearity, to all of T V {\displaystyle TV} , because T V {\displaystyle TV} is a free object and V {\displaystyle V} is a generator of the free algebra, and Δ Δ {\displaystyle \Delta } is a homomorphism. However, it is insightful to provide explicit expressions. So, for v ⊗ ⊗ w ∈ ∈ T 2 V {\displaystyle v\otimes w\in T^{2}V} , one has (by definition) the homomorphism Δ Δ : v ⊗ ⊗ w ↦ ↦ Δ Δ ( v ) ⊗ ⊗ Δ Δ ( w ) {\displaystyle \Delta :v\otimes w\mapsto \Delta (v)\otimes \Delta (w)} Expanding, one has Δ Δ ( v ⊗ ⊗ w ) = ( v ⊠ ⊠ 1 + 1 ⊠ ⊠ v ) ⊗ ⊗ ( w ⊠ ⊠ 1 + 1 ⊠ ⊠ w ) = ( v ⊗ ⊗ w ) ⊠ ⊠ 1 + v ⊠ ⊠ w + w ⊠ ⊠ v + 1 ⊠ ⊠ ( v ⊗ ⊗ w ) {\displaystyle {\begin{aligned}\Delta (v\otimes w)&=(v\boxtimes 1+1\boxtimes v)\otimes (w\boxtimes 1+1\boxtimes w)\\&=(v\otimes w)\boxtimes 1+v\boxtimes w+w\boxtimes v+1\boxtimes (v\otimes w)\end{aligned}}} In the above expansion, there is no need to ever write 1 ⊗ ⊗ v {\displaystyle 1\otimes v} as this is just plain-old scalar multiplication in the algebra; that is, one trivially has that 1 ⊗ ⊗ v = 1 ⋅ ⋅ v = v .

{\displaystyle 1\otimes v=1\cdot v=v.} The extension above preserves the algebra grading. That is, Δ Δ : T 2 V → → ⨁ ⨁ k = 0 2 T k V ⊠ ⊠ T 2 − − k V {\displaystyle \Delta :T^{2}V\to \bigoplus _{k=0}^{2}T^{k}V\boxtimes T^{2-k}V} Continuing in this fashion, one can obtain an explicit expression for the coproduct acting on a homogenous element of order m : Δ Δ ( v 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v m ) = Δ Δ ( v 1 ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ Δ Δ ( v m ) = ∑ ∑ p = 0 m ( v 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v p ) ω ω ( v p + 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v m ) = ∑ ∑ p = 0 m ∑ ∑ σ σ ∈ ∈ S h ( p , m − − p ) ( v σ σ ( 1 ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v σ σ ( p ) ) ⊠ ⊠ ( v σ σ ( p + 1 ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v σ σ ( m ) ) {\displaystyle {\begin{aligned}\Delta (v_{1}\otimes \cdots \otimes v_{m})&=\Delta (v_{1})\otimes \cdots \otimes \Delta (v_{m})\\&=\sum _{p=0}^{m}\left(v_{1}\otimes \cdots \otimes v_{p}\right)\;\omega \;\left(v_{p+1}\otimes \cdots \otimes v_{m}\right)\\&=\sum _{p=0}^{m}\;\sum _{\sigma \in \mathrm {Sh} (p,m-p)}\;\left(v_{\sigma (1)}\otimes \dots \otimes v_{\sigma (p)}\right)\boxtimes \left(v_{\sigma (p+1)}\otimes \dots \otimes v_{\sigma (m)}\right)\end{aligned}}} where the ω ω {\displaystyle \omega } symbol, which should appear as ш, the sha, denotes the shuffle product . This is expressed in the second summation, which is taken over all ( p , m − p )-shuffles . The shuffle is Sh ⁡ ⁡ ( p , q ) = { σ σ : { 1 , … … , p + q } → → { 1 , … … , p + q } ∣ ∣ σ σ is bijective , σ σ ( 1 ) < σ σ ( 2 ) < ⋯ ⋯ < σ σ ( p ) , and σ σ ( p + 1 ) < σ σ ( p + 2 ) < ⋯ ⋯ < σ σ ( m ) } .

{\displaystyle {\begin{aligned}\operatorname {Sh} (p,q)=\{\sigma :\{1,\dots ,p+q\}\to \{1,\dots ,p+q\}\;\mid \;&\sigma {\text{ is bijective}},\;\sigma (1)<\sigma (2)<\cdots <\sigma (p),\\&{\text{and }}\;\sigma (p+1)<\sigma (p+2)<\cdots <\sigma (m)\}.\end{aligned}}} By convention, one takes that Sh( m, 0) and Sh(0, m ) equals {id: {1, ..., m } → {1, ..., m }}. It is also convenient to take the pure tensor products v σ σ ( 1 ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v σ σ ( p ) {\displaystyle v_{\sigma (1)}\otimes \dots \otimes v_{\sigma (p)}} and v σ σ ( p + 1 ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v σ σ ( m ) {\displaystyle v_{\sigma (p+1)}\otimes \dots \otimes v_{\sigma (m)}} to equal 1 for p = 0 and p = m , respectively (the empty product in T V {\displaystyle TV} ). The shuffle follows directly from the first axiom of a co-algebra: the relative order of the elements v k {\displaystyle v_{k}} is preserved in the riffle shuffle: the riffle shuffle merely splits the ordered sequence into two ordered sequences, one on the left, and one on the right.

Equivalently, Δ Δ ( v 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v n ) = ∑ ∑ S ⊆ ⊆ { 1 , … … , n } ( ∏ ∏ k = 1 k ∈ ∈ S n v k ) ⊠ ⊠ ( ∏ ∏ k = 1 k ∉ ∉ S n v k ) , {\displaystyle \Delta (v_{1}\otimes \cdots \otimes v_{n})=\sum _{S\subseteq \{1,\dots ,n\}}\left(\prod _{k=1 \atop k\in S}^{n}v_{k}\right)\boxtimes \left(\prod _{k=1 \atop k\notin S}^{n}v_{k}\right)\!,} where the products are in T V {\displaystyle TV} , and where the sum is over all subsets of { 1 , … … , n } {\displaystyle \{1,\dots ,n\}} .

As before, the algebra grading is preserved: Δ Δ : T m V → → ⨁ ⨁ k = 0 m T k V ⊠ ⊠ T ( m − − k ) V {\displaystyle \Delta :T^{m}V\to \bigoplus _{k=0}^{m}T^{k}V\boxtimes T^{(m-k)}V} Counit [ edit ] The counit ϵ ϵ : T V → → K {\displaystyle \epsilon :TV\to K} is given by the projection of the field component out from the algebra. This can be written as ϵ ϵ : v ↦ ↦ 0 {\displaystyle \epsilon :v\mapsto 0} for v ∈ ∈ V {\displaystyle v\in V} and ϵ ϵ : k ↦ ↦ k {\displaystyle \epsilon :k\mapsto k} for k ∈ ∈ K = T 0 V {\displaystyle k\in K=T^{0}V} .  By homomorphism under the tensor product ⊗ ⊗ {\displaystyle \otimes } , this extends to ϵ ϵ : x ↦ ↦ 0 {\displaystyle \epsilon :x\mapsto 0} for all x ∈ ∈ T 1 V ⊕ ⊕ T 2 V ⊕ ⊕ ⋯ ⋯ {\displaystyle x\in T^{1}V\oplus T^{2}V\oplus \cdots } It is a straightforward matter to verify that this counit satisfies the needed axiom for the coalgebra: ( i d ⊠ ⊠ ϵ ϵ ) ∘ ∘ Δ Δ = i d = ( ϵ ϵ ⊠ ⊠ i d ) ∘ ∘ Δ Δ .

{\displaystyle (\mathrm {id} \boxtimes \epsilon )\circ \Delta =\mathrm {id} =(\epsilon \boxtimes \mathrm {id} )\circ \Delta .} Working this explicitly, one has ( ( i d ⊠ ⊠ ϵ ϵ ) ∘ ∘ Δ Δ ) ( x ) = ( i d ⊠ ⊠ ϵ ϵ ) ( 1 ⊠ ⊠ x + x ⊠ ⊠ 1 ) = 1 ⊠ ⊠ ϵ ϵ ( x ) + x ⊠ ⊠ ϵ ϵ ( 1 ) = 0 + x ⊠ ⊠ 1 ≅ ≅ x {\displaystyle {\begin{aligned}((\mathrm {id} \boxtimes \epsilon )\circ \Delta )(x)&=(\mathrm {id} \boxtimes \epsilon )(1\boxtimes x+x\boxtimes 1)\\&=1\boxtimes \epsilon (x)+x\boxtimes \epsilon (1)\\&=0+x\boxtimes 1\\&\cong x\end{aligned}}} where, for the last step, one has made use of the isomorphism T V ⊠ ⊠ K ≅ ≅ T V {\displaystyle TV\boxtimes K\cong TV} , as is appropriate for the defining axiom of the counit.

Bialgebra [ edit ] A bialgebra defines both multiplication, and comultiplication, and requires them to be compatible.

Multiplication [ edit ] Multiplication is given by an operator ∇ ∇ : T V ⊠ ⊠ T V → → T V {\displaystyle \nabla :TV\boxtimes TV\to TV} which, in this case, was already given as the "internal" tensor product. That is, ∇ ∇ : x ⊠ ⊠ y ↦ ↦ x ⊗ ⊗ y {\displaystyle \nabla :x\boxtimes y\mapsto x\otimes y} That is, ∇ ∇ ( x ⊠ ⊠ y ) = x ⊗ ⊗ y .

{\displaystyle \nabla (x\boxtimes y)=x\otimes y.} The above should make it clear why the ⊠ ⊠ {\displaystyle \boxtimes } symbol needs to be used: the ⊗ ⊗ {\displaystyle \otimes } was actually one and the same thing as ∇ ∇ {\displaystyle \nabla } ; and notational sloppiness here would lead to utter chaos.  To strengthen this: the tensor product ⊗ ⊗ {\displaystyle \otimes } of the tensor algebra corresponds to the multiplication ∇ ∇ {\displaystyle \nabla } used in the definition of an algebra, whereas the tensor product ⊠ ⊠ {\displaystyle \boxtimes } is the one required in the definition of comultiplication in a coalgebra.  These two tensor products are not the same thing!

Unit [ edit ] The unit for the algebra η η : K → → T V {\displaystyle \eta :K\to TV} is just the embedding, so that η η : k ↦ ↦ k {\displaystyle \eta :k\mapsto k} That the unit is compatible with the tensor product ⊗ ⊗ {\displaystyle \otimes } is "trivial": it is just part of the standard definition of the tensor product of vector spaces.  That is, k ⊗ ⊗ x = k x {\displaystyle k\otimes x=kx} for field element k and any x ∈ ∈ T V .

{\displaystyle x\in TV.} More verbosely, the axioms for an associative algebra require the two homomorphisms (or commuting diagrams): ∇ ∇ ∘ ∘ ( η η ⊠ ⊠ i d T V ) = η η ⊗ ⊗ i d T V = η η ⋅ ⋅ i d T V {\displaystyle \nabla \circ (\eta \boxtimes \mathrm {id} _{TV})=\eta \otimes \mathrm {id} _{TV}=\eta \cdot \mathrm {id} _{TV}} on K ⊠ ⊠ T V {\displaystyle K\boxtimes TV} , and that symmetrically, on T V ⊠ ⊠ K {\displaystyle TV\boxtimes K} , that ∇ ∇ ∘ ∘ ( i d T V ⊠ ⊠ η η ) = i d T V ⊗ ⊗ η η = i d T V ⋅ ⋅ η η {\displaystyle \nabla \circ (\mathrm {id} _{TV}\boxtimes \eta )=\mathrm {id} _{TV}\otimes \eta =\mathrm {id} _{TV}\cdot \eta } where the right-hand side of these equations should be understood as the scalar product.

Compatibility [ edit ] The unit and counit, and multiplication and comultiplication, all have to satisfy compatibility conditions. It is straightforward to see that ϵ ϵ ∘ ∘ η η = i d K .

{\displaystyle \epsilon \circ \eta =\mathrm {id} _{K}.} Similarly, the unit is compatible with comultiplication: Δ Δ ∘ ∘ η η = η η ⊠ ⊠ η η ≅ ≅ η η {\displaystyle \Delta \circ \eta =\eta \boxtimes \eta \cong \eta } The above requires the use of the isomorphism K ⊠ ⊠ K ≅ ≅ K {\displaystyle K\boxtimes K\cong K} in order to work; without this, one loses linearity. Component-wise, ( Δ Δ ∘ ∘ η η ) ( k ) = Δ Δ ( k ) = k ( 1 ⊠ ⊠ 1 ) ≅ ≅ k {\displaystyle (\Delta \circ \eta )(k)=\Delta (k)=k(1\boxtimes 1)\cong k} with the right-hand side making use of the isomorphism.

Multiplication and the counit are compatible: ( ϵ ϵ ∘ ∘ ∇ ∇ ) ( x ⊠ ⊠ y ) = ϵ ϵ ( x ⊗ ⊗ y ) = 0 {\displaystyle (\epsilon \circ \nabla )(x\boxtimes y)=\epsilon (x\otimes y)=0} whenever x or y are not elements of K {\displaystyle K} , and otherwise, one has scalar multiplication on the field: k 1 ⊗ ⊗ k 2 = k 1 k 2 .

{\displaystyle k_{1}\otimes k_{2}=k_{1}k_{2}.} The most difficult to verify is the compatibility of multiplication and comultiplication: Δ Δ ∘ ∘ ∇ ∇ = ( ∇ ∇ ⊠ ⊠ ∇ ∇ ) ∘ ∘ ( i d ⊠ ⊠ τ τ ⊠ ⊠ i d ) ∘ ∘ ( Δ Δ ⊠ ⊠ Δ Δ ) {\displaystyle \Delta \circ \nabla =(\nabla \boxtimes \nabla )\circ (\mathrm {id} \boxtimes \tau \boxtimes \mathrm {id} )\circ (\Delta \boxtimes \Delta )} where τ τ ( x ⊠ ⊠ y ) = y ⊠ ⊠ x {\displaystyle \tau (x\boxtimes y)=y\boxtimes x} exchanges elements. The compatibility condition only needs to be verified on V ⊂ ⊂ T V {\displaystyle V\subset TV} ; the full compatibility follows as a homomorphic extension to all of T V .

{\displaystyle TV.} The verification is verbose but straightforward; it is not given here, except for the final result: ( Δ Δ ∘ ∘ ∇ ∇ ) ( v ⊠ ⊠ w ) = Δ Δ ( v ⊗ ⊗ w ) {\displaystyle (\Delta \circ \nabla )(v\boxtimes w)=\Delta (v\otimes w)} For v , w ∈ ∈ V , {\displaystyle v,w\in V,} an explicit expression for this was given in the coalgebra section, above.

Hopf algebra [ edit ] The Hopf algebra adds an antipode to the bialgebra axioms.  The antipode S {\displaystyle S} on k ∈ ∈ K = T 0 V {\displaystyle k\in K=T^{0}V} is given by S ( k ) = k {\displaystyle S(k)=k} This is sometimes called the "anti-identity". The antipode on v ∈ ∈ V = T 1 V {\displaystyle v\in V=T^{1}V} is given by S ( v ) = − − v {\displaystyle S(v)=-v} and on v ⊗ ⊗ w ∈ ∈ T 2 V {\displaystyle v\otimes w\in T^{2}V} by S ( v ⊗ ⊗ w ) = S ( w ) ⊗ ⊗ S ( v ) = w ⊗ ⊗ v {\displaystyle S(v\otimes w)=S(w)\otimes S(v)=w\otimes v} This extends homomorphically to S ( v 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v m ) = S ( v m ) ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ S ( v 1 ) = ( − − 1 ) m v m ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v 1 {\displaystyle {\begin{aligned}S(v_{1}\otimes \cdots \otimes v_{m})&=S(v_{m})\otimes \cdots \otimes S(v_{1})\\&=(-1)^{m}v_{m}\otimes \cdots \otimes v_{1}\end{aligned}}} Compatibility [ edit ] Compatibility of the antipode with multiplication and comultiplication requires that ∇ ∇ ∘ ∘ ( S ⊠ ⊠ i d ) ∘ ∘ Δ Δ = η η ∘ ∘ ϵ ϵ = ∇ ∇ ∘ ∘ ( i d ⊠ ⊠ S ) ∘ ∘ Δ Δ {\displaystyle \nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta =\eta \circ \epsilon =\nabla \circ (\mathrm {id} \boxtimes S)\circ \Delta } This is straightforward to verify componentwise on k ∈ ∈ K {\displaystyle k\in K} : ( ∇ ∇ ∘ ∘ ( S ⊠ ⊠ i d ) ∘ ∘ Δ Δ ) ( k ) = ( ∇ ∇ ∘ ∘ ( S ⊠ ⊠ i d ) ) ( 1 ⊠ ⊠ k ) = ∇ ∇ ( 1 ⊠ ⊠ k ) = 1 ⊗ ⊗ k = k {\displaystyle {\begin{aligned}(\nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta )(k)&=(\nabla \circ (S\boxtimes \mathrm {id} ))(1\boxtimes k)\\&=\nabla (1\boxtimes k)\\&=1\otimes k\\&=k\end{aligned}}} Similarly, on v ∈ ∈ V {\displaystyle v\in V} : ( ∇ ∇ ∘ ∘ ( S ⊠ ⊠ i d ) ∘ ∘ Δ Δ ) ( v ) = ( ∇ ∇ ∘ ∘ ( S ⊠ ⊠ i d ) ) ( v ⊠ ⊠ 1 + 1 ⊠ ⊠ v ) = ∇ ∇ ( − − v ⊠ ⊠ 1 + 1 ⊠ ⊠ v ) = − − v ⊗ ⊗ 1 + 1 ⊗ ⊗ v = − − v + v = 0 {\displaystyle {\begin{aligned}(\nabla \circ (S\boxtimes \mathrm {id} )\circ \Delta )(v)&=(\nabla \circ (S\boxtimes \mathrm {id} ))(v\boxtimes 1+1\boxtimes v)\\&=\nabla (-v\boxtimes 1+1\boxtimes v)\\&=-v\otimes 1+1\otimes v\\&=-v+v\\&=0\end{aligned}}} Recall that ( η η ∘ ∘ ϵ ϵ ) ( k ) = η η ( k ) = k {\displaystyle (\eta \circ \epsilon )(k)=\eta (k)=k} and that ( η η ∘ ∘ ϵ ϵ ) ( x ) = η η ( 0 ) = 0 {\displaystyle (\eta \circ \epsilon )(x)=\eta (0)=0} for any x ∈ ∈ T V {\displaystyle x\in TV} that is not in K .

{\displaystyle K.} One may proceed in a similar manner, by homomorphism, verifying that the antipode inserts the appropriate cancellative signs in the shuffle, starting with the compatibility condition on T 2 V {\displaystyle T^{2}V} and proceeding by induction.

Cofree cocomplete coalgebra [ edit ] Main article: Cofree coalgebra One may define a different coproduct on the tensor algebra, simpler than the one given above.  It is given by Δ Δ ( v 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v k ) := ∑ ∑ j = 0 k ( v 0 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v j ) ⊠ ⊠ ( v j + 1 ⊗ ⊗ ⋯ ⋯ ⊗ ⊗ v k + 1 ) {\displaystyle \Delta (v_{1}\otimes \dots \otimes v_{k}):=\sum _{j=0}^{k}(v_{0}\otimes \dots \otimes v_{j})\boxtimes (v_{j+1}\otimes \dots \otimes v_{k+1})} Here, as before, one uses the notational trick v 0 = v k + 1 = 1 ∈ ∈ K {\displaystyle v_{0}=v_{k+1}=1\in K} (recalling that v ⊗ ⊗ 1 = v {\displaystyle v\otimes 1=v} trivially).

This coproduct gives rise to a coalgebra. It describes a coalgebra that is dual to the algebra structure on T ( V ∗ ), where V ∗ denotes the dual vector space of linear maps V → F . In the same way that the tensor algebra is a free algebra , the corresponding coalgebra is termed cocomplete co-free.  With the usual product this is not a bialgebra. It can be turned into a bialgebra with the product v i ⋅ ⋅ v j = ( i , j ) v i + j {\displaystyle v_{i}\cdot v_{j}=(i,j)v_{i+j}} where (i,j) denotes the binomial coefficient for ( i + j i ) {\displaystyle {\tbinom {i+j}{i}}} . This bialgebra is known as the divided power Hopf algebra .

The difference between this, and the other coalgebra is most easily seen in the T 2 V {\displaystyle T^{2}V} term.  Here, one has that Δ Δ ( v ⊗ ⊗ w ) = 1 ⊠ ⊠ ( v ⊗ ⊗ w ) + v ⊠ ⊠ w + ( v ⊗ ⊗ w ) ⊠ ⊠ 1 {\displaystyle \Delta (v\otimes w)=1\boxtimes (v\otimes w)+v\boxtimes w+(v\otimes w)\boxtimes 1} for v , w ∈ ∈ V {\displaystyle v,w\in V} , which is clearly missing a shuffled term, as compared to before.

See also [ edit ] Braided vector space Braided Hopf algebra Monoidal category Multilinear algebra Fock space References [ edit ] Bourbaki, Nicolas (1989).

Algebra I. Chapters 1-3 .

Elements of Mathematics .

Springer-Verlag .

ISBN 3-540-64243-9 .

(See Chapter 3 §5) Serge Lang (2002), Algebra , Graduate Texts in Mathematics , vol. 211 (3rd ed.), Springer Verlag , ISBN 978-0-387-95385-4 v t e Algebra Outline History Areas Abstract algebra Algebraic geometry Algebraic variety Scheme Algebraic number theory Category theory Commutative algebra Elementary algebra Homological algebra K-theory Linear algebra Multilinear algebra Noncommutative algebra Order theory Representation theory Universal algebra Basic concepts Algebraic expression Equation ( Linear equation , Quadratic equation ) Function ( Polynomial function ) Inequality ( Linear inequality ) Operation ( Addition , Multiplication ) Relation ( Equivalence relation ) Variable Algebraic structures Field ( theory ) Group ( theory ) Module ( theory ) Ring ( theory ) Vector space ( Vector ) Linear and multilinear algebra Basis Determinant Eigenvalues and eigenvectors Inner product space ( Dot product ) Hilbert space Linear map ( Matrix ) Linear subspace ( Affine space ) Norm ( Euclidean norm ) Orthogonality ( Orthogonal complement ) Rank Trace Algebraic maps Homomorphism ( Group homomorphism , Ring homomorphism ) Isomorphism Endomorphism Automorphism Kernel (algebra) Algebraic constructions Composition algebra Exterior algebra Free object ( Free group , ...) Geometric algebra ( Multivector ) Polynomial ring ( Polynomial ) Quotient object ( Quotient group , ...) Symmetric algebra Tensor algebra Topic lists Algebraic structures Glossaries Field theory Linear algebra Order theory Ring theory Category v t e Tensors Glossary of tensor theory Scope Mathematics Coordinate system Differential geometry Dyadic algebra Euclidean geometry Exterior calculus Multilinear algebra Tensor algebra Tensor calculus Physics Engineering Computer vision Continuum mechanics Electromagnetism General relativity Transport phenomena Notation Abstract index notation Einstein notation Index notation Multi-index notation Penrose graphical notation Ricci calculus Tetrad (index notation) Van der Waerden notation Voigt notation Tensor definitions Tensor (intrinsic definition) Tensor field Tensor density Tensors in curvilinear coordinates Mixed tensor Antisymmetric tensor Symmetric tensor Tensor operator Tensor bundle Two-point tensor Operations Covariant derivative Exterior covariant derivative Exterior derivative Exterior product Hodge star operator Lie derivative Raising and lowering indices Symmetrization Tensor contraction Tensor product Transpose (2nd-order tensors) Related abstractions Affine connection Basis Cartan formalism (physics) Connection form Covariance and contravariance of vectors Differential form Dimension Exterior form Fiber bundle Geodesic Levi-Civita connection Linear map Manifold Matrix Multivector Pseudotensor Spinor Vector Vector space Notable tensors Mathematics Kronecker delta Levi-Civita symbol Metric tensor Nonmetricity tensor Ricci curvature Riemann curvature tensor Torsion tensor Weyl tensor Physics Moment of inertia Angular momentum tensor Spin tensor Cauchy stress tensor stress–energy tensor Einstein tensor EM tensor Gluon field strength tensor Metric tensor (GR) Mathematicians Élie Cartan Augustin-Louis Cauchy Elwin Bruno Christoffel Albert Einstein Leonhard Euler Carl Friedrich Gauss Hermann Grassmann Tullio Levi-Civita Gregorio Ricci-Curbastro Bernhard Riemann Jan Arnoldus Schouten Woldemar Voigt Hermann Weyl Authority control databases : National Czech Republic Retrieved from " https://en.wikipedia.org/w/index.php?title=Tensor_algebra&oldid=1273293215 " Categories : Algebras Multilinear algebra Tensors Hopf algebras Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 1 February 2025, at 17:18 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Tensor algebra 15 languages Add topic

