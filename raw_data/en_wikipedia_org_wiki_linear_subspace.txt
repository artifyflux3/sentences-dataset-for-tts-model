Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 Examples Toggle Examples subsection 2.1 Example I 2.2 Example II 2.3 Example III 2.4 Example IV 3 Properties of subspaces 4 Descriptions Toggle Descriptions subsection 4.1 Systems of linear equations 4.2 Null space of a matrix 4.3 Linear parametric equations 4.4 Span of vectors 4.5 Column space and row space 4.6 Independence, basis, and dimension 5 Operations and relations on subspaces Toggle Operations and relations on subspaces subsection 5.1 Inclusion 5.2 Intersection 5.3 Sum 5.4 Lattice of subspaces 5.5 Orthogonal complements 6 Algorithms Toggle Algorithms subsection 6.1 Basis for a row space 6.2 Subspace membership 6.3 Basis for a column space 6.4 Coordinates for a vector 6.5 Basis for a null space 6.6 Basis for the sum and intersection of two subspaces 6.7 Equations for a subspace 7 See also 8 Notes 9 Citations 10 Sources Toggle Sources subsection 10.1 Textbook 10.2 Web 11 External links Toggle the table of contents Linear subspace 28 languages Български Català Čeština Deutsch Español Euskara فارسی Français Galego Bahasa Indonesia Italiano Lombard Magyar Nederlands 日本語 Polski Português Русский Simple English Slovenčina Suomi Svenska தமிழ் Українська اردو Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia In mathematics, vector subspace In mathematics , and more specifically in linear algebra , a linear subspace or vector subspace [ 1 ] [ note 1 ] is a vector space that is a subset of some larger vector space. A linear subspace is usually simply called a subspace when the context serves to distinguish it from other types of subspaces .

Definition [ edit ] If V is a vector space over a field K , a subset W of V is a linear subspace of V if it is a vector space over K for the operations of V . Equivalently, a linear subspace of V is a nonempty subset W such that, whenever w 1 , w 2 are elements of W and α , β are elements of K , it follows that αw 1 + βw 2 is in W .

[ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] The singleton set consisting of the zero vector alone and the entire vector space itself are linear subspaces that are called the trivial subspaces of the vector space.

[ 7 ] Examples [ edit ] Example I [ edit ] In the vector space V = R 3 (the real coordinate space over the field R of real numbers ), take W to be the set of all vectors in V whose last component is 0.
Then W is a subspace of V .

Proof: Given u and v in W , then they can be expressed as u = ( u 1 , u 2 , 0) and v = ( v 1 , v 2 , 0) . Then u + v = ( u 1 + v 1 , u 2 + v 2 , 0+0) = ( u 1 + v 1 , u 2 + v 2 , 0) . Thus, u + v is an element of W , too.

Given u in W and a scalar c in R , if u = ( u 1 , u 2 , 0) again, then c u = ( cu 1 , cu 2 , c 0) = ( cu 1 , cu 2 ,0) . Thus, c u is an element of W too.

Example II [ edit ] Let the field be R again, but now let the vector space V be the Cartesian plane R 2 .
Take W to be the set of points ( x , y ) of R 2 such that x = y .
Then W is a subspace of R 2 .

Proof: Let p = ( p 1 , p 2 ) and q = ( q 1 , q 2 ) be elements of W , that is, points in the plane such that p 1 = p 2 and q 1 = q 2 . Then p + q = ( p 1 + q 1 , p 2 + q 2 ) ; since p 1 = p 2 and q 1 = q 2 , then p 1 + q 1 = p 2 + q 2 , so p + q is an element of W .

Let p = ( p 1 , p 2 ) be an element of W , that is, a point in the plane such that p 1 = p 2 , and let c be a scalar in R . Then c p = ( cp 1 , cp 2 ) ; since p 1 = p 2 , then cp 1 = cp 2 , so c p is an element of W .

In general, any subset of the real coordinate space R n that is defined by a homogeneous system of linear equations will yield a subspace.
(The equation in example I was z = 0, and the equation in example II was x = y .) Example III [ edit ] Again take the field to be R , but now let the vector space V be the set R R of all functions from R to R .
Let C( R ) be the subset consisting of continuous functions .
Then C( R ) is a subspace of R R .

Proof: We know from calculus that 0 ∈ C( R ) ⊂ R R .

We know from calculus that the sum of continuous functions is continuous.

Again, we know from calculus that the product of a continuous function and a number is continuous.

Example IV [ edit ] Keep the same field and vector space as before, but now consider the set Diff( R ) of all differentiable functions .
The same sort of argument as before shows that this is a subspace too.

Examples that extend these themes are common in functional analysis .

Properties of subspaces [ edit ] From the definition of vector spaces, it follows that subspaces are nonempty, and are closed under sums and under scalar multiples.

[ 8 ] Equivalently, subspaces can be characterized by the property of being closed under linear combinations. That is, a nonempty set W is a subspace if and only if every linear combination of finitely many elements of W also belongs to W .
The equivalent definition states that it is also equivalent to consider linear combinations of two elements at a time.

In a topological vector space X , a subspace W need not be topologically closed , but a finite-dimensional subspace is always closed.

[ 9 ] The same is true for subspaces of finite codimension (i.e., subspaces determined by a finite number of continuous linear functionals ).

Descriptions [ edit ] Descriptions of subspaces include the solution set to a homogeneous system of linear equations , the subset of Euclidean space described by a system of homogeneous linear parametric equations , the span of a collection of vectors, and the null space , column space , and row space of a matrix . Geometrically (especially over the field of real numbers and its subfields), a subspace is a flat in an n -space that passes through the origin.

A natural description of a 1-subspace is the scalar multiplication of one non- zero vector v to all possible scalar values. 1-subspaces specified by two vectors are equal if and only if one vector can be obtained from another with scalar multiplication: ∃ ∃ c ∈ ∈ K : v ′ = c v (or v = 1 c v ′ ) {\displaystyle \exists c\in K:\mathbf {v} '=c\mathbf {v} {\text{ (or }}\mathbf {v} ={\frac {1}{c}}\mathbf {v} '{\text{)}}} This idea is generalized for higher dimensions with linear span , but criteria for equality of k -spaces specified by sets of k vectors are not so simple.

A dual description is provided with linear functionals (usually implemented as linear equations). One non- zero linear functional F specifies its kernel subspace F = 0 of codimension 1. Subspaces of codimension 1 specified by two linear functionals are equal, if and only if one functional can be obtained from another with scalar multiplication (in the dual space ): ∃ ∃ c ∈ ∈ K : F ′ = c F (or F = 1 c F ′ ) {\displaystyle \exists c\in K:\mathbf {F} '=c\mathbf {F} {\text{ (or }}\mathbf {F} ={\frac {1}{c}}\mathbf {F} '{\text{)}}} It is generalized for higher codimensions with a system of equations . The following two subsections will present this latter description in details, and the remaining four subsections further describe the idea of linear span.

Systems of linear equations [ edit ] The solution set to any homogeneous system of linear equations with n variables is a subspace in the coordinate space K n : { [ x 1 x 2 ⋮ ⋮ x n ] ∈ ∈ K n : a 11 x 1 + a 12 x 2 + ⋯ ⋯ + a 1 n x n = 0 a 21 x 1 + a 22 x 2 + ⋯ ⋯ + a 2 n x n = 0 ⋮ ⋮ a m 1 x 1 + a m 2 x 2 + ⋯ ⋯ + a m n x n = 0 } .

{\displaystyle \left\{\left[\!\!{\begin{array}{c}x_{1}\\x_{2}\\\vdots \\x_{n}\end{array}}\!\!\right]\in K^{n}:{\begin{alignedat}{6}a_{11}x_{1}&&\;+\;&&a_{12}x_{2}&&\;+\cdots +\;&&a_{1n}x_{n}&&\;=0&\\a_{21}x_{1}&&\;+\;&&a_{22}x_{2}&&\;+\cdots +\;&&a_{2n}x_{n}&&\;=0&\\&&&&&&&&&&\vdots \quad &\\a_{m1}x_{1}&&\;+\;&&a_{m2}x_{2}&&\;+\cdots +\;&&a_{mn}x_{n}&&\;=0&\end{alignedat}}\right\}.} For example, the set of all vectors ( x , y , z ) (over real or rational numbers ) satisfying the equations x + 3 y + 2 z = 0 and 2 x − − 4 y + 5 z = 0 {\displaystyle x+3y+2z=0\quad {\text{and}}\quad 2x-4y+5z=0} is a one-dimensional subspace. More generally, that is to say that given a set of n independent functions, the dimension of the subspace in K k will be the dimension of the null set of A , the composite matrix of the n functions.

Null space of a matrix [ edit ] Main article: Null space In a finite-dimensional space, a homogeneous system of linear equations can be written as a single matrix equation: A x = 0 .

{\displaystyle A\mathbf {x} =\mathbf {0} .} The set of solutions to this equation is known as the null space of the matrix. For example, the subspace described above is the null space of the matrix A = [ 1 3 2 2 − − 4 5 ] .

{\displaystyle A={\begin{bmatrix}1&3&2\\2&-4&5\end{bmatrix}}.} Every subspace of K n can be described as the null space of some matrix (see § Algorithms below for more).

Linear parametric equations [ edit ] The subset of K n described by a system of homogeneous linear parametric equations is a subspace: { [ x 1 x 2 ⋮ ⋮ x n ] ∈ ∈ K n : x 1 = a 11 t 1 + a 12 t 2 + ⋯ ⋯ + a 1 m t m x 2 = a 21 t 1 + a 22 t 2 + ⋯ ⋯ + a 2 m t m ⋮ ⋮ x n = a n 1 t 1 + a n 2 t 2 + ⋯ ⋯ + a n m t m for some t 1 , … … , t m ∈ ∈ K } .

{\displaystyle \left\{\left[\!\!{\begin{array}{c}x_{1}\\x_{2}\\\vdots \\x_{n}\end{array}}\!\!\right]\in K^{n}:{\begin{alignedat}{7}x_{1}&&\;=\;&&a_{11}t_{1}&&\;+\;&&a_{12}t_{2}&&\;+\cdots +\;&&a_{1m}t_{m}&\\x_{2}&&\;=\;&&a_{21}t_{1}&&\;+\;&&a_{22}t_{2}&&\;+\cdots +\;&&a_{2m}t_{m}&\\&&\vdots \;\;&&&&&&&&&&&\\x_{n}&&\;=\;&&a_{n1}t_{1}&&\;+\;&&a_{n2}t_{2}&&\;+\cdots +\;&&a_{nm}t_{m}&\\\end{alignedat}}{\text{ for some }}t_{1},\ldots ,t_{m}\in K\right\}.} For example, the set of all vectors ( x , y , z ) parameterized by the equations x = 2 t 1 + 3 t 2 , y = 5 t 1 − − 4 t 2 , and z = − − t 1 + 2 t 2 {\displaystyle x=2t_{1}+3t_{2},\;\;\;\;y=5t_{1}-4t_{2},\;\;\;\;{\text{and}}\;\;\;\;z=-t_{1}+2t_{2}} is a two-dimensional subspace of K 3 , if K is a number field (such as real or rational numbers).

[ note 2 ] Span of vectors [ edit ] Main article: Linear span In linear algebra, the system of parametric equations can be written as a single vector equation: [ x y z ] = t 1 [ 2 5 − − 1 ] + t 2 [ 3 − − 4 2 ] .

{\displaystyle {\begin{bmatrix}x\\y\\z\end{bmatrix}}\;=\;t_{1}\!{\begin{bmatrix}2\\5\\-1\end{bmatrix}}+t_{2}\!{\begin{bmatrix}3\\-4\\2\end{bmatrix}}.} The expression on the right is called a linear combination of the vectors
(2, 5, −1) and (3, −4, 2). These two vectors are said to span the resulting subspace.

In general, a linear combination of vectors v 1 , v 2 , ... , v k is any vector of the form t 1 v 1 + ⋯ ⋯ + t k v k .

{\displaystyle t_{1}\mathbf {v} _{1}+\cdots +t_{k}\mathbf {v} _{k}.} The set of all possible linear combinations is called the span : Span { v 1 , … … , v k } = { t 1 v 1 + ⋯ ⋯ + t k v k : t 1 , … … , t k ∈ ∈ K } .

{\displaystyle {\text{Span}}\{\mathbf {v} _{1},\ldots ,\mathbf {v} _{k}\}=\left\{t_{1}\mathbf {v} _{1}+\cdots +t_{k}\mathbf {v} _{k}:t_{1},\ldots ,t_{k}\in K\right\}.} If the vectors v 1 , ... , v k have n components, then their span is a subspace of K n . Geometrically, the span is the flat through the origin in n -dimensional space determined by the points v 1 , ... , v k .

Example The xz -plane in R 3 can be parameterized by the equations x = t 1 , y = 0 , z = t 2 .

{\displaystyle x=t_{1},\;\;\;y=0,\;\;\;z=t_{2}.} As a subspace, the xz -plane is spanned by the vectors (1, 0, 0) and (0, 0, 1). Every vector in the xz -plane can be written as a linear combination of these two: ( t 1 , 0 , t 2 ) = t 1 ( 1 , 0 , 0 ) + t 2 ( 0 , 0 , 1 ) .

{\displaystyle (t_{1},0,t_{2})=t_{1}(1,0,0)+t_{2}(0,0,1){\text{.}}} Geometrically, this corresponds to the fact that every point on the xz -plane can be reached from the origin by first moving some distance in the direction of (1, 0, 0) and then moving some distance in the direction of (0, 0, 1).

Column space and row space [ edit ] Main article: Row and column spaces A system of linear parametric equations in a finite-dimensional space can also be written as a single matrix equation: x = A t where A = [ 2 3 5 − − 4 − − 1 2 ] .

{\displaystyle \mathbf {x} =A\mathbf {t} \;\;\;\;{\text{where}}\;\;\;\;A=\left[{\begin{alignedat}{2}2&&3&\\5&&\;\;-4&\\-1&&2&\end{alignedat}}\,\right]{\text{.}}} In this case, the subspace consists of all possible values of the vector x . In linear algebra, this subspace is known as the column space (or image ) of the matrix A . It is precisely the subspace of K n spanned by the column vectors of A .

The row space of a matrix is the subspace spanned by its row vectors. The row space is interesting because it is the orthogonal complement of the null space (see below).

Independence, basis, and dimension [ edit ] Main articles: Linear independence , Basis (linear algebra) , and Dimension (vector space) The vectors u and v are a basis for this two-dimensional subspace of R 3 .

In general, a subspace of K n determined by k parameters (or spanned by k vectors) has dimension k . However, there are exceptions to this rule. For example, the subspace of K 3 spanned by the three vectors (1, 0, 0), (0, 0, 1), and (2, 0, 3) is just the xz -plane, with each point on the plane described by infinitely many different values of t 1 , t 2 , t 3 .

In general, vectors v 1 , ... , v k are called linearly independent if t 1 v 1 + ⋯ ⋯ + t k v k ≠ ≠ u 1 v 1 + ⋯ ⋯ + u k v k {\displaystyle t_{1}\mathbf {v} _{1}+\cdots +t_{k}\mathbf {v} _{k}\;\neq \;u_{1}\mathbf {v} _{1}+\cdots +u_{k}\mathbf {v} _{k}} for
( t 1 , t 2 , ... , t k ) ≠ ( u 1 , u 2 , ... , u k ).

[ note 3 ] If v 1 , ..., v k are linearly independent, then the coordinates t 1 , ..., t k for a vector in the span are uniquely determined.

A basis for a subspace S is a set of linearly independent vectors whose span is S . The number of elements in a basis is always equal to the geometric dimension of the subspace. Any spanning set for a subspace can be changed into a basis by removing redundant vectors (see § Algorithms below for more).

Example Let S be the subspace of R 4 defined by the equations x 1 = 2 x 2 and x 3 = 5 x 4 .

{\displaystyle x_{1}=2x_{2}\;\;\;\;{\text{and}}\;\;\;\;x_{3}=5x_{4}.} Then the vectors (2, 1, 0, 0) and (0, 0, 5, 1) are a basis for S . In particular, every vector that satisfies the above equations can be written uniquely as a linear combination of the two basis vectors: ( 2 t 1 , t 1 , 5 t 2 , t 2 ) = t 1 ( 2 , 1 , 0 , 0 ) + t 2 ( 0 , 0 , 5 , 1 ) .

{\displaystyle (2t_{1},t_{1},5t_{2},t_{2})=t_{1}(2,1,0,0)+t_{2}(0,0,5,1).} The subspace S is two-dimensional. Geometrically, it is the plane in R 4 passing through the points (0, 0, 0, 0), (2, 1, 0, 0), and (0, 0, 5, 1).

Operations and relations on subspaces [ edit ] Inclusion [ edit ] The set-theoretical inclusion binary relation specifies a partial order on the set of all subspaces (of any dimension).

A subspace cannot lie in any subspace of lesser dimension. If dim U = k , a finite number, and U ⊂ W , then dim W = k if and only if U = W .

Intersection [ edit ] In R 3 , the intersection of two distinct two-dimensional subspaces is one-dimensional Given subspaces U and W of a vector space V , then their intersection U ∩ W := { v ∈ V : v is an element of both U and W } is also a subspace of V .

[ 10 ] Proof: Let v and w be elements of U ∩ W . Then v and w belong to both U and W . Because U is a subspace, then v + w belongs to U . Similarly, since W is a subspace, then v + w belongs to W . Thus, v + w belongs to U ∩ W .

Let v belong to U ∩ W , and let c be a scalar. Then v belongs to both U and W . Since U and W are subspaces, c v belongs to both U and W .

Since U and W are vector spaces, then 0 belongs to both sets. Thus, 0 belongs to U ∩ W .

For every vector space V , the set { 0 } and V itself are subspaces of V .

[ 11 ] [ 12 ] Sum [ edit ] If U and W are subspaces, their sum is the subspace [ 13 ] [ 14 ] U + W = { u + w : : u ∈ ∈ U , w ∈ ∈ W } .

{\displaystyle U+W=\left\{\mathbf {u} +\mathbf {w} \colon \mathbf {u} \in U,\mathbf {w} \in W\right\}.} For example, the sum of two lines is the plane that contains them both. The dimension of the sum satisfies the inequality max ( dim ⁡ ⁡ U , dim ⁡ ⁡ W ) ≤ ≤ dim ⁡ ⁡ ( U + W ) ≤ ≤ dim ⁡ ⁡ ( U ) + dim ⁡ ⁡ ( W ) .

{\displaystyle \max(\dim U,\dim W)\leq \dim(U+W)\leq \dim(U)+\dim(W).} Here, the minimum only occurs if one subspace is contained in the other, while the maximum is the most general case. The dimension of the intersection and the sum are related by the following equation: [ 15 ] dim ⁡ ⁡ ( U + W ) = dim ⁡ ⁡ ( U ) + dim ⁡ ⁡ ( W ) − − dim ⁡ ⁡ ( U ∩ ∩ W ) .

{\displaystyle \dim(U+W)=\dim(U)+\dim(W)-\dim(U\cap W).} A set of subspaces is independent when the only intersection between any pair of subspaces is the trivial subspace. The direct sum is the sum of independent subspaces, written as U ⊕ ⊕ W {\displaystyle U\oplus W} . An equivalent restatement is that a direct sum is a subspace sum under the condition that every subspace contributes to the span of the sum.

[ 16 ] [ 17 ] [ 18 ] [ 19 ] The dimension of a direct sum U ⊕ ⊕ W {\displaystyle U\oplus W} is the same as the sum of subspaces, but may be shortened because the dimension of the trivial subspace is zero.

[ 20 ] dim ⁡ ⁡ ( U ⊕ ⊕ W ) = dim ⁡ ⁡ ( U ) + dim ⁡ ⁡ ( W ) {\displaystyle \dim(U\oplus W)=\dim(U)+\dim(W)} Lattice of subspaces [ edit ] The operations intersection and sum make the set of all subspaces a bounded modular lattice , where the {0} subspace , the least element , is an identity element of the sum operation, and the identical subspace V , the greatest element, is an identity element of the intersection operation.

Orthogonal complements [ edit ] If V {\displaystyle V} is an inner product space and N {\displaystyle N} is a subset of V {\displaystyle V} , then the orthogonal complement of N {\displaystyle N} , denoted N ⊥ ⊥ {\displaystyle N^{\perp }} , is again a subspace.

[ 21 ] If V {\displaystyle V} is finite-dimensional and N {\displaystyle N} is a subspace, then the dimensions of N {\displaystyle N} and N ⊥ ⊥ {\displaystyle N^{\perp }} satisfy the complementary relationship dim ⁡ ⁡ ( N ) + dim ⁡ ⁡ ( N ⊥ ⊥ ) = dim ⁡ ⁡ ( V ) {\displaystyle \dim(N)+\dim(N^{\perp })=\dim(V)} .

[ 22 ] Moreover, no vector is orthogonal to itself, so N ∩ ∩ N ⊥ ⊥ = { 0 } {\displaystyle N\cap N^{\perp }=\{0\}} and V {\displaystyle V} is the direct sum of N {\displaystyle N} and N ⊥ ⊥ {\displaystyle N^{\perp }} .

[ 23 ] Applying orthogonal complements twice returns the original subspace: ( N ⊥ ⊥ ) ⊥ ⊥ = N {\displaystyle (N^{\perp })^{\perp }=N} for every subspace N {\displaystyle N} .

[ 24 ] This operation, understood as negation ( ¬ ¬ {\displaystyle \neg } ), makes the lattice of subspaces a (possibly infinite ) orthocomplemented lattice (although not a distributive lattice).

[ citation needed ] In spaces with other bilinear forms , some but not all of these results still hold. In pseudo-Euclidean spaces and symplectic vector spaces , for example, orthogonal complements exist. However, these spaces may have null vectors that are orthogonal to themselves, and consequently there exist subspaces N {\displaystyle N} such that N ∩ ∩ N ⊥ ⊥ ≠ ≠ { 0 } {\displaystyle N\cap N^{\perp }\neq \{0\}} . As a result, this operation does not turn the lattice of subspaces into a Boolean algebra (nor a Heyting algebra ).

[ citation needed ] Algorithms [ edit ] Most algorithms for dealing with subspaces involve row reduction . This is the process of applying elementary row operations to a matrix, until it reaches either row echelon form or reduced row echelon form . Row reduction has the following important properties: The reduced matrix has the same null space as the original.

Row reduction does not change the span of the row vectors, i.e. the reduced matrix has the same row space as the original.

Row reduction does not affect the linear dependence of the column vectors.

Basis for a row space [ edit ] Input An m × n matrix A .

Output A basis for the row space of A .

Use elementary row operations to put A into row echelon form.

The nonzero rows of the echelon form are a basis for the row space of A .

See the article on row space for an example .

If we instead put the matrix A into reduced row echelon form, then the resulting basis for the row space is uniquely determined. This provides an algorithm for checking whether two row spaces are equal and, by extension, whether two subspaces of K n are equal.

Subspace membership [ edit ] Input A basis { b 1 , b 2 , ..., b k } for a subspace S of K n , and a vector v with n components.

Output Determines whether v is an element of S Create a ( k + 1) × n matrix A whose rows are the vectors b 1 , ... , b k and v .

Use elementary row operations to put A into row echelon form.

If the echelon form has a row of zeroes, then the vectors { b 1 , ..., b k , v } are linearly dependent, and therefore v ∈ S .

Basis for a column space [ edit ] Input An m × n matrix A Output A basis for the column space of A Use elementary row operations to put A into row echelon form.

Determine which columns of the echelon form have pivots . The corresponding columns of the original matrix are a basis for the column space.

See the article on column space for an example .

This produces a basis for the column space that is a subset of the original column vectors. It works because the columns with pivots are a basis for the column space of the echelon form, and row reduction does not change the linear dependence relationships between the columns.

Coordinates for a vector [ edit ] Input A basis { b 1 , b 2 , ..., b k } for a subspace S of K n , and a vector v ∈ S Output Numbers t 1 , t 2 , ..., t k such that v = t 1 b 1 + ··· + t k b k Create an augmented matrix A whose columns are b 1 ,..., b k , with the last column being v .

Use elementary row operations to put A into reduced row echelon form.

Express the final column of the reduced echelon form as a linear combination of the first k columns. The coefficients used are the desired numbers t 1 , t 2 , ..., t k . (These should be precisely the first k entries in the final column of the reduced echelon form.) If the final column of the reduced row echelon form contains a pivot, then the input vector v does not lie in S .

Basis for a null space [ edit ] Input An m × n matrix A .

Output A basis for the null space of A Use elementary row operations to put A in reduced row echelon form.

Using the reduced row echelon form, determine which of the variables x 1 , x 2 , ..., x n are free. Write equations for the dependent variables in terms of the free variables.

For each free variable x i , choose a vector in the null space for which x i = 1 and the remaining free variables are zero. The resulting collection of vectors is a basis for the null space of A .

See the article on null space for an example .

Basis for the sum and intersection of two subspaces [ edit ] Given two subspaces U and W of V , a basis of the sum U + W {\displaystyle U+W} and the intersection U ∩ ∩ W {\displaystyle U\cap W} can be calculated using the Zassenhaus algorithm .

Equations for a subspace [ edit ] Input A basis { b 1 , b 2 , ..., b k } for a subspace S of K n Output An ( n − k ) × n matrix whose null space is S .

Create a matrix A whose rows are b 1 , b 2 , ..., b k .

Use elementary row operations to put A into reduced row echelon form.

Let c 1 , c 2 , ..., c n be the columns of the reduced row echelon form. For each column without a pivot, write an equation expressing the column as a linear combination of the columns with pivots.

This results in a homogeneous system of n − k linear equations involving the variables c 1 ,..., c n . The ( n − k ) × n matrix corresponding to this system is the desired matrix with nullspace S .

Example If the reduced row echelon form of A is [ 1 0 − − 3 0 2 0 0 1 5 0 − − 1 4 0 0 0 1 7 − − 9 0 0 0 0 0 0 ] {\displaystyle \left[{\begin{alignedat}{6}1&&0&&-3&&0&&2&&0\\0&&1&&5&&0&&-1&&4\\0&&0&&0&&1&&7&&-9\\0&&\;\;\;\;\;0&&\;\;\;\;\;0&&\;\;\;\;\;0&&\;\;\;\;\;0&&\;\;\;\;\;0\end{alignedat}}\,\right]} then the column vectors c 1 , ..., c 6 satisfy the equations c 3 = − − 3 c 1 + 5 c 2 c 5 = 2 c 1 − − c 2 + 7 c 4 c 6 = 4 c 2 − − 9 c 4 {\displaystyle {\begin{alignedat}{1}\mathbf {c} _{3}&=-3\mathbf {c} _{1}+5\mathbf {c} _{2}\\\mathbf {c} _{5}&=2\mathbf {c} _{1}-\mathbf {c} _{2}+7\mathbf {c} _{4}\\\mathbf {c} _{6}&=4\mathbf {c} _{2}-9\mathbf {c} _{4}\end{alignedat}}} It follows that the row vectors of A satisfy the equations x 3 = − − 3 x 1 + 5 x 2 x 5 = 2 x 1 − − x 2 + 7 x 4 x 6 = 4 x 2 − − 9 x 4 .

{\displaystyle {\begin{alignedat}{1}x_{3}&=-3x_{1}+5x_{2}\\x_{5}&=2x_{1}-x_{2}+7x_{4}\\x_{6}&=4x_{2}-9x_{4}.\end{alignedat}}} In particular, the row vectors of A are a basis for the null space of the corresponding matrix.

See also [ edit ] Cyclic subspace Invariant subspace Multilinear subspace learning Quotient space (linear algebra) Signal subspace Subspace topology Notes [ edit ] ^ The term linear subspace is sometimes used for referring to flats and affine subspaces . In the case of vector spaces over the reals, linear subspaces, flats, and affine subspaces are also called linear manifolds for emphasizing that they are also manifolds .

^ Generally, K can be any field of such characteristic that the given integer matrix has the appropriate rank in it. All fields include integers , but some integers may equal to zero in some fields.

^ This definition is often stated differently: vectors v 1 , ..., v k are linearly independent if t 1 v 1 + ··· + t k v k ≠ 0 for ( t 1 , t 2 , ..., t k ) ≠ (0, 0, ..., 0) . The two definitions are equivalent.

Citations [ edit ] ^ Halmos (1974) pp. 16–17, § 10 ^ Anton (2005 , p. 155) ^ Beauregard & Fraleigh (1973 , p. 176) ^ Herstein (1964 , p. 132) ^ Kreyszig (1972 , p. 200) ^ Nering (1970 , p. 20) ^ Hefferon (2020) p. 100, ch. 2, Definition 2.13 ^ MathWorld (2021) Subspace.

^ DuChateau (2002) Basic facts about Hilbert Space — class notes from Colorado State University on Partial Differential Equations (M645).

^ Nering (1970 , p. 21) ^ Hefferon (2020) p. 100, ch. 2, Definition 2.13 ^ Nering (1970 , p. 20) ^ Nering (1970 , p. 21) ^ Vector space related operators.

^ Nering (1970 , p. 22) ^ Hefferon (2020) p. 148, ch. 2, §4.10 ^ Axler (2015) p. 21 § 1.40 ^ Katznelson & Katznelson (2008) pp. 10–11, § 1.2.5 ^ Halmos (1974) pp. 28–29, § 18 ^ Halmos (1974) pp. 30–31, § 19 ^ Axler (2015) p. 193, § 6.46 ^ Axler (2015) p. 195, § 6.50 ^ Axler (2015) p. 194, § 6.47 ^ Axler (2015) p. 195, § 6.51 Sources [ edit ] Textbook [ edit ] Anton, Howard (2005), Elementary Linear Algebra (Applications Version) (9th ed.), Wiley International Axler, Sheldon Jay (2015).

Linear Algebra Done Right (3rd ed.).

Springer .

ISBN 978-3-319-11079-0 .

Beauregard, Raymond A.; Fraleigh, John B. (1973), A First Course In Linear Algebra: with Optional Introduction to Groups, Rings, and Fields , Boston: Houghton Mifflin Company , ISBN 0-395-14017-X Halmos, Paul Richard (1974) [1958].

Finite-Dimensional Vector Spaces (2nd ed.).

Springer .

ISBN 0-387-90093-4 .

Hefferon, Jim (2020).

Linear Algebra (4th ed.). Orthogonal Publishing.

ISBN 978-1-944325-11-4 .

Herstein, I. N. (1964), Topics In Algebra , Waltham: Blaisdell Publishing Company , ISBN 978-1114541016 {{ citation }} : ISBN / Date incompatibility ( help ) Katznelson, Yitzhak ; Katznelson, Yonatan R. (2008).

A (Terse) Introduction to Linear Algebra .

American Mathematical Society .

ISBN 978-0-8218-4419-9 .

Kreyszig, Erwin (1972), Advanced Engineering Mathematics (3rd ed.), New York: Wiley , ISBN 0-471-50728-8 Lay, David C. (August 22, 2005), Linear Algebra and Its Applications (3rd ed.), Addison Wesley, ISBN 978-0-321-28713-7 Leon, Steven J. (2006), Linear Algebra With Applications (7th ed.), Pearson Prentice Hall Meyer, Carl D. (February 15, 2001), Matrix Analysis and Applied Linear Algebra , Society for Industrial and Applied Mathematics (SIAM), ISBN 978-0-89871-454-8 , archived from the original on March 1, 2001 Nering, Evar D. (1970), Linear Algebra and Matrix Theory (2nd ed.), New York: Wiley , LCCN 76091646 Poole, David (2006), Linear Algebra: A Modern Introduction (2nd ed.), Brooks/Cole, ISBN 0-534-99845-3 Web [ edit ] Weisstein, Eric Wolfgang .

"Subspace" .

MathWorld . Retrieved 16 Feb 2021 .

DuChateau, Paul (5 Sep 2002).

"Basic facts about Hilbert Space" (PDF) .

Colorado State University . Retrieved 17 Feb 2021 .

External links [ edit ] Strang, Gilbert (7 May 2009).

"The four fundamental subspaces" .

Archived from the original on 2021-12-11 . Retrieved 17 Feb 2021 – via YouTube .

Strang, Gilbert (5 May 2020).

"The big picture of linear algebra" .

Archived from the original on 2021-12-11 . Retrieved 17 Feb 2021 – via YouTube .

v t e Linear algebra Outline Glossary Basic concepts Scalar Vector Vector space Scalar multiplication Vector projection Linear span Linear map Linear projection Linear independence Linear combination Multilinear map Basis Change of basis Row and column vectors Row and column spaces Kernel Eigenvalues and eigenvectors Transpose Linear equations Matrices Block Decomposition Invertible Minor Multiplication Rank Transformation Cramer's rule Gaussian elimination Productive matrix Gram matrix Bilinear Orthogonality Dot product Hadamard product Inner product space Outer product Kronecker product Gram–Schmidt process Multilinear algebra Determinant Cross product Triple product Seven-dimensional cross product Geometric algebra Exterior algebra Bivector Multivector Tensor Outermorphism Vector space constructions Dual Direct sum Function space Quotient Subspace Tensor product Numerical Floating-point Numerical stability Basic Linear Algebra Subprograms Sparse matrix Comparison of linear algebra libraries Category NewPP limit report
Parsed by mw‐api‐ext.codfw.canary‐784c79b4b8‐ls29n
Cached time: 20250818050637
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.628 seconds
Real time usage: 0.811 seconds
Preprocessor visited node count: 3150/1000000
Revision size: 34092/2097152 bytes
Post‐expand include size: 51820/2097152 bytes
Template argument size: 3685/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 8/500
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 60603/5000000 bytes
Lua time usage: 0.353/10.000 seconds
Lua memory usage: 8226330/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  560.862      1 -total
 22.83%  128.044      9 Template:Citation
 17.57%   98.541      1 Template:Reflist
 16.07%   90.103      1 Template:Linear_algebra
 15.70%   88.047      1 Template:Navbox
 14.61%   81.951      1 Template:Short_description
 13.81%   77.459     23 Template:Harvtxt
  9.48%   53.186      2 Template:Pagetype
  9.11%   51.115      2 Template:Citation_needed
  7.67%   43.036      2 Template:Fix Saved in parser cache with key enwiki:pcache:56357:|#|:idhash:canonical and timestamp 20250818050637 and revision id 1306519060. Rendering was triggered because: unknown Retrieved from " https://en.wikipedia.org/w/index.php?title=Linear_subspace&oldid=1306519060 " Categories : Linear algebra Operator theory Functional analysis Hidden categories: Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from January 2019 CS1 errors: ISBN date Articles containing proofs This page was last edited on 18 August 2025, at 05:06 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Linear subspace 28 languages Add topic

