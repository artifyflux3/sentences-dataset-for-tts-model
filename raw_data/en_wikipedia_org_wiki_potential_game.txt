Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 A simple example 3 Potential games and congestion games 4 Potential games and improvement paths 5 Pseudo-potential games 6 Correlated equilibria 7 See also 8 References 9 External links Toggle the table of contents Potential game 7 languages Deutsch فارسی Français Italiano עברית Русский 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Game class in game theory In game theory , a game is said to be a potential game if the incentive of all players to change their strategy can be expressed using a single global function called the potential function . The concept originated in a 1996 paper by Dov Monderer and Lloyd Shapley .

[ 1 ] The properties of several types of potential games have since been studied. Games can be either ordinal or cardinal potential games. In cardinal games, the difference in individual payoffs for each player from individually changing one's strategy, other things equal, has to have the same value as the difference in values for the potential function. In ordinal games, only the signs of the differences have to be the same.

The potential function is a useful tool to analyze equilibrium properties of games, since the incentives of all players are mapped into one function, and the set of pure Nash equilibria can be found by locating the local optima of the potential function. Convergence and finite-time convergence of an iterated game towards a Nash equilibrium can also be understood by studying the potential function.

Potential games can be studied as repeated games with state so that every round played has a direct consequence on game's state in the next round.

[ 2 ] This approach has applications in distributed control such as distributed resource allocation, where players without a central correlation mechanism can cooperate to achieve a globally optimal resource distribution.

Definition [ edit ] Let N {\displaystyle N} be the number of players, A {\displaystyle A} the set of action profiles over the action sets A i {\displaystyle A_{i}} of each player and u i : A → → R {\displaystyle u_{i}:A\to \mathbb {R} } be the payoff function for player 1 ≤ ≤ i ≤ ≤ N {\displaystyle 1\leq i\leq N} .

Given a game G = ( N , A = A 1 × × … … × × A N , u : A → → R N ) {\displaystyle G=(N,A=A_{1}\times \ldots \times A_{N},u:A\rightarrow \mathbb {R} ^{N})} , we say that G {\displaystyle G} is a potential game with an exact (weighted, ordinal, generalized ordinal, best response) potential function if Φ Φ : A → → R {\displaystyle \Phi :A\rightarrow \mathbb {R} } is an exact (weighted, ordinal, generalized ordinal, best response, respectively) potential function for G {\displaystyle G} . We define these notions below.

Φ Φ {\displaystyle \Phi } is called an exact potential function if ∀ ∀ i , ∀ ∀ a − − i ∈ ∈ A − − i , ∀ ∀ a i ′ , a i ″ ∈ ∈ A i {\displaystyle \forall i,\forall {a_{-i}\in A_{-i}},\ \forall {a'_{i},\ a''_{i}\in A_{i}}} , Φ Φ ( a i ′ , a − − i ) − − Φ Φ ( a i ″ , a − − i ) = u i ( a i ′ , a − − i ) − − u i ( a i ″ , a − − i ) {\displaystyle \Phi (a'_{i},a_{-i})-\Phi (a''_{i},a_{-i})=u_{i}(a'_{i},a_{-i})-u_{i}(a''_{i},a_{-i})} That is: when player i {\displaystyle i} switches from action a ′ {\displaystyle a'} to action a ″ {\displaystyle a''} ,  the change in the potential Φ Φ {\displaystyle \Phi } equals the change in the utility of that player.

Φ Φ {\displaystyle \Phi } is called a weighted potential function if there is a vector w ∈ ∈ R + + N {\displaystyle w\in \mathbb {R} _{++}^{N}} such that ∀ ∀ i , ∀ ∀ a − − i ∈ ∈ A − − i , ∀ ∀ a i ′ , a i ″ ∈ ∈ A i {\displaystyle \forall i,\forall {a_{-i}\in A_{-i}},\ \forall {a'_{i},\ a''_{i}\in A_{i}}} , Φ Φ ( a i ′ , a − − i ) − − Φ Φ ( a i ″ , a − − i ) = w i ( u i ( a i ′ , a − − i ) − − u i ( a i ″ , a − − i ) ) {\displaystyle \Phi (a'_{i},a_{-i})-\Phi (a''_{i},a_{-i})=w_{i}(u_{i}(a'_{i},a_{-i})-u_{i}(a''_{i},a_{-i}))} That is: when a player switches action,  the change in Φ Φ {\displaystyle \Phi } equals the change in the player's utility, times a positive player-specific weight. Every exact PF is a weighted PF with w i =1 for all i .

Φ Φ {\displaystyle \Phi } is called an ordinal potential function if ∀ ∀ i , ∀ ∀ a − − i ∈ ∈ A − − i , ∀ ∀ a i ′ , a i ″ ∈ ∈ A i {\displaystyle \forall i,\forall {a_{-i}\in A_{-i}},\ \forall {a'_{i},\ a''_{i}\in A_{i}}} , u i ( a i ′ , a − − i ) − − u i ( a i ″ , a − − i ) > 0 ⇔ ⇔ Φ Φ ( a i ′ , a − − i ) − − Φ Φ ( a i ″ , a − − i ) > 0 {\displaystyle u_{i}(a'_{i},a_{-i})-u_{i}(a''_{i},a_{-i})>0\Leftrightarrow \Phi (a'_{i},a_{-i})-\Phi (a''_{i},a_{-i})>0} That is: when a player switches action,  the sign of the change in Φ Φ {\displaystyle \Phi } equals the sign of the change in the player's utility, whereas the magnitude of change may differ. Every weighted PF is an ordinal PF.

Φ Φ {\displaystyle \Phi } is called a generalized ordinal potential function if ∀ ∀ i , ∀ ∀ a − − i ∈ ∈ A − − i , ∀ ∀ a i ′ , a i ″ ∈ ∈ A i {\displaystyle \forall i,\forall {a_{-i}\in A_{-i}},\ \forall {a'_{i},\ a''_{i}\in A_{i}}} , u i ( a i ′ , a − − i ) − − u i ( a i ″ , a − − i ) > 0 ⇒ ⇒ Φ Φ ( a i ′ , a − − i ) − − Φ Φ ( a i ″ , a − − i ) > 0 {\displaystyle u_{i}(a'_{i},a_{-i})-u_{i}(a''_{i},a_{-i})>0\Rightarrow \Phi (a'_{i},a_{-i})-\Phi (a''_{i},a_{-i})>0} That is: when a player switches action, if the player's utility increases, then the potential increases (but the opposite is not necessarily true). Every ordinal PF is a generalized-ordinal PF.

Φ Φ {\displaystyle \Phi } is called a best-response potential function if ∀ ∀ i ∈ ∈ N , ∀ ∀ a − − i ∈ ∈ A − − i {\displaystyle \forall i\in N,\ \forall {a_{-i}\in A_{-i}}} , arg ⁡ ⁡ max a i ∈ ∈ A i u i ( a i , a − − i ) = arg ⁡ ⁡ max a i ∈ ∈ A i Φ Φ ( a i , a − − i ) {\displaystyle \arg \max _{a_{i}\in A_{i}}u_{i}(a_{i},a_{-i})=\arg \max _{a_{i}\in A_{i}}\Phi (a_{i},a_{-i})} . That is: for each player i , maximizing the common potential function leads to the same outcome as maximizing his own utility.

Φ Φ {\displaystyle \Phi } is called a pseudo-potential function [ 3 ] if ∀ ∀ i ∈ ∈ N , ∀ ∀ a − − i ∈ ∈ A − − i {\displaystyle \forall i\in N,\ \forall {a_{-i}\in A_{-i}}} , arg ⁡ ⁡ max a i ∈ ∈ A i u i ( a i , a − − i ) ⊇ ⊇ arg ⁡ ⁡ max a i ∈ ∈ A i Φ Φ ( a i , a − − i ) {\displaystyle \arg \max _{a_{i}\in A_{i}}u_{i}(a_{i},a_{-i})\supseteq \arg \max _{a_{i}\in A_{i}}\Phi (a_{i},a_{-i})} .  That is: for each player i , maximizing the common potential function leads to some best response.

Note that while there are N {\displaystyle N} utility functions, one for each player, there is only one potential function. Thus, through the lens of potential functions, the players become interchangeable (in the sense of one of the definitions above). Because of this symmetry of the game, decentralized algorithms based on the shared potential function often lead to convergence (in some of sense) to a Nash equilibria.

A simple example [ edit ] In a 2-player, 2-action game with externalities, individual players' payoffs are given by the function u i ( a i , a j ) = b i a i + w a i a j , where a i is players i's action, a j is the opponent's action, and w is a positive externality from choosing the same action. The action choices are +1 and −1, as seen in the payoff matrix in Figure 1.

This game has a potential function P( a 1 , a 2 ) = b 1 a 1 + b 2 a 2 + w a 1 a 2 .

If player 1 moves from −1 to +1, the payoff difference is Δ u 1 = u 1 (+1, a 2 ) – u 1 (–1, a 2 ) = 2 b 1 + 2 w a 2 .

The change in potential is ΔP = P(+1, a 2 ) – P(–1, a 2 ) = ( b 1 + b 2 a 2 + w a 2 ) – (– b 1 + b 2 a 2 – w a 2 ) = 2 b 1 + 2 w a 2 = Δ u 1 .

The solution for player 2 is equivalent. Using numerical values b 1 = 2 , b 2 = −1 , w = 3 , this example transforms into a simple battle of the sexes , as shown in Figure 2. The game has two pure Nash equilibria, (+1, +1) and (−1, −1) . These are also the local maxima of the potential function (Figure 3). The only stochastically stable equilibrium is (+1, +1) , the global maximum of the potential function.

+1 –1 +1 + b 1 + w , + b 2 + w + b 1 – w , – b 2 – w –1 – b 1 – w , + b 2 – w – b 1 + w , – b 2 + w Fig. 1: Potential game example +1 –1 +1 5, 2 –1, –2 –1 –5, –4 1, 4 Fig. 2: Battle of the sexes (payoffs) +1 –1 +1 4 0 –1 –6 2 Fig. 3: Battle of the sexes (potentials) A 2-player, 2-action game cannot be a potential game unless [ u 1 ( + 1 , − − 1 ) + u 1 ( − − 1 , + 1 ) ] − − [ u 1 ( + 1 , + 1 ) + u 1 ( − − 1 , − − 1 ) ] = [ u 2 ( + 1 , − − 1 ) + u 2 ( − − 1 , + 1 ) ] − − [ u 2 ( + 1 , + 1 ) + u 2 ( − − 1 , − − 1 ) ] {\displaystyle [u_{1}(+1,-1)+u_{1}(-1,+1)]-[u_{1}(+1,+1)+u_{1}(-1,-1)]=[u_{2}(+1,-1)+u_{2}(-1,+1)]-[u_{2}(+1,+1)+u_{2}(-1,-1)]} Potential games and congestion games [ edit ] Exact potential games are equivalent to congestion games : Rosenthal [ 4 ] proved that every congestion game has an exact potential; Monderer and Shapley [ 1 ] proved the opposite direction: every game with an exact potential function is a congestion game .

The class of ordinal potential games is much larger. Fabrikant, Papadimitriou and Talwar [ 5 ] : Thm.6 proved that, for every problem in the complexity class PLS (essentially, every local search problem), there exists an ordinal potential game with polynomially many players, such that the set of pure Nash equilibria equals the set of local optima.

Potential games and improvement paths [ edit ] An improvement path (also called Nash dynamics ) is a sequence of strategy-vectors, in which each vector is attained from the previous vector by a single player switching his strategy to a strategy that strictly increases his utility. If a game has a generalized-ordinal-potential function Φ Φ {\displaystyle \Phi } , then Φ Φ {\displaystyle \Phi } is strictly increasing in every improvement path, so every improvement path is acyclic. If, in addition, the game has finitely many strategies, then every improvement path must be finite. This property is called the finite  improvement property (FIP) . We have just proved that every finite generalized-ordinal-potential game has the FIP. The opposite is also true: every finite game has the FIP has a generalized-ordinal-potential function.

[ 6 ] [ clarification needed ] The terminal state in every finite improvement path is a Nash equilibrium, so FIP implies the existence of a pure-strategy Nash equilibrium. Moreover, it implies that a Nash equilibrium can be computed by a distributed process, in which each agent only has to improve his own strategy.

A best-response path is a special case of an improvement path, in which each vector is attained from the previous vector by a single player switching his strategy to a best-response strategy. The property that every best-response path is finite is called the finite best-response property (FBRP) . FBRP is weaker than FIP, and it still implies the existence of a pure-strategy Nash equilibrium. It also implies that a Nash equilibrium can be computed by a distributed process, but the computational burden on the agents is higher than with FIP, since they have to compute a best-response.

An even weaker property is weak-acyclicity (WA) .

[ 7 ] It means that, for any initial strategy-vector, there exists a finite best-response path starting at that vector. Weak-acyclicity is not sufficient for existence of a potential function (since some improvement-paths may be cyclic), but it is sufficient for the existence of pure-strategy Nash equilibrium. It implies that a Nash equilibrium can be computed almost-surely by a stochastic distributed process, in which at each point, a player is chosen at random, and this player chooses a best-strategy at random.

[ 6 ] Pseudo-potential games [ edit ] Dubey, Haimanko and Zapechelnyuk [ 3 ] : Thm.1 prove: Any game of weak strategic substitutes or strategic complements with aggregation is a pseudo-potential game.

Any pseudo-potential game has a pure-strategy Nash equilibrium.

Correlated equilibria [ edit ] Abraham Neyman [ 8 ] studied potential games in which (a) the potential is a smooth and concave function , (b) the strategy sets are convex, (c) the utilities are bounded. He proves that, in such games, any correlated equilibrium is a mixture of pure strategy profiles which maximize the potential.

If, in addition, (d) the strategy sets are compact, (e) the potential is a strictly concave function, then the correlated equilibrium is unique.

See also [ edit ] Congestion game Econophysics A characterization of ordinal potential games.

[ 9 ] References [ edit ] ^ a b Monderer, Dov; Shapley, Lloyd (1996). "Potential Games".

Games and Economic Behavior .

14 : 124– 143.

doi : 10.1006/game.1996.0044 .

^ Marden, J., (2012) State based potential games http://ecee.colorado.edu/marden/files/state-based-games.pdf ^ a b Dubey, Pradeep; Haimanko, Ori; Zapechelnyuk, Andriy (2006-01-01).

"Strategic complements and substitutes, and potential games" .

Games and Economic Behavior .

54 (1): 77– 94.

doi : 10.1016/j.geb.2004.10.007 .

ISSN 0899-8256 .

^ Rosenthal, Robert W. (1973), "A class of games possessing pure-strategy Nash equilibria", International Journal of Game Theory , 2 : 65– 67, doi : 10.1007/BF01737559 , MR 0319584 , S2CID 121904640 .

^ Fabrikant, Alex; Papadimitriou, Christos; Talwar, Kunal (2004-06-13).

"The complexity of pure Nash equilibria" .

Proceedings of the thirty-sixth annual ACM symposium on Theory of computing . STOC '04. New York, NY, USA: Association for Computing Machinery. pp.

604– 612.

doi : 10.1145/1007352.1007445 .

ISBN 978-1-58113-852-8 .

S2CID 1037326 .

^ a b Milchtaich, Igal (1996-03-01).

"Congestion Games with Player-Specific Payoff Functions" .

Games and Economic Behavior .

13 (1): 111– 124.

doi : 10.1006/game.1996.0027 .

ISSN 0899-8256 .

^ Young, H. Peyton (1993).

"The Evolution of Conventions" .

Econometrica .

61 (1): 57– 84.

doi : 10.2307/2951778 .

ISSN 0012-9682 .

JSTOR 2951778 .

^ Neyman, Abraham (1997-06-01).

"Correlated equilibrium and potential games" .

International Journal of Game Theory .

26 (2): 223– 227.

doi : 10.1007/BF01295851 .

ISSN 1432-1270 .

^ Voorneveld, Mark; Norde, Henk (1997-05-01).

"A Characterization of Ordinal Potential Games" .

Games and Economic Behavior .

19 (2): 235– 242.

doi : 10.1006/game.1997.0554 .

ISSN 0899-8256 .

S2CID 122795041 .

External links [ edit ] Lecture notes of Yishay Mansour about Potential and congestion games Section 19 in: Vazirani, Vijay V.

; Nisan, Noam ; Roughgarden, Tim ; Tardos, Éva (2007).

Algorithmic Game Theory (PDF) . Cambridge, UK: Cambridge University Press.

ISBN 0-521-87282-0 .

Non technical exposition by Huw Dixon of the inevitability of collusion Chapter 8, Donut world and the duopoly archipelago , Surfing Economics .

v t e Game theory Glossary Game theorists Games Traditional game theory Definitions Asynchrony Bayesian regret Best response Bounded rationality Cheap talk Coalition Complete contract Complete information Complete mixing Confrontation analysis Conjectural variation Contingent cooperator Coopetition Cooperative game theory Dynamic inconsistency Escalation of commitment Farsightedness Game semantics Hierarchy of beliefs Imperfect information Incomplete information Information set Move by nature Mutual knowledge Non-cooperative game theory Non-credible threat Outcome Perfect information Perfect recall Ply Preference Rationality Sequential game Simultaneous action selection Spite Strategic complements Strategic dominance Strategic form Strategic interaction Strategic move Strategy Subgame Succinct game Topological game Tragedy of the commons Uncorrelated asymmetry Equilibrium concepts Backward induction Bayes correlated equilibrium Bayesian efficiency Bayesian game Bayesian Nash equilibrium Berge equilibrium Bertrand–Edgeworth model Coalition-proof Nash equilibrium Core Correlated equilibrium Cursed equilibrium Edgeworth price cycle Epsilon-equilibrium Gibbs equilibrium Incomplete contracts Inequity aversion Individual rationality Iterated elimination of dominated strategies Markov perfect equilibrium Mertens-stable equilibrium Nash equilibrium Open-loop model Pareto efficiency Payoff dominance Perfect Bayesian equilibrium Price of anarchy Program equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Rational agent Rationalizability Rationalizable strategy Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfect equilibrium Trembling hand equilibrium Strategies Appeasement Bid shading Cheap talk Collusion Commitment device De-escalation Deterrence Escalation Fictitious play Focal point Grim trigger Hobbesian trap Markov strategy Max-dominated strategy Mixed strategy Pure strategy Tit for tat Win–stay, lose–switch Games All-pay auction Battle of the sexes Nash bargaining game Bertrand competition Blotto game Centipede game Coordination game Cournot competition Deadlock Dictator game Trust game Diner's dilemma Dollar auction El Farol Bar problem Electronic mail game Gift-exchange game Guess 2/3 of the average Keynesian beauty contest Kuhn poker Lewis signaling game Matching pennies Obligationes Optional prisoner's dilemma Pirate game Prisoner's dilemma Public goods game Rendezvous problem Rock paper scissors Stackelberg competition Stag hunt Traveler's dilemma Ultimatum game Volunteer's dilemma War of attrition Theorems Arrow's impossibility theorem Aumann's agreement theorem Brouwer fixed-point theorem Competitive altruism Folk theorem Gibbard–Satterthwaite theorem Gibbs lemma Glicksberg's theorem Kakutani fixed-point theorem Kuhn's theorem One-shot deviation principle Prim–Read theory Rational ignorance Rational irrationality Sperner's lemma Zermelo's theorem Subfields Algorithmic game theory Behavioral game theory Behavioral strategy Compositional game theory Contract theory Drama theory Graphical game theory Heresthetic Mean-field game theory Negotiation theory Quantum game theory Social software Key people Albert W. Tucker Alvin E. Roth Amos Tversky Antoine Augustin Cournot Ariel Rubinstein David Gale David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Herbert Scarf Hervé Moulin Jean Tirole Jean-François Mertens Jennifer Tour Chayes Ken Binmore Kenneth Arrow Leonid Hurwicz Lloyd Shapley Martin Shubik Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Aumann Robert Axelrod Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Combinatorial game theory Core concepts Combinatorial explosion Determinacy Disjunctive sum First-player and second-player win Game complexity Game tree Impartial game Misère Partisan game Solved game Sprague–Grundy theorem Strategy-stealing argument Zugzwang Games Chess Chomp Clobber Cram Domineering Hackenbush Nim Notakto Subtract a square Sylver coinage Toads and Frogs Mathematical tools Mex Nimber On Numbers and Games Star Surreal number Winning Ways for Your Mathematical Plays Search algorithms Alpha–beta pruning Expectiminimax Minimax Monte Carlo tree search Negamax Paranoid algorithm Principal variation search Key people Claude Shannon John Conway John von Neumann Evolutionary game theory Core concepts Bishop–Cannings theorem Evolution and the Theory of Games Evolutionarily stable set Evolutionarily stable state Evolutionarily stable strategy Replicator equation Risk dominance Stochastically stable equilibrium Weak evolutionarily stable strategy Games Chicken Stag hunt Applications Cultural group selection Fisher's principle Mobbing Terminal investment hypothesis Key people John Maynard Smith Robert Axelrod Mechanism design Core concepts Algorithmic mechanism design Bayesian-optimal mechanism Incentive compatibility Market design Monotonicity Participation constraint Revelation principle Strategyproofness Vickrey–Clarke–Groves mechanism Theorems Myerson–Satterthwaite theorem Revenue equivalence Applications Digital goods auction Knapsack auction Truthful cake-cutting Other topics Bertrand paradox Chainstore paradox Computational complexity of games Helly metric Multi-agent system PPAD-complete Mathematics portal Commons WikiProject Category v t e Microeconomics Major topics Aggregation Budget set Consumer choice Convexity and non-convexity Cost Average Marginal Opportunity Implicit Social Sunk Transaction Cost–benefit analysis Deadweight loss Distribution Economies of scale Economies of scope Elasticity Cross elasticity of demand Income elasticity of demand Price elasticity of demand Price elasticity of supply Equilibrium General Exchange Externality Firms Goods and services Goods Service Household Income–consumption curve Information Indifference curve Intertemporal choice Market Market failure Market structure Competition Monopolistic Perfect Duopoly Monopoly Bilateral Complementary Monopsony Oligopoly Oligopsony Pareto efficiency Preferences Price Price controls Price ceiling Price floor Price discrimination Price signal Price system / Free Pricing Production Profit Public goods Rationing Rent Returns to scale Risk aversion Scarcity Shortage / Excess supply Substitution effect Surplus Social choice Supply and demand Demand / Law of demand Supply / Law of supply Uncertainty Utility Expected Marginal Wage Subfields Behavioral Business Computational Development Statistical decision theory Econometrics Engineering economics Civil engineering economics Evolutionary Experimental Game theory Green Industrial organization Institutional Labour Law Managerial Mathematical Microfoundations of macroeconomics Operations research Optimization Welfare See also Economics Applied Macroeconomics Political economy Business portal Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Potential_game&oldid=1305737002 " Category : Game theory game classes Hidden categories: Articles with short description Short description is different from Wikidata Wikipedia articles needing clarification from June 2023 This page was last edited on 13 August 2025, at 20:38 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Potential game 7 languages Add topic

