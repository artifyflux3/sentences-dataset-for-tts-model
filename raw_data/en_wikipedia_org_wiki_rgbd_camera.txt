Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Types of range cameras Toggle Types of range cameras subsection 1.1 Stereo triangulation 1.2 Sheet of light triangulation 1.3 Structured light 1.4 Time-of-flight 1.5 Interferometry 1.6 Coded aperture 2 See also 3 References Toggle the table of contents Range imaging 3 languages 한국어 Italiano Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from RGBD camera ) Measuring technique Not to be confused with high-dynamic-range imaging .

This article needs to be updated .

Please help update this article to reflect recent events or newly available information.

( October 2019 ) Range imaging is the name for a collection of techniques that are used to produce a 2D image showing the distance to points in a scene from a specific point, normally associated with some type of sensor device.

The resulting range image has pixel values that correspond to the distance. If the sensor that is used to produce the range image is properly calibrated the pixel values can be given directly in physical units, such as meters.

Types of range cameras [ edit ] The sensor device that is used for producing the range image is sometimes referred to as a range camera or depth camera . Range cameras can operate according to a number of different techniques, some of which are presented here.

Stereo triangulation [ edit ] Stereo triangulation is an application of stereophotogrammetry where the depth data of the pixels are determined from data acquired using a stereo or multiple-camera setup system. This way it is possible to determine the depth to points in the scene, for example, from the center point of the line between their focal points. In order to solve the depth measurement problem using a stereo camera system it is necessary to first find corresponding points in the different images. Solving the correspondence problem is one of the main problems when using this type of technique. For instance, it is difficult to solve the correspondence problem for image points that lie inside regions of homogeneous intensity or color. As a consequence, range imaging based on stereo triangulation can usually produce reliable depth estimates only for a subset of all points visible in the multiple cameras.

The advantage of this technique is that the measurement is more or less passive; it does not require special conditions in terms of scene illumination. The other techniques mentioned here do not have to solve the correspondence problem but are instead dependent on particular scene illumination conditions.

Sheet of light triangulation [ edit ] If the scene is illuminated with a sheet of light this creates a reflected line as seen from the light source. From any point out of the plane of the sheet the line will typically appear as a curve, the exact shape of which depends both on the distance between the observer and the light source, and the distance between the light source and the reflected points. By observing the reflected sheet of light using a camera (often a high resolution camera) and knowing the positions and orientations of both camera and light source, it is possible to determine the distances between the reflected points and the light source or camera.

By moving either the light source (and normally also the camera) or the scene in front of the camera, a sequence of depth profiles of the scene can be generated. These can be represented as a 2D range image.

Structured light [ edit ] Main article: Structured-light 3D scanner By illuminating the scene with a specially designed light pattern, structured light , depth can be determined using only a single image of the reflected light. The structured light can be in the form of horizontal and vertical lines, points or checker board patterns. A light stage is basically a generic structured light range imaging device originally created for the job of reflectance capture .

Time-of-flight [ edit ] Main article: Time-of-flight camera The depth can also be measured using the standard time-of-flight (ToF) technique, more or less like a radar , in that a range image similar to a radar image is produced, except that a light pulse is used instead of an RF pulse. It is also not unlike a LIDAR , except that ToF is scannerless, i.e., the entire scene is captured with a single light pulse, as opposed to point-by-point with a rotating laser beam. Time-of-flight cameras are relatively new devices that capture a whole scene in three dimensions with a dedicated image sensor, and therefore have no need for moving parts. A time-of-flight laser radar with a fast gating intensified CCD camera achieves sub-millimeter depth resolution. With this technique a short laser pulse illuminates a scene, and the intensified CCD camera opens its high speed shutter only for a few hundred picoseconds . The 3D information is calculated from a 2D image series that was gathered with increasing delay between the laser pulse and the shutter opening.

[ 1 ] Interferometry [ edit ] By illuminating points with coherent light and measuring the phase shift of the reflected light relative to the light source it is possible to determine depth. Under the assumption that the true range image is a more or less continuous function of the image coordinates, the correct depth can be obtained using a technique called phase-unwrapping. See terrestrial SAR interferometry .

Coded aperture [ edit ] Further information: Coded aperture Depth information may be partially or wholly inferred alongside intensity through reverse convolution of an image captured with a specially designed coded aperture pattern with a specific complex arrangement of holes through which the incoming light is either allowed through or blocked. The complex shape of the aperture creates a non-uniform blurring of the image for those parts of the scene not at the focal plane of the lens. The extent of blurring across the scene, which is related to the displacement from the focal plane, may be used to infer the depth.

[ 2 ] In order to identify the size of the blur (needed to decode depth information) in the captured image, two approaches can be used: 1) deblurring the captured image with different blurs, or 2) learning some linear filters that identify the type of blur.

The first approach uses correct mathematical deconvolution that takes account of the known aperture design pattern; this deconvolution can identify where and by what degree the scene has become convoluted by out of focus light selectively falling on the capture surface, and reverse the process.

[ 3 ] Thus the blur-free scene may be retrieved together with the size of the blur.

The second approach, instead, extracts the extent of the blur bypassing the recovery of the blur-free image, and therefore without performing reverse convolution. Using a principal component analysis (PCA) based technique, the method learns off-line a bank of filters that uniquely identify each size of blur; these filters are then applied directly to the captured image, as a normal convolution.

[ 4 ] The most important  advantage of this approach is that no information about the coded aperture pattern is required. Because of its efficiency, this algorithm has also been extended to video sequences with moving and deformable objects.

[ 5 ] Since the depth for a point is inferred from its extent of blurring caused by the light spreading from the corresponding point in the scene arriving across the entire surface of the aperture and distorting according to this spread, this is a complex form of stereo triangulation. Each point in the image is effectively spatially sampled across the width of the aperture.

This technology has lately been used in the iPhone X . Many other phones from Samsung and computers from Microsoft have tried to use this technology but they do not use the 3D mapping.

See also [ edit ] 3D scanner Depth map Intensified CCD camera Kinect Laser Dynamic Range Imager Laser rangefinder Lidar Light-field camera (plenoptic camera) Optical flow technique developed for the Matrix franchise provides an effective solution to the correspondence problem to enable virtual cinematography .

Photogrammetry Structure from motion Time-of-flight camera References [ edit ] ^ High accuracy 3D laser radar Jens Busck and Henning Heiselberg, Danmarks Tekniske University, 2004 ^ Martinello, Manuel (2012).

Coded Aperture Imaging (PDF) . Heriot-Watt University. Archived from the original (PDF) on 2022-03-20 . Retrieved 2017-04-02 .

^ Image and depth from a conventional camera with a coded aperture Anat Levin, Rob Fergus, Fredo Durand, William T. Freeman, MIT ^ Martinello, Manuel; Favaro, Paolo (2011).

"Single Image Blind Deconvolution with Higher-Order Texture Statistics" (PDF) .

Video Processing and Computational Video . Lecture Notes in Computer Science. Vol. 7082. Springer-Verlag. pp.

124– 151.

doi : 10.1007/978-3-642-24870-2_6 .

ISBN 978-3-642-24869-6 .

^ Martinello, Manuel; Favaro, Paolo (2012). "Depth estimation from a video sequence with moving and deformable objects".

IET Conference on Image Processing (IPR 2012) (PDF) . p. 131.

doi : 10.1049/cp.2012.0425 .

ISBN 978-1-84919-632-1 .

[ permanent dead link ] Bernd Jähne (1997).

Practical Handbook on Image Processing for Scientific Applications . CRC Press.

ISBN 0-8493-8906-2 .

Linda G. Shapiro and George C. Stockman (2001).

Computer Vision . Prentice Hall.

ISBN 0-13-030796-3 .

David A. Forsyth and Jean Ponce (2003).

Computer Vision, A Modern Approach . Prentice Hall.

ISBN 0-12-379777-2 .

NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐gjj9r
Cached time: 20250812065003
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.222 seconds
Real time usage: 0.296 seconds
Preprocessor visited node count: 851/1000000
Revision size: 10340/2097152 bytes
Post‐expand include size: 20199/2097152 bytes
Template argument size: 1956/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 23578/5000000 bytes
Lua time usage: 0.144/10.000 seconds
Lua memory usage: 5405459/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  269.966      1 -total
 40.65%  109.730      1 Template:Reflist
 36.96%   99.790      6 Template:Cite_book
 24.06%   64.947      6 Template:Main_other
 21.96%   59.287      1 Template:Short_description
 20.06%   54.166      1 Template:Update
 18.36%   49.571      1 Template:Ambox
 12.60%   34.023      2 Template:Pagetype
  7.35%   19.835      1 Template:Distinguish
  4.75%   12.831      1 Template:SDcat Saved in parser cache with key enwiki:pcache:12593461:|#|:idhash:canonical and timestamp 20250812065003 and revision id 1304507565. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Range_imaging&oldid=1304507565 " Categories : Image sensor technology in computer vision Cameras 3D imaging Hidden categories: All articles with dead external links Articles with dead external links from August 2025 Articles with permanently dead external links Articles with short description Short description is different from Wikidata Wikipedia articles in need of updating from October 2019 All Wikipedia articles in need of updating This page was last edited on 6 August 2025, at 12:25 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Range imaging 3 languages Add topic

