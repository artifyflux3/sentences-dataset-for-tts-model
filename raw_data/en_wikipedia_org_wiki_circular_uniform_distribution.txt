Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Description Toggle Description subsection 1.1 Definition 1.2 Moments with respect to a parametrization 2 Descriptive statistics Toggle Descriptive statistics subsection 2.1 Distribution of the mean 3 Entropy 4 See also 5 References Toggle the table of contents Circular uniform distribution 2 languages Català 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Probability distribution This article relies largely or entirely on a single source .

Relevant discussion may be found on the talk page . Please help improve this article by introducing  citations to additional sources .

Find sources: "Circular uniform distribution" – news · newspapers · books · scholar · JSTOR ( May 2010 ) In probability theory and directional statistics , a circular uniform distribution is a probability distribution on the unit circle whose density is uniform for all angles.

Description [ edit ] Definition [ edit ] The probability density function (pdf) of the circular uniform distribution, e.g. with θ θ ∈ ∈ [ 0 , 2 π π ) {\displaystyle \theta \in [0,2\pi )} , is: f U C ( θ θ ) = 1 2 π π .

{\displaystyle f_{UC}(\theta )={\frac {1}{2\pi }}.} Moments with respect to a parametrization [ edit ] We consider the circular variable z = e i θ θ {\displaystyle z=e^{i\theta }} with z = 1 {\displaystyle z=1} at base angle θ θ = 0 {\displaystyle \theta =0} . In these terms, the circular moments of the circular uniform distribution are all zero, except for m 0 {\displaystyle m_{0}} : ⟨ ⟨ z n ⟩ ⟩ = δ δ n {\displaystyle \langle z^{n}\rangle =\delta _{n}} where δ δ n {\displaystyle \delta _{n}} is the Kronecker delta symbol.

Descriptive statistics [ edit ] Here the mean angle is undefined, and the length of the mean resultant is zero.

R = | ⟨ ⟨ z n ⟩ ⟩ | = 0 {\displaystyle R=|\langle z^{n}\rangle |=0\,} Distribution of the mean [ edit ] A 10,000 point Monte Carlo simulation of the distribution of the sample mean of a circular uniform distribution for N = 3 Probability densities P N ( R ¯ ¯ ) {\displaystyle P_{N}({\bar {R}})} for small values of N {\displaystyle N} . Densities for N > 3 {\displaystyle N>3} are normalised to the maximum density, those for N = 1 {\displaystyle N=1} and 2 {\displaystyle 2} are scaled to aid visibility.

The sample mean of a set of N measurements z n = e i θ θ n {\displaystyle z_{n}=e^{i\theta _{n}}} drawn from a circular uniform distribution is defined as: z ¯ ¯ = 1 N ∑ ∑ n = 1 N z n = C ¯ ¯ + i S ¯ ¯ = R ¯ ¯ e i θ θ ¯ ¯ {\displaystyle {\overline {z}}={\frac {1}{N}}\sum _{n=1}^{N}z_{n}={\overline {C}}+i{\overline {S}}={\overline {R}}e^{i{\overline {\theta }}}} where the average sine and cosine are: [ 1 ] C ¯ ¯ = 1 N ∑ ∑ n = 1 N cos ⁡ ⁡ ( θ θ n ) S ¯ ¯ = 1 N ∑ ∑ n = 1 N sin ⁡ ⁡ ( θ θ n ) {\displaystyle {\overline {C}}={\frac {1}{N}}\sum _{n=1}^{N}\cos(\theta _{n})\qquad \qquad {\overline {S}}={\frac {1}{N}}\sum _{n=1}^{N}\sin(\theta _{n})} and the average resultant length is: R ¯ ¯ 2 = | z ¯ ¯ | 2 = C ¯ ¯ 2 + S ¯ ¯ 2 {\displaystyle {\overline {R}}^{2}=|{\overline {z}}|^{2}={\overline {C}}^{2}+{\overline {S}}^{2}} and the mean angle is: θ θ ¯ ¯ = A r g ( z ¯ ¯ ) .

{\displaystyle {\overline {\theta }}=\mathrm {Arg} ({\overline {z}}).\,} The sample mean for the circular uniform distribution will be concentrated about zero, becoming more concentrated as N increases. The distribution of the sample mean for the uniform distribution is given by: [ 2 ] 1 ( 2 π π ) N ∫ ∫ Γ Γ ∏ ∏ n = 1 N d θ θ n = P ( R ¯ ¯ ) P ( θ θ ¯ ¯ ) d R ¯ ¯ d θ θ ¯ ¯ {\displaystyle {\frac {1}{(2\pi )^{N}}}\int _{\Gamma }\prod _{n=1}^{N}d\theta _{n}=P({\overline {R}})P({\overline {\theta }})\,d{\overline {R}}\,d{\overline {\theta }}} where Γ Γ {\displaystyle \Gamma \,} consists of intervals of 2 π π {\displaystyle 2\pi } in the variables, subject to the constraint that R ¯ ¯ {\displaystyle {\overline {R}}} and θ θ ¯ ¯ {\displaystyle {\overline {\theta }}} are constant, or, alternatively, that C ¯ ¯ {\displaystyle {\overline {C}}} and S ¯ ¯ {\displaystyle {\overline {S}}} are constant. The distribution of the angle P ( θ θ ¯ ¯ ) {\displaystyle P({\overline {\theta }})} is uniform P ( θ θ ¯ ¯ ) = 1 2 π π {\displaystyle P({\overline {\theta }})={\frac {1}{2\pi }}} and the distribution of R ¯ ¯ {\displaystyle {\overline {R}}} is given by: [ 2 ] P N ( R ¯ ¯ ) = N 2 R ¯ ¯ ∫ ∫ 0 ∞ ∞ J 0 ( N R ¯ ¯ t ) J 0 ( t ) N t d t {\displaystyle P_{N}({\overline {R}})=N^{2}{\overline {R}}\int _{0}^{\infty }J_{0}(N{\overline {R}}\,t)J_{0}(t)^{N}t\,dt} where J 0 {\displaystyle J_{0}} is the Bessel function of order zero. There is no known general analytic solution for the above integral, and it is difficult to evaluate due to the large number of oscillations in the integrand. A 10,000 point Monte Carlo simulation of the distribution of the mean for N=3 is shown in the figure.

For certain special cases, the above integral can be evaluated: P 2 ( R ¯ ¯ ) = 2 π π 1 − − R ¯ ¯ 2 .

{\displaystyle P_{2}({\overline {R}})={\frac {2}{\pi {\sqrt {1-{\overline {R}}^{2}}}}}.} For large N , the distribution of the mean can be determined from the central limit theorem for directional statistics . Since the angles are uniformly distributed, the individual sines and cosines of the angles will be distributed as: P ( u ) d u = 1 π π d u 1 − − u 2 {\displaystyle P(u)du={\frac {1}{\pi }}\,{\frac {du}{\sqrt {1-u^{2}}}}} where u = cos ⁡ ⁡ θ θ n {\displaystyle u=\cos \theta _{n}\,} or sin ⁡ ⁡ θ θ n {\displaystyle \sin \theta _{n}\,} . It follows that they will have zero mean and a variance of 1/2. By the central limit theorem, in the limit of large N , C ¯ ¯ {\displaystyle {\overline {C}}\,} and S ¯ ¯ {\displaystyle {\overline {S}}\,} , being the sum of a large number of i.i.d 's, will be normally distributed with mean zero and variance 1 / 2 N {\displaystyle 1/2N} . The mean resultant length R ¯ ¯ {\displaystyle {\overline {R}}\,} , being the square root of the sum of squares of two normally distributed independent variables, will be Chi-distributed with two degrees of freedom (i.e.

Rayleigh-distributed ) and variance 1 / 2 N {\displaystyle 1/2N} : lim N → → ∞ ∞ P N ( R ¯ ¯ ) = 2 N R ¯ ¯ e − − N R ¯ ¯ 2 .

{\displaystyle \lim _{N\rightarrow \infty }P_{N}({\overline {R}})=2N{\overline {R}}\,e^{-N{\overline {R}}^{2}}.} Entropy [ edit ] The differential information entropy of the uniform distribution is simply H U = − − ∫ ∫ Γ Γ 1 2 π π ln ⁡ ⁡ ( 1 2 π π ) d θ θ = ln ⁡ ⁡ ( 2 π π ) {\displaystyle H_{U}=-\int _{\Gamma }{\frac {1}{2\pi }}\ln \left({\frac {1}{2\pi }}\right)\,d\theta =\ln(2\pi )} where Γ Γ {\displaystyle \Gamma } is any interval of length 2 π π {\displaystyle 2\pi } . This is the maximum entropy any circular distribution may have.

See also [ edit ] Wrapped distribution References [ edit ] ^ "Transmit beamforming for radar applications using circularly tapered random arrays - IEEE Conference Publication".

doi : 10.1109/RADAR.2017.7944181 .

S2CID 38429370 .

{{ cite journal }} : Cite journal requires |journal= ( help ) ^ a b Jammalamadaka, S. Rao; Sengupta, A. (2001).

Topics in Circular Statistics . World Scientific Publishing Company.

ISBN 978-981-02-3778-3 .

v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Circular_uniform_distribution&oldid=1173382996 " Categories : Continuous distributions Directional statistics Hidden categories: CS1 errors: missing periodical Articles with short description Short description matches Wikidata Articles needing additional references from May 2010 All articles needing additional references This page was last edited on 2 September 2023, at 02:21 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Circular uniform distribution 2 languages Add topic

