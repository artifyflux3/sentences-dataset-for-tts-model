Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Symmetric version Toggle Symmetric version subsection 1.1 Parameter estimation 1.1.1 Maximum likelihood estimator 1.2 Applications 1.3 Properties 1.3.1 Moments 1.3.2 Connection to Stable Count Distribution 1.3.3 Connection to Positive-Definite Functions 1.3.4 Infinite divisibility 1.4 Generalizations 2 Asymmetric version Toggle Asymmetric version subsection 2.1 Parameter estimation 2.2 Applications 3 Kullback–Leibler divergence between two PDFs 4 Other distributions related to the normal 5 See also 6 References Toggle the table of contents Generalized normal distribution 6 languages Català فارسی Français עברית Русский Slovenščina Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Probability distribution The generalized normal distribution ( GND ) or generalized Gaussian distribution ( GGD ) is either of two families of parametric continuous probability distributions on the real line.  Both families add a shape parameter to the normal distribution .  To distinguish the two families, they are referred to below as "symmetric" and "asymmetric"; however, this is not a standard nomenclature.

Symmetric version [ edit ] Symmetric Generalized Normal Probability density function Cumulative distribution function Parameters μ μ {\displaystyle \mu \,} location ( real ) α α {\displaystyle \alpha \,} scale (positive, real ) β β {\displaystyle \beta \,} shape (positive, real ) Support x ∈ ∈ ( − − ∞ ∞ ; + ∞ ∞ ) {\displaystyle x\in (-\infty ;+\infty )\!} PDF β β 2 α α Γ Γ ( 1 / β β ) e − − ( | x − − μ μ | / α α ) β β {\displaystyle {\frac {\beta }{2\alpha \Gamma (1/\beta )}}\;e^{-(|x-\mu |/\alpha )^{\beta }}} Γ Γ {\displaystyle \Gamma } denotes the gamma function CDF 1 2 + sign ( x − − μ μ ) 1 2 Γ Γ ( 1 / β β ) γ γ ( 1 / β β , | x − − μ μ α α | β β ) {\displaystyle {\frac {1}{2}}+{\text{sign}}(x-\mu ){\frac {1}{2\Gamma (1/\beta )}}\gamma \left(1/\beta ,\left|{\frac {x-\mu }{\alpha }}\right|^{\beta }\right)} where β β {\displaystyle \beta } is a shape parameter, α α {\displaystyle \alpha } is a scale parameter and γ γ {\displaystyle \gamma } is the unnormalized incomplete lower gamma function .

Quantile sign ( p − − 0.5 ) [ α α β β F − − 1 ( 2 | p − − 0.5 | ; 1 β β ) ] 1 / β β + μ μ {\displaystyle {\text{sign}}(p-0.5)\left[\alpha ^{\beta }F^{-1}\left(2|p-0.5|;{\frac {1}{\beta }}\right)\right]^{1/\beta }+\mu } where F − − 1 ( p ; a ) {\displaystyle F^{-1}\left(p;a\right)} is the quantile function of Gamma distribution [ 1 ] Mean μ μ {\displaystyle \mu \,} Median μ μ {\displaystyle \mu \,} Mode μ μ {\displaystyle \mu \,} Variance α α 2 Γ Γ ( 3 / β β ) Γ Γ ( 1 / β β ) {\displaystyle {\frac {\alpha ^{2}\Gamma (3/\beta )}{\Gamma (1/\beta )}}} Skewness 0 Excess kurtosis Γ Γ ( 5 / β β ) Γ Γ ( 1 / β β ) Γ Γ ( 3 / β β ) 2 − − 3 {\displaystyle {\frac {\Gamma (5/\beta )\Gamma (1/\beta )}{\Gamma (3/\beta )^{2}}}-3} Entropy 1 β β − − log ⁡ ⁡ [ β β 2 α α Γ Γ ( 1 / β β ) ] {\displaystyle {\frac {1}{\beta }}-\log \left[{\frac {\beta }{2\alpha \Gamma (1/\beta )}}\right]} [ 2 ] The symmetric generalized normal distribution , also known as the exponential power distribution or the generalized error distribution , is a parametric family of symmetric distributions .  It includes all normal and Laplace distributions, and as limiting cases it includes all continuous uniform distributions on bounded intervals of the real line.

This family includes the normal distribution when β β = 2 {\displaystyle \textstyle \beta =2} (with mean μ μ {\displaystyle \textstyle \mu } and variance α α 2 2 {\displaystyle \textstyle {\frac {\alpha ^{2}}{2}}} ) and it includes the Laplace distribution when β β = 1 {\displaystyle \textstyle \beta =1} . As β β → → ∞ ∞ {\displaystyle \textstyle \beta \rightarrow \infty } , the density converges pointwise to a uniform density on ( μ μ − − α α , μ μ + α α ) {\displaystyle \textstyle (\mu -\alpha ,\mu +\alpha )} .

This family allows for tails that are either heavier than normal (when β β < 2 {\displaystyle \beta <2} ) or lighter than normal (when β β > 2 {\displaystyle \beta >2} ).  It is a useful way to parametrize a continuum of symmetric, platykurtic densities spanning from the normal ( β β = 2 {\displaystyle \textstyle \beta =2} ) to the uniform density ( β β = ∞ ∞ {\displaystyle \textstyle \beta =\infty } ), and a continuum of symmetric, leptokurtic densities spanning from the Laplace ( β β = 1 {\displaystyle \textstyle \beta =1} ) to the normal density ( β β = 2 {\displaystyle \textstyle \beta =2} ).
The shape parameter β β {\displaystyle \beta } also controls the peakedness in addition to the tails.

Parameter estimation [ edit ] Parameter estimation via maximum likelihood and the method of moments has been studied.

[ 3 ] The estimates do not have a closed form and must be obtained numerically.  Estimators that do not require numerical calculation have also been proposed.

[ 4 ] The generalized normal log-likelihood function has infinitely many continuous derivates (i.e. it belongs to the class C ∞ of smooth functions ) only if β β {\displaystyle \textstyle \beta } is a positive, even integer.  Otherwise, the function has ⌊ ⌊ β β ⌋ ⌋ {\displaystyle \textstyle \lfloor \beta \rfloor } continuous derivatives.  As a result, the standard results for consistency and asymptotic normality of maximum likelihood estimates of β β {\displaystyle \beta } only apply when β β ≥ ≥ 2 {\displaystyle \textstyle \beta \geq 2} .

Maximum likelihood estimator [ edit ] It is possible to fit the generalized normal distribution adopting an approximate maximum likelihood method.

[ 5 ] [ 6 ] With μ μ {\displaystyle \mu } initially set to the sample first moment m 1 {\displaystyle m_{1}} , β β {\displaystyle \textstyle \beta } is estimated by using a Newton–Raphson iterative procedure, starting from an initial guess of β β = β β 0 {\displaystyle \textstyle \beta =\textstyle \beta _{0}} , β β 0 = m 1 m 2 , {\displaystyle \beta _{0}={\frac {m_{1}}{\sqrt {m_{2}}}},} where m 1 = 1 N ∑ ∑ i = 1 N | x i | , {\displaystyle m_{1}={1 \over N}\sum _{i=1}^{N}|x_{i}|,} is the first statistical moment of the absolute values and m 2 {\displaystyle m_{2}} is the second statistical moment . The iteration is β β i + 1 = β β i − − g ( β β i ) g ′ ( β β i ) , {\displaystyle \beta _{i+1}=\beta _{i}-{\frac {g(\beta _{i})}{g'(\beta _{i})}},} where g ( β β ) = 1 + ψ ψ ( 1 / β β ) β β − − ∑ ∑ i = 1 N | x i − − μ μ | β β log ⁡ ⁡ | x i − − μ μ | ∑ ∑ i = 1 N | x i − − μ μ | β β + log ⁡ ⁡ ( β β N ∑ ∑ i = 1 N | x i − − μ μ | β β ) β β , {\displaystyle g(\beta )=1+{\frac {\psi (1/\beta )}{\beta }}-{\frac {\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\log |x_{i}-\mu |}{\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }}}+{\frac {\log({\frac {\beta }{N}}\sum _{i=1}^{N}|x_{i}-\mu |^{\beta })}{\beta }},} and g ′ ( β β ) = − − ψ ψ ( 1 / β β ) β β 2 − − ψ ψ ′ ( 1 / β β ) β β 3 + 1 β β 2 − − ∑ ∑ i = 1 N | x i − − μ μ | β β ( log ⁡ ⁡ | x i − − μ μ | ) 2 ∑ ∑ i = 1 N | x i − − μ μ | β β + ( ∑ ∑ i = 1 N | x i − − μ μ | β β log ⁡ ⁡ | x i − − μ μ | ) 2 ( ∑ ∑ i = 1 N | x i − − μ μ | β β ) 2 + ∑ ∑ i = 1 N | x i − − μ μ | β β log ⁡ ⁡ | x i − − μ μ | β β ∑ ∑ i = 1 N | x i − − μ μ | β β − − log ⁡ ⁡ ( β β N ∑ ∑ i = 1 N | x i − − μ μ | β β ) β β 2 , {\displaystyle {\begin{aligned}g'(\beta )={}&-{\frac {\psi (1/\beta )}{\beta ^{2}}}-{\frac {\psi '(1/\beta )}{\beta ^{3}}}+{\frac {1}{\beta ^{2}}}-{\frac {\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }(\log |x_{i}-\mu |)^{2}}{\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }}}\\[6pt]&{}+{\frac {\left(\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\log |x_{i}-\mu |\right)^{2}}{\left(\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\right)^{2}}}+{\frac {\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\log |x_{i}-\mu |}{\beta \sum _{i=1}^{N}|x_{i}-\mu |^{\beta }}}\\[6pt]&{}-{\frac {\log \left({\frac {\beta }{N}}\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\right)}{\beta ^{2}}},\end{aligned}}} and where ψ ψ {\displaystyle \psi } and ψ ψ ′ {\displaystyle \psi '} are the digamma function and trigamma function .

Given a value for β β {\displaystyle \textstyle \beta } , it is possible to estimate μ μ {\displaystyle \mu } by finding the minimum of: min μ μ = ∑ ∑ i = 1 N | x i − − μ μ | β β {\displaystyle \min _{\mu }=\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }} Finally α α {\displaystyle \textstyle \alpha } is evaluated as α α = ( β β N ∑ ∑ i = 1 N | x i − − μ μ | β β ) 1 / β β .

{\displaystyle \alpha =\left({\frac {\beta }{N}}\sum _{i=1}^{N}|x_{i}-\mu |^{\beta }\right)^{1/\beta }.} For β β ≤ ≤ 1 {\displaystyle \beta \leq 1} , median is a more appropriate estimator of μ μ {\displaystyle \mu } . Once μ μ {\displaystyle \mu } is estimated, β β {\displaystyle \beta } and α α {\displaystyle \alpha } can be estimated as described above.

[ 7 ] Applications [ edit ] The symmetric generalized normal distribution has been used in modeling when the concentration of values around the mean and the tail behavior are of particular interest.

[ 8 ] [ 9 ] Other families of distributions can be used if the focus is on other deviations from normality.  If the symmetry of the distribution is the main interest, the skew normal family or asymmetric version of the generalized normal family discussed below can be used.  If the tail behavior is the main interest, the student t family can be used, which approximates the normal distribution as the degrees of freedom grows to infinity.  The t distribution, unlike this generalized normal distribution, obtains heavier than normal tails without acquiring a cusp at the origin. It finds uses in plasma physics under the name of Langdon Distribution resulting from inverse bremsstrahlung.

[ 10 ] In a linear regression problem modeled as y ∼ ∼ G e n e r a l i z e d N o r m a l ( X ⋅ ⋅ θ θ , α α , p ) {\displaystyle y\sim \mathrm {GeneralizedNormal} (X\cdot \theta ,\alpha ,p)} , the MLE will be the arg ⁡ ⁡ min θ θ ‖ ‖ X ⋅ ⋅ θ θ − − y ‖ ‖ p {\displaystyle \arg \min _{\theta }\|X\cdot \theta -y\|_{p}} where the p-norm is used.

Properties [ edit ] Moments [ edit ] Let X β β {\displaystyle X_{\beta }} be zero mean generalized Gaussian distribution of shape β β {\displaystyle \beta } and scaling parameter α α {\displaystyle \alpha } .  The moments of X β β {\displaystyle X_{\beta }} exist and are finite for any k greater than −1.  For any non-negative integer k, the plain central moments are [ 2 ] E ⁡ ⁡ [ X β β k ] = { 0 if k is odd, α α k Γ Γ ( k + 1 β β ) / Γ Γ ( 1 β β ) if k is even.

{\displaystyle \operatorname {E} \left[X_{\beta }^{k}\right]={\begin{cases}0&{\text{if }}k{\text{ is odd,}}\\\alpha ^{k}\Gamma \left({\frac {k+1}{\beta }}\right){\Big /}\,\Gamma \left({\frac {1}{\beta }}\right)&{\text{if }}k{\text{ is even.}}\end{cases}}} Connection to Stable Count Distribution [ edit ] From the viewpoint of the Stable count distribution , β β {\displaystyle \beta } can be regarded as Lévy's stability parameter. This distribution can be decomposed to an integral of kernel density where the kernel is either a Laplace distribution or a Gaussian distribution : 1 2 1 Γ Γ ( 1 β β + 1 ) e − − z β β = { ∫ ∫ 0 ∞ ∞ 1 ν ν ( 1 2 e − − | z | / ν ν ) N β β ( ν ν ) d ν ν , 1 ≥ ≥ β β > 0 ; or ∫ ∫ 0 ∞ ∞ 1 s ( 1 2 π π e − − 1 2 ( z / s ) 2 ) V β β ( s ) d s , 2 ≥ ≥ β β > 0 ; {\displaystyle {\frac {1}{2}}{\frac {1}{\Gamma ({\frac {1}{\beta }}+1)}}e^{-z^{\beta }}={\begin{cases}\displaystyle \int _{0}^{\infty }{\frac {1}{\nu }}\left({\frac {1}{2}}e^{-|z|/\nu }\right){\mathfrak {N}}_{\beta }(\nu )\,d\nu ,&1\geq \beta >0;{\text{or }}\\\displaystyle \int _{0}^{\infty }{\frac {1}{s}}\left({\frac {1}{\sqrt {2\pi }}}e^{-{\frac {1}{2}}(z/s)^{2}}\right)V_{\beta }(s)\,ds,&2\geq \beta >0;\end{cases}}} where N β β ( ν ν ) {\displaystyle {\mathfrak {N}}_{\beta }(\nu )} is the Stable count distribution and V β β ( s ) {\displaystyle V_{\beta }(s)} is the Stable vol distribution .

Connection to Positive-Definite Functions [ edit ] The probability density function of the symmetric generalized normal distribution is a positive-definite function for β β ∈ ∈ ( 0 , 2 ] {\displaystyle \beta \in (0,2]} .

[ 11 ] [ 12 ] Infinite divisibility [ edit ] The symmetric generalized Gaussian distribution is an infinitely divisible distribution if and only if β β ∈ ∈ ( 0 , 1 ] ∪ ∪ { 2 } {\displaystyle \beta \in (0,1]\cup \{2\}} .

[ 11 ] Generalizations [ edit ] The multivariate generalized normal distribution, i.e. the product of n {\displaystyle n} exponential power distributions with the same β β {\displaystyle \beta } and α α {\displaystyle \alpha } parameters, is the only probability density that can be written in the form p ( x ) = g ( ‖ ‖ x ‖ ‖ β β ) {\displaystyle p(\mathbf {x} )=g(\|\mathbf {x} \|_{\beta })} and has independent marginals.

[ 13 ] The results for the special case of the Multivariate normal distribution is originally attributed to Maxwell .

[ 14 ] Asymmetric version [ edit ] Asymmetric Generalized Normal Probability density function Cumulative distribution function Parameters ξ ξ {\displaystyle \xi \,} location ( real ) α α {\displaystyle \alpha \,} scale (positive, real ) κ κ {\displaystyle \kappa \,} shape ( real ) Support x ∈ ∈ ( − − ∞ ∞ , ξ ξ + α α / κ κ ) if κ κ > 0 {\displaystyle x\in (-\infty ,\xi +\alpha /\kappa ){\text{ if }}\kappa >0} x ∈ ∈ ( − − ∞ ∞ , ∞ ∞ ) if κ κ = 0 {\displaystyle x\in (-\infty ,\infty ){\text{ if }}\kappa =0} x ∈ ∈ ( ξ ξ + α α / κ κ , + ∞ ∞ ) if κ κ < 0 {\displaystyle x\in (\xi +\alpha /\kappa ,+\infty ){\text{ if }}\kappa <0} PDF ϕ ϕ ( y ) α α − − κ κ ( x − − ξ ξ ) {\displaystyle {\frac {\phi (y)}{\alpha -\kappa (x-\xi )}}} , where y = { − − 1 κ κ log ⁡ ⁡ [ 1 − − κ κ ( x − − ξ ξ ) α α ] if κ κ ≠ ≠ 0 x − − ξ ξ α α if κ κ = 0 {\displaystyle y={\begin{cases}-{\frac {1}{\kappa }}\log \left[1-{\frac {\kappa (x-\xi )}{\alpha }}\right]&{\text{if }}\kappa \neq 0\\{\frac {x-\xi }{\alpha }}&{\text{if }}\kappa =0\end{cases}}} ϕ ϕ {\displaystyle \phi } is the standard normal pdf CDF Φ Φ ( y ) {\displaystyle \Phi (y)} , where y = { − − 1 κ κ log ⁡ ⁡ [ 1 − − κ κ ( x − − ξ ξ ) α α ] if κ κ ≠ ≠ 0 x − − ξ ξ α α if κ κ = 0 {\displaystyle y={\begin{cases}-{\frac {1}{\kappa }}\log \left[1-{\frac {\kappa (x-\xi )}{\alpha }}\right]&{\text{if }}\kappa \neq 0\\{\frac {x-\xi }{\alpha }}&{\text{if }}\kappa =0\end{cases}}} Φ Φ {\displaystyle \Phi } is the standard normal CDF Mean ξ ξ − − α α κ κ ( e κ κ 2 / 2 − − 1 ) {\displaystyle \xi -{\frac {\alpha }{\kappa }}\left(e^{\kappa ^{2}/2}-1\right)} Median ξ ξ {\displaystyle \xi \,} Variance α α 2 κ κ 2 e κ κ 2 ( e κ κ 2 − − 1 ) {\displaystyle {\frac {\alpha ^{2}}{\kappa ^{2}}}e^{\kappa ^{2}}\left(e^{\kappa ^{2}}-1\right)} Skewness 3 e κ κ 2 − − e 3 κ κ 2 − − 2 ( e κ κ 2 − − 1 ) 3 / 2 sign ( κ κ ) {\displaystyle {\frac {3e^{\kappa ^{2}}-e^{3\kappa ^{2}}-2}{(e^{\kappa ^{2}}-1)^{3/2}}}{\text{ sign}}(\kappa )} Excess kurtosis e 4 κ κ 2 + 2 e 3 κ κ 2 + 3 e 2 κ κ 2 − − 6 {\displaystyle e^{4\kappa ^{2}}+2e^{3\kappa ^{2}}+3e^{2\kappa ^{2}}-6} Not to be confused with Skew normal distribution .

The asymmetric generalized normal distribution is a family of continuous probability distributions in which the shape parameter can be used to introduce asymmetry or skewness.

[ 15 ] [ 16 ] When the shape parameter is zero, the normal distribution results.  Positive values of the shape parameter yield left-skewed distributions bounded to the right, and negative values of the shape parameter yield right-skewed distributions bounded to the left. Only when the shape parameter is zero is the density function for this distribution positive over the whole real line: in this case the distribution is a normal distribution , otherwise the distributions are shifted and possibly reversed log-normal distributions .

Parameter estimation [ edit ] Parameters can be estimated via maximum likelihood estimation or the method of moments.  The parameter estimates do not have a closed form, so numerical calculations must be used to compute the estimates.  Since the sample space (the set of real numbers where the density is non-zero) depends on the true value of the parameter, some standard results about the performance of parameter estimates will not automatically apply when working with this family.

Applications [ edit ] The asymmetric generalized normal distribution can be used to model values that may be normally distributed, or that may be either right-skewed or left-skewed relative to the normal distribution.  The skew normal distribution is another distribution that is useful for modeling deviations from normality due to skew.  Other distributions used to model skewed data include the gamma , lognormal , and Weibull distributions, but these do not include the normal distributions as special cases.

Kullback–Leibler divergence between two PDFs [ edit ] Kullback–Leibler divergence (KLD) is a method using for compute the divergence or similarity between two probability density functions.

[ 17 ] Let P ( x ) {\displaystyle P(x)} and Q ( x ) {\displaystyle Q(x)} two generalized Gaussian distributions with parameters α α 1 , β β 1 , μ μ 1 {\displaystyle \alpha _{1},\beta _{1},\mu _{1}} and α α 2 , β β 2 , μ μ 2 {\displaystyle \alpha _{2},\beta _{2},\mu _{2}} subject to the constraint μ μ 1 = μ μ 2 = 0 {\displaystyle \mu _{1}=\mu _{2}=0} .

[ 18 ] Then this divergence is given by: K L D p d f ( P ( x ) | | Q ( x ) ) = − − 1 β β 1 + ( α α 1 α α 2 ) β β 2 Γ Γ ( 1 + β β 2 β β 1 ) Γ Γ ( 1 β β 1 ) + log ⁡ ⁡ ( α α 2 Γ Γ ( 1 + 1 β β 2 ) α α 1 Γ Γ ( 1 + 1 β β 1 ) ) {\displaystyle {\rm {KLD_{pdf}}}(P(x)||Q(x))=-{\frac {1}{\beta _{1}}}+{\frac {({\frac {\alpha _{1}}{\alpha _{2}}})^{\beta _{2}}\Gamma ({\frac {1+\beta _{2}}{\beta _{1}}})}{\Gamma ({\frac {1}{\beta _{1}}})}}+\log \left({\frac {\alpha _{2}\Gamma (1+{\frac {1}{\beta _{2}}})}{\alpha _{1}\Gamma (1+{\frac {1}{\beta _{1}}})}}\right)} Other distributions related to the normal [ edit ] The two generalized normal families described here, like the skew normal family, are parametric families that extends the normal distribution by adding a shape parameter.  Due to the central role of the normal distribution in probability and statistics, many distributions can be characterized in terms of their relationship to the normal distribution.  For example, the log-normal , folded normal , and inverse normal distributions are defined as transformations of a normally-distributed value, but unlike the generalized normal and skew-normal families, these do not include the normal distributions as special cases.

Actually all distributions with finite variance are in the limit highly related to the normal distribution. The Student-t distribution, the Irwin–Hall distribution and the Bates distribution also extend the normal distribution, and include in the limit the normal distribution. So there is no strong reason to prefer the "generalized" normal distribution of type 1, e.g. over a combination of Student-t and a normalized extended Irwin–Hall – this would include e.g. the triangular distribution (which cannot be modeled by the generalized Gaussian type 1).

A symmetric distribution which can model both tail (long and short) and center behavior (like flat, triangular or Gaussian) completely independently could be derived e.g. by using X = IH/chi.

The Tukey g- and h-distribution also allows for a deviation from normality, both through skewness and fat tails.

[ 19 ] See also [ edit ] Complex normal distribution Skew normal distribution References [ edit ] ^ Griffin, Maryclare.

"Working with the Exponential Power Distribution Using gnorm" .

Github, gnorm package . Retrieved 26 June 2020 .

^ a b Nadarajah, Saralees (September 2005). "A generalized normal distribution".

Journal of Applied Statistics .

32 (7): 685– 694.

Bibcode : 2005JApSt..32..685N .

doi : 10.1080/02664760500079464 .

S2CID 121914682 .

^ Varanasi, M.K.; Aazhang, B. (October 1989). "Parametric generalized Gaussian density estimation".

Journal of the Acoustical Society of America .

86 (4): 1404– 1415.

Bibcode : 1989ASAJ...86.1404V .

doi : 10.1121/1.398700 .

^ Domínguez-Molina, J. Armando; González-Farías, Graciela ; Rodríguez-Dagnino, Ramón M.

"A practical procedure to estimate the shape parameter in the generalized Gaussian distribution" (PDF) . Archived from the original (PDF) on 2007-09-28 . Retrieved 2009-03-03 .

^ Varanasi, M.K.; Aazhang B. (1989). "Parametric generalized Gaussian density estimation".

J. Acoust. Soc. Am.

86 (4): 1404– 1415.

Bibcode : 1989ASAJ...86.1404V .

doi : 10.1121/1.398700 .

^ Do, M.N.; Vetterli, M. (February 2002).

"Wavelet-based Texture Retrieval Using Generalised Gaussian Density and Kullback–Leibler Distance" .

IEEE Transactions on Image Processing .

11 (2): 146– 158.

Bibcode : 2002ITIP...11..146D .

doi : 10.1109/83.982822 .

PMID 18244620 .

^ Varanasi, Mahesh K.; Aazhang, Behnaam (1989-10-01). "Parametric generalized Gaussian density estimation".

The Journal of the Acoustical Society of America .

86 (4): 1404– 1415.

Bibcode : 1989ASAJ...86.1404V .

doi : 10.1121/1.398700 .

ISSN 0001-4966 .

^ Liang, Faming; Liu, Chuanhai; Wang, Naisyin (April 2007).

"A robust sequential Bayesian method for identification of differentially expressed genes" .

Statistica Sinica .

17 (2): 571– 597. Archived from the original on 2007-10-09 . Retrieved 2009-03-03 .

^ Box, George E. P.

; Tiao, George C.

(1992).

Bayesian Inference in Statistical Analysis . New York: Wiley.

ISBN 978-0-471-57428-6 .

^ Milder, Avram L. (2021).

Electron velocity distribution functions and Thomson scattering (PhD thesis). University of Rochester.

hdl : 1802/36536 .

^ a b Dytso, Alex; Bustin, Ronit; Poor, H. Vincent; Shamai, Shlomo (2018).

"Analytical properties of generalized Gaussian distributions" .

Journal of Statistical Distributions and Applications .

5 (1): 6.

doi : 10.1186/s40488-018-0088-5 .

^ Bochner, Salomon (1937).

"Stable laws of probability and completely monotone functions" .

Duke Mathematical Journal .

3 (4): 726– 728.

doi : 10.1215/s0012-7094-37-00360-0 .

^ Sinz, Fabian; Gerwinn, Sebastian; Bethge, Matthias (May 2009).

"Characterization of the p-Generalized Normal Distribution" .

Journal of Multivariate Analysis .

100 (5): 817– 820.

doi : 10.1016/j.jmva.2008.07.006 .

^ Kac, M. (1939). "On a characterization of the normal distribution".

American Journal of Mathematics .

61 (3): 726– 728.

doi : 10.2307/2371328 .

JSTOR 2371328 .

^ Hosking, J.R.M., Wallis, J.R. (1997) Regional frequency analysis: an approach based on L-moments , Cambridge University Press.

ISBN 0-521-43045-3 . Section A.8 ^ Documentation for the lmomco R package ^ Kullback, S.; Leibler, R.A. (1951).

"On information and sufficiency" .

The Annals of Mathematical Statistics .

22 (1): 79– 86.

doi : 10.1214/aoms/1177729694 .

^ Quintero-Rincón, A.; Pereyra, M.; D’Giano, C.; Batatia, H.; Risk, M. (2017). "A visual EEG epilepsy detection method based on a wavelet statistical representation and the Kullback-Leibler divergence".

VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016 . IFMBE Proceedings. Vol. 60. pp.

13– 16.

doi : 10.1007/978-981-10-4086-3_4 .

hdl : 11336/77054 .

ISBN 978-981-10-4085-6 .

^ The Tukey g-and-h Distribution , 
Yuan Yan, Marc G. Genton
Significance, Volume 16, Issue 3, June 2019, Pages 12–13, doi : 10.1111/j.1740-9713.2019.01273.x v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject NewPP limit report
Parsed by mw‐web.codfw.main‐7c956d68b4‐pvc89
Cached time: 20250817054152
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.669 seconds
Real time usage: 0.976 seconds
Preprocessor visited node count: 3761/1000000
Revision size: 24090/2097152 bytes
Post‐expand include size: 259951/2097152 bytes
Template argument size: 6794/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 95063/5000000 bytes
Lua time usage: 0.294/10.000 seconds
Lua memory usage: 6569533/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  486.404      1 -total
 38.55%  187.517      1 Template:Reflist
 26.93%  130.966     15 Template:Navbox
 17.10%   83.175      1 Template:ProbDistributions
 15.60%   75.900      2 Template:Cite_web
 15.36%   74.701      1 Template:Short_description
 13.17%   64.048      1 Template:Statistics
 12.64%   61.492     11 Template:Cite_journal
 12.60%   61.289      1 Template:Navbox_with_collapsible_groups
  9.58%   46.614      2 Template:Pagetype Saved in parser cache with key enwiki:pcache:21736981:|#|:idhash:canonical and timestamp 20250817054152 and revision id 1303267485. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Generalized_normal_distribution&oldid=1303267485 " Categories : Continuous distributions Normal distribution Hidden categories: Articles with short description Short description is different from Wikidata This page was last edited on 30 July 2025, at 00:34 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Generalized normal distribution 6 languages Add topic

