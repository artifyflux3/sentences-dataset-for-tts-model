Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Examples 2 Basic formula 3 Orthonormal system 4 Existence 5 Choice of basis as a choice of isomorphism 6 As a principal homogeneous space 7 See also 8 Notes 9 References 10 External links Toggle the table of contents Orthonormal basis 21 languages العربية Català Čeština Deutsch Español Français 한국어 Italiano עברית Magyar Nederlands 日本語 Polski Português Română Slovenčina Српски / srpski Svenska Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Specific linear basis (mathematics) In mathematics , particularly linear algebra , an orthonormal basis for an inner product space V {\displaystyle V} with finite dimension is a basis for V {\displaystyle V} whose vectors are orthonormal , that is, they are all unit vectors and orthogonal to each other.

[ 1 ] [ 2 ] [ 3 ] For example, the standard basis for a Euclidean space R n {\displaystyle \mathbb {R} ^{n}} is an orthonormal basis, where the relevant inner product is the dot product of vectors. The image of the standard basis under a rotation or reflection (or any orthogonal transformation ) is also orthonormal, and every orthonormal basis for R n {\displaystyle \mathbb {R} ^{n}} arises in this fashion.
An orthonormal basis can be derived from an orthogonal basis via normalization .

The choice of an origin and an orthonormal basis forms a coordinate frame known as an orthonormal frame .

For a general inner product space V , {\displaystyle V,} an orthonormal basis can be used to define normalized orthogonal coordinates on V .

{\displaystyle V.} Under these coordinates, the inner product becomes a dot product of vectors. Thus the presence of an orthonormal basis reduces the study of a finite-dimensional inner product space to the study of R n {\displaystyle \mathbb {R} ^{n}} under the dot product. Every finite-dimensional inner product space has an orthonormal basis, which may be obtained from an arbitrary basis using the Gram–Schmidt process .

In functional analysis , the concept of an orthonormal basis can be generalized to arbitrary (infinite-dimensional) inner product spaces .

[ 4 ] Given a pre-Hilbert space H , {\displaystyle H,} an orthonormal basis for H {\displaystyle H} is an orthonormal set of vectors with the property that every vector in H {\displaystyle H} can be written as an infinite linear combination of the vectors in the basis. In this case, the orthonormal basis is sometimes called a Hilbert basis for H .

{\displaystyle H.} Note that an orthonormal basis in this sense is not generally a Hamel basis , since infinite linear combinations are required.

[ 5 ] Specifically, the linear span of the basis must be dense in H , {\displaystyle H,} although not necessarily the entire space.

If we go on to Hilbert spaces , a non-orthonormal set of vectors having the same linear span as an orthonormal basis may not be a basis at all. For instance, any square-integrable function on the interval [ − − 1 , 1 ] {\displaystyle [-1,1]} can be expressed ( almost everywhere ) as an infinite sum of Legendre polynomials (an orthonormal basis), but not necessarily as an infinite sum of the monomials x n .

{\displaystyle x^{n}.} A different generalisation is to pseudo-inner product spaces, finite-dimensional vector spaces M {\displaystyle M} equipped with a non-degenerate symmetric bilinear form known as the metric tensor . In such a basis, the metric takes the form diag ( + 1 , ⋯ ⋯ , + 1 , − − 1 , ⋯ ⋯ , − − 1 ) {\displaystyle {\text{diag}}(+1,\cdots ,+1,-1,\cdots ,-1)} with p {\displaystyle p} positive ones and q {\displaystyle q} negative ones.

Examples [ edit ] For R 3 {\displaystyle \mathbb {R} ^{3}} , the set of vectors { e 1 = ( 1 0 0 ) , e 2 = ( 0 1 0 ) , e 3 = ( 0 0 1 ) } , {\displaystyle \left\{\mathbf {e_{1}} ={\begin{pmatrix}1&0&0\end{pmatrix}}\ ,\ \mathbf {e_{2}} ={\begin{pmatrix}0&1&0\end{pmatrix}}\ ,\ \mathbf {e_{3}} ={\begin{pmatrix}0&0&1\end{pmatrix}}\right\},} is called the standard basis and forms an orthonormal basis of R 3 {\displaystyle \mathbb {R} ^{3}} with respect to the standard dot product. Note that both the standard basis and standard dot product rely on viewing R 3 {\displaystyle \mathbb {R} ^{3}} as the Cartesian product R × × R × × R {\displaystyle \mathbb {R} \times \mathbb {R} \times \mathbb {R} } Proof: A straightforward computation shows that the inner products of these vectors equals zero, ⟨ e 1 , e 2 ⟩ = ⟨ e 1 , e 3 ⟩ = ⟨ e 2 , e 3 ⟩ = 0 {\displaystyle \left\langle \mathbf {e_{1}} ,\mathbf {e_{2}} \right\rangle =\left\langle \mathbf {e_{1}} ,\mathbf {e_{3}} \right\rangle =\left\langle \mathbf {e_{2}} ,\mathbf {e_{3}} \right\rangle =0} and that each of their magnitudes equals one, ‖ e 1 ‖ = ‖ e 2 ‖ = ‖ e 3 ‖ = 1.

{\displaystyle \left\|\mathbf {e_{1}} \right\|=\left\|\mathbf {e_{2}} \right\|=\left\|\mathbf {e_{3}} \right\|=1.} This means that { e 1 , e 2 , e 3 } {\displaystyle \left\{\mathbf {e_{1}} ,\mathbf {e_{2}} ,\mathbf {e_{3}} \right\}} is an orthonormal set. All vectors ( x , y , z ) ∈ ∈ R 3 {\displaystyle (\mathbf {x} ,\mathbf {y} ,\mathbf {z} )\in \mathbb {R} ^{3}} can be expressed as a sum of the basis vectors scaled ( x , y , z ) = x e 1 + y e 2 + z e 3 , {\displaystyle (\mathbf {x} ,\mathbf {y} ,\mathbf {z} )=\mathbf {xe_{1}} +\mathbf {ye_{2}} +\mathbf {ze_{3}} ,} so { e 1 , e 2 , e 3 } {\displaystyle \left\{\mathbf {e_{1}} ,\mathbf {e_{2}} ,\mathbf {e_{3}} \right\}} spans R 3 {\displaystyle \mathbb {R} ^{3}} and hence must be a basis. It may also be shown that the standard basis rotated about an axis through the origin or reflected in a plane through the origin also forms an orthonormal basis of R 3 {\displaystyle \mathbb {R} ^{3}} .

For R n {\displaystyle \mathbb {R} ^{n}} , the standard basis and inner product are similarly defined. Any other orthonormal basis is related to the standard basis by an orthogonal transformation in the group O(n).

For pseudo-Euclidean space R p , q , {\displaystyle \mathbb {R} ^{p,q},} , an orthogonal basis { e μ μ } {\displaystyle \{e_{\mu }\}} with metric η η {\displaystyle \eta } instead satisfies η η ( e μ μ , e ν ν ) = 0 {\displaystyle \eta (e_{\mu },e_{\nu })=0} if μ μ ≠ ≠ ν ν {\displaystyle \mu \neq \nu } , η η ( e μ μ , e μ μ ) = + 1 {\displaystyle \eta (e_{\mu },e_{\mu })=+1} if 1 ≤ ≤ μ μ ≤ ≤ p {\displaystyle 1\leq \mu \leq p} , and η η ( e μ μ , e μ μ ) = − − 1 {\displaystyle \eta (e_{\mu },e_{\mu })=-1} if p + 1 ≤ ≤ μ μ ≤ ≤ p + q {\displaystyle p+1\leq \mu \leq p+q} . Any two orthonormal bases are related by a pseudo-orthogonal transformation. In the case ( p , q ) = ( 1 , 3 ) {\displaystyle (p,q)=(1,3)} , these are Lorentz transformations.

The set { f n : n ∈ ∈ Z } {\displaystyle \left\{f_{n}:n\in \mathbb {Z} \right\}} with f n ( x ) = exp ⁡ ⁡ ( 2 π π i n x ) , {\displaystyle f_{n}(x)=\exp(2\pi inx),} where exp {\displaystyle \exp } denotes the exponential function , forms an orthonormal basis of the space of functions with finite Lebesgue integrals, L 2 ( [ 0 , 1 ] ) , {\displaystyle L^{2}([0,1]),} with respect to the 2-norm . This is fundamental to the study of Fourier series .

The set { e b : b ∈ ∈ B } {\displaystyle \left\{e_{b}:b\in B\right\}} with e b ( c ) = 1 {\displaystyle e_{b}(c)=1} if b = c {\displaystyle b=c} and e b ( c ) = 0 {\displaystyle e_{b}(c)=0} otherwise forms an orthonormal basis of ℓ ℓ 2 ( B ) .

{\displaystyle \ell ^{2}(B).} Eigenfunctions of a Sturm–Liouville eigenproblem .

The column vectors of an orthogonal matrix form an orthonormal set.

Basic formula [ edit ] If B {\displaystyle B} is an orthogonal basis of H , {\displaystyle H,} then every element x ∈ ∈ H {\displaystyle x\in H} may be written as x = ∑ ∑ b ∈ ∈ B ⟨ ⟨ x , b ⟩ ⟩ ‖ ‖ b ‖ ‖ 2 b .

{\displaystyle x=\sum _{b\in B}{\frac {\langle x,b\rangle }{\lVert b\rVert ^{2}}}b.} When B {\displaystyle B} is orthonormal, this simplifies to x = ∑ ∑ b ∈ ∈ B ⟨ ⟨ x , b ⟩ ⟩ b {\displaystyle x=\sum _{b\in B}\langle x,b\rangle b} and the square of the norm of x {\displaystyle x} can be given by ‖ ‖ x ‖ ‖ 2 = ∑ ∑ b ∈ ∈ B | ⟨ ⟨ x , b ⟩ ⟩ | 2 .

{\displaystyle \|x\|^{2}=\sum _{b\in B}|\langle x,b\rangle |^{2}.} Even if B {\displaystyle B} is uncountable , only countably many terms in this sum will be non-zero, and the expression is therefore well-defined. This sum is also called the Fourier expansion of x , {\displaystyle x,} and the formula is usually known as Parseval's identity .

If B {\displaystyle B} is an orthonormal basis of H , {\displaystyle H,} then H {\displaystyle H} is isomorphic to ℓ ℓ 2 ( B ) {\displaystyle \ell ^{2}(B)} in the following sense: there exists a bijective linear map Φ Φ : H → → ℓ ℓ 2 ( B ) {\displaystyle \Phi :H\to \ell ^{2}(B)} such that ⟨ ⟨ Φ Φ ( x ) , Φ Φ ( y ) ⟩ ⟩ = ⟨ ⟨ x , y ⟩ ⟩ ∀ ∀ x , y ∈ ∈ H .

{\displaystyle \langle \Phi (x),\Phi (y)\rangle =\langle x,y\rangle \ \ \forall \ x,y\in H.} Orthonormal system [ edit ] A set S {\displaystyle S} of mutually orthonormal vectors in a Hilbert space H {\displaystyle H} is called an orthonormal system. An orthonormal basis is an orthonormal system with the additional property that the linear span of S {\displaystyle S} is dense in H {\displaystyle H} .

[ 6 ] Alternatively, the set S {\displaystyle S} can be regarded as either complete or incomplete with respect to H {\displaystyle H} . That is, we can take the smallest closed linear subspace V ⊆ ⊆ H {\displaystyle V\subseteq H} containing S .

{\displaystyle S.} Then S {\displaystyle S} will be an orthonormal basis of V ; {\displaystyle V;} which may of course be smaller than H {\displaystyle H} itself, being an incomplete orthonormal set, or be H , {\displaystyle H,} when it is a complete orthonormal set.

Existence [ edit ] Using Zorn's lemma and the Gram–Schmidt process (or more simply well-ordering and transfinite recursion), one can show that every Hilbert space admits an orthonormal basis; [ 7 ] furthermore, any two orthonormal bases of the same space have the same cardinality (this can be proven in a manner akin to that of the proof of the usual dimension theorem for vector spaces , with separate cases depending on whether  the larger basis candidate is countable or not). A Hilbert space is separable if and only if it admits a countable orthonormal basis. (One can prove this last statement without using the axiom of choice . However, one would have to use the axiom of countable choice .) Choice of basis as a choice of isomorphism [ edit ] For concreteness we discuss orthonormal bases for a real, n {\displaystyle n} -dimensional vector space V {\displaystyle V} with a positive definite symmetric bilinear form ϕ ϕ = ⟨ ⟨ ⋅ ⋅ , ⋅ ⋅ ⟩ ⟩ {\displaystyle \phi =\langle \cdot ,\cdot \rangle } .

One way to view an orthonormal basis with respect to ϕ ϕ {\displaystyle \phi } is as a set of vectors B = { e i } {\displaystyle {\mathcal {B}}=\{e_{i}\}} , which allow us to write v = v i e i ∀ ∀ v ∈ ∈ V {\displaystyle v=v^{i}e_{i}\ \ \forall \ v\in V} , and v i ∈ ∈ R {\displaystyle v^{i}\in \mathbb {R} } or ( v i ) ∈ ∈ R n {\displaystyle (v^{i})\in \mathbb {R} ^{n}} . With respect to this basis, the components of ϕ ϕ {\displaystyle \phi } are particularly simple: ϕ ϕ ( e i , e j ) = δ δ i j {\displaystyle \phi (e_{i},e_{j})=\delta _{ij}} (where δ δ i j {\displaystyle \delta _{ij}} is the Kronecker delta ).

We can now view the basis as a map ψ ψ B : V → → R n {\displaystyle \psi _{\mathcal {B}}:V\rightarrow \mathbb {R} ^{n}} which is an isomorphism of inner product spaces: to make this more explicit we can write ψ ψ B : ( V , ϕ ϕ ) → → ( R n , δ δ i j ) .

{\displaystyle \psi _{\mathcal {B}}:(V,\phi )\rightarrow (\mathbb {R} ^{n},\delta _{ij}).} Explicitly we can write ( ψ ψ B ( v ) ) i = e i ( v ) = ϕ ϕ ( e i , v ) {\displaystyle (\psi _{\mathcal {B}}(v))^{i}=e^{i}(v)=\phi (e_{i},v)} where e i {\displaystyle e^{i}} is the dual basis element to e i {\displaystyle e_{i}} .

The inverse is a component map C B : R n → → V , ( v i ) ↦ ↦ ∑ ∑ i = 1 n v i e i .

{\displaystyle C_{\mathcal {B}}:\mathbb {R} ^{n}\rightarrow V,(v^{i})\mapsto \sum _{i=1}^{n}v^{i}e_{i}.} These definitions make it manifest that there is a bijection { Space of orthogonal bases B } ↔ ↔ { Space of isomorphisms V ↔ ↔ R n } .

{\displaystyle \{{\text{Space of orthogonal bases }}{\mathcal {B}}\}\leftrightarrow \{{\text{Space of isomorphisms }}V\leftrightarrow \mathbb {R} ^{n}\}.} The space of isomorphisms admits actions of orthogonal groups at either the V {\displaystyle V} side or the R n {\displaystyle \mathbb {R} ^{n}} side. For concreteness we fix the isomorphisms to point in the direction R n → → V {\displaystyle \mathbb {R} ^{n}\rightarrow V} , and consider the space of such maps, Iso ( R n → → V ) {\displaystyle {\text{Iso}}(\mathbb {R} ^{n}\rightarrow V)} .

This space admits a left action by the group of isometries of V {\displaystyle V} , that is, R ∈ ∈ GL ( V ) {\displaystyle R\in {\text{GL}}(V)} such that ϕ ϕ ( ⋅ ⋅ , ⋅ ⋅ ) = ϕ ϕ ( R ⋅ ⋅ , R ⋅ ⋅ ) {\displaystyle \phi (\cdot ,\cdot )=\phi (R\cdot ,R\cdot )} , with the action given by composition: R ∗ ∗ C = R ∘ ∘ C .

{\displaystyle R*C=R\circ C.} This space also admits a right action by the group of isometries of R n {\displaystyle \mathbb {R} ^{n}} , that is, R i j ∈ ∈ O ( n ) ⊂ ⊂ Mat n × × n ( R ) {\displaystyle R_{ij}\in {\text{O}}(n)\subset {\text{Mat}}_{n\times n}(\mathbb {R} )} , with the action again given by composition: C ∗ ∗ R i j = C ∘ ∘ R i j {\displaystyle C*R_{ij}=C\circ R_{ij}} .

As a principal homogeneous space [ edit ] Main article: Stiefel manifold The set of orthonormal bases for R n {\displaystyle \mathbb {R} ^{n}} with the standard inner product is a principal homogeneous space or G-torsor for the orthogonal group G = O ( n ) , {\displaystyle G={\text{O}}(n),} and is called the Stiefel manifold V n ( R n ) {\displaystyle V_{n}(\mathbb {R} ^{n})} of orthonormal n {\displaystyle n} -frames .

[ 8 ] In other words, the space of orthonormal bases is like the orthogonal group, but without a choice of base point: given the space of orthonormal bases, there is no natural choice of orthonormal basis, but once one is given one, there is a one-to-one correspondence between bases and the orthogonal group.
Concretely, a linear map is determined by where it sends a given basis: just as an invertible map can take any basis to any other basis, an orthogonal map can take any orthogonal basis to any other orthogonal basis.

The other Stiefel manifolds V k ( R n ) {\displaystyle V_{k}(\mathbb {R} ^{n})} for k < n {\displaystyle k<n} of incomplete orthonormal bases (orthonormal k {\displaystyle k} -frames) are still homogeneous spaces for the orthogonal group, but not principal homogeneous spaces: any k {\displaystyle k} -frame can be taken to any other k {\displaystyle k} -frame by an orthogonal map, but this map is not uniquely determined.

The set of orthonormal bases for R p , q {\displaystyle \mathbb {R} ^{p,q}} is a G-torsor for G = O ( p , q ) {\displaystyle G={\text{O}}(p,q)} .

The set of orthonormal bases for C n {\displaystyle \mathbb {C} ^{n}} is a G-torsor for G = U ( n ) {\displaystyle G={\text{U}}(n)} .

The set of orthonormal bases for C p , q {\displaystyle \mathbb {C} ^{p,q}} is a G-torsor for G = U ( p , q ) {\displaystyle G={\text{U}}(p,q)} .

The set of right-handed orthonormal bases for R n {\displaystyle \mathbb {R} ^{n}} is a G-torsor for G = SO ( n ) {\displaystyle G={\text{SO}}(n)} See also [ edit ] Orthogonal basis – Basis for v whose vectors are mutually orthogonal Basis (linear algebra) – Set of vectors used to define coordinates Orthonormal frame – Euclidean space without  distance and angles Schauder basis – Computational tool Total set Notes [ edit ] ^ Lay, David C. (2006).

Linear Algebra and Its Applications (3rd ed.).

Addison–Wesley .

ISBN 0-321-28713-4 .

^ Strang, Gilbert (2006).

Linear Algebra and Its Applications (4th ed.).

Brooks Cole .

ISBN 0-03-010567-6 .

^ Axler, Sheldon (2002).

Linear Algebra Done Right (2nd ed.).

Springer .

ISBN 0-387-98258-2 .

^ Rudin, Walter (1987).

Real & Complex Analysis .

McGraw-Hill .

ISBN 0-07-054234-1 .

^ Roman 2008 , p. 218, ch. 9.

^ Steinwart & Christmann 2008 , p. 503.

^ Linear Functional Analysis Authors: Rynne, Bryan, Youngson, M.A. page 79 ^ "CU Faculty" .

engfac.cooper.edu . Retrieved 2021-04-15 .

References [ edit ] Roman, Stephen (2008).

Advanced Linear Algebra .

Graduate Texts in Mathematics (Third ed.). Springer.

ISBN 978-0-387-72828-5 .

(page 218, ch.9) Rudin, Walter (1991).

Functional Analysis . International Series in Pure and Applied Mathematics. Vol. 8 (Second ed.). New York, NY: McGraw-Hill Science/Engineering/Math .

ISBN 978-0-07-054236-5 .

OCLC 21163277 .

Steinwart, Ingo; Christmann, Andreas (2008).

Support vector machines . New York: Springer.

doi : 10.1007/978-0-387-77242-4 .

ISBN 978-0-387-77241-7 .

External links [ edit ] This Stack Exchange Post discusses why the set of Dirac Delta functions is not a basis of L 2 ([0,1]).

v t e Linear algebra Outline Glossary Basic concepts Scalar Vector Vector space Scalar multiplication Vector projection Linear span Linear map Linear projection Linear independence Linear combination Multilinear map Basis Change of basis Row and column vectors Row and column spaces Kernel Eigenvalues and eigenvectors Transpose Linear equations Matrices Block Decomposition Invertible Minor Multiplication Rank Transformation Cramer's rule Gaussian elimination Productive matrix Gram matrix Bilinear Orthogonality Dot product Hadamard product Inner product space Outer product Kronecker product Gram–Schmidt process Multilinear algebra Determinant Cross product Triple product Seven-dimensional cross product Geometric algebra Exterior algebra Bivector Multivector Tensor Outermorphism Vector space constructions Dual Direct sum Function space Quotient Subspace Tensor product Numerical Floating-point Numerical stability Basic Linear Algebra Subprograms Sparse matrix Comparison of linear algebra libraries Category v t e Hilbert spaces Basic concepts Adjoint Inner product and L-semi-inner product Hilbert space and Prehilbert space Orthogonal complement Orthonormal basis Main results Bessel's inequality Cauchy–Schwarz inequality Riesz representation Other results Hilbert projection theorem Parseval's identity Polarization identity ( Parallelogram law ) Maps Compact operator on Hilbert space Densely defined Hermitian form Hilbert–Schmidt Normal Self-adjoint Sesquilinear form Trace class Unitary Examples C n ( K ) with K compact & n <∞ Segal–Bargmann F v t e Functional analysis ( topics – glossary ) Spaces Banach Besov Fréchet Hilbert Hölder Nuclear Orlicz Schwartz Sobolev Topological vector Properties Barrelled Complete Dual ( Algebraic / Topological ) Locally convex Reflexive Separable Theorems Hahn–Banach Riesz representation Closed graph Uniform boundedness principle Kakutani fixed-point Krein–Milman Min–max Gelfand–Naimark Banach–Alaoglu Operators Adjoint Bounded Compact Hilbert–Schmidt Normal Nuclear Trace class Transpose Unbounded Unitary Algebras Banach algebra C*-algebra Spectrum of a C*-algebra Operator algebra Group algebra of a locally compact group Von Neumann algebra Open problems Invariant subspace problem Mahler's conjecture Applications Hardy space Spectral theory of ordinary differential equations Heat kernel Index theorem Calculus of variations Functional calculus Integral linear operator Jones polynomial Topological quantum field theory Noncommutative geometry Riemann hypothesis Distribution (or Generalized functions ) Advanced topics Approximation property Balanced set Choquet theory Weak topology Banach–Mazur distance Tomita–Takesaki theory Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Orthonormal_basis&oldid=1274263111 " Categories : Fourier analysis Functional analysis Linear algebra Hidden categories: Articles with short description Short description is different from Wikidata This page was last edited on 6 February 2025, at 10:50 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Orthonormal basis 21 languages Add topic

