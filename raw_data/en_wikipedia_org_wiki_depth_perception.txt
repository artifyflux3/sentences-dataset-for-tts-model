Title: Depth perception

URL Source: https://en.wikipedia.org/wiki/Depth_perception

Published Time: 2003-08-23T04:35:26Z

Markdown Content:
[![Image 1](https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Depth_cues_1.png/500px-Depth_cues_1.png)](https://en.wikipedia.org/wiki/File:Depth_cues_1.png)

Perspective, relative size, occultation and texture gradients all contribute to the three-dimensional appearance of this photo.

**Depth perception** is the ability to perceive distance to objects in the world using the [visual system](https://en.wikipedia.org/wiki/Visual_system "Visual system") and [visual perception](https://en.wikipedia.org/wiki/Visual_perception "Visual perception"). It is a major factor in perceiving the world in [three dimensions](https://en.wikipedia.org/wiki/Three-dimensional_space "Three-dimensional space").

**Depth sensation** is the corresponding term for non-human animals, since although it is known that they can sense the distance of an object, it is not known whether they [perceive](https://en.wikipedia.org/wiki/Perception "Perception") it in the same way that humans do.[[1]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-1)

Depth perception arises from a variety of depth cues. These are typically classified into [binocular](https://en.wikipedia.org/wiki/Binocular_vision "Binocular vision") cues and [monocular](https://en.wikipedia.org/wiki/Monocular_vision "Monocular vision") cues. Binocular cues are based on the receipt of sensory information in three dimensions from both eyes and monocular cues can be observed with just one eye.[[2]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-2)[[3]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-3) Binocular cues include retinal [disparity](https://en.wikipedia.org/wiki/Binocular_disparity "Binocular disparity"), which exploits [parallax](https://en.wikipedia.org/wiki/Parallax "Parallax") and [vergence](https://en.wikipedia.org/wiki/Vergence "Vergence"). [Stereopsis](https://en.wikipedia.org/wiki/Stereopsis "Stereopsis") is made possible with [binocular vision](https://en.wikipedia.org/wiki/Binocular_vision "Binocular vision"). Monocular cues include relative size (distant objects subtend smaller [visual angles](https://en.wikipedia.org/wiki/Visual_angle "Visual angle") than near objects), texture gradient, occlusion, linear perspective, contrast differences, and motion [parallax](https://en.wikipedia.org/wiki/Parallax "Parallax").[[4]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-4)

[![Image 2](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Parallax_scroll.gif/250px-Parallax_scroll.gif)](https://en.wikipedia.org/wiki/File:Parallax_scroll.gif)

Motion parallax

[Monocular](https://en.wikipedia.org/wiki/Monocular_vision "Monocular vision") cues provide depth information even when viewing a scene with only one eye.

When an observer moves, the apparent relative motion of several stationary objects against a background gives hints about their relative distance. If information about the direction and velocity of movement is known, motion parallax can provide absolute depth information.[[5]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-5) This effect can be seen clearly when driving in a car. Nearby things pass quickly, while far-off objects appear stationary. Some animals that lack [binocular vision](https://en.wikipedia.org/wiki/Binocular_vision "Binocular vision") due to their eyes having little common field-of-view employ motion parallax more explicitly than humans for depth cueing (for example, some types of birds, which bob their heads to achieve motion parallax, and squirrels, which move in lines [orthogonal](https://en.wikipedia.org/wiki/Orthogonal "Orthogonal") to an object of interest to do the same[[6]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-6)).[[note 1]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-parallax-7)

When an object moves toward the observer, the retinal projection of an object expands over a period of time, which leads to the perception of movement in a line toward the observer. Another name for this phenomenon is _depth from optical expansion_.[[7]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-8) The dynamic stimulus change enables the observer not only to see the object as moving, but to perceive the distance of the moving object. Thus, in this context, the changing size serves as a distance cue.[[8]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-9) A related phenomenon is the visual system's capacity to calculate time-to-contact (TTC) of an approaching object from the rate of optical expansionâ€“ a useful ability in contexts ranging from driving a car to playing a [ball game](https://en.wikipedia.org/wiki/Ball_game "Ball game"). However, the calculation of TTC is, strictly speaking, a perception of velocity rather than depth.

### Kinetic depth effect

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=4 "Edit section: Kinetic depth effect")]

If a stationary rigid figure (for example, a wire cube) is placed in front of a point source of light so that its shadow falls on a translucent screen, an observer on the other side of the screen will see a two-dimensional pattern of lines. But if the cube rotates, the visual system will extract the necessary information for perception of the third dimension from the movements of the lines, and a cube is seen. This is an example of the _kinetic depth effect_.[[9]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-10) The effect also occurs when the rotating object is solid (rather than an outline figure), provided that the projected shadow consists of lines which have definite corners or end points, and that these lines change in both length and orientation during the rotation.[[10]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-11)

The property of parallel lines converging in the distance, at infinity, allows us to reconstruct the relative distance of two parts of an object, or of landscape features. An example would be standing on a straight road, looking down the road, and noticing the road narrows as it goes off in the distance. [Visual perception](https://en.wikipedia.org/wiki/Visual_perception "Visual perception") of perspective in real space, for instance in rooms, in settlements and in nature, is a result of several optical impressions and the interpretation by the [visual system](https://en.wikipedia.org/wiki/Visual_system "Visual system"). The [angle of vision](https://en.wikipedia.org/wiki/Visual_angle "Visual angle") is important for the [apparent size](https://en.wikipedia.org/wiki/Apparent_size "Apparent size"). A nearby object is imaged on a larger area on the [retina](https://en.wikipedia.org/wiki/Retina "Retina"), the same object or an object of the same size further away on a smaller area.[[11]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-12) The perception of perspective is possible when looking with one eye only, but [stereoscopic vision](https://en.wikipedia.org/wiki/Stereoscopic_vision "Stereoscopic vision") enhances the impression of the spatial. Regardless of whether the light rays entering the eye come from a three-dimensional space or from a two-dimensional image, they hit the inside of the eye on the retina as a surface. What a person sees, is based on the reconstruction by their visual system, in which one and the same image on the retina can be interpreted both two-dimensionally and three-dimensionally. If a three-dimensional interpretation has been recognised, it receives a preference and determines the perception.[[12]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-13)

*   [![Image 3: Context-dependent interpretation of the size](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Perspektivisches_Sehen_und_Interpretation.png/120px-Perspektivisches_Sehen_und_Interpretation.png)](https://en.wikipedia.org/wiki/File:Perspektivisches_Sehen_und_Interpretation.png "Context-dependent interpretation of the size")

Context-dependent interpretation of the size

*   [![Image 4: Shots at different distances](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/08913-Perspective_Run.jpg/120px-08913-Perspective_Run.jpg)](https://en.wikipedia.org/wiki/File:08913-Perspective_Run.jpg "Shots at different distances")

Shots at different distances

*   [![Image 5: The horizon line is at the height of the armrests.](https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Study_in_Vanishing_Perspective.jpg/120px-Study_in_Vanishing_Perspective.jpg)](https://en.wikipedia.org/wiki/File:Study_in_Vanishing_Perspective.jpg "The horizon line is at the height of the armrests.")

The horizon line is at the height of the armrests.

*   [![Image 6: View from a window on the 2nd floor of a house](https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Spatial_vision_and_perspective.jpg/120px-Spatial_vision_and_perspective.jpg)](https://en.wikipedia.org/wiki/File:Spatial_vision_and_perspective.jpg "View from a window on the 2nd floor of a house")

View from a window on the 2nd floor of a house

*   [![Image 7: Mountain peak near the snow line and several mountain peaks above the snow line](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Mountain_panorama_in_France_3.jpg/120px-Mountain_panorama_in_France_3.jpg)](https://en.wikipedia.org/wiki/File:Mountain_panorama_in_France_3.jpg "Mountain peak near the snow line and several mountain peaks above the snow line")

Mountain peak near the [snow line](https://en.wikipedia.org/wiki/Snow_line "Snow line") and several mountain peaks above the snow line

*   [![Image 8: Earth curvature](https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/ISS-40_Sicily_and_Italy.jpg/120px-ISS-40_Sicily_and_Italy.jpg)](https://en.wikipedia.org/wiki/File:ISS-40_Sicily_and_Italy.jpg "Earth curvature")

In spatial vision, the horizontal line of sight can play a role. In the picture taken from the window of a house, the horizontal line of sight is at the level of the second floor (yellow line). Below this line, the further away objects are, the higher up in the [visual field](https://en.wikipedia.org/wiki/Visual_field "Visual field") they appear. Above the horizontal line of sight, objects that are further away appear lower than those that are closer. To represent spatial impressions in [graphical perspective](https://en.wikipedia.org/wiki/Perspective_(graphical) "Perspective (graphical)"), one can use a [vanishing point](https://en.wikipedia.org/wiki/Vanishing_point "Vanishing point").[[13]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-14) When looking at long [geographical distances](https://en.wikipedia.org/wiki/Geographical_distance "Geographical distance"), perspective effects also partially result from the angle of vision, but not only by this. In picture 5 of the series, in the background is [Mont Blanc](https://en.wikipedia.org/wiki/Mont_Blanc "Mont Blanc"), the highest mountain in the Alps. It appears lower than the mountain in front in the center of the picture. Measurements and calculations can be used to determine the proportion of the [curvature of Earth](https://en.wikipedia.org/wiki/Earth#Size_and_shape "Earth") in the [subjectively](https://en.wikipedia.org/wiki/Subjectivity "Subjectivity") perceived proportions.

If two objects are known to be the same size (for example, two trees) but their absolute size is unknown, relative size cues can provide information about the relative depth of the two objects. If one subtends a larger visual angle on the retina than the other, the object which subtends the larger visual angle appears closer.

Since the visual angle of an object projected onto the retina decreases with distance, this information can be combined with previous knowledge of the object's size to determine the absolute depth of the object. For example, people are generally familiar with the size of an average automobile. This prior knowledge can be combined with information about the angle it subtends on the retina to determine the absolute depth of an automobile in a scene.

Even if the actual size of the object is unknown and there is only one object visible, a smaller object seems farther away than a large object that is presented at the same location.[[14]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-15)

Due to light scattering by the atmosphere, objects that are a great distance away have lower luminance [contrast](https://en.wikipedia.org/wiki/Contrast_(vision) "Contrast (vision)") and lower [color saturation](https://en.wikipedia.org/wiki/Color_saturation "Color saturation"). Due to this, images seem hazy the farther they are away from a person's point of view. In [computer graphics](https://en.wikipedia.org/wiki/Computer_graphics "Computer graphics"), this is often called "[distance fog](https://en.wikipedia.org/wiki/Distance_fog "Distance fog")". The foreground has high contrast; the background has low contrast. Objects differing only in their contrast with a background appear to be at different depths.[[15]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-16) The color of distant objects is also shifted toward the blue end of the [spectrum](https://en.wikipedia.org/wiki/Spectrum "Spectrum") (for example, distant mountains). Some painters, notably [CÃ©zanne](https://en.wikipedia.org/wiki/C%C3%A9zanne "CÃ©zanne"), employ "warm" pigments (red, yellow and orange) to bring features forward towards the viewer, and "cool" ones (blue, violet, and blue-green) to indicate the part of a form that curves away from the [picture plane](https://en.wikipedia.org/wiki/Picture_plane "Picture plane").

Accommodation is an oculomotor cue for depth perception. When humans try to focus on distant objects, the [ciliary muscles](https://en.wikipedia.org/wiki/Ciliary_muscles "Ciliary muscles") relax, allowing the eye lens to become thinner, which increases the [focal length](https://en.wikipedia.org/wiki/Focal_length "Focal length"). Depth perception of distant objects is made possible by other methods besides accommodation. The [kinesthetic sensations](https://en.wikipedia.org/wiki/Proprioception "Proprioception") of the contracting and relaxing ciliary muscles (intraocular muscles) are sent to the visual cortex where they are used for interpreting distance and depth. Accommodation is only effective for distances less than 2 meters.

Occultation (also referred to as _interposition_) happens when near surfaces overlap far surfaces.[[16]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-17) If one object partially blocks the view of another object, humans perceive it as closer. However, this information only allows the observer to make a "ranking" of relative nearness. The presence of monocular [ambient occlusions](https://en.wikipedia.org/wiki/Ambient_occlusion "Ambient occlusion") consist of the object's texture and geometry. These phenomena are able to reduce depth perception latency both in natural and artificial stimuli.[[17]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-18)[[18]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-19)

### Curvilinear perspective

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=12 "Edit section: Curvilinear perspective")]

At the outer extremes of the [visual field](https://en.wikipedia.org/wiki/Visual_field "Visual field"), parallel lines become curved, as in a photo taken through a [fisheye lens](https://en.wikipedia.org/wiki/Fisheye_lens "Fisheye lens"). This effect, although it is usually eliminated from both art and photos by the cropping or framing of a picture, greatly enhances the viewer's sense of being positioned within a real, three-dimensional space. (Classical perspective has no use for this so-called "distortion", although in fact the "distortions" strictly obey optical laws and provide perfectly valid visual information, just as classical perspective does for the part of the field of vision that falls within its frame.)

Fine details on nearby objects can be seen clearly, whereas such details are not visible on faraway objects. Texture gradients are the grains of an item. For example, on a long gravel road, the gravel near the observer can be clearly seen of shape, size and colour. In the distance, the road's texture cannot be clearly differentiated.

### Lighting and shading

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=14 "Edit section: Lighting and shading")]

The way that light falls on an object and reflects off its surfaces, and the shadows that are cast by objects provide an effective cue for the brain to determine the shape of objects and their position in space.[[19]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-20)

Selective image blurring is very commonly used in photography and video to establish the impression of depth. This can act as a monocular cue even when all other cues are removed. It may contribute to depth perception in natural retinal images, because the depth of focus of the [human eye](https://en.wikipedia.org/wiki/Human_eye "Human eye") is limited. In addition, there are several depth estimation algorithms based on defocus and blurring.[[20]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-21) Some jumping spiders are known to use image defocus to judge depth.[[21]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-22)

When an object is visible relative to the horizon, humans tend to perceive objects which are closer to the horizon as being farther away from them, and objects which are farther from the horizon as being closer to them.[[22]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-23) In addition, if an object moves from a position close to the horizon to a position higher or lower than the horizon, it will appear to move closer to the viewer.

Ocular parallax is a perceptual effect where the rotation of the eye causes perspective-dependent image shifts. This happens because the optical center and the rotation center of the eye are not the same.[[23]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Konrad_Angelopoulos_Wetzstein_2020_pp._1%E2%80%9312-24) Ocular parallax does not require head movement. It is separate and distinct from motion parallax.

[Binocular](https://en.wikipedia.org/wiki/Binocular_vision "Binocular vision") cues provide depth information when viewing a scene with both eyes.

### Stereopsis, or retinal (binocular) disparity, or binocular parallax

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=19 "Edit section: Stereopsis, or retinal (binocular) disparity, or binocular parallax")]

[Animals](https://en.wikipedia.org/wiki/Animal "Animal") that have their eyes placed frontally can also use information derived from the different projections of objects onto each [retina](https://en.wikipedia.org/wiki/Retina "Retina") to judge depth. By using two images of the same scene obtained from slightly different angles, it is possible to [triangulate](https://en.wikipedia.org/wiki/Triangulation "Triangulation") the distance to an object with a high degree of accuracy. Each eye views a slightly different angle of an object seen by the left and right eyes. This happens because of the horizontal separation parallax of the eyes. If an object is far away, the disparity of that image falling on both retinas will be small. If the object is close or near, the disparity will be large. It is stereopsis that tricks people into thinking they perceive depth when viewing [Magic Eyes](https://en.wikipedia.org/wiki/Magic_Eye "Magic Eye"), [autostereograms](https://en.wikipedia.org/wiki/Autostereogram "Autostereogram"), [3-D movies](https://en.wikipedia.org/wiki/3-D_film "3-D film"), and [stereoscopic photos](https://en.wikipedia.org/wiki/Stereoscopy "Stereoscopy").

Convergence is a binocular oculomotor cue for distance and depth perception. Because of stereopsis, the two eyeballs focus on the same object; in doing so they converge. The convergence will stretch the [extraocular muscles](https://en.wikipedia.org/wiki/Extraocular_muscles "Extraocular muscles")â€“ the receptors for this are [muscle spindles](https://en.wikipedia.org/wiki/Muscle_spindle "Muscle spindle"). As happens with the monocular accommodation cue, kinesthetic sensations from these extraocular muscles also help in distance and depth perception. The angle of convergence is smaller when the eye is fixating on objects which are far away. Convergence is effective for distances less than 10 meters.[[24]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-25)

Antonio Medina Puerta demonstrated that retinal images with no parallax disparity but with different shadows were fused stereoscopically, imparting depth perception to the imaged scene. He named the phenomenon "shadow stereopsis". Shadows are therefore an important, stereoscopic cue for depth perception.[[25]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Puerta-26)

Of these various cues, only convergence, accommodation and familiar size provide absolute distance information. All other cues are relative (as in, they can only be used to tell which objects are closer relative to others). Stereopsis is merely relative because a greater or lesser disparity for nearby objects could either mean that those objects differ more or less substantially in relative depth or that the foveated object is nearer or further away (the further away a scene is, the smaller is the retinal disparity indicating the same depth difference).

Theories of evolution
---------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=22 "Edit section: Theories of evolution")]

### The law of Newtonâ€“MÃ¼llerâ€“Gudden

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=23 "Edit section: The law of Newtonâ€“MÃ¼llerâ€“Gudden")]

[Isaac Newton](https://en.wikipedia.org/wiki/Isaac_Newton "Isaac Newton") proposed that the optic nerve of humans and other primates has a specific architecture on its way from the eye to the brain. Nearly half of the fibres from the human retina project to the brain hemisphere on the same side as the eye from which they originate. That architecture is labelled hemi-decussation or ipsilateral (same sided) visual projections (IVP). In most other animals, these nerve fibres cross to the opposite side of the brain.

[Bernhard von Gudden](https://en.wikipedia.org/wiki/Bernhard_von_Gudden "Bernhard von Gudden") showed that the OC contains both crossed and uncrossed retinal fibers, and Ramon y Cajal[[26]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Ramon_Cajal_1972_pp_368-380-27) observed that the grade of hemidecussation differs between species.[[27]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-28)[[26]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Ramon_Cajal_1972_pp_368-380-27)[Gordon Lynn Walls](https://en.wikipedia.org/wiki/Gordon_Lynn_Walls "Gordon Lynn Walls") formalized a commonly accepted notion into the law of Newtonâ€“MÃ¼llerâ€“Gudden (NGM) saying: that the degree of optic fibre decussation in the optic chiasm is contrariwise related to the degree of frontal orientation of the optical axes of the eyes.[[28]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-29)[_[page needed](https://en.wikipedia.org/wiki/Wikipedia:Citing\_sources "Wikipedia:Citing sources")_] In other words, that the number of fibers that do not cross the midline is proportional to the size of the binocular visual field. However, an issue of the Newtonâ€“MÃ¼llerâ€“Gudden law is the considerable interspecific variation in IVP seen in non-mammalian species. That variation is unrelated to mode of life, taxonomic situation, and the overlap of visual fields.[[29]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-30)

Thus, the general hypothesis was for long that the arrangement of nerve fibres in the optic chiasm in primates and humans has developed primarily to create accurate depth perception, stereopsis, or explicitly that the eyes observe an object from somewhat dissimilar angles and that this difference in angle assists the brain to evaluate the distance.

### The eye-forelimb (EF) hypothesis

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=24 "Edit section: The eye-forelimb (EF) hypothesis")]

The eye-forelimb (EF) hypothesis suggests that the need for accurate eye-hand control was key in the evolution of stereopsis. According to the EF hypothesis, stereopsis is evolutionary spinoff from a more vital process: that the construction of the optic chiasm and the position of eyes (the degree of lateral or frontal direction) is shaped by evolution to help the animal to coordinate the limbs (hands, claws, wings or fins).

The EF hypothesis postulates that it has a selective value to have short neural pathways between areas of the brain that receive visual information about the hand and the motor nuclei that control the coordination of the hand. The essence of the EF hypothesis is that evolutionary transformation in OC will affect the length and thereby speed of these neural pathways. Having the primate type of OC means that motor neurons controlling/executing let us say right hand movement, neurons receiving sensory e.g. tactile information about the right hand, and neurons obtaining visual information about the right hand, all will be situated in the same (left) brain hemisphere. The reverse is true for the left hand, the processing of visual, tactile information, and motor commandâ€“ all of which takes place in the right hemisphere. Cats and arboreal (tree-climbing) marsupials have analogous arrangements (between 30 and 45% of IVP and forward-directed eyes). The result will be that visual info of their forelimbs reaches the proper (executing) hemisphere. The evolution has resulted in small, and gradual fluctuations in the direction of the nerve pathways in the OC. This transformation can go in either direction. Snakes, cyclostomes and other animals that lack extremities have relatively many IVP. Notably these animals have no limbs (hands, paws, fins or wings) to direct. Besides, the left and right body parts of snakelike animals cannot move independently of each other. For example, if a snake coils clockwise, its left eye only sees the left body-part and in an anti-clock-wise position the same eye will see just the right body-part. For that reason, it is functional for snakes to have some IVP in the OC (Naked). Cyclostome descendants (in other words, most vertebrates) that due to evolution ceased to curl and, instead developed forelimbs would be favored by achieving completely crossed pathways as long as forelimbs were primarily occupied in a lateral direction. Reptiles such as snakes that lost their limbs, would gain by recollecting a cluster of uncrossed fibres in their evolution. That seems to have happened, providing further support for the EF hypothesis.

Mice' paws are usually busy only in the lateral visual fields. So, it is in accordance with the EF hypothesis that mice have laterally situated eyes and very few crossings in the OC. The list from the animal kingdom supporting the EF hypothesis is long (BBE). The EF hypothesis applies to essentially all vertebrates while the NGM law and stereopsis hypothesis largely apply just to mammals. Even some mammals display important exceptions, e.g. dolphins have only uncrossed pathways although they are predators.

It is a common suggestion that predatory animals generally have frontally-placed eyes since that permit them to evaluate the distance to prey, whereas preyed-upon animals have eyes in a lateral position, since that permit them to scan and detect the enemy in time. However, many predatory animals may also become prey, and several predators, for instance, the crocodile, have laterally situated eyes and no IVP at all. That OC architecture will provide short nerve connections and optimal eye control of the crocodile's front foot.

Birds, usually have laterally situated eyes, in spite of that they manage to fly through e.g. a dense wood. In conclusion, the EF hypothesis does not reject a significant role of stereopsis, but proposes that primates' superb depth perception (stereopsis) evolved to be in service of the hand; that the particular architecture of the primate visual system largely evolved to establish rapid neural pathways between neurons involved in hand coordination, assisting the hand in gripping the correct branch

Most open-plain [herbivores](https://en.wikipedia.org/wiki/Herbivore "Herbivore"), especially hoofed grazers, lack binocular vision because they have their eyes on the sides of the head, providing a panoramic, almost 360Â°, view of the horizonâ€“ enabling them to notice the approach of predators from almost any direction. However, most [predators](https://en.wikipedia.org/wiki/Predator "Predator") have both eyes looking forwards, allowing binocular depth perception and helping them to judge distances when they pounce or swoop down onto their prey. Animals that spend a lot of time in trees take advantage of binocular vision in order to accurately judge distances when rapidly moving from branch to branch.

Matt Cartmill, a physical anthropologist and anatomist at [Boston University](https://en.wikipedia.org/wiki/Boston_University "Boston University"), has criticized this theory, citing other arboreal species which lack binocular vision, such as [squirrels](https://en.wikipedia.org/wiki/Squirrels "Squirrels") and certain [birds](https://en.wikipedia.org/wiki/Birds "Birds"). Instead, he proposes a "Visual Predation Hypothesis," which argues that ancestral primates were insectivorous predators resembling [tarsiers](https://en.wikipedia.org/wiki/Tarsiers "Tarsiers"), subject to the same selection pressure for frontal vision as other predatory species. He also uses this hypothesis to account for the specialization of primate hands, which he suggests became adapted for grasping prey, somewhat like the way [raptors](https://en.wikipedia.org/wiki/Bird_of_prey "Bird of prey") employ their [talons](https://en.wikipedia.org/wiki/Talons "Talons").

[Photographs](https://en.wikipedia.org/wiki/Photograph "Photograph") capturing perspective are two-dimensional images that often illustrate the illusion of depth. Photography utilizes size, environmental context, lighting, textural gradience, and other effects to capture the illusion of depth.[[33]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-34)[Stereoscopes](https://en.wikipedia.org/wiki/Stereoscope "Stereoscope") and [Viewmasters](https://en.wikipedia.org/wiki/Viewmaster "Viewmaster"), as well as [3D films](https://en.wikipedia.org/wiki/3D_film "3D film"), employ binocular vision by forcing the viewer to see two images created from slightly different positions (points of view). [Charles Wheatstone](https://en.wikipedia.org/wiki/Charles_Wheatstone "Charles Wheatstone") was the first to discuss depth perception being a cue of binocular disparity.[[34]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-35) He invented the stereoscope, which is an instrument with two eyepieces that displays two photographs of the same location/scene taken at relatively different angles. When observed, separately by each eye, the pairs of images induced a clear sense of depth.[[35]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-36) By contrast, a [telephoto lens](https://en.wikipedia.org/wiki/Telephoto_lens "Telephoto lens")â€”used in televised sports, for example, to zero in on members of a stadium audienceâ€”has the opposite effect. The viewer sees the size and detail of the scene as if it were close enough to touch, but the camera's perspective is still derived from its actual position a hundred meters away, so background faces and objects appear about the same size as those in the foreground.

Trained artists are keenly aware of the various methods for indicating spatial depth (color shading, [distance fog](https://en.wikipedia.org/wiki/Distance_fog "Distance fog"), [perspective](https://en.wikipedia.org/wiki/Perspective_(visual) "Perspective (visual)") and relative size), and take advantage of them to make their works appear "real". The viewer feels it would be possible to reach in and grab the nose of a [Rembrandt](https://en.wikipedia.org/wiki/Rembrandt "Rembrandt") portrait or an apple in a [CÃ©zanne](https://en.wikipedia.org/wiki/C%C3%A9zanne "CÃ©zanne") still lifeâ€”or step inside a landscape and walk around among its trees and rocks.

[Cubism](https://en.wikipedia.org/wiki/Cubism "Cubism") was based on the idea of incorporating multiple points of view in a painted image, as if to simulate the visual experience of being physically in the presence of the subject, and seeing it from different angles. The radical experiments of [Georges Braque](https://en.wikipedia.org/wiki/Georges_Braque "Georges Braque"), [Pablo Picasso](https://en.wikipedia.org/wiki/Pablo_Picasso "Pablo Picasso"), [Jean Metzinger](https://en.wikipedia.org/wiki/Jean_Metzinger "Jean Metzinger")'s _[Nu Ã  la cheminÃ©e](https://en.wikipedia.org/wiki/Nu\_%C3%A0\_la\_chemin%C3%A9e "Nu Ã  la cheminÃ©e")_,[[36]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-37)[Albert Gleizes](https://en.wikipedia.org/wiki/Albert_Gleizes "Albert Gleizes")'s _[La Femme aux Phlox](https://en.wikipedia.org/wiki/La\_Femme\_aux\_Phlox "La Femme aux Phlox")_,[[37]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Robbins_1964-38)[[38]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-Brooke,_Gleizes-39) or [Robert Delaunay](https://en.wikipedia.org/wiki/Robert_Delaunay "Robert Delaunay")'s [views of the Eiffel Tower](https://en.wikipedia.org/wiki/Eiffel_Tower_(Delaunay_series) "Eiffel Tower (Delaunay series)"),[[39]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-kh-40)[[40]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-41) employ the explosive angularity of Cubism to exaggerate the traditional illusion of three-dimensional space. The subtle use of multiple points of view can be found in the pioneering late work of CÃ©zanne, which both anticipated and inspired the first actual Cubists. CÃ©zanne's landscapes and still lives powerfully suggest the artist's own highly developed depth perception. At the same time, like the other [Post-Impressionists](https://en.wikipedia.org/wiki/Post-Impressionist "Post-Impressionist"), CÃ©zanne had learned from [Japanese art](https://en.wikipedia.org/wiki/Japanese_art "Japanese art") the significance of respecting the flat (two-dimensional) rectangle of the picture itself; [Hokusai](https://en.wikipedia.org/wiki/Hokusai "Hokusai") and [Hiroshige](https://en.wikipedia.org/wiki/Hiroshige "Hiroshige") ignored or even reversed linear perspective and thereby remind the viewer that a picture can only be "true" when it acknowledges the truth of its own flat surface. By contrast, European "academic" painting was devoted to a sort of [Big Lie](https://en.wikipedia.org/wiki/Big_Lie "Big Lie") that the surface of the canvas is _only_ an enchanted doorway to a "real" scene unfolding beyond, and that the artist's main task is to distract the viewer from any disenchanting awareness of the presence of the painted canvas. [Cubism](https://en.wikipedia.org/wiki/Cubism "Cubism"), and indeed most of [modern art](https://en.wikipedia.org/wiki/Modern_art "Modern art") is an attempt to confront, if not resolve, the paradox of suggesting spatial depth on a flat surface, and explore that inherent contradiction through innovative ways of seeing, as well as new methods of drawing and painting.

In robotics and computer vision
-------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Depth_perception&action=edit&section=26 "Edit section: In robotics and computer vision")]

In robotics and [computer vision](https://en.wikipedia.org/wiki/Computer_vision "Computer vision"), depth perception is often achieved using sensors such as [RGBD cameras](https://en.wikipedia.org/wiki/RGBD_camera "RGBD camera").[[41]](https://en.wikipedia.org/wiki/Depth_perception#cite_note-42)

*   [Arboreal theory](https://en.wikipedia.org/wiki/Arboreal_theory "Arboreal theory")
*   [Cyclopean stimuli](https://en.wikipedia.org/wiki/Cyclopean_stimuli "Cyclopean stimuli")
*   [Optical illusion](https://en.wikipedia.org/wiki/Optical_illusion "Optical illusion")
*   [Orthoptics](https://en.wikipedia.org/wiki/Orthoptics "Orthoptics")
*   [Peripheral vision](https://en.wikipedia.org/wiki/Peripheral_vision "Peripheral vision")
*   [Senses](https://en.wikipedia.org/wiki/Senses "Senses")
*   [Vision therapy](https://en.wikipedia.org/wiki/Vision_therapy "Vision therapy")
*   [Visual cliff](https://en.wikipedia.org/wiki/Visual_cliff "Visual cliff")
*   [Vista paradox](https://en.wikipedia.org/wiki/Vista_paradox "Vista paradox")

1.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-1)**Howard, Ian (2012). _Perceiving in Depth_. New York: Oxford University Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-199-76414-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-199-76414-3 "Special:BookSources/978-0-199-76414-3").
2.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-2)**Sternberg, R. K. (2012).
3.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-3)**Goldstein E.B. (2014, 2017) _[Sensation and perception](https://books.google.com/books?id=x5d4CgAAQBAJ&q=%22Depth+perception%22)_ (10th ed.). Pacific Grove, Calif.: Wadsworth.
4.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-4)**Burton HE (1945). "The optics of Euclid". _Journal of the Optical Society of America_. **35** (5): 357â€“372. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1945JOSA...35..357B](https://ui.adsabs.harvard.edu/abs/1945JOSA...35..357B). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1364/JOSA.35.000357](https://doi.org/10.1364%2FJOSA.35.000357).
5.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-5)**Ferris SH (1972). ["Motion parallax and absolute distance"](https://web.archive.org/web/20190209232805/http://archive.rubicon-foundation.org/xmlui/bitstream/handle/123456789/8713/NSMRL_673.pdf?sequence=1)(PDF). _Journal of Experimental Psychology_. **95** (2): 258â€“263. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/h0033605](https://doi.org/10.1037%2Fh0033605). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[5071906](https://pubmed.ncbi.nlm.nih.gov/5071906). Archived from the original on February 9, 2019.
6.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-6)**Kral K. (2003). ["Behavioural-analytical studies of the role of head movements in depth perception in insects, birds and mammals"](http://wexler.free.fr/library/files/kral%20(2003)%20behavioural-analytical%20studies%20of%20the%20role%20of%20head%20movements%20in%20depth%20perception%20in%20insects,%20birds%20and%20mammals.pdf). _Behavioural Processes_**64**: 1â€“12.
7.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-8)**Swanston, M.C.; Gogel, W.C. (1986). ["Perceived size and motion in depth from optical expansion"](https://doi.org/10.3758%2FBF03202998). _Perception & Psychophysics_. **39** (5): 309â€“326. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.3758/BF03202998](https://doi.org/10.3758%2FBF03202998). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[3737362](https://pubmed.ncbi.nlm.nih.gov/3737362).
8.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-9)**Ittelson, W.H. (Apr 1951). "Size as a cue to distance: Radial motion". _American Journal of Psychology_. **64** (2): 188â€“202. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.2307/1418666](https://doi.org/10.2307%2F1418666). [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[1418666](https://www.jstor.org/stable/1418666). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[14829626](https://pubmed.ncbi.nlm.nih.gov/14829626).
9.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-10)**Wallach, H.; O'Connell, D.N. (1953). "The kinetic depth effect". _Journal of Experimental Psychology_. **45** (4): 205â€“217. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1037/h0056880](https://doi.org/10.1037%2Fh0056880). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[13052853](https://pubmed.ncbi.nlm.nih.gov/13052853). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[11979303](https://api.semanticscholar.org/CorpusID:11979303).
10.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-11)**Kaufman, Lloyd (1974). _Sight and Mind_. New York: Oxford University Press. pp.139â€“141.
11.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-12)**_[Grundlagen der Optik](https://www.univie.ac.at/mikroskopie/1\_grundlagen/optik/Grundlagen%20der%20Optik.pdf)._ page 24.
12.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-13)**Georg Eisner: _[Perspektive und Visuelles System â€“ Wege zur Wahrnehmung des Raumes](http://www.eisner-georg.ch/Andere/Perspektive/Perspektiven.pdf)_ pp. 102â€“103
13.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-14)**Georg Eisner: _[Perspektive und Visuelles System â€“ Wege zur Wahrnehmung des Raumes](http://www.eisner-georg.ch/Andere/Perspektive/Perspektiven.pdf)_ page 181
14.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-15)**Sousa, R., Brenner, E., & Smeets, J.B.J. (2011). "Judging an unfamiliar object's distance from its retinal image size". [_Journal of Vision_, 11(9), 10, 1â€“6](https://dx.doi.org/10.1167/11.9.10). Sousa, R., Smeets, J.B.J., & Brenner, E. (2012). "Does size matter?" [_Perception_, 41(12), 1532â€“1534](https://dx.doi.org/10.1068/p7324).
15.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-16)**O'Shea RP, Blackburn SG, Ono H (1994). "Contrast as a depth cue". _Vision Research_. **34** (12): 1595â€“1604. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0042-6989(94)90116-3](https://doi.org/10.1016%2F0042-6989%2894%2990116-3). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[7941367](https://pubmed.ncbi.nlm.nih.gov/7941367). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[149436](https://api.semanticscholar.org/CorpusID:149436).
16.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-17)**Johnston, Alan. ["Depth Perception"](https://web.archive.org/web/20130927185827/http://www.psychol.ucl.ac.uk/alan.johnston/Depth.html). UCL Division of Psychology and Language Sciences. Archived from [the original](http://www.psychol.ucl.ac.uk/alan.johnston/Depth.html) on 27 September 2013. Retrieved 22 September 2013.
17.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-18)**Gillam B, Borsting E (1988). "The role of monocular regions in stereoscopic displays". _Perception_. **17** (5): 603â€“608. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1068/p170603](https://doi.org/10.1068%2Fp170603). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[3249668](https://pubmed.ncbi.nlm.nih.gov/3249668). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[42118792](https://api.semanticscholar.org/CorpusID:42118792).
18.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-19)**Schacter, Daniel L.; Gilbert, Daniel T.; Wegner, Daniel M. (2011). ["Sensation and Perception"](https://archive.org/details/psychology0000scha). _Psychology_ (2nd ed.). New York: Worth, Inc. pp.[136â€“137](https://archive.org/details/psychology0000scha/page/136). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781429237192](https://en.wikipedia.org/wiki/Special:BookSources/9781429237192 "Special:BookSources/9781429237192").
19.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-20)**Lipton, L. (1982). [_Foundations of the Stereoscopic Cinema â€“ A Study in Depth_](http://www.stereoscopic.org/library/index.html). New York: Van Nostrand Reinhold. p.56.
20.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-21)**Mather G (22 February 1996). "Image Blur as a Pictorial Depth Cue". _Proceedings: Biological Sciences_. **263** (1367): 169â€“172. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1996RSPSB.263..169M](https://ui.adsabs.harvard.edu/abs/1996RSPSB.263..169M). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1098/rspb.1996.0027](https://doi.org/10.1098%2Frspb.1996.0027). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[8728981](https://pubmed.ncbi.nlm.nih.gov/8728981). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[30513172](https://api.semanticscholar.org/CorpusID:30513172).
21.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-22)**Takashi Nagata; Koyanagi, M; Tsukamoto, H; Saeki, S; Isono, K; Shichida, Y; Tokunaga, F; Kinoshita, M; Arikawa, K; et al. (27 January 2012). ["Depth Perception from image defocus in a jumping spider"](https://ir.soken.ac.jp/?action=repository_uri&item_id=4203). _Science_. **335** (6067): 469â€“471. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2012Sci...335..469N](https://ui.adsabs.harvard.edu/abs/2012Sci...335..469N). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1126/science.1211667](https://doi.org/10.1126%2Fscience.1211667). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[22282813](https://pubmed.ncbi.nlm.nih.gov/22282813). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[8039638](https://api.semanticscholar.org/CorpusID:8039638).
22.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-23)**Carlson, Neil R.; Miller Jr., Harold L.; Heth, Donald S.; Donahoe, John W.; Martin, G. Neil (2010). _Psychology: The Science of Behavior_ (7th ed.). Pearson. p.187. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-205-76223-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-205-76223-1 "Special:BookSources/978-0-205-76223-1").
23.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Konrad_Angelopoulos_Wetzstein_2020_pp._1%E2%80%9312_24-0)**Konrad, Robert; Angelopoulos, Anastasios; Wetzstein, Gordon (2020-04-30). "Gaze-Contingent Ocular Parallax Rendering for Virtual Reality". _ACM Transactions on Graphics_. **39** (2): 1â€“12. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[1906.09740](https://arxiv.org/abs/1906.09740). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1145/3361330](https://doi.org/10.1145%2F3361330). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0730-0301](https://search.worldcat.org/issn/0730-0301).
24.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-25)**Okoshi, Takanori. (2012). _Three-dimensional imaging techniques_. Elsevier. p.387. [ASIN](https://en.wikipedia.org/wiki/ASIN_(identifier) "ASIN (identifier)")[B01D3RGBGS](https://www.amazon.com/dp/B01D3RGBGS).
25.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Puerta_26-0)**Medina Puerta A (1989). "The power of shadows: shadow stereopsis". _J. Opt. Soc. Am. A_. **6** (2): 309â€“311. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1989JOSAA...6..309M](https://ui.adsabs.harvard.edu/abs/1989JOSAA...6..309M). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1364/JOSAA.6.000309](https://doi.org/10.1364%2FJOSAA.6.000309). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[2926527](https://pubmed.ncbi.nlm.nih.gov/2926527).
26.   ^ [_**a**_](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Ramon_Cajal_1972_pp_368-380_27-0)[_**b**_](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Ramon_Cajal_1972_pp_368-380_27-1)Ramon Y, Cajal S (1972): "Nerfs, chiasma et bandelenes optiques"; in _Histologie du SystÃ¨me de l'Homme et des VertÃ©brÃ©s_. Madrid, Consejo Superior de Investigaciones CientÃ­ficas, vol 2, pp. 368â€“380.
27.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-28)**Polyak S (1957): Investigation of the visual pathways and centers during Classical Antiquity, the Middle Ages, and the early period of the modern scientific Era; in KlÃ¼ver H (ed): The Vertebrate Visual System. Chicago, University of Chicago Press, pp 113â€“115.
28.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-29)**Walls, Gordon L. (1942): _The Vertebrate Eye and Its Adaptive Radiation_. New York, Hafner.
29.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-30)**Ward R, Reperant J, Hergueta S, Miceli D, Lemire M (1995): "Ipsilateral visual projections in non-eutherian species: random variation in the central nervous system?" _Brain Research Reviews_ 20:155â€“170.
30.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-34)**["Eight visual cues to perfect compositional depth and legibility"](http://photopigs.com/2018/02/12/visual-depth-cues/). _photopigs_. 2018-02-12. Retrieved 2018-04-12.
31.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-35)**Brooks, Kevin R. (January 2017). ["Depth Perception and the History of Three-Dimensional Art: Who Produced the First Stereoscopic Images?"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5298491). _i-Perception_. **8** (1): 204166951668011. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1177/2041669516680114](https://doi.org/10.1177%2F2041669516680114). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[2041-6695](https://search.worldcat.org/issn/2041-6695). [PMC](https://en.wikipedia.org/wiki/PMC_(identifier) "PMC (identifier)")[5298491](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5298491). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[28203349](https://pubmed.ncbi.nlm.nih.gov/28203349).
32.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-36)**Schacter, Daniel L. (2011). _Psychology_ (2nd ed.). New York: Worth, In. p.151.
33.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-37)**Daniel Robbins, _Jean Metzinger: At the Center of Cubism_, 1985, Jean Metzinger in Retrospect, The University of Iowa Museum of Art, p. 22
34.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Robbins_1964_38-0)**[_Albert Gleizes 1881â€“1953, a retrospective exhibition_, Daniel Robbins. The Solomon R. Guggenheim Museum, New York, in collaboration with MusÃ©e national d'art moderne, Paris; Museum am Ostwall, Dortmund, published 1964](https://openlibrary.org/books/OL5921018M/Albert_Gleizes_1881%E2%80%931953)
35.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-Brooke,_Gleizes_39-0)**[Peter Brooke, _Albert Gleizes, Chronology of his life, 1881â€“1953_](http://www.peterbrooke.org.uk/a%26r/a%26rintro)
36.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-kh_40-0)**Robert Delaunay â€“ Sonia Delaunay, 1999, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[3-7701-5216-6](https://en.wikipedia.org/wiki/Special:BookSources/3-7701-5216-6 "Special:BookSources/3-7701-5216-6")
37.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-41)**[Robert Delaunay, First Notebook, 1939, in The New Art of Color: The Writings of Robert and Sonia Delaunay, Viking Press, 1978](https://books.google.com/books?id=_D5QAAAAMAAJ&q=%22Cubism+was+in+full+force%22)
38.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-42)**Rosin, Paul L.; Lai, Yu-Kun; Shao, Ling; Liu, Yonghuai (2019-10-26). [_RGB-D Image Analysis and Processing_](https://books.google.com/books?id=OEa5DwAAQBAJ&q=%22depth+perception%22+RGBD&pg=PA35). Springer Nature. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-030-28603-3](https://en.wikipedia.org/wiki/Special:BookSources/978-3-030-28603-3 "Special:BookSources/978-3-030-28603-3").

1.   **[^](https://en.wikipedia.org/wiki/Depth_perception#cite_ref-parallax_7-0)**The term 'parallax vision' is often used as a synonym for binocular vision, and should not be confused with motion parallax. The former allows far more accurate gauging of depth than the latter.

*   Howard, Ian P.; Rogers, Brian J. (2012). _Perceiving in Depth_. New York: Oxford University Press. In three volumes
*   Palmer, S. E. (1999). [_Vision science: Photons to phenomenology_](https://books.google.com/books?id=mNrxCwAAQBAJ). Cambridge, Mass.: Bradford Books/MIT Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780262304016](https://en.wikipedia.org/wiki/Special:BookSources/9780262304016 "Special:BookSources/9780262304016").
*   Pirazzoli, G.P. (2015). _Le Corbusier, Picasso, Polyphemus and Other Monocular Giants / e altri giganti monÃ²culi_. Firenze, Italy: goWare.
*   [Pinker, Steven](https://en.wikipedia.org/wiki/Steven_Pinker "Steven Pinker") (1997). "The Mind's Eye". [_How the Mind Works_](https://en.wikipedia.org/wiki/How_the_Mind_Works "How the Mind Works"). pp.[211â€“233](https://archive.org/details/howmindworks00pink/page/211). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-393-31848-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-393-31848-7 "Special:BookSources/978-0-393-31848-7").
*   Sternberg RJ, Sternberg K, Sternberg K (2011). _Cognitive Psychology_ (6th ed.). Wadsworth Pub Co.
*   Purves D, Lotto B (2003). _Why We See What We Do: An Empirical Theory of Vision_. Sunderland, Mass.: Sinauer Associates.
*   Steinman, Scott B.; Steinman, Barbara A.; Garzia, Ralph Philip (2000). _Foundations of Binocular Vision: A Clinical Perspective_. New York: McGraw-Hill Medical. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8385-2670-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8385-2670-5 "Special:BookSources/978-0-8385-2670-5").
*   Okoshi, Takanori. (2012). _Three-dimensional imaging techniques_. Elsevier. p.387. [ASIN](https://en.wikipedia.org/wiki/ASIN_(identifier) "ASIN (identifier)")[B01D3RGBGS](https://www.amazon.com/dp/B01D3RGBGS).

*   [Depth perception example](http://www.goillusions.com/2015/07/3d-floor-tiles-optical-illusion.html)[Archived](https://web.archive.org/web/20160817070132/http://www.goillusions.com/2015/07/3d-floor-tiles-optical-illusion.html) 2016-08-17 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine") | GO Illusions.
*   [Monocular Giants](http://www.domusweb.it/en/news/2015/08/27/giacomo_pirazzoli_monocular_giants.html)
*   [What is Binocular (Two-eyed) Depth Perception?](http://www.vision3d.com/stereo.html)
*   [Why Some People Can't See in Depth](http://www.vision3d.com/whycant.html)
*   [Space perception](https://web.archive.org/web/20100722110530/http://webvision.med.utah.edu/space_perception.html) | Webvision.
*   [Depth perception](https://web.archive.org/web/20100324122517/http://webvision.med.utah.edu/KallDepth.html) | Webvision.
*   [Make3D](http://make3d.cs.cornell.edu/).
*   [Depth Cues for Film, TV and Photography](http://www.phillipsmcintosh.com/lighting/how-to-light-video-appendix1-binocular-cues.html)
