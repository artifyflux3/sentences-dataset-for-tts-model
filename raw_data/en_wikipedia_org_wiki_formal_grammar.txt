Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Introductory example Toggle Introductory example subsection 1.1 Example 1 1.2 Examples 2 and 3 2 Definition Toggle Definition subsection 2.1 The syntax of grammars 2.2 Some mathematical constructs regarding formal grammars 2.3 Example 3 The Chomsky hierarchy Toggle The Chomsky hierarchy subsection 3.1 Context-free grammars 3.2 Regular grammars 3.3 Other forms of generative grammars 3.4 Recursive grammars 4 Analytic grammars 5 See also 6 References Toggle the table of contents Formal grammar 34 languages Azərbaycanca Bosanski Català Čeština Deutsch Eesti Ελληνικά Español Esperanto فارسی Français Galego 한국어 Hrvatski Ido Italiano Kreyòl ayisyen Magyar Mirandés Nederlands 日本語 Norsk bokmål Polski Português Русский Simple English Slovenčina Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia An example of a formal grammar with parsed sentence. Formal grammars consist of a set of non-terminal symbols, terminal symbols, production rules, and a designated start symbol.

Structure of a formal language Part of a series on Formal languages Key concepts Formal system Alphabet Syntax Formal semantics Semantics (programming languages) Formal grammar Formation rule Well-formed formula Automata theory Regular expression Production Ground expression Atomic formula Applications Formal methods Propositional calculus Predicate logic Mathematical notation Natural language processing Programming language theory Mathematical linguistics Computational linguistics Syntax analysis Formal verification Automated theorem proving v t e A formal grammar is a set of symbols and the production rules for rewriting some of them into every possible string of a formal language over an alphabet . A grammar does not describe the meaning of the strings — only their form.

In applied mathematics , formal language theory is the discipline that studies formal grammars and languages. Its applications are found in theoretical computer science , theoretical linguistics , formal semantics , mathematical logic , and other areas.

A formal grammar is a set of rules for rewriting strings, along with a "start symbol" from which rewriting starts. Therefore, a grammar is usually thought of as a language generator. However, it can also sometimes be used as the basis for a " recognizer "—a function in computing that determines whether a given string belongs to the language or is grammatically incorrect. To describe such recognizers, formal language theory uses separate formalisms, known as automata theory . One of the interesting results of automata theory is that it is not possible to design a recognizer for certain formal languages.

[ 1 ] Parsing is the process of recognizing an utterance (a string in natural languages) by breaking it down to a set of symbols and analyzing each one against the grammar of the language.  Most languages have the meanings of their utterances structured according to their syntax—a practice known as compositional semantics . As a result, the first step to describing the meaning of an utterance in language is to break it down part by part and look at its analyzed form (known as its parse tree in computer science, and as its deep structure in generative grammar ).

Introductory example [ edit ] A grammar mainly consists of a set of production rules , rewrite rules for transforming strings. Each rule specifies a replacement of a particular string (its left-hand side ) with another (its right-hand side ). A rule can be applied to each string that contains its left-hand side and produces a string in which an occurrence of that left-hand side has been replaced with its right-hand side.

Unlike a semi-Thue system , which is wholly defined by these rules, a grammar further distinguishes between two kinds of symbols: nonterminal and terminal symbols ; each left-hand side must contain at least one nonterminal symbol. It also distinguishes a special nonterminal symbol, called the start symbol .

The language generated by the grammar is defined to be the set of all strings without any nonterminal symbols that can be generated from the string consisting of a single start symbol by (possibly repeated) application of its rules in whatever way possible.
If there are essentially different ways of generating the same single string, the grammar is said to be ambiguous .

In the following examples, the terminal symbols are a and b , and the start symbol is S .

Example 1 [ edit ] Suppose we have the following production rules: 1.

S → → a S b {\displaystyle S\rightarrow aSb} 2.

S → → b a {\displaystyle S\rightarrow ba} then we start with S , and can choose a rule to apply to it. If we choose rule 1, we obtain the string aSb . If we then choose rule 1 again, we replace S with aSb and obtain the string aaSbb . If we now choose rule 2, we replace S with ba and obtain the string aababb , and are done. We can write this series of choices more briefly, using symbols: S ⇒ ⇒ a S b ⇒ ⇒ a a S b b ⇒ ⇒ a a b a b b {\displaystyle S\Rightarrow aSb\Rightarrow aaSbb\Rightarrow aababb} .

The language of the grammar is the infinite set { a n b a b n ∣ ∣ n ≥ ≥ 0 } = { b a , a b a b , a a b a b b , a a a b a b b b , … … } {\displaystyle \{a^{n}bab^{n}\mid n\geq 0\}=\{ba,abab,aababb,aaababbb,\dotsc \}} , where a k {\displaystyle a^{k}} is a {\displaystyle a} repeated k {\displaystyle k} times (and n {\displaystyle n} in particular represents the number of times production rule 1 has been applied). This grammar is context-free (only single nonterminals appear as left-hand sides) and unambiguous.

Examples 2 and 3 [ edit ] Suppose the rules are these instead: 1.

S → → a {\displaystyle S\rightarrow a} 2.

S → → S S {\displaystyle S\rightarrow SS} 3.

a S a → → b {\displaystyle aSa\rightarrow b} This grammar is not context-free due to rule 3 and it is ambiguous due to the multiple ways in which rule 2 can be used to generate sequences of S {\displaystyle S} s.

However, the language it generates is simply the set of all nonempty strings consisting of a {\displaystyle a} s and/or b {\displaystyle b} s.
This is easy to see: to generate a b {\displaystyle b} from an S {\displaystyle S} , use rule 2 twice to generate S S S {\displaystyle SSS} , then rule 1 twice and rule 3 once to produce b {\displaystyle b} . This means we can generate arbitrary nonempty sequences of S {\displaystyle S} s and then replace each of them with a {\displaystyle a} or b {\displaystyle b} as we please.

That same language can alternatively be generated by a context-free, nonambiguous grammar; for instance, the regular grammar with rules 1.

S → → a S {\displaystyle S\rightarrow aS} 2.

S → → b S {\displaystyle S\rightarrow bS} 3.

S → → a {\displaystyle S\rightarrow a} 4.

S → → b {\displaystyle S\rightarrow b} Definition [ edit ] Main article: Unrestricted grammar The syntax of grammars [ edit ] In the classic formalization of generative grammars first proposed by Noam Chomsky in the 1950s, [ 2 ] [ 3 ] a grammar G consists of the following components: A finite set N of nonterminal symbols , that is disjoint with the strings formed from G .

A finite set Σ Σ {\displaystyle \Sigma } of terminal symbols that is disjoint from N .

A finite set P of production rules , each rule of the form ( Σ Σ ∪ ∪ N ) ∗ ∗ N ( Σ Σ ∪ ∪ N ) ∗ ∗ → → ( Σ Σ ∪ ∪ N ) ∗ ∗ {\displaystyle (\Sigma \cup N)^{*}N(\Sigma \cup N)^{*}\rightarrow (\Sigma \cup N)^{*}} where ∗ ∗ {\displaystyle {*}} is the Kleene star operator and ∪ ∪ {\displaystyle \cup } denotes set union . That is, each production rule maps from one string of symbols to another, where the first string (the "head") contains an arbitrary number of symbols provided at least one of them is a nonterminal. In the case that the second string (the "body") consists solely of the empty string —i.e., that it contains no symbols at all—it may be denoted with a special notation (often Λ Λ {\displaystyle \Lambda } , e or ϵ ϵ {\displaystyle \epsilon } ) in order to avoid confusion. Such a rule is called an erasing rule .

[ 4 ] A distinguished symbol S ∈ ∈ N {\displaystyle S\in N} that is the start symbol , also called the sentence symbol .

A grammar is formally defined as the tuple ( N , Σ Σ , P , S ) {\displaystyle (N,\Sigma ,P,S)} . Such a formal grammar is often called a rewriting system or a phrase structure grammar in the literature.

[ 5 ] [ 6 ] Some mathematical constructs regarding formal grammars [ edit ] The operation of a grammar can be defined in terms of relations on strings: Given a grammar G = ( N , Σ Σ , P , S ) {\displaystyle G=(N,\Sigma ,P,S)} , the binary relation ⇒ ⇒ G {\displaystyle {\underset {G}{\Rightarrow }}} (pronounced as  "G derives in one step") on strings in ( Σ Σ ∪ ∪ N ) ∗ ∗ {\displaystyle (\Sigma \cup N)^{*}} is defined by: x ⇒ ⇒ G y ⟺ ⟺ ∃ ∃ u , v , p , q ∈ ∈ ( Σ Σ ∪ ∪ N ) ∗ ∗ : ( x = u p v ) ∧ ∧ ( p → → q ∈ ∈ P ) ∧ ∧ ( y = u q v ) {\displaystyle x{\underset {G}{\Rightarrow }}y\iff \exists u,v,p,q\in (\Sigma \cup N)^{*}:(x=upv)\wedge (p\rightarrow q\in P)\wedge (y=uqv)} the relation ⇒ ⇒ G ∗ ∗ {\displaystyle {\overset {*}{\underset {G}{\Rightarrow }}}} (pronounced as G derives in zero or more steps ) is defined as the reflexive transitive closure of ⇒ ⇒ G {\displaystyle {\underset {G}{\Rightarrow }}} a sentential form is a member of ( Σ Σ ∪ ∪ N ) ∗ ∗ {\displaystyle (\Sigma \cup N)^{*}} that can be derived in a finite number of steps from the start symbol S {\displaystyle S} ; that is, a sentential form is a member of { w ∈ ∈ ( Σ Σ ∪ ∪ N ) ∗ ∗ ∣ ∣ S ⇒ ⇒ G ∗ ∗ w } {\displaystyle \left\{w\in (\Sigma \cup N)^{*}\mid S{\overset {*}{\underset {G}{\Rightarrow }}}w\right\}} . A sentential form that contains no nonterminal symbols (i.e. is a member of Σ Σ ∗ ∗ {\displaystyle \Sigma ^{*}} ) is called a sentence .

[ 7 ] the language of G {\displaystyle G} , denoted as L ( G ) {\displaystyle {\boldsymbol {L}}(G)} , is defined as the set of sentences built by G {\displaystyle G} .

The grammar G = ( N , Σ Σ , P , S ) {\displaystyle G=(N,\Sigma ,P,S)} is effectively the semi-Thue system ( N ∪ ∪ Σ Σ , P ) {\displaystyle (N\cup \Sigma ,P)} , rewriting strings in exactly the same way; the only difference is in that we distinguish specific nonterminal symbols, which must be replaced in rewrite rules, and are only interested in rewritings from the designated start symbol S {\displaystyle S} to strings without nonterminal symbols.

Example [ edit ] For these examples, formal languages are specified using set-builder notation .

Consider the grammar G {\displaystyle G} where N = { S , B } {\displaystyle N=\left\{S,B\right\}} , Σ Σ = { a , b , c } {\displaystyle \Sigma =\left\{a,b,c\right\}} , S {\displaystyle S} is the start symbol, and P {\displaystyle P} consists of the following production rules: 1.

S → → a B S c {\displaystyle S\rightarrow aBSc} 2.

S → → a b c {\displaystyle S\rightarrow abc} 3.

B a → → a B {\displaystyle Ba\rightarrow aB} 4.

B b → → b b {\displaystyle Bb\rightarrow bb} This grammar defines the language L ( G ) = { a n b n c n ∣ ∣ n ≥ ≥ 1 } {\displaystyle L(G)=\left\{a^{n}b^{n}c^{n}\mid n\geq 1\right\}} where a n {\displaystyle a^{n}} denotes a string of n consecutive a {\displaystyle a} 's. Thus, the language is the set of strings that consist of 1 or more a {\displaystyle a} 's, followed by the same number of b {\displaystyle b} 's, followed by the same number of c {\displaystyle c} 's.

Some examples of the derivation of strings in L ( G ) {\displaystyle L(G)} are: S ⇒ ⇒ 2 a b c {\displaystyle {\boldsymbol {S}}{\underset {2}{\Rightarrow }}{\boldsymbol {abc}}} S ⇒ ⇒ 1 a B S c ⇒ ⇒ 2 a B a b c c ⇒ ⇒ 3 a a B b c c ⇒ ⇒ 4 a a b b c c {\displaystyle {\begin{aligned}{\boldsymbol {S}}&{\underset {1}{\Rightarrow }}{\boldsymbol {aBSc}}\\&{\underset {2}{\Rightarrow }}aB{\boldsymbol {abc}}c\\&{\underset {3}{\Rightarrow }}a{\boldsymbol {aB}}bcc\\&{\underset {4}{\Rightarrow }}aa{\boldsymbol {bb}}cc\end{aligned}}} S ⇒ ⇒ 1 a B S c ⇒ ⇒ 1 a B a B S c c ⇒ ⇒ 2 a B a B a b c c c ⇒ ⇒ 3 a a B B a b c c c ⇒ ⇒ 3 a a B a B b c c c ⇒ ⇒ 3 a a a B B b c c c ⇒ ⇒ 4 a a a B b b c c c ⇒ ⇒ 4 a a a b b b c c c {\displaystyle {\begin{aligned}{\boldsymbol {S}}&{\underset {1}{\Rightarrow }}{\boldsymbol {aBSc}}{\underset {1}{\Rightarrow }}aB{\boldsymbol {aBSc}}c\\&{\underset {2}{\Rightarrow }}aBaB{\boldsymbol {abc}}cc\\&{\underset {3}{\Rightarrow }}a{\boldsymbol {aB}}Babccc{\underset {3}{\Rightarrow }}aaB{\boldsymbol {aB}}bccc{\underset {3}{\Rightarrow }}aa{\boldsymbol {aB}}Bbccc\\&{\underset {4}{\Rightarrow }}aaaB{\boldsymbol {bb}}ccc{\underset {4}{\Rightarrow }}aaa{\boldsymbol {bb}}bccc\end{aligned}}} (On notation: P ⇒ ⇒ i Q {\displaystyle P{\underset {i}{\Rightarrow }}Q} reads "String P generates string Q by means of production i ", and the generated part is each time indicated in bold type.) The Chomsky hierarchy [ edit ] Main articles: Chomsky hierarchy and Generative grammar When Noam Chomsky first formalized generative grammars in 1956, [ 2 ] he classified them into types now known as the Chomsky hierarchy . The difference between these types is that they have increasingly strict production rules and can therefore express fewer formal languages. Two important types are context-free grammars (Type 2) and regular grammars (Type 3). The languages that can be described with such a grammar are called context-free languages and regular languages , respectively. Although much less powerful than unrestricted grammars (Type 0), which can in fact express any language that can be accepted by a Turing machine , these two restricted types of grammars are most often used because parsers for them can be efficiently implemented.

[ 8 ] For example, all regular languages can be recognized by a finite-state machine , and for useful subsets of context-free grammars there are well-known algorithms to generate efficient LL parsers and LR parsers to recognize the corresponding languages those grammars generate.

Context-free grammars [ edit ] A context-free grammar is a grammar in which the left-hand side of each production rule consists of only a single nonterminal symbol. This restriction is non-trivial; not all languages can be generated by context-free grammars. Those that can are called context-free languages .

The language L ( G ) = { a n b n c n ∣ ∣ n ≥ ≥ 1 } {\displaystyle L(G)=\left\{a^{n}b^{n}c^{n}\mid n\geq 1\right\}} defined above is not a context-free language, and this can be strictly proven using the pumping lemma for context-free languages , but for example the language { a n b n ∣ ∣ n ≥ ≥ 1 } {\displaystyle \left\{a^{n}b^{n}\mid n\geq 1\right\}} (at least 1 a {\displaystyle a} followed by the same number of b {\displaystyle b} 's) is context-free, as it can be defined by the grammar G 2 {\displaystyle G_{2}} with N = { S } {\displaystyle N=\left\{S\right\}} , Σ Σ = { a , b } {\displaystyle \Sigma =\left\{a,b\right\}} , S {\displaystyle S} the start symbol, and the following production rules: 1.

S → → a S b {\displaystyle S\rightarrow aSb} 2.

S → → a b {\displaystyle S\rightarrow ab} A context-free language can be recognized in O ( n 3 ) {\displaystyle O(n^{3})} time ( see Big O notation ) by an algorithm such as Earley's recogniser . That is, for every context-free language, a machine can be built that takes a string as input and determines in O ( n 3 ) {\displaystyle O(n^{3})} time whether the string is a member of the language, where n {\displaystyle n} is the length of the string.

[ 9 ] Deterministic context-free languages is a subset of context-free languages that can be recognized in linear time.

[ 10 ] There exist various algorithms that target either this set of languages or some subset of it.

Regular grammars [ edit ] In regular grammars , the left hand side is again only a single nonterminal symbol, but now the right-hand side is also restricted. The right side may be the empty string, or a single terminal symbol, or a single terminal symbol followed by a nonterminal symbol, but nothing else. (Sometimes a broader definition is used: one can allow longer strings of terminals or single nonterminals without anything else, making languages easier to denote while still defining the same class of languages.) The language { a n b n ∣ ∣ n ≥ ≥ 1 } {\displaystyle \left\{a^{n}b^{n}\mid n\geq 1\right\}} defined above is not regular, but the language { a n b m ∣ ∣ m , n ≥ ≥ 1 } {\displaystyle \left\{a^{n}b^{m}\mid m,n\geq 1\right\}} (at least 1 a {\displaystyle a} followed by at least 1 b {\displaystyle b} , where the numbers may be different) is, as it can be defined by the grammar G 3 {\displaystyle G_{3}} with N = { S , A , B } {\displaystyle N=\left\{S,A,B\right\}} , Σ Σ = { a , b } {\displaystyle \Sigma =\left\{a,b\right\}} , S {\displaystyle S} the start symbol, and the following production rules: S → → a A {\displaystyle S\rightarrow aA} A → → a A {\displaystyle A\rightarrow aA} A → → b B {\displaystyle A\rightarrow bB} B → → b B {\displaystyle B\rightarrow bB} B → → ϵ ϵ {\displaystyle B\rightarrow \epsilon } All languages generated by a regular grammar can be recognized in O ( n ) {\displaystyle O(n)} time by a finite-state machine. Although in practice, regular grammars are commonly expressed using regular expressions , some forms of regular expression used in practice do not strictly generate the regular languages and do not show linear recognitional performance due to those deviations.

Other forms of generative grammars [ edit ] Many extensions and variations on Chomsky's original hierarchy of formal grammars have been developed, both by linguists and by computer scientists, usually either in order to increase their expressive power or in order to make them easier to analyze or parse. Some forms of grammars developed include: Tree-adjoining grammars increase the expressiveness of conventional generative grammars by allowing rewrite rules to operate on parse trees instead of just strings.

[ 11 ] Affix grammars [ 12 ] and attribute grammars [ 13 ] [ 14 ] allow rewrite rules to be augmented with semantic attributes and operations, useful both for increasing grammar expressiveness and for constructing practical language translation tools.

Recursive grammars [ edit ] Not to be confused with Recursive language .

A recursive grammar is a grammar that contains production rules that are recursive . For example, a grammar for a context-free language is left-recursive if there exists a non-terminal symbol A that can be put through the production rules to produce a string with A as the leftmost symbol.

[ 15 ] An example of recursive grammar is a clause within a sentence separated by two commas.

[ 16 ] All types of grammars in the Chomsky hierarchy can be recursive.

Analytic grammars [ edit ] Though there is a tremendous body of literature on parsing algorithms , most of these algorithms assume that the language to be parsed is initially described by means of a generative formal grammar, and that the goal is to transform this generative grammar into a working parser. Strictly speaking, a generative grammar does not in any way correspond to the algorithm used to parse a language, and various algorithms have different restrictions on the form of production rules that are considered well-formed.

An alternative approach is to formalize the language in terms of an analytic grammar in the first place, which more directly corresponds to the structure and semantics of a parser for the language. Examples of analytic grammar formalisms include the following: Top-down parsing language (TDPL): a highly minimalist analytic grammar formalism developed in the early 1970s to study the behavior of top-down parsers .

[ 17 ] Link grammars : a form of analytic grammar designed for linguistics , which derives syntactic structure by examining the positional relationships between pairs of words.

[ 18 ] [ 19 ] Parsing expression grammars (PEGs): a more recent generalization of TDPL designed around the practical expressiveness needs of programming language and compiler writers.

[ 20 ] See also [ edit ] Abstract syntax tree Adaptive grammar Ambiguous grammar Backus–Naur form (BNF) Categorial grammar Concrete syntax tree Extended Backus–Naur form (EBNF) Grammar Grammar framework L-system Lojban Post canonical system Shape grammar Well-formed formula References [ edit ] ^ Meduna, Alexander (2014), Formal Languages and Computation: Models and Their Applications , CRC Press, p. 233, ISBN 9781466513457 . For more on this subject, see undecidable problem .

^ a b Chomsky, Noam (Sep 1956). "Three models for the description of language".

IRE Transactions on Information Theory .

2 (3): 113– 124.

doi : 10.1109/TIT.1956.1056813 .

S2CID 19519474 .

^ Chomsky, Noam (1957).

Syntactic Structures . The Hague: Mouton .

^ Ashaari, S.; Turaev, S.; Okhunov, A. (2016).

"Structurally and Arithmetically Controlled Grammars" (PDF) .

International Journal on Perceptive and Cognitive Computing .

2 (2): 27.

doi : 10.31436/ijpcc.v2i2.39 . Retrieved 2024-11-05 .

^ Ginsburg, Seymour (1975).

Algebraic and automata theoretic properties of formal languages . North-Holland. pp.

8– 9.

ISBN 978-0-7204-2506-2 .

^ Harrison, Michael A.

(1978).

Introduction to Formal Language Theory . Reading, Mass.: Addison-Wesley Publishing Company. p. 13.

ISBN 978-0-201-02955-0 .

^ Sentential Forms Archived 2019-11-13 at the Wayback Machine , Context-Free Grammars, David Matuszek ^ Grune, Dick & Jacobs, Ceriel H., Parsing Techniques – A Practical Guide , Ellis Horwood, England, 1990.

^ Earley, Jay, " An Efficient Context-Free Parsing Algorithm Archived 2020-05-19 at the Wayback Machine ," Communications of the ACM , Vol. 13 No. 2, pp. 94-102, February 1970.

^ Knuth, D. E.

(July 1965). "On the translation of languages from left to right".

Information and Control .

8 (6): 607– 639.

doi : 10.1016/S0019-9958(65)90426-2 .

^ Joshi, Aravind K., et al.

, " Tree Adjunct Grammars ," Journal of Computer Systems Science , Vol. 10 No. 1, pp. 136-163, 1975.

^ Koster , Cornelis H. A., "Affix Grammars," in ALGOL 68 Implementation , North Holland Publishing Company, Amsterdam, p. 95-109, 1971.

^ Knuth, Donald E., " Semantics of Context-Free Languages ," Mathematical Systems Theory , Vol. 2 No. 2, pp. 127-145, 1968.

^ Knuth, Donald E., "Semantics of Context-Free Languages (correction)," Mathematical Systems Theory , Vol. 5 No. 1, pp 95-96, 1971.

^ Notes on Formal Language Theory and Parsing Archived 2017-08-28 at the Wayback Machine , James Power, Department of Computer Science National University of Ireland, Maynooth Maynooth, Co. Kildare, Ireland.

JPR02 ^ Borenstein, Seth (April 27, 2006).

"Songbirds grasp grammar, too" .

Northwest Herald . p. 2 – via Newspapers.com.

^ Birman, Alexander, The TMG Recognition Schema , Doctoral thesis, Princeton University, Dept. of Electrical Engineering, February 1970.

^ Sleator, Daniel D. & Temperly, Davy, " Parsing English with a Link Grammar ," Technical Report CMU-CS-91-196, Carnegie Mellon University Computer Science, 1991.

^ Sleator, Daniel D. & Temperly, Davy, "Parsing English with a Link Grammar," Third International Workshop on Parsing Technologies , 1993. (Revised version of above report.) ^ Ford, Bryan, Packrat Parsing: a Practical Linear-Time Algorithm with Backtracking , Master’s thesis, Massachusetts Institute of Technology, Sept. 2002.

v t e Automata theory : formal languages and formal grammars Chomsky hierarchy Grammars Languages Abstract machines Type-0 — Type-1 — — — — — Type-2 — — Type-3 — — Unrestricted (no common name) Context-sensitive Positive range concatenation Indexed — Linear context-free rewriting systems Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular — Non-recursive Recursively enumerable Decidable Context-sensitive Positive range concatenation * Indexed * — Linear context-free rewriting language Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular Star-free Finite Turing machine Decider Linear-bounded PTIME Turing Machine Nested stack Thread automaton restricted Tree stack automaton Embedded pushdown Nondeterministic pushdown Deterministic pushdown Visibly pushdown Finite Counter-free (with aperiodic finite monoid) Acyclic finite Each category of languages, except those marked by a * , is a proper subset of the category directly above it.

Any language in each category is generated by a grammar and by an automaton in the category in the same line.

v t e Mathematical logic General Axiom list Cardinality First-order logic Formal proof Formal semantics Foundations of mathematics Information theory Lemma Logical consequence Model Theorem Theory Type theory Theorems ( list ) and paradoxes Gödel's completeness and incompleteness theorems Tarski's undefinability Banach–Tarski paradox Cantor's theorem, paradox and diagonal argument Compactness Halting problem Lindström's Löwenheim–Skolem Russell's paradox Logics Traditional Classical logic Logical truth Tautology Proposition Inference Logical equivalence Consistency Equiconsistency Argument Soundness Validity Syllogism Square of opposition Venn diagram Propositional Boolean algebra Boolean functions Logical connectives Propositional calculus Propositional formula Truth tables Many-valued logic 3 finite ∞ Predicate First-order list Second-order Monadic Higher-order Fixed-point Free Quantifiers Predicate Monadic predicate calculus Set theory Set hereditary Class ( Ur- ) Element Ordinal number Extensionality Forcing Relation equivalence partition Set operations: intersection union complement Cartesian product power set identities Types of sets Countable Uncountable Empty Inhabited Singleton Finite Infinite Transitive Ultrafilter Recursive Fuzzy Universal Universe constructible Grothendieck Von Neumann Maps and cardinality Function / Map domain codomain image In / Sur / Bi -jection Schröder–Bernstein theorem Isomorphism Gödel numbering Enumeration Large cardinal inaccessible Aleph number Operation binary Set theories Zermelo–Fraenkel axiom of choice continuum hypothesis General Kripke–Platek Morse–Kelley Naive New Foundations Tarski–Grothendieck Von Neumann–Bernays–Gödel Ackermann Constructive Formal systems ( list ), language and syntax Alphabet Arity Automata Axiom schema Expression ground Extension by definition conservative Relation Formation rule Grammar Formula atomic closed ground open Free/bound variable Language Metalanguage Logical connective ¬ ∨ ∧ → ↔ = Predicate functional variable propositional variable Proof Quantifier ∃ !

∀ rank Sentence atomic spectrum Signature String Substitution Symbol function logical/constant non-logical variable Term Theory list Example axiomatic systems ( list ) of arithmetic : Peano second-order elementary function primitive recursive Robinson Skolem of the real numbers Tarski's axiomatization of Boolean algebras canonical minimal axioms of geometry : Euclidean : Elements Hilbert's Tarski's non-Euclidean Principia Mathematica Proof theory Formal proof Natural deduction Logical consequence Rule of inference Sequent calculus Theorem Systems axiomatic deductive Hilbert list Complete theory Independence ( from ZFC ) Proof of impossibility Ordinal analysis Reverse mathematics Self-verifying theories Model theory Interpretation function of models Model equivalence finite saturated spectrum submodel Non-standard model of arithmetic Diagram elementary Categorical theory Model complete theory Satisfiability Semantics of logic Strength Theories of truth semantic Tarski's Kripke's T-schema Transfer principle Truth predicate Truth value Type Ultraproduct Validity Computability theory Church encoding Church–Turing thesis Computably enumerable Computable function Computable set Decision problem decidable undecidable P NP P versus NP problem Kolmogorov complexity Lambda calculus Primitive recursive function Recursion Recursive set Turing machine Type theory Related Abstract logic Algebraic logic Automated theorem proving Category theory Concrete / Abstract category Category of sets History of logic History of mathematical logic timeline Logicism Mathematical object Philosophy of mathematics Supertask Mathematics portal Authority control databases : National Germany NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐7nnbl
Cached time: 20250812011429
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.569 seconds
Real time usage: 0.853 seconds
Preprocessor visited node count: 2113/1000000
Revision size: 24067/2097152 bytes
Post‐expand include size: 102377/2097152 bytes
Template argument size: 1540/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 72464/5000000 bytes
Lua time usage: 0.309/10.000 seconds
Lua memory usage: 5651024/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  506.652      1 -total
 30.85%  156.319      1 Template:Reflist
 21.49%  108.860      1 Template:Formal_languages
 21.13%  107.079      1 Template:Sidebar_with_collapsible_lists
 16.31%   82.638      1 Template:Citation
 15.62%   79.139      1 Template:Short_description
  9.28%   47.014      4 Template:Navbox
  8.86%   44.866      2 Template:Pagetype
  6.85%   34.702      1 Template:Mathematical_logic
  6.56%   33.220      1 Template:Formal_languages_and_grammars Saved in parser cache with key enwiki:pcache:18020716:|#|:idhash:canonical and timestamp 20250812011429 and revision id 1290102462. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Formal_grammar&oldid=1290102462 " Categories : Formal languages Grammar Mathematical logic Syntax Automata (computation) Mathematical linguistics Hidden categories: Webarchive template wayback links Articles with short description Short description matches Wikidata This page was last edited on 12 May 2025, at 20:46 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Formal grammar 34 languages Add topic

