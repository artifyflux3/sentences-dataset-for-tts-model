Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Issues and problems with the power usage effectiveness 2 Benefits and limitation 3 Notably efficient companies 4 Standards 5 See also 6 References Toggle the table of contents Power usage effectiveness 7 languages Català Čeština Español Français Italiano Suomi 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Ratio to describe data-center efficiency Power usage effectiveness ( PUE ) or power unit efficiency is a ratio that describes how efficiently a computer data center uses energy; specifically, how much energy is used by the computing equipment (in contrast to cooling and other overhead that supports the equipment).

PUE is the ratio of the total amount of energy used by a computer data center facility [ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ] [ excessive citations ] to the energy delivered to computing equipment. PUE is the inverse of data center infrastructure efficiency .

PUE was originally developed by a consortium called The Green Grid . PUE was published in 2016 as a global standard under ISO/IEC 30134-2:2016 An ideal PUE is 1.0. Anything that isn't considered a computing device in a data center (e.g. lighting, cooling, etc.) falls into the category of facility energy consumption.

P U E = Total Facility Energy IT Equipment Energy = 1 + Non IT Facility Energy IT Equipment Energy {\displaystyle \mathrm {PUE} ={{\mbox{Total Facility Energy}} \over {\mbox{IT Equipment Energy}}}=1+{{\mbox{Non IT Facility Energy}} \over {\mbox{IT Equipment Energy}}}} Issues and problems with the power usage effectiveness [ edit ] This article is written like a personal reflection, personal essay, or argumentative essay that states a Wikipedia editor's personal feelings or presents an original argument about a topic.

Please help improve it by rewriting it in an encyclopedic style .

( June 2020 ) ( Learn how and when to remove this message ) The PUE metric is the most popular method of calculating energy efficiency . Although it is the most effective in comparison to other metrics, PUE comes with its share of flaws. This is the most frequently used metric for operators, facility technicians, and building architects to determine how energy efficient their data center buildings are.

[ 9 ] Some professionals even brag about their PUE being lower than others. Naturally, it is not a surprise that in some cases an operator may “accidentally” not count the energy used for lighting, resulting in lower PUE. This problem is more linked to a human mistake, rather than an issue with the PUE metric system itself.

One real problem is PUE does not account for the climate within the cities the data centers are built. In particular, it does not account for different normal temperatures outside the data center. For example, a data center located in Alaska cannot be effectively compared to a data center in Miami. A colder climate results in a lesser need for a massive cooling system. Cooling systems account for roughly 30 percent of consumed energy in a facility, while the data center equipment accounts for nearly 50 percent.

[ 9 ] Due to this, the Miami data center may have a final PUE of 1.8 and the data center in Alaska may have a ratio of 1.7, but the Miami data center may be running overall more efficiently. In particular, if it happened to be in Alaska, it may get a better result.

Additionally, according to a case study on Science Direct , "an estimated PUE is practically meaningless unless the IT is working at full capacity".

[ 10 ] All in all, finding simple, yet recurring issues such as the problems associated with the effect of varying temperatures in cities and learning how to properly calculate all the facility energy consumption is very essential. By doing so, continuing to reduce these problems ensures that further progress and higher standards are always being pushed to improve the success of the PUE for future data center facilities.

[ 9 ] To get precise results from an efficiency calculation, all the data associated with the data center must be included. Even a small mistake can cause many differences in PUE results. One practical problem that is frequently noticed in typically data centers include adding the energy endowment of any alternate energy generation systems (such as wind turbines and solar panels) running in parallel with the data center to the PUE, leading to an obfuscation of the true data center performance. Another problem is that some devices that consume power and are associated with a data center may actually share energy or uses elsewhere, causing a huge error on PUE.

Benefits and limitation [ edit ] PUE was introduced in 2006 and promoted by The Green Grid (a non-profit organization of IT professionals) in 2007, and has become the most commonly used metric for reporting the energy efficiency of data centres.

[ 10 ] Although it is named "power usage effectiveness", it actually measures the energy use of the data centre.

[ 10 ] The PUE metric has several important benefits. First, the calculation can be repeated over time, allowing a company to view their efficiency changes historically, or during time-limited events like seasonal changes. Second, companies can gauge how more efficient practices (such as powering down idle hardware) affect their overall usage. Finally, the PUE metric creates competition, “driving efficiencies up as advertised PUE values become lower".

[ 10 ] Companies can then use PUE as a marketing tool.

However, there are some issues with the PUE metric. The main one arises from the way the ratio is calculated. Because IT load is the sole denominator, any reduction in IT load (for example through virtualisation allowing some hardware to be stood down, or simply through more energy-efficient hardware) will cause the PUE to rise. This gives a perverse result.

As well as the issues mentioned in the last paragraph, some other issues are the efficiency of the power supply network and calculating  the accurate IT load. According to the sensitivity analysis by Gemma, [ 10 ] "Total energy consumption is equal to the total amount of energy used by the equipment and infrastructure in the facility (WT) plus the energy losses due to inefficiencies in the power delivery network (WL), hence: PUE=(WT+WL)/WIT." Based on the equation, the inefficiencies of the power delivery network (WL) will increase the total energy consumption of the data center. The PUE value goes up as the data center becomes less efficient. IT load is another important issue of the PUE metric. "It is crucial that an accurate IT load is used for the PUE, and that it is not based upon the rated power use of the equipment. Accuracy in the IT load is one of the major factors affecting the measurement of the PUE metric, as utilization of the servers has an important effect on IT energy consumption and hence the overall PUE value".

[ 10 ] For example, a data center with high PUE value and high server utilization could be more efficient than a data center with low PUE value and low server utilization.

[ 10 ] There is also some concern within the industry of PUE as a marketing tool [ 11 ] leading some to use the term "PUE Abuse".

[ 12 ] Notably efficient companies [ edit ] In October 2008, Google's data center was noted to have a ratio of 1.21 PUE across all 6 of its centers, which at the time was considered as close to perfect as possible. Right behind Google was Microsoft, which had another notable PUE ratio of 1.22.

[ 13 ] Since 2015, Switch , the developer of SUPERNAP data centers, has had a third party audited colocation PUE of 1.18 for its SUPERNAP 7 Las Vegas, Nevada facility, with an average cold aisle temp of 20.6 °C (69.1 °F) and average humidity of 40.3%. This is attributed to Switch's patented hot aisle containment and HVAC technologies.

[ 14 ] As of the end of Q2 2015, Facebook's Prineville data center had a power usage effectiveness (PUE) of 1.078 and its Forest City data center had a PUE of 1.082.

[ 15 ] In October 2015, Allied Control has a claimed PUE ratio of 1.02 [ 16 ] through the use of two-phase immersion cooling using 3M Novec 7100 fluid.

In January 2016, the Green IT Cube in Darmstadt was dedicated with a 1.07 PUE.

[ 17 ] It uses cold water cooling through the rack doors.

In February 2017, Supermicro has announced deployment of its disaggregated MicroBlade systems. An unnamed Fortune 100 company has deployed over 30,000 Supermicro MicroBlade servers at its Silicon Valley data center with a (PUE) of 1.06.

[ 18 ] Through proprietary innovations in liquid cooling systems, French hosting company OVH has managed to attain a PUE ratio of 1.09 in its data centers in Europe and North America [ 19 ] while in 2023 they reported a 12 months overall PUE of 1.29.

[ 20 ] In 2021, Google reported a PUE of 1.1 across their data centers worldwide, and less than 1.06 for their best sites.

[ 21 ] [ 22 ] In scientific projects in 2022, the Research Institutes of Sweden reported a PUE of 1.0148, notably reached in the north of Sweden.

[ 23 ] Standards [ edit ] PUE was published in 2016 as a global standard under ISO/IEC 30134-2:2016 as well as a European standard under EN 50600-4-2:2016 .

See also [ edit ] Data center infrastructure efficiency Performance per watt Green power usage effectiveness Green computing IT energy management WUE References [ edit ] ^ "What is power usage effectiveness (PUE)? - Definition from WhatIs.com" .

^ Digital Realty - PUE Data Center Efficiency Metric ^ "Optimizing Power Usage Effectiveness In Data Centers" .

www.esmagazine.com .

^ "The Green Grid - The Green Grid Data Center Power Efficiency Metrics: PUE and DCiE" .

^ Google - Efficient Computing - Data Centers - Efficiency: How we do it?

^ Dell - Best Practices for Increasing Data Center Energy Efficiency ^ Cisco Systems - Cisco Energywise ^ Google Data Center Optimization - [1] ^ a b c Yuventi, Jumie; Mehdizadeh, Roshan (2013). "A critical analysis of Power Usage Effectiveness and its use in communicating data center energy consumption".

Energy and Buildings .

64 : 90– 94.

Bibcode : 2013EneBu..64...90Y .

doi : 10.1016/j.enbuild.2013.04.015 .

^ a b c d e f g Brady, Gemma, Nikil Kapur, Jonathan Summers, and Harvey Thompson. " A Case Study and Critical Assessment in Calculating Power Usage Effectiveness for a Data Centre ." Energy Conversion & Management , 76 (2013): 155-161.

^ "Romonet website, Blogs, 'Look at the size of my PUE!' " . Archived from the original on 2015-09-24 . Retrieved 2015-09-04 .

^ "PUE abuse beyond the pale? - Datacenter Dynamics" .

archive.datacenterdynamics.com .

^ Tuf, Steve. "Power Usage Effectiveness." It.toolbox. Toolbox, n.d. Web. 17 Nov. 2014.

^ Miller, Rich.

“Inside SUPERNAP 8: Switch’s Tier IV Data Fortress.” Data Center Knowledge. Feb. 11, 2014 ^ "Energy Efficiency" .

Open Compute Project . Open Compute Project. Archived from the original on 12 March 2016 . Retrieved 18 March 2016 .

^ 3M (October 15, 2015).

"Two-Phase Immersion Cooling" (PDF) . Archived from the original (PDF) on December 8, 2015 . Retrieved December 7, 2024 .

{{ cite web }} :  CS1 maint: numeric names: authors list ( link ) ^ "Green IT Cube: Hocheffizientes Supercomputer-Domizil eingeweiht" . 2016-01-23 . Retrieved 2016-01-24 .

^ "Supermicro - News - Supermicro Deploys 30,000+ MicroBlade™ Servers to Enable One of the World's Highest Efficiency (1.06 PUE) Data Centers" .

www.supermicro.com .

^ OVH.

"A green hosting provider - OVH Canada" .

www.ovh.com .

^ "Managing our environmental impact every step of the way" .

ovhcloud.com . 6 January 2023.

^ "Google Data Centers efficiency" .

google.com .

^ "How Google plans to use 100% carbon-free energy in its data centers by 2030" .

cnbc.com . 13 April 2022.

^ "Holistic cooling at the world's most efficient data center" .

ri.se .

Retrieved from " https://en.wikipedia.org/w/index.php?title=Power_usage_effectiveness&oldid=1262031042 " Categories : Benchmarks (computing) Energy conservation Electric power Hidden categories: CS1 maint: numeric names: authors list Articles with short description Short description is different from Wikidata Citation overkill Articles tagged with the inline citation overkill template from February 2024 Wikipedia articles with style issues from June 2020 All articles with style issues This page was last edited on 9 December 2024, at 06:46 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Power usage effectiveness 7 languages Add topic

