Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 Overview 3 Euler's transform 4 Conformal mappings 5 Non-linear sequence transformations Toggle Non-linear sequence transformations subsection 5.1 Aitken method 6 See also 7 References 8 External links Toggle the table of contents Series acceleration 5 languages Deutsch Français 日本語 Simple English Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Mathematical technique for improving convergence In mathematics , a series acceleration method is any one of a collection of sequence transformations for improving the rate of convergence of a series . Techniques for series acceleration are often applied in numerical analysis , where they are used to improve the speed of numerical integration . Series acceleration techniques may also be used, for example, to obtain a variety of identities on special functions . Thus, the Euler transform applied to the hypergeometric series gives some of the classic, well-known hypergeometric series identities.

Definition [ edit ] Given an infinite series with a sequence of partial sums ( S n ) n ∈ ∈ N {\displaystyle (S_{n})_{n\in \mathbb {N} }} having a limit lim n → → ∞ ∞ S n = S , {\displaystyle \lim _{n\to \infty }S_{n}=S,} an accelerated series is an infinite series with a second sequence of partial sums ( S n ′ ) n ∈ ∈ N {\displaystyle (S'_{n})_{n\in \mathbb {N} }} which asymptotically converges faster to S {\displaystyle S} than the original sequence of partial sums would: lim n → → ∞ ∞ S n ′ − − S S n − − S = 0.

{\displaystyle \lim _{n\to \infty }{\frac {S'_{n}-S}{S_{n}-S}}=0.} A series acceleration method is a sequence transformation that transforms the convergent sequences of partial sums of a series into more quickly convergent sequences of partial sums of an accelerated series with the same limit. If a series acceleration method is applied to a divergent series then the proper limit of the series is undefined, but the sequence transformation can still act usefully as an extrapolation method to an antilimit of the series.

The mappings from the original to the transformed series may be linear sequence transformations or non-linear sequence transformations. In general, the non-linear sequence transformations tend to be more powerful.

Overview [ edit ] Two classical techniques for series acceleration are Euler's transformation of series [ 1 ] and Kummer's transformation of series .

[ 2 ] A variety of much more rapidly convergent and special-case tools have been developed in the 20th century, including Richardson extrapolation , introduced by Lewis Fry Richardson in the early 20th century but also known and used by Katahiro Takebe in 1722; the Aitken delta-squared process , introduced by Alexander Aitken in 1926 but also known and used by Takakazu Seki in the 18th century; the epsilon method given by Peter Wynn in 1956; the Levin u-transform; and the Wilf-Zeilberger-Ekhad method or WZ method .

For alternating series , several powerful techniques, offering convergence rates  from 5.828 − − n {\displaystyle 5.828^{-n}} all the way to 17.93 − − n {\displaystyle 17.93^{-n}} for a summation of n {\displaystyle n} terms, are described by Cohen et al .

[ 3 ] Euler's transform [ edit ] A basic example of a linear sequence transformation , offering improved convergence, is Euler's transform. It is intended to be applied to an alternating series; it is given by ∑ ∑ n = 0 ∞ ∞ ( − − 1 ) n a n = ∑ ∑ n = 0 ∞ ∞ ( − − 1 ) n ( Δ Δ n a ) 0 2 n + 1 {\displaystyle \sum _{n=0}^{\infty }(-1)^{n}a_{n}=\sum _{n=0}^{\infty }(-1)^{n}{\frac {(\Delta ^{n}a)_{0}}{2^{n+1}}}} where Δ Δ {\displaystyle \Delta } is the forward difference operator , for which one has the formula ( Δ Δ n a ) 0 = ∑ ∑ k = 0 n ( − − 1 ) k ( n k ) a n − − k .

{\displaystyle (\Delta ^{n}a)_{0}=\sum _{k=0}^{n}(-1)^{k}{n \choose k}a_{n-k}.} If the original series, on the left hand side, is only slowly converging, the forward differences will tend to become small quite rapidly; the additional power of two further improves the rate at which the right hand side converges.

A particularly efficient numerical implementation of the Euler transform is the van Wijngaarden transformation .

[ 4 ] Conformal mappings [ edit ] A series S = ∑ ∑ n = 0 ∞ ∞ a n {\displaystyle S=\sum _{n=0}^{\infty }a_{n}} can be written as f ( 1 ) {\displaystyle f(1)} , where the function f is defined as f ( z ) = ∑ ∑ n = 0 ∞ ∞ a n z n .

{\displaystyle f(z)=\sum _{n=0}^{\infty }a_{n}z^{n}.} The function f ( z ) {\displaystyle f(z)} can have singularities in the complex plane ( branch point singularities, poles or essential singularities ), which limit the radius of convergence of the series. If the point z = 1 {\displaystyle z=1} is close to or on the boundary of the disk of convergence, the series for S {\displaystyle S} will converge very slowly. One can then improve the convergence of the series by means of a conformal mapping that moves the singularities such that the point that is mapped to z = 1 {\displaystyle z=1} ends up deeper in the new disk of convergence.

The conformal transform z = Φ Φ ( w ) {\displaystyle z=\Phi (w)} needs to be chosen such that Φ Φ ( 0 ) = 0 {\displaystyle \Phi (0)=0} , and one usually chooses a function that has a finite derivative at w = 0. One can assume that Φ Φ ( 1 ) = 1 {\displaystyle \Phi (1)=1} without loss of generality, as one can always rescale w to redefine Φ Φ {\displaystyle \Phi } . We then consider the function g ( w ) = f ( Φ Φ ( w ) ) .

{\displaystyle g(w)=f(\Phi (w)).} Since Φ Φ ( 1 ) = 1 {\displaystyle \Phi (1)=1} , we have f ( 1 ) = g ( 1 ) {\displaystyle f(1)=g(1)} . We can obtain the series expansion of g ( w ) {\displaystyle g(w)} by putting z = Φ Φ ( w ) {\displaystyle z=\Phi (w)} in the series expansion of f ( z ) {\displaystyle f(z)} because Φ Φ ( 0 ) = 0 {\displaystyle \Phi (0)=0} ; the first n {\displaystyle n} terms of the series expansion for f ( z ) {\displaystyle f(z)} will yield the first n {\displaystyle n} terms of the series expansion for g ( w ) {\displaystyle g(w)} if Φ Φ ′ ( 0 ) ≠ ≠ 0 {\displaystyle \Phi '(0)\neq 0} . Putting w = 1 {\displaystyle w=1} in that series expansion will thus yield a series such that if it converges, it will converge to the same value as the original series.

Non-linear sequence transformations [ edit ] Examples of such nonlinear sequence transformations are Padé approximants , the Shanks transformation , and Levin-type sequence transformations .

Especially nonlinear sequence transformations often provide powerful numerical methods for the summation of divergent series or asymptotic series that arise for instance in perturbation theory , and therefore may be used as effective extrapolation methods .

Aitken method [ edit ] Main article: Aitken's delta-squared process A simple nonlinear sequence transformation is the Aitken extrapolation or delta-squared method, A : S → → S ′ = A ( S ) = ( s n ′ ) n ∈ ∈ N {\displaystyle \mathbb {A} :S\to S'=\mathbb {A} (S)={(s'_{n})}_{n\in \mathbb {N} }} defined by s n ′ = s n + 2 − − ( s n + 2 − − s n + 1 ) 2 s n + 2 − − 2 s n + 1 + s n .

{\displaystyle s'_{n}=s_{n+2}-{\frac {(s_{n+2}-s_{n+1})^{2}}{s_{n+2}-2s_{n+1}+s_{n}}}.} This transformation is commonly used to improve the rate of convergence of a slowly converging sequence; heuristically, it eliminates the largest part of the absolute error .

See also [ edit ] Shanks transformation Minimum polynomial extrapolation Van Wijngaarden transformation References [ edit ] ^ Abramowitz, Milton ; Stegun, Irene Ann , eds. (1983) [June 1964].

"Chapter 3, eqn 3.6.27" .

Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables . Applied Mathematics Series. Vol. 55 (Ninth reprint with additional corrections of tenth original printing with corrections (December 1972); first ed.). Washington D.C.; New York: United States Department of Commerce, National Bureau of Standards; Dover Publications. p. 16.

ISBN 978-0-486-61272-0 .

LCCN 64-60036 .

MR 0167642 .

LCCN 65-12253 .

^ Abramowitz, Milton ; Stegun, Irene Ann , eds. (1983) [June 1964].

"Chapter 3, eqn 3.6.26" .

Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables . Applied Mathematics Series. Vol. 55 (Ninth reprint with additional corrections of tenth original printing with corrections (December 1972); first ed.). Washington D.C.; New York: United States Department of Commerce, National Bureau of Standards; Dover Publications. p. 16.

ISBN 978-0-486-61272-0 .

LCCN 64-60036 .

MR 0167642 .

LCCN 65-12253 .

^ Henri Cohen , Fernando Rodriguez Villegas, and Don Zagier ,
" Convergence Acceleration of Alternating Series ", Experimental Mathematics , 9 :1 (2000) page 3.

^ William H. Press, et al.

, Numerical Recipes in C , (1987) Cambridge University Press, ISBN 0-521-43108-5 (See section 5.1).

C. Brezinski and M. Redivo Zaglia , Extrapolation Methods. Theory and Practice , North-Holland, 1991.

G. A. Baker Jr. and P. Graves-Morris, Padé  Approximants , Cambridge U.P., 1996.

Weisstein, Eric W.

"Convergence Improvement" .

MathWorld .

Herbert H. H. Homeier: Scalar Levin-Type Sequence Transformations , Journal of Computational and Applied Mathematics, vol. 122, no. 1–2, p 81 (2000).

Homeier, H. H. H. (2000). "Scalar Levin-type sequence transformations".

Journal of Computational and Applied Mathematics .

122 ( 1– 2): 81– 147.

arXiv : math/0005209 .

Bibcode : 2000JCoAM.122...81H .

doi : 10.1016/S0377-0427(00)00359-9 .

, arXiv : math/0005209 .

Brezinski Claude and Redivo-Zaglia Michela : "The genesis and early developments of Aitken's process, Shanks transformation, the ϵ ϵ {\displaystyle \epsilon } -algorithm, and related fixed point methods", Numerical Algorithms, Vol.80, No.1, (2019), pp.11-133.

Delahaye J. P. : "Sequence Transformations", Springer-Verlag, Berlin, ISBN 978-3540152835 (1988).

Sidi Avram : "Vector Extrapolation Methods with Applications", SIAM, ISBN 978-1-61197-495-9 (2017).

Brezinski Claude, Redivo-Zaglia Michela and Saad Yousef : "Shanks Sequence Transformations and Anderson Acceleration", SIAM Review, Vol.60, No.3 (2018), pp.646–669. doi:10.1137/17M1120725 .

Brezinski Claude : "Reminiscences of Peter Wynn ", Numerical Algorithms, Vol.80(2019), pp.5-10.

Brezinski Claude and Redivo-Zaglia Michela : "Extrapolation and Rational Approximation", Springer, ISBN 978-3-030-58417-7 (2020).

External links [ edit ] Convergence acceleration of series GNU Scientific Library, Series Acceleration Digital Library of Mathematical Functions Retrieved from " https://en.wikipedia.org/w/index.php?title=Series_acceleration&oldid=1294369779 " Categories : Numerical analysis Asymptotic analysis Summability methods Perturbation theory Series acceleration methods Hidden categories: Articles with short description Short description is different from Wikidata This page was last edited on 7 June 2025, at 09:48 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Series acceleration 5 languages Add topic

