Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Generalization to metric spaces 2 Energy statistics Toggle Energy statistics subsection 2.1 Testing for equal distributions 2.2 Goodness-of-fit 3 Applications 4 References Toggle the table of contents Energy distance 1 language Español Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia This article relies excessively on references to primary sources .

Please improve this article by adding secondary or tertiary sources .

Find sources: "Energy distance" – news · newspapers · books · scholar · JSTOR ( January 2011 ) ( Learn how and when to remove this message ) Energy distance is a statistical distance between probability distributions . If X and Y are independent random vectors in R d with cumulative distribution functions (cdf) F and G respectively, then the energy distance between the distributions F and G is defined to be the square root of D 2 ( F , G ) = 2 E ⁡ ⁡ ‖ ‖ X − − Y ‖ ‖ − − E ⁡ ⁡ ‖ ‖ X − − X ′ ‖ ‖ − − E ⁡ ⁡ ‖ ‖ Y − − Y ′ ‖ ‖ ≥ ≥ 0 , {\displaystyle D^{2}(F,G)=2\operatorname {E} \|X-Y\|-\operatorname {E} \|X-X'\|-\operatorname {E} \|Y-Y'\|\geq 0,} where (X, X', Y, Y') are independent, the cdf of X and X' is F, the cdf of Y and Y' is G, E {\displaystyle \operatorname {E} } is the expected value , and || . || denotes the length of a vector. Energy distance satisfies all axioms of a metric thus energy distance characterizes  the equality of distributions: D(F,G) = 0 if and only if F = G.
Energy distance for statistical applications was introduced in 1985 by Gábor J. Székely , who proved that for real-valued random variables D 2 ( F , G ) {\displaystyle D^{2}(F,G)} is exactly twice Harald Cramér 's distance: [ 1 ] ∫ ∫ − − ∞ ∞ ∞ ∞ ( F ( x ) − − G ( x ) ) 2 d x .

{\displaystyle \int _{-\infty }^{\infty }(F(x)-G(x))^{2}\,dx.} For a simple proof of this equivalence, see Székely (2002).

[ 2 ] In higher dimensions, however, the two distances are different because the energy distance is rotation invariant while Cramér's distance is not. (Notice that Cramér's distance is not the same as the distribution-free Cramér–von Mises criterion .) Generalization to metric spaces [ edit ] One can generalize the notion of energy distance to probability distributions on metric spaces. Let ( M , d ) {\displaystyle (M,d)} be a metric space with its Borel sigma algebra B ( M ) {\displaystyle {\mathcal {B}}(M)} . Let P ( M ) {\displaystyle {\mathcal {P}}(M)} denote the collection of all probability measures on the measurable space ( M , B ( M ) ) {\displaystyle (M,{\mathcal {B}}(M))} . If μ and ν are probability measures in P ( M ) {\displaystyle {\mathcal {P}}(M)} , then the energy-distance D {\displaystyle D} of μ and ν can be defined as the square root of D 2 ( μ μ , ν ν ) = 2 E ⁡ ⁡ [ d ( X , Y ) ] − − E ⁡ ⁡ [ d ( X , X ′ ) ] − − E ⁡ ⁡ [ d ( Y , Y ′ ) ] .

{\displaystyle D^{2}(\mu ,\nu )=2\operatorname {E} [d(X,Y)]-\operatorname {E} [d(X,X')]-\operatorname {E} [d(Y,Y')].} This is not necessarily non-negative, however. If ( M , d ) {\displaystyle (M,d)} is a strongly negative definite kernel, then D {\displaystyle D} is a metric , and conversely.

[ 3 ] This condition is expressed by saying that ( M , d ) {\displaystyle (M,d)} has negative type. Negative type is not sufficient for D {\displaystyle D} to be a metric; the latter condition is expressed by saying that ( M , d ) {\displaystyle (M,d)} has strong negative type. In this situation, the energy distance is zero if and only if X and Y are identically distributed. An example of a metric of negative type but not of strong negative type is the plane with the taxicab metric . All Euclidean spaces and even separable Hilbert spaces have strong negative type.

[ 4 ] In the literature on kernel methods for machine learning , these generalized notions of energy distance are studied under the name of maximum mean discrepancy. Equivalence of distance based and kernel methods for hypothesis testing is covered by several authors.

[ 5 ] [ 6 ] Energy statistics [ edit ] A related statistical concept, the notion of E-statistic or energy-statistic [ 7 ] was introduced by Gábor J. Székely in the 1980s when he was giving colloquium lectures in Budapest, Hungary and at MIT, Yale, and Columbia. This concept is based on the notion of Newton’s potential energy .

[ 8 ] The idea is to consider statistical observations as heavenly bodies governed by a statistical potential energy which is zero only when an underlying statistical null hypothesis is true.  Energy statistics are functions of distances between statistical observations.

Energy distance and E-statistic were considered as N -distances and N-statistic in Zinger A.A., Kakosyan A.V., Klebanov L.B. Characterization of distributions by means of mean values of some statistics in connection with some probability metrics, Stability Problems for Stochastic Models. Moscow, VNIISI, 1989,47-55. (in Russian), English Translation: A characterization of distributions by mean values of statistics and certain probabilistic metrics A. A. Zinger, A. V. Kakosyan, L. B. Klebanov in Journal of Soviet Mathematics (1992). In the same paper there was given a definition of strongly negative definite kernel, and provided a generalization on metric spaces, discussed above. The book [ 3 ] gives these results and their applications to statistical testing as well. The book contains also some applications to recovering the measure from its potential.

Testing for equal distributions [ edit ] Consider the null hypothesis that two random variables, X and Y , have the same probability distributions: μ μ = ν ν {\displaystyle \mu =\nu } . For statistical samples from X and Y : x 1 , … … , x n {\displaystyle x_{1},\dots ,x_{n}} and y 1 , … … , y m {\displaystyle y_{1},\dots ,y_{m}} , the following arithmetic averages of distances are computed between the X and the Y samples: A := 1 n m ∑ ∑ i = 1 n ∑ ∑ j = 1 m ‖ ‖ x i − − y j ‖ ‖ , B := 1 n 2 ∑ ∑ i = 1 n ∑ ∑ j = 1 n ‖ ‖ x i − − x j ‖ ‖ , C := 1 m 2 ∑ ∑ i = 1 m ∑ ∑ j = 1 m ‖ ‖ y i − − y j ‖ ‖ {\displaystyle A:={\frac {1}{nm}}\sum _{i=1}^{n}\sum _{j=1}^{m}\|x_{i}-y_{j}\|,B:={\frac {1}{n^{2}}}\sum _{i=1}^{n}\sum _{j=1}^{n}\|x_{i}-x_{j}\|,C:={\frac {1}{m^{2}}}\sum _{i=1}^{m}\sum _{j=1}^{m}\|y_{i}-y_{j}\|} .

The E-statistic of the underlying null hypothesis is defined as follows: E n , m ( X , Y ) := 2 A − − B − − C {\displaystyle E_{n,m}(X,Y):=2A-B-C} One can prove [ 8 ] [ 9 ] that E n , m ( X , Y ) ≥ ≥ 0 {\displaystyle E_{n,m}(X,Y)\geq 0} and that the corresponding population value is zero if and only if X and Y have the same distribution ( μ μ = ν ν {\displaystyle \mu =\nu } ).  Under this null hypothesis the test statistic T = n m n + m E n , m ( X , Y ) {\displaystyle T={\frac {nm}{n+m}}E_{n,m}(X,Y)} converges in distribution to a quadratic form of independent standard normal random variables . Under the alternative hypothesis T tends to infinity. This makes it possible to construct a consistent statistical test , the energy test for equal distributions.

[ 10 ] The E-coefficient of inhomogeneity can also be introduced. This is always between 0 and 1 and is defined as H = D 2 ( F X , F Y ) 2 E ⁡ ⁡ ‖ ‖ X − − Y ‖ ‖ = 2 E ⁡ ⁡ ‖ ‖ X − − Y ‖ ‖ − − E ⁡ ⁡ ‖ ‖ X − − X ′ ‖ ‖ − − E ⁡ ⁡ ‖ ‖ Y − − Y ′ ‖ ‖ 2 E ⁡ ⁡ ‖ ‖ X − − Y ‖ ‖ , {\displaystyle H={\frac {D^{2}(F_{X},F_{Y})}{2\operatorname {\operatorname {E} } \|X-Y\|}}={\frac {2\operatorname {E} \|X-Y\|-\operatorname {E} \|X-X'\|-\operatorname {E} \|Y-Y'\|}{2\operatorname {\operatorname {E} } \|X-Y\|}},} where E {\displaystyle \operatorname {E} } denotes the expected value .

H = 0 exactly when X and Y have the same distribution.

Goodness-of-fit [ edit ] A multivariate goodness-of-fit measure is defined for distributions in arbitrary dimension (not restricted by sample size). The energy goodness-of-fit statistic is Q n = n ( 2 n ∑ ∑ i = 1 n E ⁡ ⁡ ‖ ‖ x i − − X ‖ ‖ α α − − E ⁡ ⁡ ‖ ‖ X − − X ′ ‖ ‖ α α − − 1 n 2 ∑ ∑ i = 1 n ∑ ∑ j = 1 n ‖ ‖ x i − − x j ‖ ‖ α α ) , {\displaystyle Q_{n}=n\left({\frac {2}{n}}\sum _{i=1}^{n}\operatorname {E} \|x_{i}-X\|^{\alpha }-\operatorname {E} \|X-X'\|^{\alpha }-{\frac {1}{n^{2}}}\sum _{i=1}^{n}\sum _{j=1}^{n}\|x_{i}-x_{j}\|^{\alpha }\right),} where X and X' are independent and identically distributed according to the hypothesized distribution, and α α ∈ ∈ ( 0 , 2 ) {\displaystyle \alpha \in (0,2)} . The only required condition is that X has finite α α {\displaystyle \alpha } moment under the null hypothesis. Under the null hypothesis E ⁡ ⁡ Q n = E ⁡ ⁡ ‖ ‖ X − − X ′ ‖ ‖ α α {\displaystyle \operatorname {E} Q_{n}=\operatorname {E} \|X-X'\|^{\alpha }} , and the asymptotic distribution of Q n is a quadratic form of centered Gaussian random variables. Under an alternative hypothesis, Q n tends to infinity stochastically, and thus determines a statistically consistent test. For most applications the exponent 1 (Euclidean distance) can be applied. The important special case of testing multivariate normality [ 9 ] is implemented in the energy package for R. Tests are also developed for heavy tailed distributions such as Pareto ( power law ), or stable distributions by application of exponents in (0,1).

Applications [ edit ] Applications include: Hierarchical clustering (a generalization of Ward's method) [ 11 ] [ 12 ] Testing multivariate normality [ 9 ] Testing the multi-sample hypothesis of equal distributions, [ 13 ] [ 14 ] [ 15 ] Change point detection [ 16 ] Multivariate independence: distance correlation , [ 17 ] Brownian covariance .

[ 18 ] Scoring rules : Gneiting and Raftery [ 19 ] apply energy distance to develop a new and very general type of proper scoring rule for probabilistic predictions, the energy score.

Robust statistics [ 20 ] Scenario reduction [ 21 ] Gene selection [ 22 ] Microarray data analysis [ 23 ] [ 24 ] [ 25 ] Material structure analysis [ 26 ] Morphometric and chemometric data [ 27 ] Applications of energy statistics are implemented in the open source energy package [ 28 ] for R .

References [ edit ] ^ Cramér, H. (1928) On the composition of elementary errors, Skandinavisk Aktuarietidskrift, 11, 141–180.

^ E-Statistics: The energy of statistical samples (2002) PDF Archived 2016-04-20 at the Wayback Machine ^ a b Klebanov, L. B. (2005) N-distances and their Applications, Karolinum Press ,
Charles University, Prague.

^ Lyons, R. (2013). "Distance Covariance in Metric Spaces".

The Annals of Probability .

41 (5): 3284– 3305.

arXiv : 1106.5758 .

doi : 10.1214/12-aop803 .

S2CID 73677891 .

^ Sejdinovic, D.; Sriperumbudur, B.; Gretton, A. & Fukumizu, K. (2013). "Equivalence of distance-based and RKHS-based statistics in hypothesis testing".

The Annals of Statistics .

41 (5): 2263– 2291.

arXiv : 1207.6076 .

doi : 10.1214/13-aos1140 .

S2CID 8308769 .

^ Shen, Cencheng; Vogelstein, Joshua T. (2021). "The exact equivalence of distance and kernel methods in hypothesis testing".

AStA Advances in Statistical Analysis .

105 (3): 385– 403.

arXiv : 1806.05514 .

doi : 10.1007/s10182-020-00378-1 .

S2CID 49210956 .

^ G. J. Szekely and M. L. Rizzo (2013). Energy statistics: statistics based on distances. Journal of Statistical Planning and Inference Volume 143, Issue 8, August 2013, pp. 1249-1272.

[1] ^ a b Székely, G.J. (2002) E-statistics: The Energy of Statistical Samples, Technical Report BGSU No 02-16.

^ a b c Székely, G. J.; Rizzo, M. L. (2005).

"A new test for multivariate normality" .

Journal of Multivariate Analysis .

93 (1): 58– 80.

doi : 10.1016/j.jmva.2003.12.002 .

Reprint Archived 2011-08-05 at the Wayback Machine ^ G. J. Szekely and M. L. Rizzo (2004). Testing for Equal Distributions in High Dimension, InterStat , Nov. (5).

Reprint Archived 2011-08-05 at the Wayback Machine .

^ Szekely, Gabor J.; Rizzo, Maria L. (2005). "Hierarchical Clustering via Joint Between-Within Distances: Extending Ward's Minimum Variance Method".

Journal of Classification .

22 (2): 151– 183.

doi : 10.1007/s00357-005-0012-9 .

^ Varin, T., Bureau, R., Mueller, C. and Willett, P. (2009).

"Clustering files of chemical structures using the Szekely-Rizzo generalization of Ward's method" (PDF) .

Journal of Molecular Graphics and Modelling .

28 (2): 187– 195.

Bibcode : 2009JMGM...28..187V .

doi : 10.1016/j.jmgm.2009.06.006 .

PMID 19640752 .

{{ cite journal }} :  CS1 maint: multiple names: authors list ( link ) "eprint" .

^ Rizzo, Maria L.; Székely, Gábor J. (2010). "DISCO analysis: A nonparametric extension of analysis of variance".

The Annals of Applied Statistics .

4 (2).

arXiv : 1011.2288 .

doi : 10.1214/09-AOAS245 .

^ Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, Nov. (5).

Reprint Archived 2011-08-05 at the Wayback Machine .

^ Ledlie, J.; Pietzuch, P.; Seltzer, M. (2006). "Stable and Accurate Network Coordinates".

26th IEEE International Conference on Distributed Computing Systems (ICDCS'06) . p. 74.

doi : 10.1109/ICDCS.2006.79 .

ISBN 0-7695-2540-7 .

^ Albert Y. Kim; Caren Marzban; Donald B. Percival; Werner Stuetzle (2009). "Using labeled data to evaluate change detectors in a multivariate streaming environment".

Signal Processing .

89 (12): 2529– 2536.

Bibcode : 2009SigPr..89.2529K .

CiteSeerX 10.1.1.143.6576 .

doi : 10.1016/j.sigpro.2009.04.011 .

ISSN 0165-1684 .

[2] Preprint:TR534 .

^ Székely, Gábor J.; Rizzo, Maria L.; Bakirov, Nail K. (2007). "Measuring and testing dependence by correlation of distances".

The Annals of Statistics .

35 (6).

arXiv : 0803.4101 .

doi : 10.1214/009053607000000505 .

^ Székely, Gábor J.; Rizzo, Maria L. (2009).

"Brownian distance covariance" .

The Annals of Applied Statistics .

3 (4): 1266– 1269.

arXiv : 1010.0297 .

doi : 10.1214/09-AOAS312 .

PMC 2889501 .

PMID 20574547 .

^ T. Gneiting; A. E. Raftery (2007). "Strictly Proper Scoring Rules, Prediction, and Estimation".

Journal of the American Statistical Association .

102 (477): 359– 378.

doi : 10.1198/016214506000001437 .

S2CID 1878582 .

Reprint ^ Klebanov, Lev B. (2002). "A Class of Probability Metrics and its Statistical Applications".

Statistical Data Analysis Based on the L1-Norm and Related Methods . pp.

241– 252.

doi : 10.1007/978-3-0348-8201-9_20 .

ISBN 978-3-0348-9472-2 .

^ F. Ziel (2021). "The energy distance for ensemble and scenario reduction".

Philosophical Transactions of the Royal Society A .

379 (2202): 20190431.

arXiv : 2005.14670 .

Bibcode : 2021RSPTA.37990431Z .

doi : 10.1098/rsta.2019.0431 .

ISSN 1364-503X .

PMID 34092100 .

S2CID 219124032 .

^ Hu, Rui; Qiu, Xing; Glazko, Galina; Klebanov, Lev; Yakovlev, Andrei (2009).

"Detecting intergene correlation changes in microarray analysis: A new approach to gene selection" .

BMC Bioinformatics .

10 .

doi : 10.1186/1471-2105-10-20 .

PMC 2657217 .

PMID 19146700 .

^ Xiao, Yuanhui; Frisina, Robert; Gordon, Alexander; Klebanov, Lev; Yakovlev, Andrei (2004).

"Multivariate search for differentially expressed gene combinations" .

BMC Bioinformatics .

5 .

doi : 10.1186/1471-2105-5-164 .

PMC 529250 .

PMID 15507138 .

^ Almudevar, Anthony; Klebanov, Lev B.; Qiu, Xing; Salzman, Peter; Yakovlev, Andrei Y. (2006).

"Utility of correlation measures in analysis of gene expression" .

NeuroRX .

3 (3): 384– 395.

doi : 10.1016/j.nurx.2006.05.037 .

PMC 3593386 .

PMID 16815221 .

^ Klebanov, L.; Gordon, A.; Xiao, Y.; Land, H.; Yakovlev, A. (2006). "A permutation test motivated by microarray data analysis".

Computational Statistics & Data Analysis .

50 (12): 3619– 3628.

doi : 10.1016/j.csda.2005.08.005 .

^ Beneš, Viktor; Lechnerová, Radka; Klebanov, Lev; Slámová, Margarita; Sláma, Peter (2009). "Statistical comparison of the geometry of second-phase particles".

Materials Characterization .

60 (10): 1076– 1081.

doi : 10.1016/j.matchar.2009.02.016 .

^ Vaiciukynas, Evaldas; Verikas, Antanas; Gelzinis, Adas; Bacauskiene, Marija; Olenina, Irina (2015). "Exploiting statistical energy test for comparison of multiple groups in morphometric and chemometric data".

Chemometrics and Intelligent Laboratory Systems .

146 : 10– 23.

doi : 10.1016/j.chemolab.2015.04.018 .

^ "energy: R package version 1.6.2" . Retrieved 30 January 2015 .

Retrieved from " https://en.wikipedia.org/w/index.php?title=Energy_distance&oldid=1288880316 " Categories : Statistical distance Statistical hypothesis testing Theory of probability distributions Hidden categories: Webarchive template wayback links CS1 maint: multiple names: authors list Articles lacking reliable references from January 2011 All articles lacking reliable references This page was last edited on 5 May 2025, at 05:05 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Energy distance 1 language Add topic

