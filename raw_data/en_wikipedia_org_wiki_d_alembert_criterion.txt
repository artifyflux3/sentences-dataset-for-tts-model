Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 The test 2 Examples Toggle Examples subsection 2.1 Convergent because L < 1 2.2 Divergent because L > 1 2.3 Inconclusive because L = 1 3 Proof 4 Extensions for L = 1 Toggle Extensions for L = 1 subsection 4.1 De Morgan hierarchy 4.1.1 1. d'Alembert's ratio test 4.1.2 2. Raabe's test 4.1.2.1 Proof of Raabe's test 4.1.3 3. Bertrand's test 4.1.4 4. Extended Bertrand's test 4.1.5 5. Gauss's test 4.1.6 6. Kummer's test 4.1.6.1 Special cases 4.1.6.2 Proof of Kummer's test 4.2 Tong's modification of Kummer's test 4.3 Frink's ratio test 4.4 Ali's second ratio test 4.5 Ali's m th ratio test 4.6 Ali--Deutsche Cohen φ-ratio test 5 See also 6 Footnotes 7 References Toggle the table of contents Ratio test 29 languages العربية Bosanski Català Čeština Dansk Deutsch Español Euskara فارسی Français 한국어 Հայերեն हिन्दी Italiano Lombard Magyar Nederlands 日本語 Polski Português Română Русский Slovenčina Slovenščina Suomi Svenska Türkçe Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from D'Alembert criterion ) Criterion for the convergence of a series Part of a series of articles about Calculus ∫ ∫ a b f ′ ( t ) d t = f ( b ) − − f ( a ) {\displaystyle \int _{a}^{b}f'(t)\,dt=f(b)-f(a)} Fundamental theorem Limits Continuity Rolle's theorem Mean value theorem Inverse function theorem Differential Definitions Derivative ( generalizations ) Differential infinitesimal of a function total Concepts Differentiation notation Second derivative Implicit differentiation Logarithmic differentiation Related rates Taylor's theorem Rules and identities Sum Product Chain Power Quotient L'Hôpital's rule Inverse General Leibniz Faà di Bruno's formula Reynolds Integral Lists of integrals Integral transform Leibniz integral rule Definitions Antiderivative Integral ( improper ) Riemann integral Lebesgue integration Contour integration Integral of inverse functions Integration by Parts Discs Cylindrical shells Substitution ( trigonometric , tangent half-angle , Euler ) Euler's formula Partial fractions ( Heaviside's method ) Changing order Reduction formulae Differentiating under the integral sign Risch algorithm Series Geometric ( arithmetico-geometric ) Harmonic Alternating Power Binomial Taylor Convergence tests Summand limit (term test) Ratio Root Integral Direct comparison Limit comparison Alternating series Cauchy condensation Dirichlet Abel Vector Gradient Divergence Curl Laplacian Directional derivative Identities Theorems Gradient Green's Stokes' Divergence Generalized Stokes Helmholtz decomposition Multivariable Formalisms Matrix Tensor Exterior Geometric Definitions Partial derivative Multiple integral Line integral Surface integral Volume integral Jacobian Hessian Advanced Calculus on Euclidean space Generalized functions Limit of distributions Specialized Fractional Malliavin Stochastic Variations Miscellanea Precalculus History Glossary List of topics Integration Bee Mathematical analysis Nonstandard analysis v t e In mathematics , the ratio test is a test (or "criterion") for the convergence of a series ∑ ∑ n = 1 ∞ ∞ a n , {\displaystyle \sum _{n=1}^{\infty }a_{n},} where each term is a real or complex number and a n is nonzero when n is large. The test was first published by Jean le Rond d'Alembert and is sometimes known as d'Alembert's ratio test or as the Cauchy ratio test .

[ 1 ] The test [ edit ] Decision diagram for the ratio test The usual form of the test makes use of the limit L = lim n → → ∞ ∞ | a n + 1 a n | .

{\displaystyle L=\lim _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|.} 1 The ratio test states that: if L < 1 then the series converges absolutely ; if L > 1 then the series diverges ; if L = 1 or the limit fails to exist, then the test is inconclusive, because there exist both convergent and divergent series that satisfy this case.

It is possible to make the ratio test applicable to certain cases where the limit L fails to exist, if limit superior and limit inferior are used. The test criteria can also be refined so that the test is sometimes conclusive even when L = 1. More specifically, let R = lim sup | a n + 1 a n | {\displaystyle R=\lim \sup \left|{\frac {a_{n+1}}{a_{n}}}\right|} r = lim inf | a n + 1 a n | {\displaystyle r=\lim \inf \left|{\frac {a_{n+1}}{a_{n}}}\right|} .

Then the ratio test states that: [ 2 ] [ 3 ] if R < 1, the series converges absolutely; if r > 1, the series diverges; or equivalently if | a n + 1 a n | > 1 {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|>1} for all large n (regardless of the value of r ), the series also diverges; this is because | a n | {\displaystyle |a_{n}|} is nonzero and increasing and hence a n does not approach zero; the test is otherwise inconclusive.

If the limit L in ( 1 ) exists, we must have L = R = r . So the original ratio test is a weaker version of the refined one.

Examples [ edit ] Convergent because L < 1 [ edit ] Consider the series ∑ ∑ n = 1 ∞ ∞ n e n {\displaystyle \sum _{n=1}^{\infty }{\frac {n}{e^{n}}}} Applying the ratio test, one computes the limit L = lim n → → ∞ ∞ | a n + 1 a n | = lim n → → ∞ ∞ | n + 1 e n + 1 n e n | = 1 e < 1.

{\displaystyle L=\lim _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|=\lim _{n\to \infty }\left|{\frac {\frac {n+1}{e^{n+1}}}{\frac {n}{e^{n}}}}\right|={\frac {1}{e}}<1.} Since this limit is less than 1, the series converges.

Divergent because L > 1 [ edit ] Consider the series ∑ ∑ n = 1 ∞ ∞ e n n .

{\displaystyle \sum _{n=1}^{\infty }{\frac {e^{n}}{n}}.} Putting this into the ratio test: L = lim n → → ∞ ∞ | a n + 1 a n | = lim n → → ∞ ∞ | e n + 1 n + 1 e n n | = e > 1.

{\displaystyle L=\lim _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|=\lim _{n\to \infty }\left|{\frac {\frac {e^{n+1}}{n+1}}{\frac {e^{n}}{n}}}\right|=e>1.} Thus the series diverges.

Inconclusive because L = 1 [ edit ] Consider the three series ∑ ∑ n = 1 ∞ ∞ 1 , {\displaystyle \sum _{n=1}^{\infty }1,} ∑ ∑ n = 1 ∞ ∞ 1 n 2 , {\displaystyle \sum _{n=1}^{\infty }{\frac {1}{n^{2}}},} ∑ ∑ n = 1 ∞ ∞ ( − − 1 ) n + 1 n .

{\displaystyle \sum _{n=1}^{\infty }{\frac {(-1)^{n+1}}{n}}.} The first series ( 1 + 1 + 1 + 1 + ⋯ ) diverges, the second (the one central to the Basel problem ) converges absolutely and the third (the alternating harmonic series ) converges conditionally. However, the term-by-term magnitude ratios | a n + 1 a n | {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|} of the three series are 1 , {\displaystyle 1,} n 2 ( n + 1 ) 2 {\displaystyle {\frac {n^{2}}{(n+1)^{2}}}} and n n + 1 {\displaystyle {\frac {n}{n+1}}} . So, in all three, the limit lim n → → ∞ ∞ | a n + 1 a n | {\displaystyle \lim _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|} is equal to 1. This illustrates that when L = 1, the series may converge or diverge: the ratio test is inconclusive.  In such cases, more refined tests are required to determine convergence or divergence.

Proof [ edit ] In this example, the ratio of adjacent terms in the blue sequence converges to L=1/2. We choose r = (L+1)/2 = 3/4. Then the blue sequence is dominated by the red sequence r k for all n ≥ 2. The red sequence converges, so the blue sequence does as well.

Below is a proof of the validity of the generalized ratio test.

Suppose that r = lim inf n → → ∞ ∞ | a n + 1 a n | > 1 {\displaystyle r=\liminf _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|>1} . We also suppose that ( a n ) {\displaystyle (a_{n})} has infinite non-zero members, otherwise the series is just a finite sum hence it converges. Then there exists some ℓ ℓ ∈ ∈ ( 1 ; r ) {\displaystyle \ell \in (1;r)} such that there exists a natural number n 0 ≥ ≥ 2 {\displaystyle n_{0}\geq 2} satisfying a n 0 ≠ ≠ 0 {\displaystyle a_{n_{0}}\neq 0} and | a n + 1 a n | > ℓ ℓ {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|>\ell } for all n ≥ ≥ n 0 {\displaystyle n\geq n_{0}} , because if no such ℓ ℓ {\displaystyle \ell } exists then there exists arbitrarily large n {\displaystyle n} satisfying | a n + 1 a n | < ℓ ℓ {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|<\ell } for every ℓ ℓ ∈ ∈ ( 1 ; r ) {\displaystyle \ell \in (1;r)} , then we can find a subsequence ( a n k ) k = 1 ∞ ∞ {\displaystyle \left(a_{n_{k}}\right)_{k=1}^{\infty }} satisfying lim sup n → → ∞ ∞ | a n k + 1 a n k | ≤ ≤ ℓ ℓ < r {\displaystyle \limsup _{n\to \infty }\left|{\frac {a_{n_{k}+1}}{a_{n_{k}}}}\right|\leq \ell <r} , but this contradicts the fact that r {\displaystyle r} is the limit inferior of | a n + 1 a n | {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|} as n → → ∞ ∞ {\displaystyle n\to \infty } , implying the existence of ℓ ℓ {\displaystyle \ell } . Then we notice that for n ≥ ≥ n 0 + 1 {\displaystyle n\geq n_{0}+1} , | a n | > ℓ ℓ | a n − − 1 | > ℓ ℓ 2 | a n − − 2 | > .

.

.

> ℓ ℓ n − − n 0 | a n 0 | {\displaystyle |a_{n}|>\ell |a_{n-1}|>\ell ^{2}|a_{n-2}|>...>\ell ^{n-n_{0}}\left|a_{n_{0}}\right|} . Notice that ℓ ℓ > 1 {\displaystyle \ell >1} so ℓ ℓ n → → ∞ ∞ {\displaystyle \ell ^{n}\to \infty } as n → → ∞ ∞ {\displaystyle n\to \infty } and | a n 0 | > 0 {\displaystyle \left|a_{n_{0}}\right|>0} , this implies ( a n ) {\displaystyle (a_{n})} diverges so the series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} diverges by the n-th term test .

Now suppose R = lim sup n → → ∞ ∞ | a n + 1 a n | < 1 {\displaystyle R=\limsup _{n\to \infty }\left|{\frac {a_{n+1}}{a_{n}}}\right|<1} . Similar to the above case, we may find a natural number n 1 {\displaystyle n_{1}} and a c ∈ ∈ ( R ; 1 ) {\displaystyle c\in (R;1)} such that | a n | ≤ ≤ c n − − n 1 | a n 1 | {\displaystyle |a_{n}|\leq c^{n-n_{1}}\left|a_{n_{1}}\right|} for n ≥ ≥ n 1 {\displaystyle n\geq n_{1}} . Then ∑ ∑ n = 1 ∞ ∞ | a n | = ∑ ∑ k = 1 n 1 − − 1 | a k | + ∑ ∑ n = n 1 ∞ ∞ | a n | ≤ ≤ ∑ ∑ k = 1 n 1 − − 1 | a k | + ∑ ∑ n = n 1 ∞ ∞ c n − − n 1 | a n 1 | = ∑ ∑ k = 1 n 1 − − 1 | a k | + | a n 1 | ∑ ∑ n = 0 ∞ ∞ c n .

{\displaystyle \sum _{n=1}^{\infty }|a_{n}|=\sum _{k=1}^{n_{1}-1}|a_{k}|+\sum _{n=n_{1}}^{\infty }|a_{n}|\leq \sum _{k=1}^{n_{1}-1}|a_{k}|+\sum _{n=n_{1}}^{\infty }c^{n-n_{1}}|a_{n_{1}}|=\sum _{k=1}^{n_{1}-1}|a_{k}|+\left|a_{n_{1}}\right|\sum _{n=0}^{\infty }c^{n}.} The series ∑ ∑ n = 0 ∞ ∞ c n {\displaystyle \sum _{n=0}^{\infty }c^{n}} is the geometric series with common ratio c ∈ ∈ ( 0 ; 1 ) {\displaystyle c\in (0;1)} , hence ∑ ∑ n = 0 ∞ ∞ c n = 1 1 − − c {\displaystyle \sum _{n=0}^{\infty }c^{n}={\frac {1}{1-c}}} which is finite. The sum ∑ ∑ k = 1 n 1 − − 1 | a k | {\displaystyle \sum _{k=1}^{n_{1}-1}|a_{k}|} is a finite sum and hence it is bounded, this implies the series ∑ ∑ n = 1 ∞ ∞ | a n | {\displaystyle \sum _{n=1}^{\infty }|a_{n}|} converges by the monotone convergence theorem and the series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} converges by the absolute convergence test.

When the limit | a n + 1 a n | {\displaystyle \left|{\frac {a_{n+1}}{a_{n}}}\right|} exists and equals to L {\displaystyle L} then r = R = L {\displaystyle r=R=L} , this gives the original ratio test.

Extensions for L = 1 [ edit ] As seen in the previous example, the ratio test may be inconclusive when the limit of the ratio is 1. Extensions to the ratio test, however, sometimes allow one to deal with this case.

[ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ] [ 9 ] [ 10 ] [ 11 ] In all the tests below one assumes that Σ a n is a sum with positive a n . These tests also may be applied to any series with a finite number of negative terms. Any such series may be written as: ∑ ∑ n = 1 ∞ ∞ a n = ∑ ∑ n = 1 N a n + ∑ ∑ n = N + 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}=\sum _{n=1}^{N}a_{n}+\sum _{n=N+1}^{\infty }a_{n}} where a N is the highest-indexed negative term. The first expression on the right is a partial sum which will be finite, and so the convergence of the entire series will be determined by the convergence properties of the second expression on the right, which may be re-indexed to form a series of all positive terms beginning at n =1.

Each test defines a test parameter (ρ n ) which specifies the behavior of that parameter needed to establish convergence or divergence. For each test, a weaker form of the test exists which will instead place restrictions upon lim n->∞ ρ n .

All of the tests have regions in which they fail to describe the convergence properties of Σa n . In fact, no convergence test can fully describe the convergence properties of the series.

[ 4 ] [ 10 ] This is because if Σa n is convergent, a second convergent series Σb n can be found which converges more slowly: i.e., it has the property that lim n->∞ (b n /a n ) = ∞. Furthermore, if Σa n is divergent, a second divergent series Σb n can be found which diverges more slowly: i.e., it has the property that lim n->∞ (b n /a n ) = 0. Convergence tests essentially use the comparison test on some particular family of a n , and fail for sequences which converge or diverge more slowly.

De Morgan hierarchy [ edit ] Augustus De Morgan proposed a hierarchy of ratio-type tests [ 4 ] [ 9 ] The ratio test parameters ( ρ ρ n {\displaystyle \rho _{n}} ) below all generally involve terms of the form D n a n / a n + 1 − − D n + 1 {\displaystyle D_{n}a_{n}/a_{n+1}-D_{n+1}} . This term may be multiplied by a n + 1 / a n {\displaystyle a_{n+1}/a_{n}} to yield D n − − D n + 1 a n + 1 / a n {\displaystyle D_{n}-D_{n+1}a_{n+1}/a_{n}} . This term can replace the former term in the definition of the test parameters and the conclusions drawn will remain the same. Accordingly, there will be no distinction drawn between references which use one or the other form of the test parameter.

1. d'Alembert's ratio test [ edit ] The first test in the De Morgan hierarchy is the ratio test as described above.

2. Raabe's test [ edit ] This extension is due to Joseph Ludwig Raabe . Define: ρ ρ n ≡ ≡ n ( a n a n + 1 − − 1 ) {\displaystyle \rho _{n}\equiv n\left({\frac {a_{n}}{a_{n+1}}}-1\right)} (and some extra terms, see Ali, Blackburn, Feld, Duris (none), Duris2) [ clarification needed ] The series will: [ 7 ] [ 10 ] [ 9 ] Converge when there exists a c> 1 such that ρ ρ n ≥ ≥ c {\displaystyle \rho _{n}\geq c} for all n>N .

Diverge when ρ ρ n ≤ ≤ 1 {\displaystyle \rho _{n}\leq 1} for all n>N .

Otherwise, the test is inconclusive.

For the limit version, [ 12 ] the series will: Converge if ρ ρ = lim n → → ∞ ∞ ρ ρ n > 1 {\displaystyle \rho =\lim _{n\to \infty }\rho _{n}>1} (this includes the case ρ = ∞) Diverge if lim n → → ∞ ∞ ρ ρ n < 1 {\displaystyle \lim _{n\to \infty }\rho _{n}<1} .

If ρ = 1, the test is inconclusive.

When the above limit does not exist, it may be possible to use limits superior and inferior.

[ 4 ] The series will: Converge if lim inf n → → ∞ ∞ ρ ρ n > 1 {\displaystyle \liminf _{n\to \infty }\rho _{n}>1} Diverge if lim sup n → → ∞ ∞ ρ ρ n < 1 {\displaystyle \limsup _{n\rightarrow \infty }\rho _{n}<1} Otherwise, the test is inconclusive.

Proof of Raabe's test [ edit ] Defining ρ ρ n ≡ ≡ n ( a n a n + 1 − − 1 ) {\displaystyle \rho _{n}\equiv n\left({\frac {a_{n}}{a_{n+1}}}-1\right)} , we need not assume the limit exists; if lim sup ρ ρ n < 1 {\displaystyle \limsup \rho _{n}<1} , then ∑ ∑ a n {\displaystyle \sum a_{n}} diverges, while if lim inf ρ ρ n > 1 {\displaystyle \liminf \rho _{n}>1} the sum converges.

The proof proceeds essentially by comparison with ∑ ∑ 1 / n R {\displaystyle \sum 1/n^{R}} . Suppose first that lim sup ρ ρ n < 1 {\displaystyle \limsup \rho _{n}<1} . Of course
if lim sup ρ ρ n < 0 {\displaystyle \limsup \rho _{n}<0} then a n + 1 ≥ ≥ a n {\displaystyle a_{n+1}\geq a_{n}} for large n {\displaystyle n} , so the sum diverges; assume then that 0 ≤ ≤ lim sup ρ ρ n < 1 {\displaystyle 0\leq \limsup \rho _{n}<1} . There exists R < 1 {\displaystyle R<1} such that ρ ρ n ≤ ≤ R {\displaystyle \rho _{n}\leq R} for all n ≥ ≥ N {\displaystyle n\geq N} , which is to say that a n / a n + 1 ≤ ≤ ( 1 + R n ) ≤ ≤ e R / n {\displaystyle a_{n}/a_{n+1}\leq \left(1+{\frac {R}{n}}\right)\leq e^{R/n}} . Thus a n + 1 ≥ ≥ a n e − − R / n {\displaystyle a_{n+1}\geq a_{n}e^{-R/n}} , which implies that a n + 1 ≥ ≥ a N e − − R ( 1 / N + ⋯ ⋯ + 1 / n ) ≥ ≥ c a N e − − R log ⁡ ⁡ ( n ) = c a N / n R {\displaystyle a_{n+1}\geq a_{N}e^{-R(1/N+\dots +1/n)}\geq ca_{N}e^{-R\log(n)}=ca_{N}/n^{R}} for n ≥ ≥ N {\displaystyle n\geq N} ; since R < 1 {\displaystyle R<1} this shows that ∑ ∑ a n {\displaystyle \sum a_{n}} diverges.

The proof of the other half is entirely analogous, with most of the inequalities simply reversed. We need a preliminary inequality to use
in place of the simple 1 + t < e t {\displaystyle 1+t<e^{t}} that was used above:  Fix R {\displaystyle R} and N {\displaystyle N} . Note that log ⁡ ⁡ ( 1 + R n ) = R n + O ( 1 n 2 ) {\displaystyle \log \left(1+{\frac {R}{n}}\right)={\frac {R}{n}}+O\left({\frac {1}{n^{2}}}\right)} . So log ⁡ ⁡ ( ( 1 + R N ) … … ( 1 + R n ) ) = R ( 1 N + ⋯ ⋯ + 1 n ) + O ( 1 ) = R log ⁡ ⁡ ( n ) + O ( 1 ) {\displaystyle \log \left(\left(1+{\frac {R}{N}}\right)\dots \left(1+{\frac {R}{n}}\right)\right)=R\left({\frac {1}{N}}+\dots +{\frac {1}{n}}\right)+O(1)=R\log(n)+O(1)} ; hence ( 1 + R N ) … … ( 1 + R n ) ≥ ≥ c n R {\displaystyle \left(1+{\frac {R}{N}}\right)\dots \left(1+{\frac {R}{n}}\right)\geq cn^{R}} .

Suppose now that lim inf ρ ρ n > 1 {\displaystyle \liminf \rho _{n}>1} . Arguing as in the first paragraph, using the inequality established in the previous paragraph, we see that there exists R > 1 {\displaystyle R>1} such that a n + 1 ≤ ≤ c a N n − − R {\displaystyle a_{n+1}\leq ca_{N}n^{-R}} for n ≥ ≥ N {\displaystyle n\geq N} ; since R > 1 {\displaystyle R>1} this shows that ∑ ∑ a n {\displaystyle \sum a_{n}} converges.

3. Bertrand's test [ edit ] This extension is due to Joseph Bertrand and Augustus De Morgan .

Defining: ρ ρ n ≡ ≡ n ln ⁡ ⁡ n ( a n a n + 1 − − 1 ) − − ln ⁡ ⁡ n {\displaystyle \rho _{n}\equiv n\ln n\left({\frac {a_{n}}{a_{n+1}}}-1\right)-\ln n} Bertrand's test [ 4 ] [ 10 ] asserts that the series will: Converge when there exists a c>1 such that ρ ρ n ≥ ≥ c {\displaystyle \rho _{n}\geq c} for all n>N .

Diverge when ρ ρ n ≤ ≤ 1 {\displaystyle \rho _{n}\leq 1} for all n>N .

Otherwise, the test is inconclusive.

For the limit version, the series will: Converge if ρ ρ = lim n → → ∞ ∞ ρ ρ n > 1 {\displaystyle \rho =\lim _{n\to \infty }\rho _{n}>1} (this includes the case ρ = ∞) Diverge if lim n → → ∞ ∞ ρ ρ n < 1 {\displaystyle \lim _{n\to \infty }\rho _{n}<1} .

If ρ = 1, the test is inconclusive.

When the above limit does not exist, it may be possible to use limits superior and inferior.

[ 4 ] [ 9 ] [ 13 ] The series will: Converge if lim inf ρ ρ n > 1 {\displaystyle \liminf \rho _{n}>1} Diverge if lim sup ρ ρ n < 1 {\displaystyle \limsup \rho _{n}<1} Otherwise, the test is inconclusive.

4. Extended Bertrand's test [ edit ] This extension probably appeared at the first time by Margaret Martin in 1941.

[ 14 ] A short proof based on Kummer's test and without technical assumptions (such as existence of the limits, for example) was provided by Vyacheslav Abramov in 2019.

[ 15 ] Let K ≥ ≥ 1 {\displaystyle K\geq 1} be an integer, and let ln ( K ) ⁡ ⁡ ( x ) {\displaystyle \ln _{(K)}(x)} denote the K {\displaystyle K} th iterate of natural logarithm , i.e.

ln ( 1 ) ⁡ ⁡ ( x ) = ln ⁡ ⁡ ( x ) {\displaystyle \ln _{(1)}(x)=\ln(x)} and for any 2 ≤ ≤ k ≤ ≤ K {\displaystyle 2\leq k\leq K} , ln ( k ) ⁡ ⁡ ( x ) = ln ( k − − 1 ) ⁡ ⁡ ( ln ⁡ ⁡ ( x ) ) {\displaystyle \ln _{(k)}(x)=\ln _{(k-1)}(\ln(x))} .

Suppose that the ratio a n / a n + 1 {\displaystyle a_{n}/a_{n+1}} , when n {\displaystyle n} is large, can be presented in the form a n a n + 1 = 1 + 1 n + 1 n ∑ ∑ i = 1 K − − 1 1 ∏ ∏ k = 1 i ln ( k ) ⁡ ⁡ ( n ) + ρ ρ n n ∏ ∏ k = 1 K ln ( k ) ⁡ ⁡ ( n ) , K ≥ ≥ 1.

{\displaystyle {\frac {a_{n}}{a_{n+1}}}=1+{\frac {1}{n}}+{\frac {1}{n}}\sum _{i=1}^{K-1}{\frac {1}{\prod _{k=1}^{i}\ln _{(k)}(n)}}+{\frac {\rho _{n}}{n\prod _{k=1}^{K}\ln _{(k)}(n)}},\quad K\geq 1.} (The empty sum is assumed to be 0. With K = 1 {\displaystyle K=1} , the test reduces to Bertrand's test.) The value ρ ρ n {\displaystyle \rho _{n}} can be presented explicitly in the form ρ ρ n = n ∏ ∏ k = 1 K ln ( k ) ⁡ ⁡ ( n ) ( a n a n + 1 − − 1 ) − − ∑ ∑ j = 1 K ∏ ∏ k = 1 j ln ( K − − k + 1 ) ⁡ ⁡ ( n ) .

{\displaystyle \rho _{n}=n\prod _{k=1}^{K}\ln _{(k)}(n)\left({\frac {a_{n}}{a_{n+1}}}-1\right)-\sum _{j=1}^{K}\prod _{k=1}^{j}\ln _{(K-k+1)}(n).} Extended Bertrand's test asserts that the series Converge when there exists a c > 1 {\displaystyle c>1} such that ρ ρ n ≥ ≥ c {\displaystyle \rho _{n}\geq c} for all n > N {\displaystyle n>N} .

Diverge when ρ ρ n ≤ ≤ 1 {\displaystyle \rho _{n}\leq 1} for all n > N {\displaystyle n>N} .

Otherwise, the test is inconclusive.

For the limit version, the series Converge if ρ ρ = lim n → → ∞ ∞ ρ ρ n > 1 {\displaystyle \rho =\lim _{n\to \infty }\rho _{n}>1} (this includes the case ρ ρ = ∞ ∞ {\displaystyle \rho =\infty } ) Diverge if lim n → → ∞ ∞ ρ ρ n < 1 {\displaystyle \lim _{n\to \infty }\rho _{n}<1} .

If ρ ρ = 1 {\displaystyle \rho =1} , the test is inconclusive.

When the above limit does not exist, it may be possible to use limits superior and inferior. The series Converge if lim inf ρ ρ n > 1 {\displaystyle \liminf \rho _{n}>1} Diverge if lim sup ρ ρ n < 1 {\displaystyle \limsup \rho _{n}<1} Otherwise, the test is inconclusive.

For applications of Extended Bertrand's test see birth–death process .

5. Gauss's test [ edit ] This extension is due to Carl Friedrich Gauss .

Assuming a n > 0 and r > 1 , if a bounded sequence C n can be found such that for all n : [ 5 ] [ 7 ] [ 9 ] [ 10 ] a n a n + 1 = 1 + ρ ρ n + C n n r {\displaystyle {\frac {a_{n}}{a_{n+1}}}=1+{\frac {\rho }{n}}+{\frac {C_{n}}{n^{r}}}} then the series will: Converge if ρ ρ > 1 {\displaystyle \rho >1} Diverge if ρ ρ ≤ ≤ 1 {\displaystyle \rho \leq 1} 6. Kummer's test [ edit ] This extension is due to Ernst Kummer .

Let ζ n be an auxiliary sequence of positive constants. Define ρ ρ n ≡ ≡ ( ζ ζ n a n a n + 1 − − ζ ζ n + 1 ) {\displaystyle \rho _{n}\equiv \left(\zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}\right)} Kummer's test states that the series will: [ 5 ] [ 6 ] [ 10 ] [ 11 ] Converge if there exists a c > 0 {\displaystyle c>0} such that ρ ρ n ≥ ≥ c {\displaystyle \rho _{n}\geq c} for all n>N. (Note this is not the same as saying ρ ρ n > 0 {\displaystyle \rho _{n}>0} ) Diverge if ρ ρ n ≤ ≤ 0 {\displaystyle \rho _{n}\leq 0} for all n>N and ∑ ∑ n = 1 ∞ ∞ 1 / ζ ζ n {\displaystyle \sum _{n=1}^{\infty }1/\zeta _{n}} diverges.

For the limit version, the series will: [ 16 ] [ 7 ] [ 9 ] Converge if lim n → → ∞ ∞ ρ ρ n > 0 {\displaystyle \lim _{n\to \infty }\rho _{n}>0} (this includes the case ρ = ∞) Diverge if lim n → → ∞ ∞ ρ ρ n < 0 {\displaystyle \lim _{n\to \infty }\rho _{n}<0} and ∑ ∑ n = 1 ∞ ∞ 1 / ζ ζ n {\displaystyle \sum _{n=1}^{\infty }1/\zeta _{n}} diverges.

Otherwise the test is inconclusive When the above limit does not exist, it may be possible to use limits superior and inferior.

[ 4 ] The series will Converge if lim inf n → → ∞ ∞ ρ ρ n > 0 {\displaystyle \liminf _{n\to \infty }\rho _{n}>0} Diverge if lim sup n → → ∞ ∞ ρ ρ n < 0 {\displaystyle \limsup _{n\to \infty }\rho _{n}<0} and ∑ ∑ 1 / ζ ζ n {\displaystyle \sum 1/\zeta _{n}} diverges.

Special cases [ edit ] All of the tests in De Morgan's hierarchy except Gauss's test can easily be seen as special cases of Kummer's test: [ 4 ] For the ratio test, let ζ n =1. Then: ρ ρ Kummer = ( a n a n + 1 − − 1 ) = 1 / ρ ρ Ratio − − 1 {\displaystyle \rho _{\text{Kummer}}=\left({\frac {a_{n}}{a_{n+1}}}-1\right)=1/\rho _{\text{Ratio}}-1} For Raabe's test, let ζ n =n. Then: ρ ρ Kummer = ( n a n a n + 1 − − ( n + 1 ) ) = ρ ρ Raabe − − 1 {\displaystyle \rho _{\text{Kummer}}=\left(n{\frac {a_{n}}{a_{n+1}}}-(n+1)\right)=\rho _{\text{Raabe}}-1} For Bertrand's test, let ζ n =n ln(n). Then: ρ ρ Kummer = n ln ⁡ ⁡ ( n ) ( a n a n + 1 ) − − ( n + 1 ) ln ⁡ ⁡ ( n + 1 ) {\displaystyle \rho _{\text{Kummer}}=n\ln(n)\left({\frac {a_{n}}{a_{n+1}}}\right)-(n+1)\ln(n+1)} Using ln ⁡ ⁡ ( n + 1 ) = ln ⁡ ⁡ ( n ) + ln ⁡ ⁡ ( 1 + 1 / n ) {\displaystyle \ln(n+1)=\ln(n)+\ln(1+1/n)} and approximating ln ⁡ ⁡ ( 1 + 1 / n ) → → 1 / n {\displaystyle \ln(1+1/n)\rightarrow 1/n} for large n , which is negligible compared to the other terms, ρ ρ Kummer {\displaystyle \rho _{\text{Kummer}}} may be written: ρ ρ Kummer = n ln ⁡ ⁡ ( n ) ( a n a n + 1 − − 1 ) − − ln ⁡ ⁡ ( n ) − − 1 = ρ ρ Bertrand − − 1 {\displaystyle \rho _{\text{Kummer}}=n\ln(n)\left({\frac {a_{n}}{a_{n+1}}}-1\right)-\ln(n)-1=\rho _{\text{Bertrand}}-1} For Extended Bertrand's test, let ζ ζ n = n ∏ ∏ k = 1 K ln ( k ) ⁡ ⁡ ( n ) .

{\displaystyle \zeta _{n}=n\prod _{k=1}^{K}\ln _{(k)}(n).} From the Taylor series expansion for large n {\displaystyle n} we arrive at the approximation ln ( k ) ⁡ ⁡ ( n + 1 ) = ln ( k ) ⁡ ⁡ ( n ) + 1 n ∏ ∏ j = 1 k − − 1 ln ( j ) ⁡ ⁡ ( n ) + O ( 1 n 2 ) , {\displaystyle \ln _{(k)}(n+1)=\ln _{(k)}(n)+{\frac {1}{n\prod _{j=1}^{k-1}\ln _{(j)}(n)}}+O\left({\frac {1}{n^{2}}}\right),} where the empty product is assumed to be 1. Then, ρ ρ Kummer = n ∏ ∏ k = 1 K ln ( k ) ⁡ ⁡ ( n ) a n a n + 1 − − ( n + 1 ) [ ∏ ∏ k = 1 K ( ln ( k ) ⁡ ⁡ ( n ) + 1 n ∏ ∏ j = 1 k − − 1 ln ( j ) ⁡ ⁡ ( n ) ) ] + o ( 1 ) = n ∏ ∏ k = 1 K ln ( k ) ⁡ ⁡ ( n ) ( a n a n + 1 − − 1 ) − − ∑ ∑ j = 1 K ∏ ∏ k = 1 j ln ( K − − k + 1 ) ⁡ ⁡ ( n ) − − 1 + o ( 1 ) .

{\displaystyle \rho _{\text{Kummer}}=n\prod _{k=1}^{K}\ln _{(k)}(n){\frac {a_{n}}{a_{n+1}}}-(n+1)\left[\prod _{k=1}^{K}\left(\ln _{(k)}(n)+{\frac {1}{n\prod _{j=1}^{k-1}\ln _{(j)}(n)}}\right)\right]+o(1)=n\prod _{k=1}^{K}\ln _{(k)}(n)\left({\frac {a_{n}}{a_{n+1}}}-1\right)-\sum _{j=1}^{K}\prod _{k=1}^{j}\ln _{(K-k+1)}(n)-1+o(1).} Hence, ρ ρ Kummer = ρ ρ Extended Bertrand − − 1.

{\displaystyle \rho _{\text{Kummer}}=\rho _{\text{Extended Bertrand}}-1.} Note that for these four tests, the higher they are in the De Morgan hierarchy, the more slowly the 1 / ζ ζ n {\displaystyle 1/\zeta _{n}} series diverges.

Proof of Kummer's test [ edit ] If ρ ρ n > 0 {\displaystyle \rho _{n}>0} then fix a positive number 0 < δ δ < ρ ρ n {\displaystyle 0<\delta <\rho _{n}} .  There exists
a natural number N {\displaystyle N} such that for every n > N , {\displaystyle n>N,} δ δ ≤ ≤ ζ ζ n a n a n + 1 − − ζ ζ n + 1 .

{\displaystyle \delta \leq \zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}.} Since a n + 1 > 0 {\displaystyle a_{n+1}>0} , for every n > N , {\displaystyle n>N,} 0 ≤ ≤ δ δ a n + 1 ≤ ≤ ζ ζ n a n − − ζ ζ n + 1 a n + 1 .

{\displaystyle 0\leq \delta a_{n+1}\leq \zeta _{n}a_{n}-\zeta _{n+1}a_{n+1}.} In particular ζ ζ n + 1 a n + 1 ≤ ≤ ζ ζ n a n {\displaystyle \zeta _{n+1}a_{n+1}\leq \zeta _{n}a_{n}} for all n ≥ ≥ N {\displaystyle n\geq N} which means that starting from the index N {\displaystyle N} the sequence ζ ζ n a n > 0 {\displaystyle \zeta _{n}a_{n}>0} is monotonically decreasing and
positive which in particular implies that it is bounded below by 0. Therefore, the limit lim n → → ∞ ∞ ζ ζ n a n = L {\displaystyle \lim _{n\to \infty }\zeta _{n}a_{n}=L} exists.

This implies that the positive telescoping series ∑ ∑ n = 1 ∞ ∞ ( ζ ζ n a n − − ζ ζ n + 1 a n + 1 ) {\displaystyle \sum _{n=1}^{\infty }\left(\zeta _{n}a_{n}-\zeta _{n+1}a_{n+1}\right)} is convergent, and since for all n > N , {\displaystyle n>N,} δ δ a n + 1 ≤ ≤ ζ ζ n a n − − ζ ζ n + 1 a n + 1 {\displaystyle \delta a_{n+1}\leq \zeta _{n}a_{n}-\zeta _{n+1}a_{n+1}} by the direct comparison test for positive series, the series ∑ ∑ n = 1 ∞ ∞ δ δ a n + 1 {\displaystyle \sum _{n=1}^{\infty }\delta a_{n+1}} is convergent.

On the other hand, if ρ ρ < 0 {\displaystyle \rho <0} , then there is an N such that ζ ζ n a n {\displaystyle \zeta _{n}a_{n}} is increasing for n > N {\displaystyle n>N} .  In particular, there exists an ϵ ϵ > 0 {\displaystyle \epsilon >0} for which ζ ζ n a n > ϵ ϵ {\displaystyle \zeta _{n}a_{n}>\epsilon } for all n > N {\displaystyle n>N} , and so ∑ ∑ n a n = ∑ ∑ n a n ζ ζ n ζ ζ n {\displaystyle \sum _{n}a_{n}=\sum _{n}{\frac {a_{n}\zeta _{n}}{\zeta _{n}}}} diverges by comparison with ∑ ∑ n ϵ ϵ ζ ζ n {\displaystyle \sum _{n}{\frac {\epsilon }{\zeta _{n}}}} .

Tong's modification of Kummer's test [ edit ] A new version of Kummer's test was established by Tong.

[ 6 ] See also [ 8 ] [ 11 ] [ 17 ] for further discussions and new proofs. The provided modification of Kummer's theorem characterizes
all positive series, and the convergence or divergence can be formulated in the form of two necessary and sufficient conditions, one for convergence and another for divergence.

Series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} converges if and only if there exists a positive sequence ζ ζ n {\displaystyle \zeta _{n}} , n = 1 , 2 , … … {\displaystyle n=1,2,\dots } , such that ζ ζ n a n a n + 1 − − ζ ζ n + 1 ≥ ≥ c > 0.

{\displaystyle \zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}\geq c>0.} Series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} diverges if and only if there exists a positive sequence ζ ζ n {\displaystyle \zeta _{n}} , n = 1 , 2 , … … {\displaystyle n=1,2,\dots } , such that ζ ζ n a n a n + 1 − − ζ ζ n + 1 ≤ ≤ 0 , {\displaystyle \zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}\leq 0,} and ∑ ∑ n = 1 ∞ ∞ 1 ζ ζ n = ∞ ∞ .

{\displaystyle \sum _{n=1}^{\infty }{\frac {1}{\zeta _{n}}}=\infty .} The first of these statements can be simplified as follows: [ 18 ] Series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} converges if and only if there exists a positive sequence ζ ζ n {\displaystyle \zeta _{n}} , n = 1 , 2 , … … {\displaystyle n=1,2,\dots } , such that ζ ζ n a n a n + 1 − − ζ ζ n + 1 = 1.

{\displaystyle \zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}=1.} The second statement can be simplified similarly: Series ∑ ∑ n = 1 ∞ ∞ a n {\displaystyle \sum _{n=1}^{\infty }a_{n}} diverges if and only if there exists a positive sequence ζ ζ n {\displaystyle \zeta _{n}} , n = 1 , 2 , … … {\displaystyle n=1,2,\dots } , such that ζ ζ n a n a n + 1 − − ζ ζ n + 1 = 0 , {\displaystyle \zeta _{n}{\frac {a_{n}}{a_{n+1}}}-\zeta _{n+1}=0,} and ∑ ∑ n = 1 ∞ ∞ 1 ζ ζ n = ∞ ∞ .

{\displaystyle \sum _{n=1}^{\infty }{\frac {1}{\zeta _{n}}}=\infty .} However, it becomes useless, since the condition ∑ ∑ n = 1 ∞ ∞ 1 ζ ζ n = ∞ ∞ {\displaystyle \sum _{n=1}^{\infty }{\frac {1}{\zeta _{n}}}=\infty } in this case reduces to the original claim ∑ ∑ n = 1 ∞ ∞ a n = ∞ ∞ .

{\displaystyle \sum _{n=1}^{\infty }a_{n}=\infty .} Frink's ratio test [ edit ] Another ratio test that can be set in the framework of Kummer's theorem was presented by Orrin Frink [ 19 ] 1948.

Suppose a n {\displaystyle a_{n}} is a sequence in C ∖ ∖ { 0 } {\displaystyle \mathbb {C} \setminus \{0\}} , If lim sup n → → ∞ ∞ ( | a n + 1 | | a n | ) n < 1 e {\displaystyle \limsup _{n\rightarrow \infty }{\Big (}{\frac {|a_{n+1}|}{|a_{n}|}}{\Big )}^{n}<{\frac {1}{e}}} , then the series ∑ ∑ n a n {\displaystyle \sum _{n}a_{n}} converges absolutely.

If there is N ∈ ∈ N {\displaystyle N\in \mathbb {N} } such that ( | a n + 1 | | a n | ) n ≥ ≥ 1 e {\displaystyle {\Big (}{\frac {|a_{n+1}|}{|a_{n}|}}{\Big )}^{n}\geq {\frac {1}{e}}} for all n ≥ ≥ N {\displaystyle n\geq N} , then ∑ ∑ n | a n | {\displaystyle \sum _{n}|a_{n}|} diverges.

This result reduces to a comparison of ∑ ∑ n | a n | {\displaystyle \sum _{n}|a_{n}|} with a power series ∑ ∑ n n − − p {\displaystyle \sum _{n}n^{-p}} , and can be seen to be related to Raabe's test.

[ 20 ] Ali's second ratio test [ edit ] A more refined ratio test is the second ratio test: [ 7 ] [ 9 ] For a n > 0 {\displaystyle a_{n}>0} define: L 0 ≡ ≡ lim n → → ∞ ∞ a 2 n a n {\displaystyle L_{0}\equiv \lim _{n\rightarrow \infty }{\frac {a_{2n}}{a_{n}}}} L 1 ≡ ≡ lim n → → ∞ ∞ a 2 n + 1 a n {\displaystyle L_{1}\equiv \lim _{n\rightarrow \infty }{\frac {a_{2n+1}}{a_{n}}}} L ≡ ≡ max ( L 0 , L 1 ) {\displaystyle L\equiv \max(L_{0},L_{1})} By the second ratio test, the series will: Converge if L < 1 2 {\displaystyle L<{\frac {1}{2}}} Diverge if L > 1 2 {\displaystyle L>{\frac {1}{2}}} If L = 1 2 {\displaystyle L={\frac {1}{2}}} then the test is inconclusive.

If the above limits do not exist, it may be possible to use the limits superior and inferior. Define: L 0 ≡ ≡ lim sup n → → ∞ ∞ a 2 n a n {\displaystyle L_{0}\equiv \limsup _{n\rightarrow \infty }{\frac {a_{2n}}{a_{n}}}} L 1 ≡ ≡ lim sup n → → ∞ ∞ a 2 n + 1 a n {\displaystyle L_{1}\equiv \limsup _{n\rightarrow \infty }{\frac {a_{2n+1}}{a_{n}}}} ℓ ℓ 0 ≡ ≡ lim inf n → → ∞ ∞ a 2 n a n {\displaystyle \ell _{0}\equiv \liminf _{n\rightarrow \infty }{\frac {a_{2n}}{a_{n}}}} ℓ ℓ 1 ≡ ≡ lim inf n → → ∞ ∞ a 2 n + 1 a n {\displaystyle \ell _{1}\equiv \liminf _{n\rightarrow \infty }{\frac {a_{2n+1}}{a_{n}}}} L ≡ ≡ max ( L 0 , L 1 ) {\displaystyle L\equiv \max(L_{0},L_{1})} ℓ ℓ ≡ ≡ min ( ℓ ℓ 0 , ℓ ℓ 1 ) {\displaystyle \ell \equiv \min(\ell _{0},\ell _{1})} Then the series will: Converge if L < 1 2 {\displaystyle L<{\frac {1}{2}}} Diverge if ℓ ℓ > 1 2 {\displaystyle \ell >{\frac {1}{2}}} If ℓ ℓ ≤ ≤ 1 2 ≤ ≤ L {\displaystyle \ell \leq {\frac {1}{2}}\leq L} then the test is inconclusive.

Ali's m th ratio test [ edit ] This test is a direct extension of the second ratio test.

[ 7 ] [ 9 ] For 0 ≤ ≤ k ≤ ≤ m − − 1 , {\displaystyle 0\leq k\leq m-1,} and positive a n {\displaystyle a_{n}} define: L k ≡ ≡ lim n → → ∞ ∞ a m n + k a n {\displaystyle L_{k}\equiv \lim _{n\rightarrow \infty }{\frac {a_{mn+k}}{a_{n}}}} L ≡ ≡ max ( L 0 , L 1 , … … , L m − − 1 ) {\displaystyle L\equiv \max(L_{0},L_{1},\ldots ,L_{m-1})} By the m {\displaystyle m} th ratio test, the series will: Converge if L < 1 m {\displaystyle L<{\frac {1}{m}}} Diverge if L > 1 m {\displaystyle L>{\frac {1}{m}}} If L = 1 m {\displaystyle L={\frac {1}{m}}} then the test is inconclusive.

If the above limits do not exist, it may be possible to use the limits superior and inferior. For 0 ≤ ≤ k ≤ ≤ m − − 1 {\displaystyle 0\leq k\leq m-1} define: L k ≡ ≡ lim sup n → → ∞ ∞ a m n + k a n {\displaystyle L_{k}\equiv \limsup _{n\rightarrow \infty }{\frac {a_{mn+k}}{a_{n}}}} ℓ ℓ k ≡ ≡ lim inf n → → ∞ ∞ a m n + k a n {\displaystyle \ell _{k}\equiv \liminf _{n\rightarrow \infty }{\frac {a_{mn+k}}{a_{n}}}} L ≡ ≡ max ( L 0 , L 1 , … … , L m − − 1 ) {\displaystyle L\equiv \max(L_{0},L_{1},\ldots ,L_{m-1})} ℓ ℓ ≡ ≡ min ( ℓ ℓ 0 , ℓ ℓ 1 , … … , ℓ ℓ m − − 1 ) {\displaystyle \ell \equiv \min(\ell _{0},\ell _{1},\ldots ,\ell _{m-1})} Then the series will: Converge if L < 1 m {\displaystyle L<{\frac {1}{m}}} Diverge if ℓ ℓ > 1 m {\displaystyle \ell >{\frac {1}{m}}} If ℓ ℓ ≤ ≤ 1 m ≤ ≤ L {\displaystyle \ell \leq {\frac {1}{m}}\leq L} , then the test is inconclusive.

Ali--Deutsche Cohen φ-ratio test [ edit ] This test is an extension of the m {\displaystyle m} th ratio test.

[ 21 ] Assume that the sequence a n {\displaystyle a_{n}} is a positive decreasing sequence.

Let φ φ : Z + → → Z + {\displaystyle \varphi :\mathbb {Z} ^{+}\to \mathbb {Z} ^{+}} be such that lim n → → ∞ ∞ n φ φ ( n ) {\displaystyle \lim _{n\to \infty }{\frac {n}{\varphi (n)}}} exists. Denote α α = lim n → → ∞ ∞ n φ φ ( n ) {\displaystyle \alpha =\lim _{n\to \infty }{\frac {n}{\varphi (n)}}} , and assume 0 < α α < 1 {\displaystyle 0<\alpha <1} .

Assume also that lim n → → ∞ ∞ a φ φ ( n ) a n = L .

{\displaystyle \lim _{n\to \infty }{\frac {a_{\varphi (n)}}{a_{n}}}=L.} Then the series will: Converge if L < α α {\displaystyle L<\alpha } Diverge if L > α α {\displaystyle L>\alpha } If L = α α {\displaystyle L=\alpha } , then the test is inconclusive.

See also [ edit ] Root test Radius of convergence Footnotes [ edit ] ^ Weisstein, Eric W.

"Ratio Test" .

MathWorld .

^ Rudin 1976 , §3.34 ^ Apostol 1974 , §8.14 ^ a b c d e f g h Bromwich, T. J. I'A (1908).

An Introduction To The Theory of Infinite Series . Merchant Books.

^ a b c Knopp, Konrad (1954).

Theory and Application of Infinite Series . London: Blackie & Son Ltd.

^ a b c Tong, Jingcheng (May 1994). "Kummer's Test Gives Characterizations for Convergence or Divergence of all Positive Series".

The American Mathematical Monthly .

101 (5): 450– 452.

doi : 10.2307/2974907 .

JSTOR 2974907 .

^ a b c d e f Ali, Sayel A. (2008).

"The mth Ratio Test: New Convergence Test for Series" .

The American Mathematical Monthly .

115 (6): 514– 524.

doi : 10.1080/00029890.2008.11920558 .

S2CID 16336333 . Retrieved 4 September 2024 .

^ a b Samelson, Hans (November 1995). "More on Kummer's Test".

The American Mathematical Monthly .

102 (9): 817– 818.

doi : 10.2307/2974510 .

JSTOR 2974510 .

^ a b c d e f g h Blackburn, Kyle (4 May 2012).

"The mth Ratio Convergence Test and Other Unconventional Convergence Tests" (PDF) . University of Washington College of Arts and Sciences . Retrieved 27 November 2018 .

^ a b c d e f Ďuriš, František (2009).

Infinite series: Convergence tests (Bachelor's thesis). Katedra Informatiky, Fakulta Matematiky, Fyziky a Informatiky, Univerzita Komenského, Bratislava . Retrieved 28 November 2018 .

^ a b c Ďuriš, František (2 February 2018). "On Kummer's test of convergence and its relation to basic comparison tests".

arXiv : 1612.05167 [ math.HO ].

^ Weisstein, Eric W.

"Raabe's Test" .

MathWorld .

^ Weisstein, Eric W.

"Bertrand's Test" .

MathWorld .

^ Martin, Margaret (1941).

"A sequence of limit tests for the convergence of series" (PDF) .

Bulletin of the American Mathematical Society .

47 (6): 452– 457.

doi : 10.1090/S0002-9904-1941-07477-X .

^ Abramov, Vyacheslav M. (May 2020). "Extension of the Bertrand–De Morgan test and its application".

The American Mathematical Monthly .

127 (5): 444– 448.

arXiv : 1901.05843 .

doi : 10.1080/00029890.2020.1722551 .

S2CID 199552015 .

^ Weisstein, Eric W.

"Kummer's Test" .

MathWorld .

^ Abramov, Vyacheslav, M. (21 June 2021). "A simple proof of Tong's theorem".

arXiv : 2106.13808 [ math.HO ].

{{ cite arXiv }} :  CS1 maint: multiple names: authors list ( link ) ^ Abramov, Vyacheslav M. (May 2022).

"Evaluating the sum of convergent positive series" (PDF) .

Publications de l'Institut Mathématique . Nouvelle Série.

111 (125): 41– 53.

doi : 10.2298/PIM2225041A .

S2CID 237499616 .

^ Frink, Orrin (October 1948).

"A ratio test" .

Bulletin of the American Mathematical Society .

54 (10): 953– 953.

^ Stark, Marceli (1949). "On the ratio test of Frink".

Colloquium Mathematicum .

2 (1): 46– 47.

^ Ali, Sayel; Cohen, Marion Deutsche (2012).

"phi-ratio tests" .

Elemente der Mathematik .

67 (4): 164– 168.

doi : 10.4171/EM/206 .

References [ edit ] d'Alembert, J.

(1768), Opuscules , vol. V, pp.

171– 183 .

Apostol, Tom M.

(1974), Mathematical analysis (2nd ed.), Addison-Wesley , ISBN 978-0-201-00288-1 : §8.14.

Knopp, Konrad (1956), Infinite Sequences and Series , New York: Dover Publications, Bibcode : 1956iss..book.....K , ISBN 978-0-486-60153-3 {{ citation }} : ISBN / Date incompatibility ( help ) : §3.3, 5.4.

Rudin, Walter (1976), Principles of Mathematical Analysis (3rd ed.), New York: McGraw-Hill, Inc., ISBN 978-0-07-054235-8 : §3.34.

"Bertrand criterion" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] "Gauss criterion" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] "Kummer criterion" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] Watson, G. N.; Whittaker, E. T. (1963), A Course in Modern Analysis (4th ed.), Cambridge University Press, ISBN 978-0-521-58807-2 {{ citation }} : ISBN / Date incompatibility ( help ) : §2.36, 2.37.

v t e Calculus Precalculus Binomial theorem Concave function Continuous function Factorial Finite difference Free variables and bound variables Graph of a function Linear function Radian Rolle's theorem Secant Slope Tangent Limits Indeterminate form Limit of a function One-sided limit Limit of a sequence Order of approximation (ε, δ)-definition of limit Differential calculus Derivative Second derivative Partial derivative Differential Differential operator Mean value theorem Notation Leibniz's notation Newton's notation Rules of differentiation linearity Power Sum Chain L'Hôpital's Product General Leibniz's rule Quotient Other techniques Implicit differentiation Inverse functions and differentiation Logarithmic derivative Related rates Stationary points First derivative test Second derivative test Extreme value theorem Maximum and minimum Further applications Newton's method Taylor's theorem Differential equation Ordinary differential equation Partial differential equation Stochastic differential equation Integral calculus Antiderivative Arc length Riemann integral Basic properties Constant of integration Fundamental theorem of calculus Differentiating under the integral sign Integration by parts Integration by substitution trigonometric Euler Tangent half-angle substitution Partial fractions in integration Quadratic integral Trapezoidal rule Volumes Washer method Shell method Integral equation Integro-differential equation Vector calculus Derivatives Curl Directional derivative Divergence Gradient Laplacian Basic theorems Line integrals Green's Stokes' Gauss' Multivariable calculus Divergence theorem Geometric Hessian matrix Jacobian matrix and determinant Lagrange multiplier Line integral Matrix Multiple integral Partial derivative Surface integral Volume integral Advanced topics Differential forms Exterior derivative Generalized Stokes' theorem Tensor calculus Sequences and series Arithmetico-geometric sequence Types of series Alternating Binomial Fourier Geometric Harmonic Infinite Power Maclaurin Taylor Telescoping Tests of convergence Abel's Alternating series Cauchy condensation Direct comparison Dirichlet's Integral Limit comparison Ratio Root Term Special functions and numbers Bernoulli numbers e (mathematical constant) Exponential function Natural logarithm Stirling's approximation History of calculus Adequality Brook Taylor Colin Maclaurin Generality of algebra Gottfried Wilhelm Leibniz Infinitesimal Infinitesimal calculus Isaac Newton Fluxion Law of Continuity Leonhard Euler Method of Fluxions The Method of Mechanical Theorems Lists Integrals rational functions irrational algebraic functions exponential functions logarithmic functions hyperbolic functions inverse trigonometric functions inverse Secant Secant cubed List of limits List of derivatives Miscellaneous topics Complex calculus Contour integral Differential geometry Manifold Curvature of curves of surfaces Tensor Euler–Maclaurin formula Gabriel's horn Integration Bee Proof that 22/7 exceeds π Regiomontanus' angle maximization problem Steinmetz solid Retrieved from " https://en.wikipedia.org/w/index.php?title=Ratio_test&oldid=1292351034 " Category : Convergence tests Hidden categories: CS1 maint: multiple names: authors list Articles with short description Short description is different from Wikidata Pages using sidebar with the child parameter Wikipedia articles needing clarification from September 2024 CS1 errors: ISBN date Articles containing proofs This page was last edited on 26 May 2025, at 14:38 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Ratio test 29 languages Add topic

