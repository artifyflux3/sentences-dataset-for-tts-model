Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 History 2 Leverage points to intervene in a system Toggle Leverage points to intervene in a system subsection 2.1 12. Constants, parameters, numbers 2.2 11. The size of buffers and other stabilizing stocks, relative to their flows 2.3 10. Structure of material stocks and flows (such as transport network, population age structures) 2.4 9. Length of delays, relative to the rate of system changes 2.5 8. Strength of negative feedback loops, relative to the effect they are trying to correct against 2.6 7. Gain around driving positive feedback loops 2.7 6. Structure of information flow (who does and does not have access to what kinds of information) 2.8 5. Rules of the system (such as incentives, punishment, constraints) 2.9 4. Power to add, change, evolve, or self-organize system structure 2.10 3. Goal of the system 2.11 2. Mindset or paradigm that the system — its goals, structure, rules, delays, parameters — arises from 2.12 1. Power to transcend paradigms 3 See also 4 References Toggle the table of contents Twelve leverage points 6 languages Čeština Español Français Português Українська Tiếng Việt Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Systems Dynamics concept This article is about leverage points related to System Dynamics. For other uses, see Center of gravity (military) .

This article relies excessively on references to primary sources .

Please improve this article by adding secondary or tertiary sources .

Find sources: "Twelve leverage points" – news · newspapers · books · scholar · JSTOR ( April 2011 ) ( Learn how and when to remove this message ) The twelve leverage points to intervene in a system were proposed by Donella Meadows , a scientist and system analyst who studied environmental limits to economic growth.

[ 1 ] History [ edit ] The leverage points, first published in 1997, were inspired by Meadows' attendance at a North American Free Trade Agreement (NAFTA) meeting in the early 1990s, where she realized a very large new system was being proposed but the mechanisms to manage it were ineffective. Meadows, who worked in the field of systems analysis , proposed a scale of places to intervene in a system .  Awareness and manipulation of these levers is an aspect of self-organization and can lead to collective intelligence . Her observations are often cited in energy economics , green economics and human development theory .

Meadows started with the observation that there are levers, or places within a complex system (such as a firm, a city, an economy, a living being, an ecosystem , an ecoregion ) where a "small shift in one thing can produce big changes in everything" (compare: constraint in the sense of the theory of constraints ).

She claimed we need to know about these shifts, where they are, and how to use them. She said most people know where these points are instinctively, but tend to adjust them in the wrong direction. A greater understanding would help solve global problems such as unemployment , hunger , economic stagnation , pollution , resources depletion , and conservation issues.

Meadows started with a nine-point list of such places, and expanded it to a list of twelve leverage points with explanations and examples, for systems in general. She describes a system as being in a certain state, consisting of a stock and flow , with inflows (amounts entering the system) and outflows (amounts leaving the system). At a given time, the system is in a certain perceived state. There may also be a goal for the system to be in a certain state. The difference between the current state and the goal is the discrepancy.

For example, one might consider a lake or reservoir, which contains a certain amount of water. The inflows are the amount of water coming from rivers, rainfall, drainage from nearby soils, and waste water from a local industrial plant. The outflows might be the amount of water used up for irrigation of nearby cornfield, water taken by that local plant to operate as well as the local camping site, water evaporating in the atmosphere , and trickling surplus water when the reservoir is full. Local inhabitants complain about the water level getting low, pollution getting higher, and the potential effect of hot water release in the lake on life (in particular, the fish). This is the difference between the perceived state (pollution or low water level) and the goal (a non-polluted lake).

Leverage points to intervene in a system [ edit ] The following are in increasing order of effectiveness.

12. Constants, parameters, numbers [ edit ] Parameters are points of lowest leverage effects. Though they are the most clearly perceived among all leverages, they rarely change behaviors and therefore have little long-term effect.

For example, climate parameters may not be changed easily (the amount of rain, the evapotranspiration rate, the temperature of the water), but they are the ones people think of first (they remember that in their youth, it was certainly raining more). These parameters are indeed very important. But even if changed (improvement of upper river stream to canalize incoming water), they will not change behavior much (the debit will probably not dramatically decrease).

11. The size of buffers and other stabilizing stocks, relative to their flows [ edit ] A buffer 's ability to stabilize a system is important when the stock amount is much higher than the potential amount of inflows or outflows.  In the lake, the water is the buffer:  if there's a lot more of it than inflow/outflow, the system stays stable.

For example, the inhabitants are worried the lake fish might die as a consequence of hot water release directly in the lake without any previous cooling off. However, the water in the lake has a large heat capacity , so it's a strong thermic buffer. Provided the release is done at low enough depth, under the thermocline , and the lake volume is big enough, the buffering capacity of the water might prevent any extinction from excess temperature.

Buffers can improve a system, but they are often physical entities whose size is critical and can't be changed easily.

10. Structure of material stocks and flows (such as transport network, population age structures) [ edit ] A system's structure may have enormous effect on operations, but may be difficult or prohibitively expensive to change. Fluctuations, limitations, and bottlenecks may be easier to address.

For example, the inhabitants are worried about their lake getting polluted, as the industry releases chemical pollutants directly in the water without any previous treatment. The system might need the used water to be diverted to a wastewater treatment plant , but this requires rebuilding the underground used water system (which could be quite expensive).

9. Length of delays, relative to the rate of system changes [ edit ] Information received too quickly or too late can cause over- or underreaction, even oscillations.

For example, the city council is considering building the wastewater treatment plant. However, the plant will take 5 years to be built, and will last about 30 years. The first delay will prevent the water being cleaned up within the first 5 years, while the second delay will make it impossible to  build a plant with exactly the right capacity.

8. Strength of negative feedback loops, relative to the effect they are trying to correct against [ edit ] A negative feedback loop slows down a process, tending to promote stability. The loop will keep the stock near the goal, thanks to parameters, accuracy and speed of information feedback, and size of correcting flows.

For example, one way to avoid the lake getting more and more polluted might be through setting up an additional levy on the industrial plant based on measured concentrations of its effluent.  Say the plant management has to pay into a water management fund, on a weekly or monthly basis, depending on the actual amount of waste found in the lake; they will, in this case, receive a direct benefit not just from reducing their waste output, but actually reducing it enough to achieve the desired effect of reducing concentrations in the lake.  They cannot benefit from "doing damage more slowly" -- only from actually helping.  If cutting emissions, even to zero, is insufficient to allow the lake to naturally purge the waste, then they will still be on the hook for cleanup.  This is similar to the US "Superfund" system, and follows the widely accepted "polluter pays" principle.

7. Gain around driving positive feedback loops [ edit ] A positive feedback loop speeds up a process. Meadows indicates that in most cases, it is preferable to slow down a positive loop, rather than speeding up a negative one.

The eutrophication of a lake is a typical feedback loop that goes wild. In a eutrophic lake (which means well-nourished), much life, including fish, can be supported. An increase of nutrients will lead to an increase of productivity, growth of phytoplankton first, using up as much nutrients as possible, followed by growth of zooplankton , feeding up on the first ones, and increase of fish populations. The more available nutrients there are, the more productivity is increased. As plankton organisms die, they fall to the bottom of the lake, where their matter is degraded by decomposers. However, this degradation uses up available oxygen , and in the presence of huge amounts of organic matter to degrade, the medium progressively becomes anoxic (there is no more oxygen available). In time, all oxygen-dependent life dies, and the lake becomes a smelly anoxic place where no life can be supported (in particular no fish).

6. Structure of information flow (who does and does not have access to what kinds of information) [ edit ] Information flow is neither a parameter, nor a reinforcing or slowing loop, but a loop that delivers new information. It is cheaper and easier to change information flows than it is to change structure.

For example, a monthly public report of water pollution level, especially nearby the industrial release, could have a lot of effect on people's opinions regarding the industry, and lead to changes in the waste water level of pollution.

5. Rules of the system (such as incentives, punishment, constraints) [ edit ] Pay attention to rules, and to who makes them.

For example, a strengthening of the law related to chemicals release limits, or an increase of the tax amount for any water containing a given pollutant, will have a very strong effect on the lake water quality.

4. Power to add, change, evolve, or self-organize system structure [ edit ] Self-organization describes a system's ability to change itself by creating new structures, adding new negative and positive feedback loops, promoting new information flows, or making new rules.

For example, microorganisms have the ability to not only change to fit their new polluted environment, but also to undergo an evolution that makes them able to biodegrade or bioaccumulate chemical pollutants. This capacity of part of the system to participate in its own eco-evolution is a major leverage for change.

3. Goal of the system [ edit ] Changing goals changes every item listed above: parameters, feedback loops, information and self-organization.

A city council decision might be to change the goal of the lake from making it a free facility for public and private use, to a more tourist oriented facility or a conservation area. That goal change will affect several of the above leverage points: information on water quality will become mandatory and legal punishment will be set for any illegal effluent.

2. Mindset or paradigm that the system — its goals, structure, rules, delays, parameters — arises from [ edit ] A societal paradigm is an idea, a shared unstated assumption, or a system of thought that is the foundation of complex social structures. Paradigms are very hard to change, but there are no limits to paradigm change. Meadows indicates paradigms might be changed by repeatedly and consistently pointing out anomalies and failures in the current paradigm to those with open minds.

A current paradigm is "Nature is a stock of resources to be converted to human purpose". What might happen to the lake were this collective idea changed ?

1. Power to transcend paradigms [ edit ] Transcending paradigms may go beyond challenging fundamental assumptions, into the realm of changing the values and priorities that lead to the assumptions, and being able to choose among value sets at will.

Many today see Nature as a stock of resources to be converted to human purpose.  Many Native Americans see Nature as a living god, to be loved, worshipped, and lived with.  These views are incompatible, but perhaps another viewpoint could incorporate them both, along with others.

See also [ edit ] Complexity, Problem Solving, and Sustainable Societies — Joseph Tainter Conflict escalation Earth's atmosphere Focused improvement Leverage Point Modeling Nature Stock and flow Systemantics — John Gall Theory of Constraints References [ edit ] ^ Meadows, Donella (2008).

Thinking in Systems: A Primer .

Chelsea Green Publishing . pp.

145– 165.

ISBN 978-1-60358-055-7 .

"Leverage Points: Places to Intervene in a System," Reproduced original work, archived at the Donella Meadows Institute "Places to Intervene in a System," by Donella Meadows, published in a software development context Meadows, Donella H. 2008.

Thinking in Systems : A Primer , Chelsea Green Publishing , Vermont, pages 145–165.

v t e Systems science System types Art Biological Complex Coupled human–environment Ecological Economic Information Multi-agent Nervous Recommender Social Concepts Doubling time Leverage points Limiting factor Negative feedback Positive feedback Theoretical fields Control theory Cybernetics Earth system science Living systems Sociotechnical system Systemics Urban metabolism World-systems theory Analysis Biology Dynamics Ecology Engineering Neuroscience Pharmacology Philosophy Psychology Theory ( Systems thinking ) Scientists Russell L. Ackoff Victor Aladjev William Ross Ashby Ruzena Bajcsy Béla H. Bánáthy Gregory Bateson Anthony Stafford Beer Richard E. Bellman Ludwig von Bertalanffy Margaret Boden Alexander Bogdanov Kenneth E. Boulding Murray Bowen Kathleen Carley Mary Cartwright C. West Churchman Manfred Clynes George Dantzig Edsger W. Dijkstra Fred Emery Heinz von Foerster Stephanie Forrest Jay Wright Forrester Barbara Grosz Charles A. S. Hall Mike Jackson Lydia Kavraki James J. Kay Faina M. Kirillova George Klir Allenna Leonard Edward Norton Lorenz Niklas Luhmann Humberto Maturana Margaret Mead Donella Meadows Mihajlo D. Mesarovic James Grier Miller Radhika Nagpal Howard T. Odum Talcott Parsons Ilya Prigogine Qian Xuesen Anatol Rapoport John Seddon Peter Senge Claude Shannon Katia Sycara Eric Trist Francisco Varela Manuela M. Veloso Kevin Warwick Norbert Wiener Jennifer Wilby Anthony Wilden Applications Systems theory in anthropology Systems theory in archaeology Systems theory in political science Organizations List Principia Cybernetica Category Portal Commons NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐d4s4k
Cached time: 20250812021541
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.246 seconds
Real time usage: 0.301 seconds
Preprocessor visited node count: 1524/1000000
Revision size: 13007/2097152 bytes
Post‐expand include size: 41568/2097152 bytes
Template argument size: 7369/2097152 bytes
Highest expansion depth: 9/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 18761/5000000 bytes
Lua time usage: 0.157/10.000 seconds
Lua memory usage: 4552965/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  253.308      1 -total
 27.16%   68.788      1 Template:Reflist
 26.50%   67.114      1 Template:Systems_science
 26.34%   66.721      2 Template:Navbox
 23.37%   59.186      1 Template:Cite_book
 18.09%   45.812      1 Template:Short_description
 15.75%   39.894      1 Template:Primary_sources
 14.58%   36.925      1 Template:Ambox
 10.82%   27.402      2 Template:Pagetype
  6.41%   16.237     12 Template:Quote Saved in parser cache with key enwiki:pcache:207881:|#|:idhash:canonical and timestamp 20250812021541 and revision id 1219714991. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Twelve_leverage_points&oldid=1219714991 " Categories : Futures studies Systems theory Theory of constraints Hidden categories: Articles with short description Short description matches Wikidata Articles lacking reliable references from April 2011 All articles lacking reliable references This page was last edited on 19 April 2024, at 11:46 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Twelve leverage points 6 languages Add topic

