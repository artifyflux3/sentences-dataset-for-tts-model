Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Purpose 2 History Toggle History subsection 2.1 Artificial intelligence 2.2 Effective altruism 2.3 Roko's basilisk 2.4 Neoreaction 3 User base Toggle User base subsection 3.1 Notable users 4 See also 5 References Toggle the table of contents LessWrong 9 languages العربية Deutsch Español Français 日本語 ਪੰਜਾਬੀ Português Русский Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Rationality-focused community blog For the concept of choosing the least undesirable of available options, see lesser evil .

LessWrong Type of site Internet forum , blog Available in English Created by Eliezer Yudkowsky URL LessWrong.com Registration Optional, but is required for contributing content Launched February 1, 2009 ; 16 years ago ( 2009-02-01 ) Current status Active Written in JavaScript , CSS (powered by React and GraphQL ) LessWrong (also written Less Wrong ) is a community blog and forum focused on discussion of cognitive biases , philosophy , psychology , economics , rationality , and artificial intelligence , among other topics.

[ 1 ] [ 2 ] It is associated with the rationalist community .

Purpose [ edit ] LessWrong describes itself as an online forum and community aimed at improving human reasoning, rationality, and decision-making, with the goal of helping its users hold more accurate beliefs and achieve their personal objectives.

[ 3 ] The best known posts of LessWrong are "The Sequences", a series of essays which aim to describe how to avoid the typical failure modes of human reasoning with the goal of improving decision-making and the evaluation of evidence.

[ 4 ] [ 5 ] One suggestion is the use of Bayes' theorem as a decision-making tool.

[ 2 ] There is also a focus on psychological barriers that prevent good decision-making, including fear conditioning and cognitive biases , that have been studied by the psychologist Daniel Kahneman .

[ 6 ] LessWrong is also concerned with artificial intelligence, transhumanism , existential threats , and the singularity .

[ 7 ] History [ edit ] Eliezer Yudkowsky at Stanford University in 2006 LessWrong developed from Overcoming Bias, an earlier group blog focused on human rationality, which began in November 2006, with artificial intelligence researcher Eliezer Yudkowsky and economist Robin Hanson as the principal contributors. In February 2009, Yudkowsky's posts were used as the seed material to create the community blog LessWrong, and Overcoming Bias became Hanson's personal blog.

[ 8 ] In 2013, a significant portion of the rationalist community shifted focus to Scott Alexander's Slate Star Codex .

[ 4 ] Artificial intelligence [ edit ] Discussions of AI within LessWrong include AI alignment , AI safety , [ 9 ] and machine consciousness .

[ citation needed ] Articles posted on LessWrong about AI have been cited in the news media.

[ 9 ] [ 10 ] LessWrong, and its surrounding movement work on AI are the subjects of the 2019 book The AI Does Not Hate You , written by former BuzzFeed science correspondent Tom Chivers.

[ 11 ] [ 12 ] [ 13 ] Effective altruism [ edit ] LessWrong played a significant role in the development of the effective altruism (EA) movement, [ 14 ] and the two communities are closely intertwined.

[ 15 ] : 227 In a survey of LessWrong users in 2016, 664 out of 3,060 respondents, or 21.7%, identified as "effective altruists". A separate survey of effective altruists in 2014 revealed that 31% of respondents had first heard of EA through LessWrong, [ 15 ] though that number had fallen to 8.2% by 2020.

[ 16 ] Roko's basilisk [ edit ] Main article: Roko's basilisk In July 2010, LessWrong contributor Roko posted a thought experiment to the site in which an otherwise benevolent future AI system tortures people who heard of the AI before it came into existence and failed to work tirelessly to bring it into existence, in order to incentivise said work. This idea came to be known as " Roko's basilisk ", based on Roko's idea that merely hearing about the idea would give the hypothetical AI system an incentive to try such blackmail .

[ 17 ] [ 18 ] [ 7 ] Neoreaction [ edit ] After LessWrong split from Overcoming Bias, it attracted some individuals affiliated with neoreaction with discussions of eugenics and evolutionary psychology .

[ 19 ] However, Yudkowsky has strongly rejected neoreaction.

[ 20 ] [ 21 ] Additionally, in a survey among LessWrong users in 2016, only 28 out of 3060 respondents (0.92%) identified as "neoreactionary".

[ 22 ] Ana Teixeira Pinto, writing for the journal Third Text in 2019, describes Less Wrong as being a component in a "new configuration of fascist ideology taking shape under the aegis of, and working in tandem with, neoliberal governance" - pointing out that, not only was it the origin place of the Roko's Basilisk but that, also, the ethno-nationalist blog "More Right" emerged out of the LessWrong community.

[ 23 ] User base [ edit ] According to the Community Survey 2023, conducted among 558 users of the forum, the user base consists of 75% cis males and 9.6% cis females , with the rest describing themselves as trans or non-binary .  Users are in most cases between 20 and 35 years old. Almost half of the users are from the United States and most of the remainder are from Western Europe or Canada . The ethnic makeup was 78.9% non-Hispanic White , 4.9% East Asian , 4.2% South Asian , 3.6% white Hispanic , 2.6% Middle Eastern , 0.7% Black and 5.1% others. LessWrong users are highly educated (with the majority having at least a Bachelor's degree ) and work primarily in IT , engineering or other STEM fields . A majority of 67% describe themselves as atheists and only 3.7% as convinced theists . In terms of political orientation, the most frequently mentioned answers were liberal (32.3%), libertarian (25.2%) and social democratic (22.3%).

[ 24 ] Notable users [ edit ] LessWrong has been associated with several influential contributors. Founder Eliezer Yudkowsky established the platform to promote rationality and raise awareness about potential risks associated with artificial intelligence.

[ 25 ] Scott Alexander became one of the site's most popular writers before starting his own blog, Slate Star Codex, contributing discussions on AI safety and rationality.

[ 25 ] Further notable users on LessWrong include Paul Christiano , Wei Dai and Zvi Mowshowitz . A selection of posts by these and other contributors, selected through a community review process, [ 26 ] were published as parts of the essay collections "A Map That Reflects the Territory" [ 27 ] and "The Engines of Cognition".

[ 28 ] [ 26 ] [ 29 ] Ziz LaSota, who was the leader of the Zizians (an offshoot of the rationalist community), was a LessWrong user. The group was eventually banned from LessWrong and associated meetups and conferences due to an alleged pattern of aggressive behavior.

[ 30 ] See also [ edit ] Internet portal Center for Applied Rationality , a rationalist nonprofit organization based in Berkeley, California TESCREAL References [ edit ] ^ "Less Wrong FAQ" . LessWrong.

Archived from the original on 30 April 2019 . Retrieved 25 March 2014 .

^ a b Miller, James (28 July 2011).

"You Can Learn How To Become More Rational" .

Business Insider .

Archived from the original on 10 August 2018 . Retrieved 25 March 2014 .

^ "Welcome to LessWrong!" .

LessWrong . 14 June 2019.

^ a b Lewis-Kraus, Gideon (9 July 2020).

"Slate Star Codex and Silicon Valley's War Against the Media" .

The New Yorker .

Archived from the original on 10 July 2020 . Retrieved 4 August 2020 .

^ "Sequences Highlights" . LessWrong.

Archived from the original on 6 July 2024 . Retrieved 12 July 2024 .

^ Burkeman, Oliver (9 March 2012).

"This column will change your life: asked a tricky question? Answer an easier one" .

The Guardian .

Archived from the original on 26 March 2014 . Retrieved 25 March 2014 .

^ a b Tiku, Nitasha (25 July 2012).

"Faith, Hope, and Singularity: Entering the Matrix with New York's Futurist Set" .

Observer .

Archived from the original on 12 April 2019 . Retrieved 12 April 2019 .

^ "Where did Less Wrong come from? (LessWrong FAQ)" .

Archived from the original on 30 April 2019 . Retrieved 25 March 2014 .

^ a b Chivers, Tom (22 November 2023).

"What we've learned about the robot apocalypse from the OpenAI debacle" .

Semafor .

Archived from the original on 3 March 2024 . Retrieved 14 July 2024 .

Since the late 1990s those worries have become more specific, and coalesced around Nick Bostrom's 2014 book Superintelligence: Paths, Dangers, Strategies and Eliezer Yudkowsky's blog LessWrong.

^ Newport, Cal (15 March 2024).

"Can an A.I. Make Plans?" .

The New Yorker .

ISSN 0028-792X . Retrieved 14 July 2024 .

^ Cowdrey, Katherine (21 September 2017).

"W&N wins Buzzfeed science reporter's debut after auction" .

The Bookseller .

Archived from the original on 27 November 2018 . Retrieved 21 September 2017 .

^ Chivers, Tom (2019).

The AI Does Not Hate You . Weidenfeld & Nicolson.

ISBN 978-1474608770 .

^ Marriott, James (31 May 2019).

"The AI Does Not Hate You by Tom Chivers review — why the nerds are nervous" .

The Times .

ISSN 0140-0460 .

Archived from the original on 23 April 2020 . Retrieved 3 May 2020 .

^ de Lazari-Radek, Katarzyna; Singer, Peter (27 September 2017).

Utilitarianism: A Very Short Introduction . Oxford University Press. p. 110.

ISBN 9780198728795 .

^ a b Chivers, Tom (2019). "Chapter 38: The Effective Altruists".

The AI Does Not Hate You . Weidenfeld & Nicolson.

ISBN 978-1474608770 .

^ Moss, David (20 May 2021).

"EA Survey 2020: How People Get Involved in EA" .

Effective Altruism Forum .

Archived from the original on 28 July 2021 . Retrieved 28 July 2021 .

^ Love, Dylan (6 August 2014).

"WARNING: Just Reading About This Thought Experiment Could Ruin Your Life" .

Business Insider .

Archived from the original on 18 November 2018 . Retrieved 6 December 2014 .

^ Auerbach, David (17 July 2014).

"The Most Terrifying Thought Experiment of All Time" .

Slate .

Archived from the original on 25 October 2018 . Retrieved 18 July 2014 .

^ Keep, Elmo (22 June 2016).

"The Strange and Conflicting World Views of Silicon Valley Billionaire Peter Thiel" .

Fusion .

Archived from the original on 13 February 2017 . Retrieved 5 October 2016 .

Thanks to LessWrong's discussions of eugenics and evolutionary psychology, it has attracted some readers and commenters affiliated with the alt-right and neoreaction, that broad cohort of neofascist, white nationalist and misogynist trolls.

^ Riggio, Adam (23 September 2016).

"The Violence of Pure Reason: Neoreaction: A Basilisk" .

Social Epistemology Review and Reply Collective .

5 (9): 34– 41.

ISSN 2471-9560 .

Archived from the original on 5 October 2016 . Retrieved 5 October 2016 .

Land and Yarvin are openly allies with the new reactionary movement, while Yudkowsky counts many reactionaries among his fanbase despite finding their racist politics disgusting.

^ Eliezer Yudkowsky (8 April 2016).

"Untitled" .

Optimize Literally Everything (blog) .

Archived from the original on 26 May 2019 . Retrieved 7 October 2016 .

^ Hermansson, Patrik; Lawrence, David; Mulhall, Joe; Murdoch, Simon (2020).

"The Dark Enlightenment: Neoreaction and Silicon Valley" .

The International Alt-Right. Fascism for the 21st Century?

. Abingdon-on-Thames, England, UK: Routledge.

ISBN 9781138363861 .

Archived from the original on 13 June 2022 . Retrieved 2 October 2020 .

^ Pinto, Ana Teixeira (May 2019).

"Capitalism with a Transhuman Face: The Afterlife of Fascism and the Digital Frontier" .

Third Text .

33 (3). Taylor & Francis: 315– 336.

doi : 10.1080/09528822.2019.1625638 . Retrieved 5 August 2025 .

^ "2023 Survey Results" .

LessWrong . 16 February 2024.

^ a b Miller, J.D. (2017). "Reflections on the Singularity Journey". In Callaghan, V.; Miller, J.; Yampolskiy, R.; Armstrong, S. (eds.).

The Technological Singularity . The Frontiers Collection. Berlin, Heidelberg: Springer. pp.

225– 226.

ISBN 978-3-662-54033-6 .

Yudkowsky helped create the Singularity Institute (now called the Machine Intelligence Research Institute) to help mankind achieve a friendly Singularity. (Disclosure: I have contributed to the Singularity Institute.) Yudkowsky then founded the community blog http://LessWrong.com, which seeks to promote the art of rationality, to raise the sanity waterline, and to in part convince people to make considered, rational charitable donations, some of which, Yudkowsky (correctly) hoped, would go to his organization.

^ a b Gasarch, William (2022). "Review of "A Map that Reflects the Territory: Essays by the LessWrong Community" ".

ACM SIGACT News .

53 (1): 13– 24.

doi : 10.1145/3532737.3532741 .

Users wrote reviews of the best posts of 2018, and voted on them using the quadratic voting system, popularized by Glen Weyl and Vitalik Buterin. From the 2000+ posts published that year, the Review narrowed down the 44 most interesting and valuable posts.

^ Lagerros, J.; Pace, B.; LessWrong.com (2020).

A Map That Reflects the Territory: Essays by the LessWrong Community . Center for Applied Rationality.

ISBN 9781736128503 .

^ Pace, B.; LessWrong (2021).

The Engines of Cognition: Essays by the LessWrong Community . Center for Applied Rationality.

ISBN 9781736128510 .

^ Gasarch, William (2022). "Review of "The Engines of Cognition: Essays by the Less Wrong Community" ".

ACM SIGACT News .

53 (3): 6– 16.

doi : 10.1145/3561064.3561066 .

^ Ratliff, Evan (21 February 2025).

"The Delirious, Violent, Impossible True Story of the Zizians" .

Wired .

Archived from the original on 26 February 2025 . Retrieved 26 February 2025 .

Their collective exile from the rationalist community was virtually complete. They were banned from LessWrong.com, along with various CFAR meetups and conferences. An anonymous rationalist launched a site, Zizians.info, branding them "the Zizians" for the first time and warning that the group was a cult.

v t e LessWrong People Aella Scott Alexander Paul Christiano Wei Dai Robin Hanson Zvi Mowshowitz Eliezer Yudkowsky Organizations Center for Applied Rationality Future of Humanity Institute Machine Intelligence Research Institute MetaMed Zizians Works Harry Potter and the Methods of Rationality Rationality: From AI to Zombies Concepts Friendly artificial intelligence Pascal's mugging Roko's basilisk Waluigi effect v t e Effective altruism Concepts Aid effectiveness Charity assessment Demandingness objection Disability-adjusted life year Disease burden Distributional cost-effectiveness analysis Earning to give Equal consideration of interests Incremental cost-effectiveness ratio Longtermism Marginal utility Moral circle expansion Psychological barriers to effective altruism Quality-adjusted life year Utilitarianism Venture philanthropy Key figures Sam Bankman-Fried Liv Boeree Nick Bostrom Hilary Greaves Holden Karnofsky William MacAskill Dustin Moskovitz Yew-Kwang Ng Toby Ord Derek Parfit Kelsey Piper Peter Singer Brian Tomasik Cari Tuna Eliezer Yudkowsky Organizations 80,000 Hours Against Malaria Foundation Animal Charity Evaluators Animal Ethics Centre for Effective Altruism Centre for Enabling EA Learning & Research Center for High Impact Philanthropy Centre for the Study of Existential Risk Development Media International Evidence Action Faunalytics Fistula Foundation Future of Humanity Institute Future of Life Institute Founders Pledge GiveDirectly GiveWell Giving Multiplier Giving What We Can Good Food Fund The Good Food Institute Good Ventures The Humane League Mercy for Animals Machine Intelligence Research Institute Malaria Consortium Open Philanthropy Raising for Effective Giving Sentience Institute Unlimit Health Wild Animal Initiative Focus areas Biotechnology risk Climate change Cultured meat Economic stability Existential risk from artificial general intelligence Global catastrophic risk Global health Global poverty Intensive animal farming Land use reform Life extension Malaria prevention Mass deworming Neglected tropical diseases Risk of astronomical suffering Wild animal suffering Literature Doing Good Better The End of Animal Farming Famine, Affluence, and Morality The Life You Can Save Living High and Letting Die The Most Good You Can Do Practical Ethics The Precipice Superintelligence: Paths, Dangers, Strategies What We Owe the Future Events Effective Altruism Global v t e Transhumanism Overviews Transhuman Transhumanism in fiction Currents Accelerationism Effective Antinaturalism Cypherpunk Dataism Eradication of suffering Extropianism Immortalism Postgenderism Posthumanism Postpoliticism Russian cosmism Singularitarianism Technogaianism Technolibertarianism Technological utopianism Techno-progressivism Organizations Foresight Institute Humanity+ Institute for Ethics and Emerging Technologies Future of Humanity Institute LessWrong US Transhumanist Party People Andrews Bostrom Church José Luis Cordeiro K. Eric Drexler Fahy FM-2030 Freitas Fuller Fyodorov de Garis Gasson David Gobel Ben Goertzel de Grey Haldane Hanson Harari Harbisson Harris Huxley Hughes Zoltan Istvan Ray Kurzweil Land Ole Martin Moen Hans Moravec Max More Elon Musk Osborn David Pearce Martine Rothblatt Anders Sandberg Savulescu Sorgner Spencer Stock Gennady Stolyarov II Teilhard de Chardin Vernor Vinge Natasha Vita-More Mark Alan Walker Warwick Eliezer Yudkowsky Category NewPP limit report
Parsed by mw‐web.codfw.canary‐666f86d675‐rr2wh
Cached time: 20250817050427
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.649 seconds
Real time usage: 0.771 seconds
Preprocessor visited node count: 3538/1000000
Revision size: 22641/2097152 bytes
Post‐expand include size: 107326/2097152 bytes
Template argument size: 2127/2097152 bytes
Highest expansion depth: 21/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 139855/5000000 bytes
Lua time usage: 0.404/10.000 seconds
Lua memory usage: 8671436/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  672.330      1 -total
 42.15%  283.354      1 Template:Reflist
 15.61%  104.932      3 Template:Navbox
 15.05%  101.162      7 Template:Cite_web
 13.75%   92.469      1 Template:Infobox_website
 12.88%   86.583      1 Template:LessWrong
 12.26%   82.419      1 Template:Infobox
  8.63%   58.007      1 Template:Short_description
  7.42%   49.893      8 Template:Cite_news
  7.24%   48.666      7 Template:Cite_book Saved in parser cache with key enwiki:pcache:27228956:|#|:idhash:canonical and timestamp 20250817050427 and revision id 1305288707. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=LessWrong&oldid=1305288707 " Categories : Internet forums Transhumanist organizations Internet properties established in 2009 Effective altruism Rationalism LessWrong rationalists Hidden categories: Articles with short description Short description matches Wikidata Use dmy dates from June 2022 All articles with unsourced statements Articles with unsourced statements from July 2024 This page was last edited on 11 August 2025, at 05:01 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents LessWrong 9 languages Add topic

