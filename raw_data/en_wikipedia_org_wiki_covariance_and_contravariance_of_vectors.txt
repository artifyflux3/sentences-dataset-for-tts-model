Title: Covariance and contravariance of vectors

URL Source: https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors

Published Time: 2003-03-29T07:43:46Z

Markdown Content:
[![Image 1](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Vector_1-form.svg/500px-Vector_1-form.svg.png)](https://en.wikipedia.org/wiki/File:Vector_1-form.svg)

 A  vector, **v**, represented in terms of tangent basis**e**1, **e**2, **e**3 to the  coordinate curves (_left_),dual basis, covector basis, or reciprocal basis**e**1, **e**2, **e**3 to  coordinate surfaces (_right_), in [3-d](https://en.wikipedia.org/wiki/Three-dimensional "Three-dimensional") general _[curvilinear coordinates](https://en.wikipedia.org/wiki/Curvilinear\_coordinates "Curvilinear coordinates")_(_q_ 1, _q_ 2, _q_ 3), a [tuple](https://en.wikipedia.org/wiki/Tuple "Tuple") of numbers to define a point in a [position space](https://en.wikipedia.org/wiki/Position_space "Position space"). Note the basis and cobasis coincide only when the basis is [orthonormal](https://en.wikipedia.org/wiki/Orthonormal_basis "Orthonormal basis").[[1]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-1)[_[specify](https://en.wikipedia.org/wiki/Wikipedia:Citing\_sources "Wikipedia:Citing sources")_]

In [physics](https://en.wikipedia.org/wiki/Physics "Physics"), especially in [multilinear algebra](https://en.wikipedia.org/wiki/Multilinear_algebra "Multilinear algebra") and [tensor analysis](https://en.wikipedia.org/wiki/Tensor_analysis "Tensor analysis"), **covariance** and **contravariance** describe how the quantitative description of certain geometric or physical entities changes with a [change of basis](https://en.wikipedia.org/wiki/Change_of_basis "Change of basis").[[2]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-2) Briefly, a contravariant vector is a list of numbers that transforms oppositely to a change of basis, and a covariant vector is a list of numbers that transforms in the same way. Contravariant vectors are often just called _vectors_ and covariant vectors are called _covectors_ or _dual vectors_. The terms _covariant_ and _contravariant_ were introduced by [James Joseph Sylvester](https://en.wikipedia.org/wiki/James_Joseph_Sylvester "James Joseph Sylvester") in 1851.[[3]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-3)[[4]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-4)

[Curvilinear coordinate systems](https://en.wikipedia.org/wiki/Curvilinear_coordinate_system "Curvilinear coordinate system"), such as [cylindrical](https://en.wikipedia.org/wiki/Cylindrical_coordinates "Cylindrical coordinates") or [spherical coordinates](https://en.wikipedia.org/wiki/Spherical_coordinates "Spherical coordinates"), are often used in physical and geometric problems. Associated with any coordinate system is a natural choice of coordinate basis for vectors based at each point of the space, and covariance and contravariance are particularly important for understanding how the coordinate description of a vector changes by passing from one coordinate system to another. [Tensors](https://en.wikipedia.org/wiki/Tensor "Tensor") are objects in [multilinear algebra](https://en.wikipedia.org/wiki/Multilinear_algebra "Multilinear algebra") that can have aspects of both covariance and contravariance.

In physics, a vector typically arises as the outcome of a measurement or series of measurements, and is represented as a list (or [tuple](https://en.wikipedia.org/wiki/Tuple "Tuple")) of numbers such as

![Image 2: {\displaystyle (v_{1},v_{2},v_{3}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a5133e94868f4f69ec17f285591b5af5849cbb5a)
The numbers in the list depend on the choice of [coordinate system](https://en.wikipedia.org/wiki/Coordinate_system "Coordinate system"). For instance, if the vector represents position with respect to an observer ([position vector](https://en.wikipedia.org/wiki/Position_vector "Position vector")), then the coordinate system may be obtained from a system of rigid rods, or reference axes, along which the components _v_ 1, _v_ 2, and _v_ 3 are measured. For a vector to represent a geometric object, it must be possible to describe how it looks in any other coordinate system. That is to say, the components of the vectors will _transform_ in a certain way in passing from one coordinate system to another.

A simple illustrative case is that of a [Euclidean vector](https://en.wikipedia.org/wiki/Euclidean_vector "Euclidean vector"). For a vector, once a set of basis vectors has been defined, then the components of that vector will always vary _opposite_ to that of the basis vectors. That vector is therefore defined as a _contravariant_ tensor. Take a standard position vector for example. By changing the scale of the reference axes from meters to centimeters (that is, _dividing_ the scale of the reference axes by 100, so that the basis vectors now are ![Image 3: {\displaystyle .01}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd790eb494ba1f343a0281804eec34b7b01130cb) meters long), the components of the measured [position](https://en.wikipedia.org/wiki/Position_(geometry) "Position (geometry)")[vector](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics) "Vector (mathematics and physics)") are _multiplied_ by 100. A vector's components change scale _inversely_ to changes in scale to the reference axes, and consequently a vector is called a _contravariant_ tensor.

A _vector_, which is an example of a _contravariant_ tensor, has components that transform inversely to the transformation of the reference axes, (with example transformations including [rotation](https://en.wikipedia.org/wiki/Rotation_(mathematics) "Rotation (mathematics)") and [dilation](https://en.wikipedia.org/wiki/Dilation_(metric_space) "Dilation (metric space)")). [The vector itself does not change under these operations](https://en.wikipedia.org/wiki/Active_and_passive_transformation#Passive_transformation "Active and passive transformation"); instead, the components of the vector change in a way that cancels the change in the spatial axes. In other words, if the reference axes were rotated in one direction, the component representation of the vector would rotate in exactly the opposite way. Similarly, if the reference axes were stretched in one direction, the components of the vector, would reduce in an exactly compensating way. Mathematically, if the coordinate system undergoes a transformation described by an ![Image 4: {\displaystyle n\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/59d2b4cb72e304526cf5b5887147729ea259da78)[invertible matrix](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix")_M_, so that the basis vectors transform according to ![Image 5: {\displaystyle {\begin{bmatrix}\mathbf {e} _{1}^{\prime }\ \mathbf {e} _{2}^{\prime }\ ...\ \mathbf {e} _{n}^{\prime }\end{bmatrix}}={\begin{bmatrix}\mathbf {e} _{1}\ \mathbf {e} _{2}\ ...\ \mathbf {e} _{n}\end{bmatrix}}M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8a3411a9b15be7e68abe91cec2c2dca89315cd7c), then the components of a vector **v** in the original basis ( ![Image 6: {\displaystyle v^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a593908199cba4c17cea2fc670fdc171f83f537d) ) must be similarly transformed via ![Image 7: {\displaystyle {\begin{bmatrix}v^{1}{^{\prime }}\\v^{2}{^{\prime }}\\...\\v^{n}{^{\prime }}\end{bmatrix}}=M^{-1}{\begin{bmatrix}v^{1}\\v^{2}\\...\\v^{n}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cae6679e8e9546e3aa5b6119062db9ffaa3d5fec). The components of a _vector_ are often represented arranged in a column.

By contrast, a _covector_ has components that transform like the reference axes. It lives in the dual vector space, and represents a linear map from vectors to scalars. The dot product operator involving vectors is a good example of a covector. To illustrate, assume we have a covector defined as ![Image 8: {\displaystyle \mathbf {v} \ \cdot }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ad4c22e8c0ddabf827c50268069ab7d27c39e28) , where ![Image 9: {\displaystyle \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c1866e359fbfd2e0f606c725ba5cc37a5195d6) is a vector. The components of this covector in some arbitrary basis are ![Image 10: {\displaystyle {\begin{bmatrix}\mathbf {v} \cdot \mathbf {e} _{1}&\mathbf {v} \cdot \mathbf {e} _{2}&...&\mathbf {v} \cdot \mathbf {e} _{n}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c69bad9a2b4172b6f408d1d464e70f3279140534), with ![Image 11: {\displaystyle {\begin{bmatrix}\mathbf {e} _{1}\ \mathbf {e} _{2}\ ...\ \mathbf {e} _{n}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c975e21b28628fd5fece97f0c5c4409bf538f9b1) being the basis vectors in the corresponding vector space. (This can be derived by noting that we want to get the correct answer for the dot product operation when multiplying by an arbitrary vector ![Image 12: {\displaystyle \mathbf {w} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/20795664b5b048744a2fd88977851104cc5816f8) , with components ![Image 13: {\displaystyle {\begin{bmatrix}w^{1}\\w^{2}\\...\\w^{n}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ecec113f380418578370aa1591109971845b1051)). The covariance of these covector components is then seen by noting that if a transformation described by an ![Image 14: {\displaystyle n\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/59d2b4cb72e304526cf5b5887147729ea259da78)[invertible matrix](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix")_M_ were to be applied to the basis vectors in the corresponding vector space, ![Image 15: {\displaystyle {\begin{bmatrix}\mathbf {e} _{1}^{\prime }\ \mathbf {e} _{2}^{\prime }\ ...\ \mathbf {e} _{n}^{\prime }\end{bmatrix}}={\begin{bmatrix}\mathbf {e} _{1}\ \mathbf {e} _{2}\ ...\ \mathbf {e} _{n}\end{bmatrix}}M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8a3411a9b15be7e68abe91cec2c2dca89315cd7c), then the components of the covector ![Image 16: {\displaystyle \mathbf {v} \ \cdot }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ad4c22e8c0ddabf827c50268069ab7d27c39e28) will transform with the same matrix ![Image 17: {\displaystyle M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd), namely, ![Image 18: {\displaystyle {\begin{bmatrix}\mathbf {v} \cdot \mathbf {e} _{1}^{\prime }&\mathbf {v} \cdot \mathbf {e} _{2}^{\prime }&...&\mathbf {v} \cdot \mathbf {e} _{n}^{\prime }\end{bmatrix}}={\begin{bmatrix}\mathbf {v} \cdot \mathbf {e} _{1}&\mathbf {v} \cdot \mathbf {e} _{2}&...&\mathbf {v} \cdot \mathbf {e} _{n}\end{bmatrix}}M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/85024205707489a8d7ce57ee1e55f9f3f85ad959). The components of a _covector_ are often represented arranged in a row.

A third concept related to covariance and contravariance is [invariance](https://en.wikipedia.org/wiki/Invariant_(physics) "Invariant (physics)"). A [scalar](https://en.wikipedia.org/wiki/Scalar_(physics) "Scalar (physics)") (also called type-0 or rank-0 tensor) is an object that does not vary with the change in basis. An example of a physical [observable](https://en.wikipedia.org/wiki/Observable "Observable") that is a scalar is the [mass](https://en.wikipedia.org/wiki/Mass "Mass") of a particle. The single, scalar value of mass is independent to changes in basis vectors and consequently is called _invariant_. The magnitude of a vector (such as [distance](https://en.wikipedia.org/wiki/Euclidean_distance "Euclidean distance")) is another example of an invariant, because it remains fixed even if geometrical vector components vary. (For example, for a position vector of length ![Image 19: {\displaystyle 3}](https://wikimedia.org/api/rest_v1/media/math/render/svg/991e33c6e207b12546f15bdfee8b5726eafbbb2f) meters, if all [Cartesian](https://en.wikipedia.org/wiki/Cartesian_coordinate_system "Cartesian coordinate system") basis vectors are changed from ![Image 20: {\displaystyle 1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/92d98b82a3778f043108d4e20960a9193df57cbf) meters in length to ![Image 21: {\displaystyle .01}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd790eb494ba1f343a0281804eec34b7b01130cb) meters in length, the length of the position vector remains unchanged at ![Image 22: {\displaystyle 3}](https://wikimedia.org/api/rest_v1/media/math/render/svg/991e33c6e207b12546f15bdfee8b5726eafbbb2f) meters, although the vector components will all increase by a factor of ![Image 23: {\displaystyle 100}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0572cd017c6d7936a12737c9d614a2f801f94a36)). The scalar product of a vector and a covector is invariant, because one has components that vary with the base change, and the other has components that vary oppositely, and the two effects cancel out. One thus says that covectors are _dual_ to vectors.

Thus, to summarize:

The general formulation of covariance and contravariance refers to how the components of a coordinate vector transform under a [change of basis](https://en.wikipedia.org/wiki/Change_of_basis "Change of basis") ([passive transformation](https://en.wikipedia.org/wiki/Active_and_passive_transformation "Active and passive transformation")).[[5]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-5) Thus let _V_ be a [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") of dimension _n_ over a [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)") of [scalars](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)")_S_, and let each of **f** = (_X_ 1, ..., _X_ _n_) and **f**′ = (_Y_ 1, ..., _Y_ _n_) be a [basis](https://en.wikipedia.org/wiki/Basis_of_a_vector_space "Basis of a vector space") of _V_.[[note 1]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-6) Also, let the [change of basis](https://en.wikipedia.org/wiki/Change_of_basis "Change of basis") from **f** to **f**′ be given by

![Image 24: {\displaystyle \mathbf {f} \mapsto \mathbf {f} '={\biggl (}\sum _{i}a_{1}^{i}X_{i},\dots ,\sum _{i}a_{n}^{i}X_{i}{\biggr )}=\mathbf {f} A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/84d68d63339abbb78e2cea90afde5371b562be1e)1

for some [invertible](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix")_n_×_n_ matrix _A_ with entries ![Image 25: {\displaystyle a_{j}^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3dbffe3f7cdbb8b3bc11c952ef57aad7cb271903). Here, each vector _Y_ _j_ of the **f**′ basis is a linear combination of the vectors _X_ _i_ of the **f** basis, so that

![Image 26: {\displaystyle Y_{j}=\sum _{i}a_{j}^{i}X_{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/099ac2567f6875258467a4a6c35952fef30be28a)
which are the columns of the matrix product ![Image 27: {\displaystyle \mathbf {f} A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/af81007b9e330379339947bb7d07d9502e29672e).

### Contravariant transformation

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=3 "Edit section: Contravariant transformation")]

A vector ![Image 28: {\displaystyle v}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597) in _V_ is expressed uniquely as a [linear combination](https://en.wikipedia.org/wiki/Linear_combination "Linear combination") of the elements ![Image 29: {\displaystyle X_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/af4a0955af42beb5f85aa05fb8c07abedc13990d) of the **f** basis as

![Image 30: {\displaystyle v=\sum _{i}v^{i}[\mathbf {f} ]X_{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/90b72abefff4c45053a324fb2fb787cf3218e4d8)2

where _v_ _i_[**f**] are elements of the field _S_ known as the **components** of _v_ in the **f** basis. Denote the [column vector](https://en.wikipedia.org/wiki/Column_vector "Column vector") of components of _v_ by **v**[**f**]:

![Image 31: {\displaystyle \mathbf {v} [\mathbf {f} ]={\begin{bmatrix}v^{1}[\mathbf {f} ]\\v^{2}[\mathbf {f} ]\\\vdots \\v^{n}[\mathbf {f} ]\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/afc428882c2502b9b82f8e88856bb8985f1836bb)
so that (**[2](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#math_2)**) can be rewritten as a matrix product

![Image 32: {\displaystyle v=\mathbf {f} \,\mathbf {v} [\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/38d62c1fce2d588ff5543c46b26b15d354db8e7b)
The vector _v_ may also be expressed in terms of the **f**′ basis, so that

![Image 33: {\displaystyle v=\mathbf {f'} \,\mathbf {v} [\mathbf {f'} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f24c4af1d82c8bba470455e014d188cb989085c9)
However, since the vector _v_ itself is invariant under the choice of basis,

![Image 34: {\displaystyle \mathbf {f} \,\mathbf {v} [\mathbf {f} ]=v=\mathbf {f'} \,\mathbf {v} [\mathbf {f'} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7f6ae22d1881c5be8c2e435fd3810a23551dda3d)
The invariance of _v_ combined with the relationship (**[1](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#math_1)**) between **f** and **f**′ implies that

![Image 35: {\displaystyle \mathbf {f} \,\mathbf {v} [\mathbf {f} ]=\mathbf {f} A\,\mathbf {v} [\mathbf {f} A],}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b3962d1a863f65b032f3b7d5a05175eac62af5bf)
giving the transformation rule

![Image 36: {\displaystyle \mathbf {v} [\mathbf {f'} ]=\mathbf {v} [\mathbf {f} A]=A^{-1}\mathbf {v} [\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6630fe6471c5410ab309a1c0ab87c7223b5464e7)
In terms of components,

![Image 37: {\displaystyle v^{i}[\mathbf {f} A]=\sum _{j}{\tilde {a}}_{j}^{i}v^{j}[\mathbf {f} ]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/36ca85c58ceffe95646387b0e4db8ca41c7d0e28)
where the coefficients ![Image 38: {\displaystyle {\tilde {a}}_{j}^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/330d1eb4f1f7d9cc4a35532ce69f508fca9286ca) are the entries of the [inverse matrix](https://en.wikipedia.org/wiki/Inverse_matrix "Inverse matrix") of _A_.

Because the components of the vector _v_ transform with the _inverse_ of the matrix _A_, these components are said to **transform contravariantly** under a change of basis.

The way _A_ relates the two pairs is depicted in the following informal diagram using an arrow. The reversal of the arrow indicates a contravariant change:

![Image 39: {\displaystyle {\begin{aligned}\mathbf {f} &\longrightarrow \mathbf {f'} \\v[\mathbf {f} ]&\longleftarrow v[\mathbf {f'} ]\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a5d2943b0ec7e69cb464eb00796b0bff1d69a0f0)

### Covariant transformation

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=4 "Edit section: Covariant transformation")]

A [linear functional](https://en.wikipedia.org/wiki/Linear_functional "Linear functional")_α_ on _V_ is expressed uniquely in terms of its **components** (elements in _S_) in the **f** basis as

![Image 40: {\displaystyle \alpha (X_{i})=\alpha _{i}[\mathbf {f} ],\quad i=1,2,\dots ,n.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/78cef0e07edd6ef776ee9446d8b5657e8cc60714)
These components are the action of _α_ on the basis vectors _X_ _i_ of the **f** basis.

Under the change of basis from **f** to **f**′ (via **[1](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#math_1)**), the components transform so that

![Image 41: {\displaystyle {\begin{aligned}\alpha _{i}[\mathbf {f} A]&=\alpha (Y_{i})\\&=\alpha {\biggl (}\sum _{j}a_{i}^{j}X_{j}{\biggr )}\\&=\sum _{j}a_{i}^{j}\alpha (X_{j})\\&=\sum _{j}a_{i}^{j}\alpha _{j}[\mathbf {f} ].\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5841ce1ac49d3390f41ea4a1e5e51bed4a4aad00)3

Denote the [row vector](https://en.wikipedia.org/wiki/Row_vector "Row vector") of components of _α_ by _α_[**f**]:

![Image 42: {\displaystyle \mathbf {\alpha } [\mathbf {f} ]={\begin{bmatrix}\alpha _{1}[\mathbf {f} ],\alpha _{2}[\mathbf {f} ],\dots ,\alpha _{n}[\mathbf {f} ]\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0247136386ed2b4d1f43e74799c7f407e11ed256)
so that (**[3](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#math_3)**) can be rewritten as the matrix product

![Image 43: {\displaystyle \alpha [\mathbf {f} A]=\alpha [\mathbf {f} ]A.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/436acd9e89552942c6d549a6a038ca9937d8b7c8)
Because the components of the linear functional α transform with the matrix _A_, these components are said to **transform covariantly** under a change of basis.

The way _A_ relates the two pairs is depicted in the following informal diagram using an arrow. A covariant relationship is indicated since the arrows travel in the same direction:

![Image 44: {\displaystyle {\begin{aligned}\mathbf {f} &\longrightarrow \mathbf {f'} \\\alpha [\mathbf {f} ]&\longrightarrow \alpha [\mathbf {f'} ]\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4c04607cbf2bfc1a7da5b554f0420330d1f74b79)
Had a column vector representation been used instead, the transformation law would be the [transpose](https://en.wikipedia.org/wiki/Matrix_transpose "Matrix transpose")

![Image 45: {\displaystyle \alpha ^{\mathrm {T} }[\mathbf {f} A]=A^{\mathrm {T} }\alpha ^{\mathrm {T} }[\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/16f71a15d988fc7aaedf7dc061404b7fcbabd86d)
The choice of basis **f** on the vector space _V_ defines uniquely a set of coordinate functions on _V_, by means of

![Image 46: {\displaystyle x^{i}[\mathbf {f} ](v)=v^{i}[\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bf418accb17eaa6ed703c602ee0d86c16f3f7b20)
The coordinates on _V_ are therefore contravariant in the sense that

![Image 47: {\displaystyle x^{i}[\mathbf {f} A]=\sum _{k=1}^{n}{\tilde {a}}_{k}^{i}x^{k}[\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d965941430a4a727c5f692ca8e41f85be625e9e5)
Conversely, a system of _n_ quantities _v_ _i_ that transform like the coordinates _x_ _i_ on _V_ defines a contravariant vector (or simply vector). A system of _n_ quantities that transform oppositely to the coordinates is then a covariant vector (or covector).

This formulation of contravariance and covariance is often more natural in applications in which there is a coordinate space (a [manifold](https://en.wikipedia.org/wiki/Manifold "Manifold")) on which vectors live as [tangent vectors](https://en.wikipedia.org/wiki/Tangent_vector "Tangent vector") or [cotangent vectors](https://en.wikipedia.org/wiki/Cotangent_vector "Cotangent vector"). Given a local coordinate system _x_ _i_ on the manifold, the reference axes for the coordinate system are the [vector fields](https://en.wikipedia.org/wiki/Vector_field "Vector field")

![Image 48: {\displaystyle X_{1}={\frac {\partial }{\partial x^{1}}},\dots ,X_{n}={\frac {\partial }{\partial x^{n}}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5a33e433701889d3bc86aada04c65bf814823058)
This gives rise to the frame **f** = (_X_ 1, ..., _X_ _n_) at every point of the coordinate patch.

If _y_ _i_ is a different coordinate system and

![Image 49: {\displaystyle Y_{1}={\frac {\partial }{\partial y^{1}}},\dots ,Y_{n}={\frac {\partial }{\partial y^{n}}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fda5534209367cc309bba9881ac67a3a0ea018fd)
then the frame **f'** is related to the frame **f** by the inverse of the [Jacobian matrix](https://en.wikipedia.org/wiki/Jacobian_matrix "Jacobian matrix") of the coordinate transition:

![Image 50: {\displaystyle \mathbf {f} '=\mathbf {f} J^{-1},\quad J=\left({\frac {\partial y^{i}}{\partial x^{j}}}\right)_{i,j=1}^{n}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d68c12f8c87f4bbb4bb012ca7b29745ba96280a)
Or, in indices,

![Image 51: {\displaystyle {\frac {\partial }{\partial y^{i}}}=\sum _{j=1}^{n}{\frac {\partial x^{j}}{\partial y^{i}}}{\frac {\partial }{\partial x^{j}}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/046759af939ced1c84b2d722d6b9c9e23d0ad4e4)
A tangent vector is by definition a vector that is a linear combination of the coordinate partials ![Image 52: {\displaystyle \partial /\partial x^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/72d7ebb1242190262e82f953aada89e48e0cb0c8). Thus a tangent vector is defined by

![Image 53: {\displaystyle v=\sum _{i=1}^{n}v^{i}[\mathbf {f} ]X_{i}=\mathbf {f} \ \mathbf {v} [\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f7f4bfe3855fb91cf213b8e6c7e4a7dbede12dd3)
Such a vector is contravariant with respect to change of frame. Under changes in the coordinate system, one has

![Image 54: {\displaystyle \mathbf {v} \left[\mathbf {f} '\right]=\mathbf {v} \left[\mathbf {f} J^{-1}\right]=J\,\mathbf {v} [\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ab62393cdc939fedcec59eb7945ffc07a8a6e79d)
Therefore, the components of a tangent vector transform via

![Image 55: {\displaystyle v^{i}\left[\mathbf {f} '\right]=\sum _{j=1}^{n}{\frac {\partial y^{i}}{\partial x^{j}}}v^{j}[\mathbf {f} ].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ea205057474e8e596a9406f07597320be1e4a660)
Accordingly, a system of _n_ quantities _v_ _i_ depending on the coordinates that transform in this way on passing from one coordinate system to another is called a contravariant vector.

Covariant and contravariant components of a vector with a metric
----------------------------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=6 "Edit section: Covariant and contravariant components of a vector with a metric")]

[![Image 56](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Covariantcomponents.gif/500px-Covariantcomponents.gif)](https://en.wikipedia.org/wiki/File:Covariantcomponents.gif)

Covariant and contravariant components of a vector when the basis is not orthogonal.

In a finite-dimensional [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space")_V_ over a field _K_ with a non-degenerate symmetric [bilinear form](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form")_g_: _V_ × _V_ → _K_ (which may be referred to as the [metric tensor](https://en.wikipedia.org/wiki/Metric_tensor "Metric tensor")), there is little distinction between covariant and contravariant vectors, because the [bilinear form](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form") allows covectors to be identified with vectors. That is, a vector _v_ uniquely determines a covector _α_ via

![Image 57: {\displaystyle \alpha (w)=g(v,w)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/191687f294e7393aad20337509ea048c2701c709)
for all vectors _w_. Conversely, each covector _α_ determines a unique vector _v_ by this equation. Because of this identification of vectors with covectors, one may speak of the **covariant components** or **contravariant components** of a vector, that is, they are just representations of the same vector using the [reciprocal basis](https://en.wikipedia.org/wiki/Dual_basis "Dual basis").

Given a basis **f** = (_X_ 1, ..., _X_ _n_) of _V_, there is a unique reciprocal basis **f**# = (_Y_ 1, ..., _Y_ _n_) of _V_ determined by requiring that

![Image 58: {\displaystyle g(Y^{i},X_{j})=\delta _{j}^{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8ac0a1e843d41f3df4903744fb37cdead7f5f1fb)
the [Kronecker delta](https://en.wikipedia.org/wiki/Kronecker_delta "Kronecker delta"). In terms of these bases, any vector _v_ can be written in two ways:

![Image 59: {\displaystyle {\begin{aligned}v&=\sum _{i}v^{i}[\mathbf {f} ]X_{i}=\mathbf {f} \,\mathbf {v} [\mathbf {f} ]\\&=\sum _{i}v_{i}[\mathbf {f^{\sharp }} ]Y^{i}=\mathbf {f} ^{\sharp }\mathbf {v} ^{\sharp }[\mathbf {f} ].\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8180d5c74eb3627caeba8e8c40fa611cc371b14e)
The components _v_ _i_[**f**] are the **contravariant components** of the vector _v_ in the basis **f**, and the components _v_ _i_[**f**] are the **covariant components** of _v_ in the basis **f**. The terminology is justified because under a change of basis,

![Image 60: {\displaystyle \mathbf {v} [\mathbf {f} A]=A^{-1}\mathbf {v} [\mathbf {f} ],\quad \mathbf {v} ^{\sharp }[\mathbf {f} A]=A^{T}\mathbf {v} ^{\sharp }[\mathbf {f} ]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aa764ce0e623ba1ddce6976c6292abe202018ffe)
where ![Image 61: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3) is an invertible ![Image 62: {\displaystyle n\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/59d2b4cb72e304526cf5b5887147729ea259da78) matrix, and the [matrix transpose](https://en.wikipedia.org/wiki/Matrix_transpose "Matrix transpose") has its usual meaning.

In the Euclidean plane, the [dot product](https://en.wikipedia.org/wiki/Dot_product "Dot product") allows for vectors to be identified with covectors. If ![Image 63: {\displaystyle \mathbf {e} _{1},\mathbf {e} _{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/612f0b7cebef2b5fd72128c07c99c4d2b28b34c9) is a basis, then the dual basis ![Image 64: {\displaystyle \mathbf {e} ^{1},\mathbf {e} ^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/37e2ecc49d52089c87dd29a500592385874f89dc) satisfies

![Image 65: {\displaystyle {\begin{aligned}\mathbf {e} ^{1}\cdot \mathbf {e} _{1}=1,&\quad \mathbf {e} ^{1}\cdot \mathbf {e} _{2}=0\\\mathbf {e} ^{2}\cdot \mathbf {e} _{1}=0,&\quad \mathbf {e} ^{2}\cdot \mathbf {e} _{2}=1.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f84b43e021d8f8f6288c817c4e7dc39b21f8ac07)
Thus, **e**1 and **e**2 are perpendicular to each other, as are **e**2 and **e**1, and the lengths of **e**1 and **e**2 normalized against **e**1 and **e**2, respectively.

For example,[[6]](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_note-7) suppose that we are given a basis **e**1, **e**2 consisting of a pair of vectors making a 45° angle with one another, such that **e**1 has length 2 and **e**2 has length 1. Then the dual basis vectors are given as follows:

*   **e**2 is the result of rotating **e**1 through an angle of 90° (where the sense is measured by assuming the pair **e**1, **e**2 to be positively oriented), and then rescaling so that **e**2 ⋅ **e**2 = 1 holds.
*   **e**1 is the result of rotating **e**2 through an angle of 90°, and then rescaling so that **e**1 ⋅ **e**1 = 1 holds.

Applying these rules, we find

![Image 66: {\displaystyle \mathbf {e} ^{1}={\frac {1}{2}}\mathbf {e} _{1}-{\frac {1}{\sqrt {2}}}\mathbf {e} _{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fea668787ae2be8f59b4a74c4af4ee468f1612cd)
and

![Image 67: {\displaystyle \mathbf {e} ^{2}=-{\frac {1}{\sqrt {2}}}\mathbf {e} _{1}+2\mathbf {e} _{2}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/19c64a18cca5152a0ffe525791e878b4404e5159)
Thus the change of basis matrix in going from the original basis to the reciprocal basis is

![Image 68: {\displaystyle R={\begin{bmatrix}{\frac {1}{2}}&-{\frac {1}{\sqrt {2}}}\\-{\frac {1}{\sqrt {2}}}&2\end{bmatrix}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5fe5a0fe977d1f1f84ee9b03dcd340ace98a324c)
since

![Image 69: {\displaystyle [\mathbf {e} ^{1}\ \mathbf {e} ^{2}]=[\mathbf {e} _{1}\ \mathbf {e} _{2}]{\begin{bmatrix}{\frac {1}{2}}&-{\frac {1}{\sqrt {2}}}\\-{\frac {1}{\sqrt {2}}}&2\end{bmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b5846e698a99413b0601d451ac86e543924a4544)
For instance, the vector

![Image 70: {\displaystyle v={\frac {3}{2}}\mathbf {e} _{1}+2\mathbf {e} _{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5af660712d7c0877bd650e1db20a0439428f0fa1)
is a vector with contravariant components

![Image 71: {\displaystyle v^{1}={\frac {3}{2}},\quad v^{2}=2.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/af1c8098ba5bebab31128a09dfbe62ed3a3261be)
The covariant components are obtained by equating the two expressions for the vector _v_:

![Image 72: {\displaystyle v=v_{1}\mathbf {e} ^{1}+v_{2}\mathbf {e} ^{2}=v^{1}\mathbf {e} _{1}+v^{2}\mathbf {e} _{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dc45ae579d8f10b02451f2be52151eda63225bf8)
so

![Image 73: {\displaystyle {\begin{aligned}{\begin{bmatrix}v_{1}\\v_{2}\end{bmatrix}}&=R^{-1}{\begin{bmatrix}v^{1}\\v^{2}\end{bmatrix}}\\&={\begin{bmatrix}4&{\sqrt {2}}\\{\sqrt {2}}&1\end{bmatrix}}{\begin{bmatrix}v^{1}\\v^{2}\end{bmatrix}}\\&={\begin{bmatrix}6+2{\sqrt {2}}\\2+{\frac {3}{\sqrt {2}}}\end{bmatrix}}\end{aligned}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f9302395c701eecc667718dd484a348897fbae7d)

### Three-dimensional Euclidean space

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=9 "Edit section: Three-dimensional Euclidean space")]

In the three-dimensional [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space"), one can also determine explicitly the dual basis to a given set of [basis vectors](https://en.wikipedia.org/wiki/Basis_vector "Basis vector")**e**1, **e**2, **e**3 of _E_ 3 that are not necessarily assumed to be orthogonal nor of unit norm. The dual basis vectors are:

![Image 74: {\displaystyle \mathbf {e} ^{1}={\frac {\mathbf {e} _{2}\times \mathbf {e} _{3}}{\mathbf {e} _{1}\cdot (\mathbf {e} _{2}\times \mathbf {e} _{3})}};\qquad \mathbf {e} ^{2}={\frac {\mathbf {e} _{3}\times \mathbf {e} _{1}}{\mathbf {e} _{2}\cdot (\mathbf {e} _{3}\times \mathbf {e} _{1})}};\qquad \mathbf {e} ^{3}={\frac {\mathbf {e} _{1}\times \mathbf {e} _{2}}{\mathbf {e} _{3}\cdot (\mathbf {e} _{1}\times \mathbf {e} _{2})}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68180e0e37d5bcc2fb21f249716513577947a8e9)
Even when the **e**i and **e**i are not [orthonormal](https://en.wikipedia.org/wiki/Orthonormality "Orthonormality"), they are still mutually reciprocal:

![Image 75: {\displaystyle \mathbf {e} ^{i}\cdot \mathbf {e} _{j}=\delta _{j}^{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4c0042ae4f57857d0c5ab176c6e9ab2172ae9566)
Then the contravariant components of any vector **v** can be obtained by the [dot product](https://en.wikipedia.org/wiki/Dot_product "Dot product") of **v** with the dual basis vectors:

![Image 76: {\displaystyle q^{1}=\mathbf {v} \cdot \mathbf {e} ^{1};\qquad q^{2}=\mathbf {v} \cdot \mathbf {e} ^{2};\qquad q^{3}=\mathbf {v} \cdot \mathbf {e} ^{3}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0c12bffc382d3e8d4f28da24b85f9af633cf27bd)
Likewise, the covariant components of **v** can be obtained from the dot product of **v** with basis vectors, viz.

![Image 77: {\displaystyle q_{1}=\mathbf {v} \cdot \mathbf {e} _{1};\qquad q_{2}=\mathbf {v} \cdot \mathbf {e} _{2};\qquad q_{3}=\mathbf {v} \cdot \mathbf {e} _{3}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cd76e89d1e1cb51576cecbf89b3c96f8459c3fe0)
Then **v** can be expressed in two (reciprocal) ways, viz.

![Image 78: {\displaystyle \mathbf {v} =q^{i}\mathbf {e} _{i}=q^{1}\mathbf {e} _{1}+q^{2}\mathbf {e} _{2}+q^{3}\mathbf {e} _{3}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a758536496c0a6d4d480a5d907cd69027a12005b)
or

![Image 79: {\displaystyle \mathbf {v} =q_{i}\mathbf {e} ^{i}=q_{1}\mathbf {e} ^{1}+q_{2}\mathbf {e} ^{2}+q_{3}\mathbf {e} ^{3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1719ab2ac925a3e4337305ba132324ca4e22cf66)
Combining the above relations, we have

![Image 80: {\displaystyle \mathbf {v} =(\mathbf {v} \cdot \mathbf {e} ^{i})\mathbf {e} _{i}=(\mathbf {v} \cdot \mathbf {e} _{i})\mathbf {e} ^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9665036d261ae26f63b904483751854e6a2c4ea3)
and we can convert between the basis and dual basis with

![Image 81: {\displaystyle q_{i}=\mathbf {v} \cdot \mathbf {e} _{i}=(q^{j}\mathbf {e} _{j})\cdot \mathbf {e} _{i}=(\mathbf {e} _{j}\cdot \mathbf {e} _{i})q^{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/73a6a7124e21aa1417037ecb5809686e4f9bd8bc)
and

![Image 82: {\displaystyle q^{i}=\mathbf {v} \cdot \mathbf {e} ^{i}=(q_{j}\mathbf {e} ^{j})\cdot \mathbf {e} ^{i}=(\mathbf {e} ^{j}\cdot \mathbf {e} ^{i})q_{j}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0137acf1628c3c9521cc1dadb6b1452d9ab5cc14)
If the basis vectors are [orthonormal](https://en.wikipedia.org/wiki/Orthonormal "Orthonormal"), then they are the same as the dual basis vectors.

### Vector spaces of any dimension

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=10 "Edit section: Vector spaces of any dimension")]

The following applies to any vector space of dimension _n_ equipped with a non-degenerate commutative and distributive dot product, and thus also to the Euclidean spaces of any dimension.

All indices in the formulas run from 1 to _n_. The [Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation "Einstein notation") for the implicit summation of the terms with the same upstairs (contravariant) and downstairs (covariant) indices is followed.

The historical and geometrical meaning of the terms _contravariant_ and _covariant_ will be explained at the end of this section.

1.   **Covariant basis** of a vector space of dimension _n_: ![Image 83: {\displaystyle \mathbf {e_{j}} \triangleq }](https://wikimedia.org/api/rest_v1/media/math/render/svg/83f5c949919d7c886742ee51dfda6159e44c59db) {any linearly independent basis for which in general is ![Image 84: {\displaystyle \mathbf {e_{i}} \cdot \mathbf {e_{j}} \neq \delta _{ij}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/94ee3a5d82ed33654adf4ecb7f106546d2bf98a6)}, i.e. not necessarily [orthonormal](https://en.wikipedia.org/wiki/Orthonormal "Orthonormal") (D.1).
2.   **Contravariant components** of a vector ![Image 85: {\displaystyle \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c1866e359fbfd2e0f606c725ba5cc37a5195d6): ![Image 86: {\displaystyle v^{i}\triangleq \{v^{i}\mid \mathbf {v} =v^{i}\mathbf {e_{i}} \}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1b417b5e91c2b7813d69168acbb72da9e46e9a19) (D.2).
3.   **Dual (contravariant) basis** of a vector space of dimension _n_: ![Image 87: {\displaystyle \mathbf {e^{i}} \triangleq \{\mathbf {e^{i}} :\mathbf {e^{i}} \cdot \mathbf {e_{j}} =\delta _{j}^{i}\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8f051b2cc782d580bd2e1fad90000db934c40a12) (D.3).
4.   **Covariant components** of a vector ![Image 88: {\displaystyle \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c1866e359fbfd2e0f606c725ba5cc37a5195d6): ![Image 89: {\displaystyle v_{i}\triangleq \{v_{i}\mid \mathbf {v} =v_{i}\mathbf {e^{i}} \}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/941db5b8b871de5b7fef9576bc09e2c51a9a1c48) (D.4).
5.   **Components of the covariant metric tensor**: ![Image 90: {\displaystyle g_{ij}\triangleq \mathbf {e_{i}} \cdot \mathbf {e_{j}} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/22a3d08d27f50ffdc72042624925382614ba9f27); the metric tensor can be considered a square matrix, since it only has two covariant indices: ![Image 91: {\displaystyle G\triangleq \{g_{ij}\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/30c5d85c7f2e9389f4fc81dc98ddbb39ace59536); for the commutative property of the dot product, the ![Image 92: {\displaystyle g_{ij}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e7c1130c3dec178129b287a3672c72f88e773832) are symmetric (D.5).
6.   **Components of the contravariant metric tensor**: ![Image 93: {\displaystyle g^{ij}\triangleq \{h_{ij}:G^{-1}=\{h_{ij}\}\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/53da1318f442a5bc0d868d367ef2586567e7ad2e); these are the elements of the inverse of the covariant metric tensor/matrix ![Image 94: {\displaystyle G^{-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2eb7adaa3f00e2cba206032fac791d65dd488de7), and for the properties of the inverse of a symmetric matrix, they're also symmetric (D.6).

![Image 95: {\displaystyle \mathbf {e^{i}} {\stackrel {\text{(2)}}{=}}g^{ik}\mathbf {e_{k}} ;\mathbf {e^{j}} {\stackrel {\text{(2)}}{=}}g^{jm}\mathbf {e_{m}} \to \mathbf {e^{i}} \cdot \mathbf {e^{j}} =g^{ik}g^{jm}(\mathbf {e_{k}} \cdot \mathbf {e_{m}} ){\stackrel {\text{(D.5)}}{=}}g^{ik}g^{jm}g_{km}{\stackrel {\text{(1)}}{=}}\delta _{m}^{i}g^{jm}=g^{ji}{\stackrel {\text{(D.6)}}{=}}g^{ij},\ {\text{Q.E.D.}}\quad \blacksquare }](https://wikimedia.org/api/rest_v1/media/math/render/svg/5bf350af9a28c20af6106b599d02bb9164f78d20)

![Image 96: {\displaystyle \mathbf {v} {\stackrel {\text{(D.2)}}{=}}v^{i}\mathbf {e_{i}} ;\mathbf {v} {\stackrel {\text{(D.4)}}{=}}v_{j}\mathbf {e^{j}} {\stackrel {\text{(2)}}{=}}v_{j}(g^{ji}\mathbf {e_{i}} )\to v^{i}\mathbf {e_{i}} =v_{j}g^{ji}\mathbf {e_{i}} ,\forall i\to v^{i}=g^{ji}v_{j}{\stackrel {\text{(D.6)}}{=}}g^{ij}v_{j},\ {\text{Q.E.D.}}\quad \blacksquare }](https://wikimedia.org/api/rest_v1/media/math/render/svg/547615a0af369222f83f47fa908e0a275f146a88)

![Image 97: {\displaystyle \mathbf {v} \cdot \mathbf {e_{i}} {\stackrel {\text{(D.4)}}{=}}(v_{j}\mathbf {e^{j}} )\cdot \mathbf {e_{i}} {\stackrel {\text{(D.3)}}{=}}v_{j}\delta _{i}^{j}=v_{i},\ {\text{Q.E.D.}}\quad \blacksquare }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e73e6cd4119839f8599659a68bd864f0e4b5d47)

![Image 98: {\displaystyle \mathbf {u} \cdot \mathbf {v} {\stackrel {\text{(D.2)}}{=}}(u^{i}\mathbf {e_{i}} )\cdot (v^{j}\mathbf {e_{j}} )=(\mathbf {e_{i}} \cdot \mathbf {e_{j}} )u^{i}v^{j}{\stackrel {\text{(D.5)}}{=}}g_{ij}u^{i}v^{j},\ {\text{Q.E.D.}}\quad \blacksquare }](https://wikimedia.org/api/rest_v1/media/math/render/svg/ec7a772ac09d347d23a95dd8bc0d18cd40dda7b0).

*   ![Image 99: {\displaystyle \mathbf {u} \cdot \mathbf {v} =g^{ij}u_{i}v_{j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d964b5655d42d51bb9758b882e4e732e5b38e7d0) (10).

_Proof:_ specular to (9).

#### Historical and geometrical meaning

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=13 "Edit section: Historical and geometrical meaning")]

[![Image 100](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Covariant_and_contravariant_vector_components.svg/250px-Covariant_and_contravariant_vector_components.svg.png)](https://en.wikipedia.org/wiki/File:Covariant_and_contravariant_vector_components.svg)

Aid for explaining the geometrical meaning of covariant and contravariant vector components.

Considering this figure for the case of an Euclidean space with ![Image 101: {\displaystyle n=2}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a02c8bd752d2cc859747ca1f3a508281bdbc3b34), since ![Image 102: {\displaystyle \mathbf {v} =\mathbf {OA} +\mathbf {OB} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/fefe3205af904bcba8ffe90c0c101d89782e2e80), if we want to express ![Image 103: {\displaystyle \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c1866e359fbfd2e0f606c725ba5cc37a5195d6) in terms of the covariant basis, we have to multiply the basis vectors by the coefficients ![Image 104: {\displaystyle v^{1}={\frac {\vert \mathbf {OA} \vert }{\vert \mathbf {e_{1}} \vert }},v^{2}={\frac {\vert \mathbf {OB} \vert }{\vert \mathbf {e_{2}} \vert }}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9c54af205f9991367915649a840a2481f643f167).

With ![Image 105: {\displaystyle \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/35c1866e359fbfd2e0f606c725ba5cc37a5195d6) and thus ![Image 106: {\displaystyle \mathbf {OA} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/d3dfd3edb26c1107ada72b227b8f726907d46ae0) and ![Image 107: {\displaystyle \mathbf {OB} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6508ed968fa411bbd69a8675e07803b01a253a8f) fixed, if the module of ![Image 108: {\displaystyle \mathbf {e_{i}} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/2cafb0e24f75af7ddb0c594cf9ad4290d2a251ba) increases, the value of the ![Image 109: {\displaystyle v^{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a593908199cba4c17cea2fc670fdc171f83f537d) component decreases, and that's why they're called _contra_-variant (with respect to the variation of the basis vectors module).

Symmetrically, corollary (7) states that the ![Image 110: {\displaystyle v_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7dffe5726650f6daac54829972a94f38eb8ec127) components equal the dot product ![Image 111: {\displaystyle \mathbf {v} \cdot \mathbf {e_{i}} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/e3c42424f9127f6f4682b17509b944632312bfc5) between the vector and the covariant basis vectors, and since this is directly proportional to the basis vectors module, they're called _co_-variant.

If we consider the dual (contravariant) basis, the situation is perfectly specular: the covariant components are _contra_-variant with respect to the module of the dual basis vectors, while the contravariant components are _co_-variant.

So in the end it all boils down to a matter of convention: historically the first non-[orthonormal](https://en.wikipedia.org/wiki/Orthonormal "Orthonormal") basis of the vector space of choice was called "covariant", its dual basis "contravariant", and the corresponding components named specularly.

If the covariant basis becomes [orthonormal](https://en.wikipedia.org/wiki/Orthonormal "Orthonormal"), the dual contravariant basis aligns with it and the covariant components collapse into the contravariant ones, the most familiar situation when dealing with geometrical Euclidean vectors. ![Image 112: {\displaystyle G}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b) and ![Image 113: {\displaystyle G^{-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2eb7adaa3f00e2cba206032fac791d65dd488de7) become the identity matrix ![Image 114: {\displaystyle I}](https://wikimedia.org/api/rest_v1/media/math/render/svg/535ea7fc4134a31cbe2251d9d3511374bc41be9f), and:

![Image 115: {\displaystyle g_{ij}=\delta _{ij},g^{ij}=\delta ^{ij},\mathbf {u} \cdot \mathbf {v} =\delta _{ij}u^{i}v^{j}=\sum _{i}u^{i}v^{i}=\delta ^{ij}u_{i}v_{j}=\sum _{i}u_{i}v_{i}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/91568b669597639380ec479d814b1adf0ef9700b)

If the metric is non-Euclidean, but for instance [Minkowskian](https://en.wikipedia.org/wiki/Minkowski_space#Minkowski_metric "Minkowski space") like in the [special relativity](https://en.wikipedia.org/wiki/Special_relativity "Special relativity") and [general relativity](https://en.wikipedia.org/wiki/General_relativity "General relativity") theories, the basis are never orthonormal, even in the case of special relativity where ![Image 116: {\displaystyle G}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b) and ![Image 117: {\displaystyle G^{-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2eb7adaa3f00e2cba206032fac791d65dd488de7) become, for ![Image 118: {\displaystyle n=4,\ \eta \triangleq diag(1,-1,-1,-1)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/da7d7accfd01e6e257f67d52055c9ef09f538066). In this scenario, the covariant and contravariant components always differ.

Use in tensor analysis
----------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=14 "Edit section: Use in tensor analysis")]

The distinction between covariance and contravariance is particularly important for computations with [tensors](https://en.wikipedia.org/wiki/Tensor "Tensor"), which often have **mixed variance**. This means that they have both covariant and contravariant components, or both vector and covector components. The valence of a tensor is the number of covariant and contravariant terms, and in [Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation "Einstein notation"), covariant components have lower indices, while contravariant components have upper indices. The duality between covariance and contravariance intervenes whenever a vector or tensor quantity is represented by its components, although modern [differential geometry](https://en.wikipedia.org/wiki/Differential_geometry "Differential geometry") uses more sophisticated [index-free methods to represent tensors](https://en.wikipedia.org/wiki/Tensor_(intrinsic_definition) "Tensor (intrinsic definition)").

In [tensor analysis](https://en.wikipedia.org/wiki/Tensor_analysis "Tensor analysis"), a **covariant** vector varies more or less reciprocally to a corresponding contravariant vector. Expressions for lengths, areas and volumes of objects in the vector space can then be given in terms of tensors with covariant and contravariant indices. Under simple expansions and contractions of the coordinates, the reciprocity is exact; under affine transformations the components of a vector intermingle on going between covariant and contravariant expression.

On a [manifold](https://en.wikipedia.org/wiki/Manifold "Manifold"), a [tensor field](https://en.wikipedia.org/wiki/Tensor_field "Tensor field") will typically have multiple, upper and lower indices, where Einstein notation is widely used. When the manifold is equipped with a [metric](https://en.wikipedia.org/wiki/Metric_tensor "Metric tensor"), covariant and contravariant indices become very closely related to one another. Contravariant indices can be turned into covariant indices by [contracting](https://en.wikipedia.org/wiki/Contraction_of_a_tensor "Contraction of a tensor") with the metric tensor. The reverse is possible by contracting with the (matrix) inverse of the metric tensor. Note that in general, no such relation exists in spaces not endowed with a metric tensor. Furthermore, from a more abstract standpoint, a tensor is simply "there" and its components of either kind are only calculational artifacts whose values depend on the chosen coordinates.

The explanation in geometric terms is that a general tensor will have contravariant indices as well as covariant indices, because it has parts that live in the [tangent bundle](https://en.wikipedia.org/wiki/Tangent_bundle "Tangent bundle") as well as the [cotangent bundle](https://en.wikipedia.org/wiki/Cotangent_bundle "Cotangent bundle").

A contravariant vector is one which transforms like ![Image 119: {\displaystyle {\frac {dx^{\mu }}{d\tau }}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2bce346c232bf0b1d0b59b44ddca5e9da4975aaa), where ![Image 120: {\displaystyle x^{\mu }\!}](https://wikimedia.org/api/rest_v1/media/math/render/svg/884e5232362f97553a6330d10aa8d5a44d0c8c5d) are the coordinates of a particle at its [proper time](https://en.wikipedia.org/wiki/Proper_time "Proper time")![Image 121: {\displaystyle \tau }](https://wikimedia.org/api/rest_v1/media/math/render/svg/38a7dcde9730ef0853809fefc18d88771f95206c). A covariant vector is one which transforms like ![Image 122: {\displaystyle {\frac {\partial \varphi }{\partial x^{\mu }}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8ebd7fca9c72a8c3739148957b0caf27dc04d435), where ![Image 123: {\displaystyle \varphi }](https://wikimedia.org/api/rest_v1/media/math/render/svg/33ee699558d09cf9d653f6351f9fda0b2f4aaa3e) is a scalar field.

Algebra and geometry
--------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Covariance_and_contravariance_of_vectors&action=edit&section=15 "Edit section: Algebra and geometry")]

In [category theory](https://en.wikipedia.org/wiki/Category_theory "Category theory"), there are [covariant functors](https://en.wikipedia.org/wiki/Covariant_functor "Covariant functor") and [contravariant functors](https://en.wikipedia.org/wiki/Contravariant_functor "Contravariant functor"). The assignment of the [dual space](https://en.wikipedia.org/wiki/Dual_space "Dual space") to a vector space is a standard example of a contravariant functor. Contravariant (resp. covariant) vectors are contravariant (resp. covariant) functors from a ![Image 124: {\displaystyle {\text{GL}}(n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c8d0207f6e0abb4e43b56713ef8f876988c4019d)-[torsor](https://en.wikipedia.org/wiki/Torsor "Torsor") to the fundamental representation of ![Image 125: {\displaystyle {\text{GL}}(n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c8d0207f6e0abb4e43b56713ef8f876988c4019d). Similarly, tensors of higher degree are functors with values in other representations of ![Image 126: {\displaystyle {\text{GL}}(n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c8d0207f6e0abb4e43b56713ef8f876988c4019d). However, some constructions of [multilinear algebra](https://en.wikipedia.org/wiki/Multilinear_algebra "Multilinear algebra") are of "mixed" variance, which prevents them from being functors.

In [differential geometry](https://en.wikipedia.org/wiki/Differential_geometry "Differential geometry"), the components of a vector relative to a basis of the [tangent bundle](https://en.wikipedia.org/wiki/Tangent_bundle "Tangent bundle") are covariant if they change with the same linear transformation as a change of basis. They are contravariant if they change by the inverse transformation. This is sometimes a source of confusion for two distinct but related reasons. The first is that vectors whose components are covariant (called covectors or [1-forms](https://en.wikipedia.org/wiki/1-form "1-form")) actually [pull back](https://en.wikipedia.org/wiki/Pullback_(differential_geometry) "Pullback (differential geometry)") under smooth functions, meaning that the operation assigning the space of covectors to a smooth manifold is actually a _contravariant_ functor. Likewise, vectors whose components are contravariant [push forward](https://en.wikipedia.org/wiki/Pushforward_(differential) "Pushforward (differential)") under smooth mappings, so the operation assigning the space of (contravariant) vectors to a smooth manifold is a _covariant_ functor. Secondly, in the classical approach to differential geometry, it is not bases of the tangent bundle that are the most primitive object, but rather changes in the coordinate system. Vectors with contravariant components transform in the same way as changes in the coordinates (because these actually change oppositely to the induced change of basis). Likewise, vectors with covariant components transform in the opposite way as changes in the coordinates.

*   [Active and passive transformation](https://en.wikipedia.org/wiki/Active_and_passive_transformation "Active and passive transformation")
*   [Mixed tensor](https://en.wikipedia.org/wiki/Mixed_tensor "Mixed tensor")
*   [Two-point tensor](https://en.wikipedia.org/wiki/Two-point_tensor "Two-point tensor"), a generalization allowing indices to reference multiple vector bases

1.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-6 "Jump up")**A basis **f** may here profitably be viewed as a [linear isomorphism](https://en.wikipedia.org/wiki/Linear_isomorphism "Linear isomorphism") from **R**_n_ to _V_. Regarding **f** as a row vector whose entries are the elements of the basis, the associated linear isomorphism is then ![Image 127: {\displaystyle \mathbf {x} \mapsto \mathbf {f} \mathbf {x} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8e1449b533a481dec771c7cd3d180b5f24ea6607)

1.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-1 "Jump up")**Misner, C.; Thorne, K.S.; Wheeler, J.A. (1973). [_Gravitation_](https://en.wikipedia.org/wiki/Gravitation_(book) "Gravitation (book)"). W.H. Freeman. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-7167-0344-0](https://en.wikipedia.org/wiki/Special:BookSources/0-7167-0344-0 "Special:BookSources/0-7167-0344-0").
2.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-2 "Jump up")**Frankel, Theodore (2012). _The geometry of physics: an introduction_. Cambridge: Cambridge University Press. p.42. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-107-60260-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-107-60260-1 "Special:BookSources/978-1-107-60260-1"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[739094283](https://search.worldcat.org/oclc/739094283).
3.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-3 "Jump up")**Sylvester, J.J. (1851). ["On the general theory of associated algebraical forms"](https://books.google.com/books?id=mZ9EAAAAcAAJ&pg=PA289). _Cambridge and Dublin Mathematical Journal_. Vol.6. pp.289–293.
4.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-4 "Jump up")**Sylvester, J.J. University Press (16 February 2012). _The collected mathematical papers of James Joseph Sylvester_. Vol.3, 1870–1883. Cambridge University Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1107661431](https://en.wikipedia.org/wiki/Special:BookSources/978-1107661431 "Special:BookSources/978-1107661431"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[758983870](https://search.worldcat.org/oclc/758983870).
5.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-5 "Jump up")**J A Schouten (1954). _Ricci calculus_ (2 ed.). Springer. p.6.
6.   **[^](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors#cite_ref-7 "Jump up")**Bowen, Ray; Wang, C.-C. (2008) [1976]. ["§3.14 Reciprocal Basis and Change of Basis"](https://books.google.com/books?id=Hr5bhIVWr4wC&pg=PA76). _Introduction to Vectors and Tensors_. Dover. pp.78, 79, 81. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780486469140](https://en.wikipedia.org/wiki/Special:BookSources/9780486469140 "Special:BookSources/9780486469140").

*   Kusse, Bruce R.; Westwig, Erik A. (2010), _Mathematical Physics: Applied Mathematics for Scientists and Engineers_ (2nd ed.), Wiley, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-527-61814-9](https://en.wikipedia.org/wiki/Special:BookSources/978-3-527-61814-9 "Special:BookSources/978-3-527-61814-9").
*   [Arfken, George B.](https://en.wikipedia.org/wiki/George_B._Arfken "George B. Arfken"); Weber, Hans J. (2005), _Mathematical Methods for Physicists_ (6th ed.), Harcourt, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-12-059876-0](https://en.wikipedia.org/wiki/Special:BookSources/0-12-059876-0 "Special:BookSources/0-12-059876-0").
*   Dodson, C. T. J.; Poston, T. (1991), _Tensor geometry_, Graduate Texts in Mathematics, vol.130 (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-52018-4](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-52018-4 "Special:BookSources/978-3-540-52018-4"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1223091](https://mathscinet.ams.org/mathscinet-getitem?mr=1223091).
*   Greub, Werner Hildbert (1967), _Multilinear algebra_, Die Grundlehren der Mathematischen Wissenschaften, Band 136, Springer, [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1967mual.book.....G](https://ui.adsabs.harvard.edu/abs/1967mual.book.....G), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387038278](https://en.wikipedia.org/wiki/Special:BookSources/9780387038278 "Special:BookSources/9780387038278"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0224623](https://mathscinet.ams.org/mathscinet-getitem?mr=0224623).
*   [Sternberg, Shlomo](https://en.wikipedia.org/wiki/Shlomo_Sternberg "Shlomo Sternberg") (1983), _Lectures on differential geometry_, Chelsea, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8284-0316-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8284-0316-0 "Special:BookSources/978-0-8284-0316-0").
*   Sylvester, J.J. (1853), ["On a Theory of the Syzygetic Relations of Two Rational Integral Functions, Comprising an Application to the Theory of Sturm's Functions, and That of the Greatest Algebraical Common Measure"](https://zenodo.org/record/1432412), _Philosophical Transactions of the Royal Society of London_, **143**: 407–548, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1098/rstl.1853.0018](https://doi.org/10.1098%2Frstl.1853.0018), [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[108572](https://www.jstor.org/stable/108572).
*   Weinreich, Gabriel (1998), _Geometrical Vectors_, Chicago Lectures in Physics, The University of Chicago Press, p.126, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780226890487](https://en.wikipedia.org/wiki/Special:BookSources/9780226890487 "Special:BookSources/9780226890487")

*   ["Covariant tensor"](https://www.encyclopediaofmath.org/index.php?title=Covariant_tensor), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society"), 2001 [1994]
*   ["Contravariant tensor"](https://www.encyclopediaofmath.org/index.php?title=Contravariant_tensor), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society"), 2001 [1994]
*   [Weisstein, Eric W.](https://en.wikipedia.org/wiki/Eric_W._Weisstein "Eric W. Weisstein")["Covariant Tensor"](https://mathworld.wolfram.com/CovariantTensor.html). _[MathWorld](https://en.wikipedia.org/wiki/MathWorld "MathWorld")_.
*   [Weisstein, Eric W.](https://en.wikipedia.org/wiki/Eric_W._Weisstein "Eric W. Weisstein")["Contravariant Tensor"](https://mathworld.wolfram.com/ContravariantTensor.html). _[MathWorld](https://en.wikipedia.org/wiki/MathWorld "MathWorld")_.
*   [Invariance, Contravariance, and Covariance](http://www.mathpages.com/home/kmath398/kmath398.htm)
*   Dullemond, Kees; Peeters, Kasper (2010). ["Introduction to tensor calculus"](http://www.ita.uni-heidelberg.de/~dullemond/lectures/tensor/tensor.pdf)(PDF).
