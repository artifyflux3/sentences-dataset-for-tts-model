Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions Toggle Definitions subsection 1.1 Background 1.2 Density 1.3 Derivation of the pdf 2 Properties Toggle Properties subsection 2.1 Moment generating function 2.2 Moments 2.3 Cumulative distribution function 2.3.1 Approximation (including for quantiles) 3 Related distributions Toggle Related distributions subsection 3.1 Transformations 4 Occurrence and applications Toggle Occurrence and applications subsection 4.1 Use in tolerance intervals 5 Notes 6 References Toggle the table of contents Noncentral chi-squared distribution 6 languages Català فارسی Français Italiano 日本語 Українська Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Noncentral generalization of the chi-squared distribution Noncentral chi-squared Probability density function Cumulative distribution function Parameters k > 0 {\displaystyle k>0\,} degrees of freedom λ λ > 0 {\displaystyle \lambda >0\,} non-centrality parameter Support x ∈ ∈ [ 0 , + ∞ ∞ ) {\displaystyle x\in [0,+\infty )\;} PDF 1 2 e − − ( x + λ λ ) / 2 ( x λ λ ) k / 4 − − 1 / 2 I k / 2 − − 1 ( λ λ x ) {\displaystyle {\frac {1}{2}}e^{-(x+\lambda )/2}\left({\frac {x}{\lambda }}\right)^{k/4-1/2}I_{k/2-1}({\sqrt {\lambda x}})} CDF 1 − − Q k 2 ( λ λ , x ) {\displaystyle 1-Q_{\frac {k}{2}}\left({\sqrt {\lambda }},{\sqrt {x}}\right)} with Marcum Q-function Q M ( a , b ) {\displaystyle Q_{M}(a,b)} Mean k + λ λ {\displaystyle k+\lambda \,} Variance 2 ( k + 2 λ λ ) {\displaystyle 2(k+2\lambda )\,} Skewness 2 3 / 2 ( k + 3 λ λ ) ( k + 2 λ λ ) 3 / 2 {\displaystyle {\frac {2^{3/2}(k+3\lambda )}{(k+2\lambda )^{3/2}}}} Excess kurtosis 12 ( k + 4 λ λ ) ( k + 2 λ λ ) 2 {\displaystyle {\frac {12(k+4\lambda )}{(k+2\lambda )^{2}}}} MGF exp ⁡ ⁡ ( λ λ t 1 − − 2 t ) ( 1 − − 2 t ) k / 2 for 2 t < 1 {\displaystyle {\frac {\exp \left({\frac {\lambda t}{1-2t}}\right)}{(1-2t)^{k/2}}}{\text{ for }}2t<1} CF exp ⁡ ⁡ ( i λ λ t 1 − − 2 i t ) ( 1 − − 2 i t ) k / 2 {\displaystyle {\frac {\exp \left({\frac {i\lambda t}{1-2it}}\right)}{(1-2it)^{k/2}}}} In probability theory and statistics , the noncentral chi-squared distribution (or noncentral chi-square distribution, noncentral χ χ 2 {\displaystyle \chi ^{2}} distribution ) is a noncentral generalization of the chi-squared distribution .  It often arises in the power analysis of statistical tests in which the null distribution is (perhaps asymptotically) a chi-squared distribution; important examples of such tests are the likelihood-ratio tests .

[ 1 ] Definitions [ edit ] Background [ edit ] Let ( X 1 , X 2 , … … , X i , … … , X k ) {\displaystyle (X_{1},X_{2},\ldots ,X_{i},\ldots ,X_{k})} be k independent , normally distributed random variables with means μ μ i {\displaystyle \mu _{i}} and unit variances. Then the random variable ∑ ∑ i = 1 k X i 2 {\displaystyle \sum _{i=1}^{k}X_{i}^{2}} is distributed according to the noncentral chi-squared distribution. It has two parameters: k {\displaystyle k} which specifies the number of degrees of freedom (i.e. the number of X i {\displaystyle X_{i}} ), and λ λ {\displaystyle \lambda } which is related to the mean of the random variables X i {\displaystyle X_{i}} by: λ λ = ∑ ∑ i = 1 k μ μ i 2 .

{\displaystyle \lambda =\sum _{i=1}^{k}\mu _{i}^{2}.} λ λ {\displaystyle \lambda } is sometimes called the noncentrality parameter . Note that some references define λ λ {\displaystyle \lambda } in other ways, such as half of the above sum, or its square root.

This distribution arises in multivariate statistics as a derivative of the multivariate normal distribution . While the central chi-squared distribution is the squared norm of a random vector with N ( 0 k , I k ) {\displaystyle N(0_{k},I_{k})} distribution (i.e., the squared distance from the origin to a point taken at random from that distribution), the non-central χ χ 2 {\displaystyle \chi ^{2}} is the squared norm of a random vector with N ( μ μ , I k ) {\displaystyle N(\mu ,I_{k})} distribution. Here 0 k {\displaystyle 0_{k}} is a zero vector of length k , μ μ = ( μ μ 1 , … … , μ μ k ) {\displaystyle \mu =(\mu _{1},\ldots ,\mu _{k})} and I k {\displaystyle I_{k}} is the identity matrix of size k .

Density [ edit ] The probability density function (pdf) is given by f X ( x ; k , λ λ ) = ∑ ∑ i = 0 ∞ ∞ e − − λ λ / 2 ( λ λ / 2 ) i i !

f Y k + 2 i ( x ) , {\displaystyle f_{X}(x;k,\lambda )=\sum _{i=0}^{\infty }{\frac {e^{-\lambda /2}(\lambda /2)^{i}}{i!}}f_{Y_{k+2i}}(x),} where Y q {\displaystyle Y_{q}} is distributed as chi-squared with q {\displaystyle q} degrees of freedom.

From this representation, the noncentral chi-squared distribution is seen to be a Poisson-weighted mixture of central chi-squared distributions. Suppose that a random variable J has a Poisson distribution with mean λ λ / 2 {\displaystyle \lambda /2} , and the conditional distribution of Z given J = i is chi-squared with k + 2 i degrees of freedom. Then the unconditional distribution of Z is non-central chi-squared with k degrees of freedom, and non-centrality parameter λ λ {\displaystyle \lambda } .

Alternatively, the pdf can be written as f X ( x ; k , λ λ ) = 1 2 e − − ( x + λ λ ) / 2 ( x λ λ ) k / 4 − − 1 / 2 I k / 2 − − 1 ( λ λ x ) {\displaystyle f_{X}(x;k,\lambda )={\frac {1}{2}}e^{-(x+\lambda )/2}\left({\frac {x}{\lambda }}\right)^{k/4-1/2}I_{k/2-1}({\sqrt {\lambda x}})} where I ν ν ( y ) {\displaystyle I_{\nu }(y)} is a modified Bessel function of the first kind given by I ν ν ( y ) = ( y / 2 ) ν ν ∑ ∑ j = 0 ∞ ∞ ( y 2 / 4 ) j j !

Γ Γ ( ν ν + j + 1 ) .

{\displaystyle I_{\nu }(y)=(y/2)^{\nu }\sum _{j=0}^{\infty }{\frac {(y^{2}/4)^{j}}{j!\Gamma (\nu +j+1)}}.} Using the relation between Bessel functions and hypergeometric functions , the pdf can also be written as: [ 2 ] f X ( x ; k , λ λ ) = e − − λ λ / 2 0 F 1 ( ; k / 2 ; λ λ x / 4 ) 1 2 k / 2 Γ Γ ( k / 2 ) e − − x / 2 x k / 2 − − 1 .

{\displaystyle f_{X}(x;k,\lambda )={{\rm {e}}^{-\lambda /2}}_{0}F_{1}(;k/2;\lambda x/4){\frac {1}{2^{k/2}\Gamma (k/2)}}{\rm {e}}^{-x/2}x^{k/2-1}.} The case k = 0 ( zero degrees of freedom ), in which case the distribution has a discrete component at zero, is discussed by Torgersen (1972) and further by Siegel (1979).

[ 3 ] [ 4 ] Derivation of the pdf [ edit ] The derivation of the probability density function is most easily done by performing the following steps: Since X 1 , … … , X k {\displaystyle X_{1},\ldots ,X_{k}} have unit variances, their joint distribution is spherically symmetric, up to a location shift.

The spherical symmetry then implies that the distribution of X = X 1 2 + ⋯ ⋯ + X k 2 {\displaystyle X=X_{1}^{2}+\cdots +X_{k}^{2}} depends on the means only through the squared length, λ λ = μ μ 1 2 + ⋯ ⋯ + μ μ k 2 {\displaystyle \lambda =\mu _{1}^{2}+\cdots +\mu _{k}^{2}} . Without loss of generality, we can therefore take μ μ 1 = λ λ {\displaystyle \mu _{1}={\sqrt {\lambda }}} and μ μ 2 = ⋯ ⋯ = μ μ k = 0 {\displaystyle \mu _{2}=\cdots =\mu _{k}=0} .

Now derive the density of X = X 1 2 {\displaystyle X=X_{1}^{2}} (i.e. the k = 1 case). Simple transformation of random variables shows that f X ( x , 1 , λ λ ) = 1 2 x ( ϕ ϕ ( x − − λ λ ) + ϕ ϕ ( x + λ λ ) ) = 1 2 π π x e − − ( x + λ λ ) / 2 cosh ⁡ ⁡ ( λ λ x ) , {\displaystyle {\begin{aligned}f_{X}(x,1,\lambda )&={\frac {1}{2{\sqrt {x}}}}\left(\phi ({\sqrt {x}}-{\sqrt {\lambda }})+\phi ({\sqrt {x}}+{\sqrt {\lambda }})\right)\\&={\frac {1}{\sqrt {2\pi x}}}e^{-(x+\lambda )/2}\cosh({\sqrt {\lambda x}}),\end{aligned}}} where ϕ ϕ ( ⋅ ⋅ ) {\displaystyle \phi (\cdot )} is the standard normal density.

Expand the cosh term in a Taylor series . This gives the Poisson-weighted mixture representation of the density, still for k = 1. The indices on the chi-squared random variables in the series above are 1 + 2 i in this case.

Finally, for the general case. We've assumed, without loss of generality, that X 2 , … … , X k {\displaystyle X_{2},\ldots ,X_{k}} are standard normal, and so X 2 2 + ⋯ ⋯ + X k 2 {\displaystyle X_{2}^{2}+\cdots +X_{k}^{2}} has a central chi-squared distribution with ( k − 1) degrees of freedom, independent of X 1 2 {\displaystyle X_{1}^{2}} . Using the poisson-weighted mixture representation for X 1 2 {\displaystyle X_{1}^{2}} , and the fact that the sum of chi-squared random variables is also a chi-square, completes the result. The indices in the series are (1 + 2 i ) + ( k − 1) = k + 2 i as required.

Properties [ edit ] Moment generating function [ edit ] The moment-generating function is given by M ( t ; k , λ λ ) = exp ⁡ ⁡ ( λ λ t 1 − − 2 t ) ( 1 − − 2 t ) k / 2 .

{\displaystyle M(t;k,\lambda )={\frac {\exp \left({\frac {\lambda t}{1-2t}}\right)}{(1-2t)^{k/2}}}.} Moments [ edit ] The first few raw moments are: μ μ 1 ′ = k + λ λ {\displaystyle \mu '_{1}=k+\lambda } μ μ 2 ′ = ( k + λ λ ) 2 + 2 ( k + 2 λ λ ) {\displaystyle \mu '_{2}=(k+\lambda )^{2}+2(k+2\lambda )} μ μ 3 ′ = ( k + λ λ ) 3 + 6 ( k + λ λ ) ( k + 2 λ λ ) + 8 ( k + 3 λ λ ) {\displaystyle \mu '_{3}=(k+\lambda )^{3}+6(k+\lambda )(k+2\lambda )+8(k+3\lambda )} μ μ 4 ′ = ( k + λ λ ) 4 + 12 ( k + λ λ ) 2 ( k + 2 λ λ ) + 4 ( 11 k 2 + 44 k λ λ + 36 λ λ 2 ) + 48 ( k + 4 λ λ ) .

{\displaystyle \mu '_{4}=(k+\lambda )^{4}+12(k+\lambda )^{2}(k+2\lambda )+4(11k^{2}+44k\lambda +36\lambda ^{2})+48(k+4\lambda ).} The first few central moments are: μ μ 2 = 2 ( k + 2 λ λ ) {\displaystyle \mu _{2}=2(k+2\lambda )\,} μ μ 3 = 8 ( k + 3 λ λ ) {\displaystyle \mu _{3}=8(k+3\lambda )\,} μ μ 4 = 12 ( k + 2 λ λ ) 2 + 48 ( k + 4 λ λ ) {\displaystyle \mu _{4}=12(k+2\lambda )^{2}+48(k+4\lambda )\,} The n th cumulant is κ κ n = 2 n − − 1 ( n − − 1 ) !

( k + n λ λ ) .

{\displaystyle \kappa _{n}=2^{n-1}(n-1)!(k+n\lambda ).\,} Hence μ μ n ′ = 2 n − − 1 ( n − − 1 ) !

( k + n λ λ ) + ∑ ∑ j = 1 n − − 1 ( n − − 1 ) !

2 j − − 1 ( n − − j ) !

( k + j λ λ ) μ μ n − − j ′ .

{\displaystyle \mu '_{n}=2^{n-1}(n-1)!(k+n\lambda )+\sum _{j=1}^{n-1}{\frac {(n-1)!2^{j-1}}{(n-j)!}}(k+j\lambda )\mu '_{n-j}.} Cumulative distribution function [ edit ] Again using the relation between the central and noncentral chi-squared distributions, the cumulative distribution function (cdf) can be written as P ( x ; k , λ λ ) = e − − λ λ / 2 ∑ ∑ j = 0 ∞ ∞ ( λ λ / 2 ) j j !

Q ( x ; k + 2 j ) {\displaystyle P(x;k,\lambda )=e^{-\lambda /2}\;\sum _{j=0}^{\infty }{\frac {(\lambda /2)^{j}}{j!}}Q(x;k+2j)} where Q ( x ; k ) {\displaystyle Q(x;k)\,} is the cumulative distribution function of the central chi-squared distribution with k degrees of freedom which is given by Q ( x ; k ) = γ γ ( k / 2 , x / 2 ) Γ Γ ( k / 2 ) {\displaystyle Q(x;k)={\frac {\gamma (k/2,x/2)}{\Gamma (k/2)}}\,} and where γ γ ( k , z ) {\displaystyle \gamma (k,z)\,} is the lower incomplete gamma function .

The Marcum Q-function Q M ( a , b ) {\displaystyle Q_{M}(a,b)} can also be used to represent the cdf.

[ 5 ] P ( x ; k , λ λ ) = 1 − − Q k 2 ( λ λ , x ) {\displaystyle P(x;k,\lambda )=1-Q_{\frac {k}{2}}\left({\sqrt {\lambda }},{\sqrt {x}}\right)} When the degrees of freedom k is positive odd integer, we have a closed form expression for the complementary cumulative distribution function given by [ 6 ] P ( x ; 2 n + 1 , λ λ ) = 1 − − Q n + 1 / 2 ( λ λ , x ) = 1 − − [ Q ( x − − λ λ ) + Q ( x + λ λ ) + e − − ( x + λ λ ) / 2 ∑ ∑ m = 1 n ( x λ λ ) m / 2 − − 1 / 4 I m − − 1 / 2 ( λ λ x ) ] , {\displaystyle {\begin{aligned}P(x;2n+1,\lambda )&=1-Q_{n+1/2}({\sqrt {\lambda }},{\sqrt {x}})\\&=1-\left[Q({\sqrt {x}}-{\sqrt {\lambda }})+Q({\sqrt {x}}+{\sqrt {\lambda }})+e^{-(x+\lambda )/2}\sum _{m=1}^{n}\left({\frac {x}{\lambda }}\right)^{m/2-1/4}I_{m-1/2}({\sqrt {\lambda x}})\right],\end{aligned}}} where n is non-negative integer, Q is the Gaussian Q-function , and I is the modified Bessel function of first kind with half-integer order. The modified Bessel function of first kind with half-integer order in itself can be represented as a finite sum in terms of hyperbolic functions .

In particular, for k = 1, we have P ( x ; 1 , λ λ ) = 1 − − [ Q ( x − − λ λ ) + Q ( x + λ λ ) ] .

{\displaystyle P(x;1,\lambda )=1-\left[Q({\sqrt {x}}-{\sqrt {\lambda }})+Q({\sqrt {x}}+{\sqrt {\lambda }})\right].} Also, for k = 3, we have P ( x ; 3 , λ λ ) = 1 − − [ Q ( x − − λ λ ) + Q ( x + λ λ ) + 2 π π sinh ⁡ ⁡ ( λ λ x ) λ λ e − − ( x + λ λ ) / 2 ] .

{\displaystyle P(x;3,\lambda )=1-\left[Q({\sqrt {x}}-{\sqrt {\lambda }})+Q({\sqrt {x}}+{\sqrt {\lambda }})+{\sqrt {\frac {2}{\pi }}}{\frac {\sinh({\sqrt {\lambda x}})}{\sqrt {\lambda }}}e^{-(x+\lambda )/2}\right].} Approximation (including for quantiles) [ edit ] Abdel-Aty derives (as "first approx.") a non-central Wilson–Hilferty transformation : [ 7 ] ( χ χ ′ 2 k + λ λ ) 1 3 {\displaystyle \left({\frac {\chi '^{2}}{k+\lambda }}\right)^{\frac {1}{3}}} is approximately normally distributed , ∼ ∼ N ( 1 − − 2 9 f , 2 9 f ) , {\displaystyle \sim {\mathcal {N}}\left(1-{\frac {2}{9f}},{\frac {2}{9f}}\right),} i.e., P ( x ; k , λ λ ) ≈ ≈ Φ Φ { ( x k + λ λ ) 1 / 3 − − ( 1 − − 2 9 f ) 2 9 f } , where f := ( k + λ λ ) 2 k + 2 λ λ = k + λ λ 2 k + 2 λ λ , {\displaystyle P(x;k,\lambda )\approx \Phi \left\{{\frac {\left({\frac {x}{k+\lambda }}\right)^{1/3}-\left(1-{\frac {2}{9f}}\right)}{\sqrt {\frac {2}{9f}}}}\right\},{\text{where }}\ f:={\frac {(k+\lambda )^{2}}{k+2\lambda }}=k+{\frac {\lambda ^{2}}{k+2\lambda }},} which is quite accurate and well adapting to the noncentrality. Also, f = f ( k , λ λ ) {\displaystyle f=f(k,\lambda )} becomes f = k {\displaystyle f=k} for λ λ = 0 {\displaystyle \lambda =0} , the (central) chi-squared case.

Sankaran discusses a number of closed form approximations for the cumulative distribution function .

[ 8 ] In an earlier paper, he derived and states the following approximation: [ 9 ] P ( x ; k , λ λ ) ≈ ≈ Φ Φ { ( x k + λ λ ) h − − ( 1 + h p ( h − − 1 − − 0.5 ( 2 − − h ) m p ) ) h 2 p ( 1 + 0.5 m p ) } {\displaystyle P(x;k,\lambda )\approx \Phi \left\{{\frac {({\frac {x}{k+\lambda }})^{h}-(1+hp(h-1-0.5(2-h)mp))}{h{\sqrt {2p}}(1+0.5mp)}}\right\}} where Φ Φ { ⋅ ⋅ } {\displaystyle \Phi \lbrace \cdot \rbrace \,} denotes the cumulative distribution function of the standard normal distribution ; h = 1 − − 2 3 ( k + λ λ ) ( k + 3 λ λ ) ( k + 2 λ λ ) 2 ; {\displaystyle h=1-{\frac {2}{3}}{\frac {(k+\lambda )(k+3\lambda )}{(k+2\lambda )^{2}}}\,;} p = k + 2 λ λ ( k + λ λ ) 2 ; {\displaystyle p={\frac {k+2\lambda }{(k+\lambda )^{2}}};} m = ( h − − 1 ) ( 1 − − 3 h ) .

{\displaystyle m=(h-1)(1-3h)\,.} This and other approximations are discussed in a later text book.

[ 10 ] More recently, since the CDF of non-central chi-squared distribution with odd degree of freedom can be exactly computed, the CDF for even degree of freedom can be approximated by exploiting the monotonicity and log-concavity properties of Marcum-Q function as P ( x ; 2 n , λ λ ) ≈ ≈ 1 2 [ P ( x ; 2 n − − 1 , λ λ ) + P ( x ; 2 n + 1 , λ λ ) ] .

{\displaystyle P(x;2n,\lambda )\approx {\frac {1}{2}}\left[P(x;2n-1,\lambda )+P(x;2n+1,\lambda )\right].} Another approximation that also serves as an upper bound is given by P ( x ; 2 n , λ λ ) ≈ ≈ 1 − − [ ( 1 − − P ( x ; 2 n − − 1 , λ λ ) ) ( 1 − − P ( x ; 2 n + 1 , λ λ ) ) ] 1 / 2 .

{\displaystyle P(x;2n,\lambda )\approx 1-\left[(1-P(x;2n-1,\lambda ))(1-P(x;2n+1,\lambda ))\right]^{1/2}.} For a given probability, these formulas are easily inverted to provide the corresponding approximation for x {\displaystyle x} , to compute approximate quantiles.

Related distributions [ edit ] If V {\displaystyle V} is chi-square distributed, V ∼ ∼ χ χ k 2 {\displaystyle V\sim \chi _{k}^{2}} , then V {\displaystyle V} is also non-central chi-square distributed: V ∼ ∼ χ χ ′ k 2 ( 0 ) {\displaystyle V\sim {\chi '}_{k}^{2}(0)} A linear combination of independent noncentral chi-squared variables ξ ξ = ∑ ∑ i λ λ i Y i + c , Y i ∼ ∼ χ χ ′ 2 ( m i , δ δ i 2 ) {\displaystyle \xi =\sum _{i}\lambda _{i}Y_{i}+c,\quad Y_{i}\sim \chi '^{2}(m_{i},\delta _{i}^{2})} , is generalized chi-square distributed .

If V 1 ∼ ∼ χ χ ′ k 1 2 ( λ λ ) {\displaystyle V_{1}\sim {\chi '}_{k_{1}}^{2}(\lambda )} and V 2 ∼ ∼ χ χ ′ k 2 2 ( 0 ) {\displaystyle V_{2}\sim {\chi '}_{k_{2}}^{2}(0)} and V 1 {\displaystyle V_{1}} is independent of V 2 {\displaystyle V_{2}} then a noncentral F -distributed variable is developed as V 1 / k 1 V 2 / k 2 ∼ ∼ F k 1 , k 2 ′ ( λ λ ) {\displaystyle {\frac {V_{1}/k_{1}}{V_{2}/k_{2}}}\sim F'_{k_{1},k_{2}}(\lambda )} If J ∼ ∼ P o i s s o n ( 1 2 λ λ ) {\displaystyle J\sim \mathrm {Poisson} \left({{\frac {1}{2}}\lambda }\right)} , then χ χ k + 2 J 2 ∼ ∼ χ χ ′ k 2 ( λ λ ) {\displaystyle \chi _{k+2J}^{2}\sim {\chi '}_{k}^{2}(\lambda )} If V ∼ ∼ χ χ ′ 2 2 ( λ λ ) {\displaystyle V\sim {\chi '}_{2}^{2}(\lambda )} , then V {\displaystyle {\sqrt {V}}} takes the Rice distribution with parameter λ λ {\displaystyle {\sqrt {\lambda }}} .

Normal approximation: [ 11 ] if V ∼ ∼ χ χ ′ k 2 ( λ λ ) {\displaystyle V\sim {\chi '}_{k}^{2}(\lambda )} , then V − − ( k + λ λ ) 2 ( k + 2 λ λ ) → → N ( 0 , 1 ) {\displaystyle {\frac {V-(k+\lambda )}{\sqrt {2(k+2\lambda )}}}\to N(0,1)} in distribution as either k → → ∞ ∞ {\displaystyle k\to \infty } or λ λ → → ∞ ∞ {\displaystyle \lambda \to \infty } .

If V 1 ∼ ∼ χ χ ′ k 1 2 ( λ λ 1 ) {\displaystyle V_{1}\sim {\chi '}_{k_{1}}^{2}(\lambda _{1})} and V 2 ∼ ∼ χ χ ′ k 2 2 ( λ λ 2 ) {\displaystyle V_{2}\sim {\chi '}_{k_{2}}^{2}(\lambda _{2})} , where V 1 , V 2 {\displaystyle V_{1},V_{2}} are independent, then W = ( V 1 + V 2 ) ∼ ∼ χ χ ′ k 1 + k 2 2 ( λ λ 1 + λ λ 2 ) {\displaystyle W=(V_{1}+V_{2})\sim {\chi '}_{k_{1}+k_{2}}^{2}(\lambda _{1}+\lambda _{2})} .

In general, for an independent finite set of V i ∼ ∼ χ χ ′ k i 2 ( λ λ i ) {\displaystyle V_{i}\sim {\chi '}_{k_{i}}^{2}(\lambda _{i})} , i ∈ ∈ { 1 , … … , N } {\displaystyle i\in \{1,\ldots ,N\}} , the sum of these non-central chi-square distributed random variables Y = ∑ ∑ i = 1 N V i {\displaystyle Y=\sum _{i=1}^{N}V_{i}} has the distribution Y ∼ ∼ χ χ ′ k y 2 ( λ λ y ) {\displaystyle Y\sim {\chi '}_{k_{y}}^{2}(\lambda _{y})} where k y = ∑ ∑ i = 1 N k i {\displaystyle k_{y}=\sum _{i=1}^{N}k_{i}} , λ λ y = ∑ ∑ i = 1 N λ λ i {\displaystyle \lambda _{y}=\sum _{i=1}^{N}\lambda _{i}} . This can be seen using moment generating functions as follows: M Y ( t ) = M ∑ ∑ i = 1 N V i ( t ) = ∏ ∏ i = 1 N M V i ( t ) {\displaystyle M_{Y}(t)=M_{\sum _{i=1}^{N}V_{i}}(t)=\prod _{i=1}^{N}M_{V_{i}}(t)} by the independence of the V i {\displaystyle V_{i}} random variables. It remains to plug in the MGF for the non-central chi square distributions into the product and compute the new MGF – this is left as an exercise. Alternatively it can be seen via the interpretation in the background section above as sums of squares of independent normally distributed random variables with variances of 1 and the specified means.

The complex noncentral chi-squared distribution has applications in radio communication and radar systems.

[ citation needed ] Let z 1 , … … , z k {\displaystyle z_{1},\ldots ,z_{k}} be independent scalar complex random variables with noncentral circular symmetry, means of μ μ i {\displaystyle \mu _{i}} and unit variances: E ⁡ ⁡ | z i − − μ μ i | 2 = 1 {\displaystyle \operatorname {E} \left|z_{i}-\mu _{i}\right|^{2}=1} . Then the real random variable S = ∑ ∑ i = 1 k | z i | 2 {\displaystyle S=\sum _{i=1}^{k}\left|z_{i}\right|^{2}} is distributed according to the complex noncentral chi-squared distribution, which is effectively a scaled (by 1/2) non-central χ χ ′ 2 {\displaystyle {\chi '}^{2}} with twice the degrees of freedom and twice the noncentrality parameter: f S ( S ) = ( S λ λ ) ( k − − 1 ) / 2 e − − ( S + λ λ ) I k − − 1 ( 2 S λ λ ) {\displaystyle f_{S}(S)=\left({\frac {S}{\lambda }}\right)^{(k-1)/2}e^{-(S+\lambda )}I_{k-1}(2{\sqrt {S\lambda }})} , where λ λ = ∑ ∑ i = 1 k | μ μ i | 2 {\displaystyle \lambda =\sum _{i=1}^{k}\left|\mu _{i}\right|^{2}} .

Transformations [ edit ] Sankaran (1963) discusses the transformations of the form z = [ ( X − − b ) / ( k + λ λ ) ] 1 / 2 {\displaystyle z=[(X-b)/(k+\lambda )]^{1/2}} . He analyzes the expansions of the cumulants of z {\displaystyle z} up to the term O ( ( k + λ λ ) − − 4 ) {\displaystyle O((k+\lambda )^{-4})} and shows that the following choices of b {\displaystyle b} produce reasonable results: b = ( k − − 1 ) / 2 {\displaystyle b=(k-1)/2} makes the second cumulant of z {\displaystyle z} approximately independent of λ λ {\displaystyle \lambda } b = ( k − − 1 ) / 3 {\displaystyle b=(k-1)/3} makes the third cumulant of z {\displaystyle z} approximately independent of λ λ {\displaystyle \lambda } b = ( k − − 1 ) / 4 {\displaystyle b=(k-1)/4} makes the fourth cumulant of z {\displaystyle z} approximately independent of λ λ {\displaystyle \lambda } Also, a simpler transformation z 1 = ( X − − ( k − − 1 ) / 2 ) 1 / 2 {\displaystyle z_{1}=(X-(k-1)/2)^{1/2}} can be used as a variance stabilizing transformation that produces a random variable with mean ( λ λ + ( k − − 1 ) / 2 ) 1 / 2 {\displaystyle (\lambda +(k-1)/2)^{1/2}} and variance O ( ( k + λ λ ) − − 2 ) {\displaystyle O((k+\lambda )^{-2})} .

Usability of these transformations may be hampered by the need to take the square roots of negative numbers.

Various chi and chi-squared distributions Name Statistic chi-squared distribution ∑ ∑ i = 1 k ( X i − − μ μ i σ σ i ) 2 {\displaystyle \sum _{i=1}^{k}\left({\frac {X_{i}-\mu _{i}}{\sigma _{i}}}\right)^{2}} noncentral chi-squared distribution ∑ ∑ i = 1 k ( X i σ σ i ) 2 {\displaystyle \sum _{i=1}^{k}\left({\frac {X_{i}}{\sigma _{i}}}\right)^{2}} chi distribution ∑ ∑ i = 1 k ( X i − − μ μ i σ σ i ) 2 {\displaystyle {\sqrt {\sum _{i=1}^{k}\left({\frac {X_{i}-\mu _{i}}{\sigma _{i}}}\right)^{2}}}} noncentral chi distribution ∑ ∑ i = 1 k ( X i σ σ i ) 2 {\displaystyle {\sqrt {\sum _{i=1}^{k}\left({\frac {X_{i}}{\sigma _{i}}}\right)^{2}}}} Occurrence and applications [ edit ] Use in tolerance intervals [ edit ] Two-sided normal regression tolerance intervals can be obtained based on the noncentral chi-squared distribution.

[ 12 ] This enables the calculation of a statistical interval within which, with some confidence level, a specified proportion of a sampled population falls.

Notes [ edit ] ^ Patnaik, P. B. (1949).

"The Non-Central χ2- and F-Distribution and their Applications" .

Biometrika .

36 (1/2): 202– 232.

doi : 10.2307/2332542 .

ISSN 0006-3444 .

JSTOR 2332542 .

^ Muirhead (2005) Theorem 1.3.4 ^ Torgersen, E. N. (1972), "Supplementary notes on linear models", Preprint series: Statistical Memoirs, Dept. of Mathematics, University of Oslo, http://urn.nb.no/URN:NBN:no-58681 ^ Siegel, A. F. (1979), "The noncentral chi-squared distribution with zero degrees of freedom and testing for uniformity", Biometrika , 66, 381–386 ^ Nuttall, Albert H. (1975): Some Integrals Involving the Q M Function , IEEE Transactions on Information Theory , 21(1), 95–96, ISSN 0018-9448 ^ A. Annamalai, C. Tellambura and John Matyjas (2009). "A New Twist on the Generalized Marcum Q-Function Q M ( a , b ) with Fractional-Order M and its Applications".

2009 6th IEEE Consumer Communications and Networking Conference , 1–5, ISBN 978-1-4244-2308-8 ^ Abdel-Aty, S. (1954). "Approximate Formulae for the Percentage Points and the Probability Integral of the Non-Central χ 2 Distribution".

Biometrika .

41 (3/4): 538– 540.

doi : 10.2307/2332731 .

JSTOR 2332731 .

^ Sankaran, M. (1963). "Approximations to the non-central chi-squared distribution".

Biometrika .

50 ( 1– 2): 199– 204.

doi : 10.1093/biomet/50.1-2.199 .

^ Sankaran, M. (1959). "On the non-central chi-squared distribution".

Biometrika .

46 ( 1– 2): 235– 237.

doi : 10.1093/biomet/46.1-2.235 .

^ Johnson et al. (1995) Continuous Univariate Distributions Section 29.8 ^ Muirhead (2005) pages 22–24 and problem 1.18.

^ Derek S. Young (August 2010).

"tolerance: An R Package for Estimating Tolerance Intervals" .

Journal of Statistical Software .

36 (5): 1– 39.

ISSN 1548-7660 . Retrieved 19 February 2013 .

, p. 32 References [ edit ] Abramowitz, M. and Stegun, I. A. (1972), Handbook of Mathematical Functions , Dover.

Johnson, N. L., Kotz, S., Balakrishnan, N. (1995), Continuous Univariate Distributions, Volume 2 (2nd Edition) , Wiley.

ISBN 0-471-58494-0 Muirhead, R. (2005) Aspects of Multivariate Statistical Theory (2nd Edition). Wiley.

ISBN 0-471-76985-1 Press, S.J. (1966), "Linear combinations of non-central chi-squared variates", The Annals of Mathematical Statistics , 37 (2): 480– 487, doi : 10.1214/aoms/1177699531 , JSTOR 2238621 v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Noncentral_chi-squared_distribution&oldid=1292161935 " Categories : Continuous distributions Noncentral distributions Hidden categories: Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from September 2020 This page was last edited on 25 May 2025, at 14:30 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Noncentral chi-squared distribution 6 languages Add topic

