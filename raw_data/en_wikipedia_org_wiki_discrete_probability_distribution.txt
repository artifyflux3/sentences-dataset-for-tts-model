Title: Probability distribution

URL Source: https://en.wikipedia.org/wiki/Discrete_probability_distribution

Published Time: 2001-03-24T16:34:02Z

Markdown Content:
In [probability theory](https://en.wikipedia.org/wiki/Probability_theory "Probability theory") and [statistics](https://en.wikipedia.org/wiki/Statistics "Statistics"), a **probability distribution** is a [function](https://en.wikipedia.org/wiki/Function_(mathematics) "Function (mathematics)") that gives the probabilities of occurrence of possible **events** for an [experiment](https://en.wikipedia.org/wiki/Experiment_(probability_theory) "Experiment (probability theory)").[[1]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:02-1)[[2]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-2) It is a mathematical description of a [random](https://en.wikipedia.org/wiki/Randomness "Randomness") phenomenon in terms of its [sample space](https://en.wikipedia.org/wiki/Sample_space "Sample space") and the [probabilities](https://en.wikipedia.org/wiki/Probability "Probability") of [events](https://en.wikipedia.org/wiki/Event_(probability_theory) "Event (probability theory)") ([subsets](https://en.wikipedia.org/wiki/Subset "Subset") of the sample space).[[3]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:1-3)

For instance, if X is used to denote the outcome of a coin toss ("the experiment"), then the probability distribution of X would take the value 0.5 (1 in 2 or 1/2) for _X_ = heads, and 0.5 for _X_ = tails (assuming that [the coin is fair](https://en.wikipedia.org/wiki/Fair_coin "Fair coin")). More commonly, probability distributions are used to compare the relative occurrence of many different random values.

Probability distributions can be defined in different ways and for discrete or for continuous variables. Distributions with special properties or for especially important applications are given specific names.

A probability distribution is a mathematical description of the probabilities of events, subsets of the [sample space](https://en.wikipedia.org/wiki/Sample_space "Sample space"). The sample space, often represented in notation by ![Image 1: {\displaystyle \ \Omega \ ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c7c5e43c8d2b22b4c0191ebd8bcc4c3f5d715179) is the [set](https://en.wikipedia.org/wiki/Set_(mathematics) "Set (mathematics)") of all possible [outcomes](https://en.wikipedia.org/wiki/Outcome_(probability) "Outcome (probability)") of a random phenomenon being observed. The sample space may be any set: a set of [real numbers](https://en.wikipedia.org/wiki/Real_numbers "Real numbers"), a set of descriptive labels, a set of [vectors](https://en.wikipedia.org/wiki/Vector_(mathematics) "Vector (mathematics)"), a set of arbitrary non-numerical values, etc. For example, the sample space of a coin flip could be Ω = {"heads", "tails"}.

To define probability distributions for the specific case of [random variables](https://en.wikipedia.org/wiki/Random_variables "Random variables") (so the sample space can be seen as a numeric set), it is common to distinguish between **discrete** and **continuous**[random variables](https://en.wikipedia.org/wiki/Random_variable "Random variable"). In the discrete case, it is sufficient to specify a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function "Probability mass function")![Image 2: {\displaystyle p}](https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36) assigning a probability to each possible outcome (e.g. when throwing a fair [die](https://en.wikipedia.org/wiki/Dice "Dice"), each of the six digits “1” to “6”, corresponding to the number of dots on the die, has probability ![Image 3: {\displaystyle {\tfrac {1}{6}}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/422878e2526ebc0b23c06a6799ef204e4672c275) The probability of an [event](https://en.wikipedia.org/wiki/Event_(probability_theory) "Event (probability theory)") is then defined to be the sum of the probabilities of all outcomes that satisfy the event; for example, the probability of the event "the die rolls an even value" is ![Image 4: {\displaystyle p({\text{“}}2{\text{”}})+p({\text{“}}4{\text{”}})+p({\text{“}}6{\text{”}})={\frac {1}{6}}+{\frac {1}{6}}+{\frac {1}{6}}={\frac {1}{2}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6d90d7232a1788e0ae65379477ee7fbf74f1a51) In contrast, when a random variable takes values from a continuum then by convention, any individual outcome is assigned probability zero. For such continuous random variables, only events that include infinitely many outcomes such as intervals have probability greater than 0.

For example, consider measuring the weight of a piece of ham in the supermarket, and assume the scale can provide arbitrarily many digits of precision. Then, the probability that it weighs _exactly_ 500[g](https://en.wikipedia.org/wiki/Gram "Gram") must be zero because no matter how high the level of precision chosen, it cannot be assumed that there are no non-zero decimal digits in the remaining omitted digits ignored by the precision level.

However, for the same use case, it is possible to meet quality control requirements such as that a package of "500 g" of ham must weigh between 490 g and 510 g with at least 98% probability. This is possible because this measurement does not require as much precision from the underlying equipment.

[![Image 5](https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Combined_Cumulative_Distribution_Graphs.png/500px-Combined_Cumulative_Distribution_Graphs.png)](https://en.wikipedia.org/wiki/File:Combined_Cumulative_Distribution_Graphs.png)

 Figure 1: The left graph shows a probability density function. The right graph shows the cumulative distribution function. The value at **a** in the cumulative distribution equals the area under the probability density curve up to the point **a**.

Continuous probability distributions can be described by means of the [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function "Cumulative distribution function"), which describes the probability that the random variable is no larger than a given value (i.e., _P_(_X_ ≤ _x_) for some x. The cumulative distribution function is the area under the [probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function") from -∞ to x, as shown in figure 1.[[4]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-dekking-4)

Most continuous probability distributions encountered in practice are not only continuous but also [absolutely continuous](https://en.wikipedia.org/wiki/Absolutely_continuous "Absolutely continuous"). Such distributions can be described by their [probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function"). Informally, the probability density ![Image 6: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) of a random variable ![Image 7: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) describes the [infinitesimal](https://en.wikipedia.org/wiki/Infinitesimal "Infinitesimal") probability that ![Image 8: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) takes any value ![Image 9: {\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) — that is ![Image 10: {\displaystyle P(x\leq X<x+\Delta x)\approx f(x)\,\Delta x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86f1ece944264a8c6b35b225ca28cf772c380e54) as ![Image 11: {\displaystyle \Delta x>0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/80ff8f6a17e8b6069576699d4e44ebdc920a581e) becomes is arbitrarily small. The probability that ![Image 12: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) lies in a given interval can be computed rigorously by [integrating](https://en.wikipedia.org/wiki/Integration_(mathematics) "Integration (mathematics)") the probability density function over that interval.[[5]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:3-5)

General probability definition
------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=2 "Edit section: General probability definition")]

Let ![Image 13: {\displaystyle (\Omega ,{\mathcal {F}},P)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d77104a5c3c49cc0634dcf6908db7ad45f738d2) be a [probability space](https://en.wikipedia.org/wiki/Probability_space "Probability space"), ![Image 14: {\displaystyle (E,{\mathcal {E}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/497b309dc3f6f358722b8a00936c8e1ed5c787b0) be a [measurable space](https://en.wikipedia.org/wiki/Measurable_space "Measurable space"), and ![Image 15: {\displaystyle X:\Omega \to E}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fa5b5c95b9df3bce45c8ba6012f7434a075f79f6) be a ![Image 16: {\displaystyle (E,{\mathcal {E}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/497b309dc3f6f358722b8a00936c8e1ed5c787b0)-valued random variable. Then the **probability distribution** of ![Image 17: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) is the [pushforward measure](https://en.wikipedia.org/wiki/Pushforward_measure "Pushforward measure") of the probability measure ![Image 18: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a) onto ![Image 19: {\displaystyle (E,{\mathcal {E}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/497b309dc3f6f358722b8a00936c8e1ed5c787b0) induced by ![Image 20: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab). Explicitly, this pushforward measure on ![Image 21: {\displaystyle (E,{\mathcal {E}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/497b309dc3f6f358722b8a00936c8e1ed5c787b0) is given by ![Image 22: {\displaystyle X_{*}(P)(B)=P\left(X^{-1}(B)\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5e10203153888a562e4dcd8903cca9c04b4d478b) for ![Image 23: {\displaystyle B\in {\mathcal {E}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/11f451040874f6ec9057df77edeecec30b6424f3)

Any probability distribution is a [probability measure](https://en.wikipedia.org/wiki/Probability_measure "Probability measure") on ![Image 24: {\displaystyle (E,{\mathcal {E}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/497b309dc3f6f358722b8a00936c8e1ed5c787b0) (in general different from ![Image 25: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a), unless ![Image 26: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) happens to be the identity map).[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\_needed "Wikipedia:Citation needed")_]

A probability distribution can be described in various forms, such as by a probability mass function or a cumulative distribution function. One of the most general descriptions, which applies for absolutely continuous and discrete variables, is by means of a probability function ![Image 27: {\displaystyle P\colon {\mathcal {A}}\to \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/80a94e20556b091a570ea52312189162094ea914) whose **input space**![Image 28: {\displaystyle {\mathcal {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/280ae03440942ab348c2ca9b8db6b56ffa9618f8) is a [σ-algebra](https://en.wikipedia.org/wiki/%CE%A3-algebra "Σ-algebra"), and gives a [real number](https://en.wikipedia.org/wiki/Real_number "Real number")**probability** as its output, particularly, a number in ![Image 29: {\displaystyle [0,1]\subseteq \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/042e529c93e86b5d03b1e1cd6ddcc50e89761c03).

The probability function ![Image 30: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a) can take as argument subsets of the sample space itself, as in the coin toss example, where the function ![Image 31: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a) was defined so that _P_(heads) = 0.5 and _P_(tails) = 0.5. However, because of the widespread use of [random variables](https://en.wikipedia.org/wiki/Random_variables "Random variables"), which transform the sample space into a set of numbers (e.g., ![Image 32: {\displaystyle \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/786849c765da7a84dbc3cce43e96aad58a5868dc), ![Image 33: {\displaystyle \mathbb {N} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/fdf9a96b565ea202d0f4322e9195613fb26a9bed)), it is more common to study probability distributions whose argument are subsets of these particular kinds of sets (number sets),[[6]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-6) and all probability distributions discussed in this article are of this type. It is common to denote as ![Image 34: {\displaystyle P(X\in E)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a4c7b71d6a4f78bd036a428ae07bc65fc540e435) the probability that a certain value of the variable ![Image 35: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) belongs to a certain event ![Image 36: {\displaystyle E}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4232c9de2ee3eec0a9c0a19b15ab92daa6223f9b).[[7]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-ross-7)[[8]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-degroot-8)

The above probability function only characterizes a probability distribution if it satisfies all the [Kolmogorov axioms](https://en.wikipedia.org/wiki/Kolmogorov_axioms "Kolmogorov axioms"), that is:

1.   ![Image 37: {\displaystyle P(X\in E)\geq 0\;\forall E\in {\mathcal {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/796ab01da78a6782a872bb1764b30f20e4529fd0), so the probability is non-negative
2.   ![Image 38: {\displaystyle P(X\in E)\leq 1\;\forall E\in {\mathcal {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c7b9108f8399411eb881ae8ec8c6a894bb1e7428), so no probability exceeds ![Image 39: {\displaystyle 1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/92d98b82a3778f043108d4e20960a9193df57cbf)
3.   ![Image 40: {\displaystyle P(X\in \bigcup _{i}E_{i})=\sum _{i}P(X\in E_{i})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bc4e074980b684224b5cb4bd3a393e275900b405) for any countable disjoint family of sets ![Image 41: {\displaystyle \{E_{i}\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5b1f300cab58fdfa1af66feb463293f3ed69f08f)

The concept of probability function is made more rigorous by defining it as the element of a [probability space](https://en.wikipedia.org/wiki/Probability_space "Probability space")![Image 42: {\displaystyle (X,{\mathcal {A}},P)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/08ceddee8f4dc310483bb745d2294991ebeab287), where ![Image 43: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) is the set of possible outcomes, ![Image 44: {\displaystyle {\mathcal {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/280ae03440942ab348c2ca9b8db6b56ffa9618f8) is the set of all subsets ![Image 45: {\displaystyle E\subset X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/14567090e62b518e1b9a0b5329f25535813b090d) whose probability can be measured, and ![Image 46: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a) is the probability function, or **probability measure**, that assigns a probability to each of these measurable subsets ![Image 47: {\displaystyle E\in {\mathcal {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/617e7bf2f419fd8a31234ec2b0d5c9df00457025).[[9]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-billingsley-9)

Probability distributions usually belong to one of two classes. A **discrete probability distribution** is applicable to the scenarios where the set of possible outcomes is [discrete](https://en.wikipedia.org/wiki/Discrete_probability_distribution "Discrete probability distribution") (e.g. a coin toss, a roll of a die) and the probabilities are encoded by a discrete list of the probabilities of the outcomes; in this case the discrete probability distribution is known as [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function "Probability mass function"). On the other hand, **absolutely continuous probability distributions** are applicable to scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day. In the absolutely continuous case, probabilities are described by a [probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function"), and the probability distribution is by definition the integral of the probability density function.[[7]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-ross-7)[[5]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:3-5)[[8]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-degroot-8) The [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution") is a commonly encountered absolutely continuous probability distribution. More complex experiments, such as those involving [stochastic processes](https://en.wikipedia.org/wiki/Stochastic_processes "Stochastic processes") defined in [continuous time](https://en.wikipedia.org/wiki/Continuous_time "Continuous time"), may demand the use of more general [probability measures](https://en.wikipedia.org/wiki/Probability_measure "Probability measure").

A probability distribution whose sample space is one-dimensional (for example real numbers, list of labels, ordered labels or binary) is called [univariate](https://en.wikipedia.org/wiki/Univariate_distribution "Univariate distribution"), while a distribution whose sample space is a [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space") of dimension 2 or more is called [multivariate](https://en.wikipedia.org/wiki/Multivariate_distribution "Multivariate distribution"). A univariate distribution gives the probabilities of a single [random variable](https://en.wikipedia.org/wiki/Random_variable "Random variable") taking on various different values; a multivariate distribution (a [joint probability distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution "Joint probability distribution")) gives the probabilities of a [random vector](https://en.wikipedia.org/wiki/Random_vector "Random vector") – a list of two or more random variables – taking on various combinations of values. Important and commonly encountered univariate probability distributions include the [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution "Binomial distribution"), the [hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution "Hypergeometric distribution"), and the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution"). A commonly encountered multivariate distribution is the [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution "Multivariate normal distribution").

Besides the probability function, the cumulative distribution function, the probability mass function and the probability density function, the [moment generating function](https://en.wikipedia.org/wiki/Moment_generating_function "Moment generating function") and the [characteristic function](https://en.wikipedia.org/wiki/Characteristic_function_(probability_theory) "Characteristic function (probability theory)") also serve to identify a probability distribution, as they uniquely determine an underlying cumulative distribution function.[[10]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-10)

[![Image 48](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/250px-Standard_deviation_diagram.svg.png)](https://en.wikipedia.org/wiki/File:Standard_deviation_diagram.svg)

Figure 2: The [probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function") (pdf) of the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution"), also called Gaussian or "bell curve", the most important absolutely continuous random distribution. As notated on the figure, the probabilities of intervals of values correspond to the area under the curve.

Some key concepts and terms, widely used in the literature on the topic of probability distributions, are listed below.[[1]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:02-1)

### Discrete probability distributions

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=5 "Edit section: Discrete probability distributions")]

*   **Discrete probability distribution**: for many random variables with finitely or countably infinitely many values.
*   _[Probability mass function](https://en.wikipedia.org/wiki/Probability\_mass\_function "Probability mass function")_ (_pmf_): function that gives the probability that a discrete random variable is equal to some value.
*   _[Frequency distribution](https://en.wikipedia.org/wiki/Frequency\_distribution "Frequency distribution")_: a table that displays the frequency of various outcomes _in a sample_.
*   _[Relative frequency](https://en.wikipedia.org/wiki/Relative\_frequency "Relative frequency") distribution_: a [frequency distribution](https://en.wikipedia.org/wiki/Frequency_distribution "Frequency distribution") where each value has been divided (normalized) by a number of outcomes in a [sample](https://en.wikipedia.org/wiki/Sample_(statistics) "Sample (statistics)") (i.e. sample size).
*   _[Categorical distribution](https://en.wikipedia.org/wiki/Categorical\_distribution "Categorical distribution")_: for discrete random variables with a finite set of values.

### Absolutely continuous probability distributions

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=6 "Edit section: Absolutely continuous probability distributions")]

*   **Absolutely continuous probability distribution**: for many random variables with uncountably many values.
*   _[Probability density function](https://en.wikipedia.org/wiki/Probability\_density\_function "Probability density function")_ (_pdf_) or _probability density_: function whose value at any given sample (or point) in the [sample space](https://en.wikipedia.org/wiki/Sample_space "Sample space") (the set of possible values taken by the random variable) can be interpreted as providing a _relative likelihood_ that the value of the random variable would equal that sample.

Cumulative distribution function
--------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=8 "Edit section: Cumulative distribution function")]

In the special case of a real-valued random variable, the probability distribution can equivalently be represented by a cumulative distribution function instead of a probability measure. The cumulative distribution function of a random variable ![Image 49: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) with regard to a probability distribution ![Image 50: {\displaystyle p}](https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36) is defined as ![Image 51: {\displaystyle F(x)=P(X\leq x).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3331ebba17c8829de342ac6670a45db7d4bff379)

The cumulative distribution function of any real-valued random variable has the properties:

Conversely, any function ![Image 52: {\displaystyle F:\mathbb {R} \to \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0d02d30fa7eb4c2cf6cb40779cb6d07e993f9dc9) that satisfies the first four of the properties above is the cumulative distribution function of some probability distribution on the real numbers.[[13]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-13)

Any probability distribution can be decomposed as the [mixture](https://en.wikipedia.org/wiki/Mixture_distribution "Mixture distribution") of a [discrete](https://en.wikipedia.org/wiki/Discrete_probability_distribution "Discrete probability distribution"), an [absolutely continuous](https://en.wikipedia.org/wiki/Absolutely_continuous_probability_distribution "Absolutely continuous probability distribution") and a [singular continuous distribution](https://en.wikipedia.org/wiki/Singular_distribution "Singular distribution"),[[14]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-14) and thus any cumulative distribution function admits a decomposition as the [convex sum](https://en.wikipedia.org/wiki/Convex_sum "Convex sum") of the three according cumulative distribution functions.

Discrete probability distribution
---------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=9 "Edit section: Discrete probability distribution")]

[![Image 53](https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Dice_Distribution_%28bar%29.svg/250px-Dice_Distribution_%28bar%29.svg.png)](https://en.wikipedia.org/wiki/File:Dice_Distribution_(bar).svg)

Figure 3: The [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function "Probability mass function") (pmf) ![Image 54: {\displaystyle p(S)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7186ed5f087b7b8ebf58d72fb80af6c0890f1b47) specifies the probability distribution for the sum ![Image 55: {\displaystyle S}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4611d85173cd3b508e67077d4a1252c9c05abca2) of counts from two [dice](https://en.wikipedia.org/wiki/Dice "Dice"). For example, the figure shows that ![Image 56: {\displaystyle p(11)=2/36=1/18}](https://wikimedia.org/api/rest_v1/media/math/render/svg/01c09b5bc67a4f236b8f56a3d367756fd6c3b4d8). The pmf allows the computation of probabilities of events such as ![Image 57: {\displaystyle P(X>9)=1/12+1/18+1/36=1/6}](https://wikimedia.org/api/rest_v1/media/math/render/svg/959b12ce5c1a6f009398e9b0cef521b11b09c2d0), and all other probabilities in the distribution.

[![Image 58](https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Discrete_probability_distrib.svg/250px-Discrete_probability_distrib.svg.png)](https://en.wikipedia.org/wiki/File:Discrete_probability_distrib.svg)

Figure 4: The probability mass function of a discrete probability distribution. The probabilities of the [singletons](https://en.wikipedia.org/wiki/Singleton_(mathematics) "Singleton (mathematics)") {1}, {3}, and {7} are respectively 0.2, 0.5, 0.3. A set not containing any of these points has probability zero.

[![Image 59](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Discrete_probability_distribution.svg/250px-Discrete_probability_distribution.svg.png)](https://en.wikipedia.org/wiki/File:Discrete_probability_distribution.svg)

Figure 5: The [cdf](https://en.wikipedia.org/wiki/Cumulative_distribution_function "Cumulative distribution function") of a discrete probability distribution, ...

[![Image 60](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Normal_probability_distribution.svg/250px-Normal_probability_distribution.svg.png)](https://en.wikipedia.org/wiki/File:Normal_probability_distribution.svg)

Figure 6: ... of a continuous probability distribution, ...

[![Image 61](https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Mixed_probability_distribution.svg/250px-Mixed_probability_distribution.svg.png)](https://en.wikipedia.org/wiki/File:Mixed_probability_distribution.svg)

Figure 7: ... of a distribution which has both a continuous part and a discrete part

A **discrete probability distribution** is the probability distribution of a random variable that can take on only a countable number of values[[15]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-15) ([almost surely](https://en.wikipedia.org/wiki/Almost_surely "Almost surely"))[[16]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-16) which means that the probability of any event ![Image 62: {\displaystyle E}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4232c9de2ee3eec0a9c0a19b15ab92daa6223f9b) can be expressed as a (finite or [countably infinite](https://en.wikipedia.org/wiki/Series_(mathematics) "Series (mathematics)")) sum: ![Image 63: {\displaystyle P(X\in E)=\sum _{\omega \in A\cap E}P(X=\omega ),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2e4b5f636393e75c3da05692ee877b605c410d00) where ![Image 64: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3) is a countable set with ![Image 65: {\displaystyle P(X\in A)=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/edb55065b605213a635fe1f65c0f254bddc07f16). Thus the discrete random variables (i.e. random variables whose probability distribution is discrete) are exactly those with a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function "Probability mass function")![Image 66: {\displaystyle p(x)=P(X=x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6c10bc497aaa4a27e77898ff933aa91e8ffe7842). In the case where the range of values is countably infinite, these values have to decline to zero fast enough for the probabilities to add up to 1. For example, if ![Image 67: {\displaystyle p(n)={\tfrac {1}{2^{n}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/33bb344a3238f16d574897cf77be95ef70ce218b) for ![Image 68: {\displaystyle n=1,2,...}](https://wikimedia.org/api/rest_v1/media/math/render/svg/94007d32129e7d62758916268a12b6108a5b6e0a), the sum of probabilities would be ![Image 69: {\displaystyle 1/2+1/4+1/8+\dots =1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7f2b11caa92398c7657837bf035267c49d94cb50).

Well-known discrete probability distributions used in statistical modeling include the [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution "Poisson distribution"), the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution "Bernoulli distribution"), the [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution "Binomial distribution"), the [geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution "Geometric distribution"), the [negative binomial distribution](https://en.wikipedia.org/wiki/Negative_binomial_distribution "Negative binomial distribution") and [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution "Categorical distribution").[[3]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:1-3) When a [sample](https://en.wikipedia.org/wiki/Sample_(statistics) "Sample (statistics)") (a set of observations) is drawn from a larger population, the sample points have an [empirical distribution](https://en.wikipedia.org/wiki/Empirical_distribution_function "Empirical distribution function") that is discrete, and which provides information about the population distribution. Additionally, the [discrete uniform distribution](https://en.wikipedia.org/wiki/Uniform_distribution_(discrete) "Uniform distribution (discrete)") is commonly used in computer programs that make equal-probability random selections between a number of choices.

### Cumulative distribution function

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=10 "Edit section: Cumulative distribution function")]

A real-valued discrete random variable can equivalently be defined as a random variable whose cumulative distribution function increases only by [jump discontinuities](https://en.wikipedia.org/wiki/Jump_discontinuity "Jump discontinuity")—that is, its cdf increases only where it "jumps" to a higher value, and is constant in intervals without jumps. The points where jumps occur are precisely the values which the random variable may take. Thus the cumulative distribution function has the form ![Image 70: {\displaystyle F(x)=P(X\leq x)=\sum _{\omega \leq x}p(\omega ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/16e61e7d0b60b2ad27c1b93764aa5108f25b4478) The points where the cdf jumps always form a countable set; this may be any countable set and thus may even be dense in the real numbers.

### Dirac delta representation

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=11 "Edit section: Dirac delta representation")]

A discrete probability distribution is often represented with [Dirac measures](https://en.wikipedia.org/wiki/Dirac_measure "Dirac measure"), also called one-point distributions (see below), the probability distributions of [deterministic random variables](https://en.wikipedia.org/wiki/Degenerate_distribution "Degenerate distribution"). For any outcome ![Image 71: {\displaystyle \omega }](https://wikimedia.org/api/rest_v1/media/math/render/svg/48eff443f9de7a985bb94ca3bde20813ea737be8), let ![Image 72: {\displaystyle \delta _{\omega }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9c12edf03721c82d470149b2680d82847a1e33bc) be the Dirac measure concentrated at ![Image 73: {\displaystyle \omega }](https://wikimedia.org/api/rest_v1/media/math/render/svg/48eff443f9de7a985bb94ca3bde20813ea737be8). Given a discrete probability distribution, there is a countable set ![Image 74: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3) with ![Image 75: {\displaystyle P(X\in A)=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/edb55065b605213a635fe1f65c0f254bddc07f16) and a probability mass function ![Image 76: {\displaystyle p}](https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36). If ![Image 77: {\displaystyle E}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4232c9de2ee3eec0a9c0a19b15ab92daa6223f9b) is any event, then ![Image 78: {\displaystyle P(X\in E)=\sum _{\omega \in A}p(\omega )\delta _{\omega }(E),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d8f0387ec1557fc8a0e822399776007f4604a87) or in short, ![Image 79: {\displaystyle P_{X}=\sum _{\omega \in A}p(\omega )\delta _{\omega }.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9bb59e2d2574c15424a0a4721064c5e9f3e757b6)

Similarly, discrete distributions can be represented with the [Dirac delta function](https://en.wikipedia.org/wiki/Dirac_delta_function "Dirac delta function") as a [generalized](https://en.wikipedia.org/wiki/Generalized_function "Generalized function")[probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function")![Image 80: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61), where ![Image 81: {\displaystyle f(x)=\sum _{\omega \in A}p(\omega )\delta (x-\omega ),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/595c7423a680e50ee38fe3271546db9680dbcab7) which means ![Image 82: {\displaystyle P(X\in E)=\int _{E}f(x)\,dx=\sum _{\omega \in A}p(\omega )\int _{E}\delta (x-\omega )=\sum _{\omega \in A\cap E}p(\omega )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a263146c1b012c2bcf164df7324d4c965e14d02) for any event ![Image 83: {\displaystyle E.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4a2566d01f104ef084ea424b8b35c2534f7f902b)[[17]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-17)

### Indicator-function representation

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=12 "Edit section: Indicator-function representation")]

For a discrete random variable ![Image 84: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab), let ![Image 85: {\displaystyle u_{0},u_{1},\dots }](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a05f796c20d85e2b84a4164131e97432e866bdb) be the values it can take with non-zero probability. Denote ![Image 86: {\displaystyle \Omega _{i}=X^{-1}(u_{i})=\{\omega :X(\omega )=u_{i}\},\,i=0,1,2,\dots }](https://wikimedia.org/api/rest_v1/media/math/render/svg/f0287108e3beaae1852b7c7a9e59a6173210dd95) These are [disjoint sets](https://en.wikipedia.org/wiki/Disjoint_set "Disjoint set"), and for such sets ![Image 87: {\displaystyle P\left(\bigcup _{i}\Omega _{i}\right)=\sum _{i}P(\Omega _{i})=\sum _{i}P(X=u_{i})=1.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b28d1881d03b77a61862b122ca61fea15c848bd7) It follows that the probability that ![Image 88: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) takes any value except for ![Image 89: {\displaystyle u_{0},u_{1},\dots }](https://wikimedia.org/api/rest_v1/media/math/render/svg/7a05f796c20d85e2b84a4164131e97432e866bdb) is zero, and thus one can write ![Image 90: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) as ![Image 91: {\displaystyle X(\omega )=\sum _{i}u_{i}1_{\Omega _{i}}(\omega )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/70cde4c6d385274c329d32b86760b8aa720d61eb) except on a set of probability zero, where ![Image 92: {\displaystyle 1_{A}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d1a15eaa9285cd4654e86a76f3318c6ab2aad95d) is the indicator function of ![Image 93: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3). This may serve as an alternative definition of discrete random variables.

### One-point distribution

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=13 "Edit section: One-point distribution")]

A special case is the discrete distribution of a random variable that can take on only one fixed value, in other words, a Dirac measure. Expressed formally, the random variable ![Image 94: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) has a one-point distribution if it has a possible outcome ![Image 95: {\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) such that ![Image 96: {\displaystyle P(X{=}x)=1.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/af5bd1f171b32c2fd6a859e5f68b52b72aa9d921)[[18]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-18) All other possible outcomes then have probability 0. Its cumulative distribution function jumps immediately from 0 before ![Image 97: {\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) to 1 at ![Image 98: {\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4). It is closely related to a deterministic distribution, which cannot take on any other value, while a one-point distribution can take other values, though only with probability 0. For most practical purposes the two notions are equivalent.

Absolutely continuous probability distribution
----------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=14 "Edit section: Absolutely continuous probability distribution")]

An **absolutely continuous probability distribution** is a probability distribution on the real numbers with uncountably many possible values, such as a whole interval in the real line, and where the probability of any event can be expressed as an integral.[[19]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-19) More precisely, a real random variable ![Image 99: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) has an [absolutely continuous](https://en.wikipedia.org/wiki/Absolutely_continuous "Absolutely continuous") probability distribution if there is a function ![Image 100: {\displaystyle f:\mathbb {R} \to [0,\infty ]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f8544ec4fd60d201e49cacb3afd640e760798489) such that for each interval ![Image 101: {\displaystyle I=[a,b]\subset \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1cad8a9865c17ed0c40a9e3f5eb3fe4a18df765e) the probability of ![Image 102: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) belonging to ![Image 103: {\displaystyle I}](https://wikimedia.org/api/rest_v1/media/math/render/svg/535ea7fc4134a31cbe2251d9d3511374bc41be9f) is given by the integral of ![Image 104: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) over ![Image 105: {\displaystyle I}](https://wikimedia.org/api/rest_v1/media/math/render/svg/535ea7fc4134a31cbe2251d9d3511374bc41be9f):[[20]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-20)[[21]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-21)![Image 106: {\displaystyle P\left(a\leq X\leq b\right)=\int _{a}^{b}f(x)\,dx.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f27b1708f4353f5241e8cda627aaa332b9f1c0ab) This is the definition of a [probability density function](https://en.wikipedia.org/wiki/Probability_density_function "Probability density function"), so that absolutely continuous probability distributions are exactly those with a probability density function. In particular, the probability for ![Image 107: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) to take any single value ![Image 108: {\displaystyle a}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ffd2487510aa438433a2579450ab2b3d557e5edc) (that is, ![Image 109: {\displaystyle a\leq X\leq a}](https://wikimedia.org/api/rest_v1/media/math/render/svg/009ba797370ba083b8325edb2d6335c4c2513d9e)) is zero, because an [integral](https://en.wikipedia.org/wiki/Integral "Integral") with coinciding upper and lower limits is always equal to zero. If the interval ![Image 110: {\displaystyle [a,b]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9c4b788fc5c637e26ee98b45f89a5c08c85f7935) is replaced by any measurable set ![Image 111: {\displaystyle A}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3), the according equality still holds: ![Image 112: {\displaystyle P(X\in A)=\int _{A}f(x)\,dx.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bf51e0600ed04f039ec1b01c452206db22523384)

An **absolutely continuous random variable** is a random variable whose probability distribution is absolutely continuous.

There are many examples of absolutely continuous probability distributions: [normal](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution"), [uniform](https://en.wikipedia.org/wiki/Uniform_distribution_(continuous) "Uniform distribution (continuous)"), [chi-squared](https://en.wikipedia.org/wiki/Chi-squared_distribution "Chi-squared distribution"), and [others](https://en.wikipedia.org/wiki/List_of_probability_distributions#Absolutely_continuous_distributions "List of probability distributions").

### Cumulative distribution function

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=15 "Edit section: Cumulative distribution function")]

Absolutely continuous probability distributions as defined above are precisely those with an [absolutely continuous](https://en.wikipedia.org/wiki/Absolute_continuity "Absolute continuity") cumulative distribution function. In this case, the cumulative distribution function ![Image 113: {\displaystyle F}](https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57) has the form ![Image 114: {\displaystyle F(x)=P(X\leq x)=\int _{-\infty }^{x}f(t)\,dt}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2e39a193583a5ffde1dbc1ad328b3012302c82f4) where ![Image 115: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) is a density of the random variable ![Image 116: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) with regard to the distribution ![Image 117: {\displaystyle P}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b4dc73bf40314945ff376bd363916a738548d40a).

_Note on terminology:_ Absolutely continuous distributions ought to be distinguished from **continuous distributions**, which are those having a continuous cumulative distribution function. Every absolutely continuous distribution is a continuous distribution but the inverse is not true, there exist [singular distributions](https://en.wikipedia.org/wiki/Singular_distribution "Singular distribution"), which are neither absolutely continuous nor discrete nor a mixture of those, and do not have a density. An example is given by the [Cantor distribution](https://en.wikipedia.org/wiki/Cantor_distribution "Cantor distribution"). Some authors however use the term "continuous distribution" to denote all distributions whose cumulative distribution function is [absolutely continuous](https://en.wikipedia.org/wiki/Absolutely_continuous_function "Absolutely continuous function"), i.e. refer to absolutely continuous distributions as continuous distributions.[[7]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-ross-7)

For a more general definition of density functions and the equivalent absolutely continuous measures see [absolutely continuous measure](https://en.wikipedia.org/wiki/Absolutely_continuous_measure "Absolutely continuous measure").

Kolmogorov definition
---------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=16 "Edit section: Kolmogorov definition")]

In the [measure-theoretic](https://en.wikipedia.org/wiki/Measure_theory "Measure theory") formalization of [probability theory](https://en.wikipedia.org/wiki/Probability_theory "Probability theory"), a [random variable](https://en.wikipedia.org/wiki/Random_variable "Random variable") is defined as a [measurable function](https://en.wikipedia.org/wiki/Measurable_function "Measurable function")![Image 118: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) from a [probability space](https://en.wikipedia.org/wiki/Probability_space "Probability space")![Image 119: {\displaystyle (\Omega ,{\mathcal {F}},\mathbb {P} )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6bb8743f7565082ed1a9ee0490d9d71be82eafaa) to a [measurable space](https://en.wikipedia.org/wiki/Measurable_space "Measurable space")![Image 120: {\displaystyle ({\mathcal {X}},{\mathcal {A}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/478d656144cecc9f1e5bbd8c4a14d4dd7092b82c). Given that probabilities of events of the form ![Image 121: {\displaystyle \{\omega \in \Omega \mid X(\omega )\in A\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/81bd1ff5385266f88263eaa39be4569558576f1f) satisfy [Kolmogorov's probability axioms](https://en.wikipedia.org/wiki/Probability_axioms "Probability axioms"), the **probability distribution of ![Image 122: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab)** is the [image measure](https://en.wikipedia.org/wiki/Pushforward_measure "Pushforward measure")![Image 123: {\displaystyle X_{*}\mathbb {P} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/573bd8cb9f9bd7a93f23974b566e8122563b16e9) of ![Image 124: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) , which is a [probability measure](https://en.wikipedia.org/wiki/Probability_measure "Probability measure") on ![Image 125: {\displaystyle ({\mathcal {X}},{\mathcal {A}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/478d656144cecc9f1e5bbd8c4a14d4dd7092b82c) satisfying ![Image 126: {\displaystyle X_{*}\mathbb {P} =\mathbb {P} X^{-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed71c56e3ffce179c691e19808e83186f02188b7).[[22]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-22)[[23]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-23)[[24]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-24)

Other kinds of distributions
----------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=17 "Edit section: Other kinds of distributions")]

[![Image 127](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Rabinovich_Fabrikant_2314.png/330px-Rabinovich_Fabrikant_2314.png)](https://en.wikipedia.org/wiki/File:Rabinovich_Fabrikant_2314.png)

Figure 8: One solution for the [Rabinovich–Fabrikant equations](https://en.wikipedia.org/wiki/Rabinovich%E2%80%93Fabrikant_equations "Rabinovich–Fabrikant equations"). What is the probability of observing a state on a certain place of the support (i.e., the red subset)?

Absolutely continuous and discrete distributions with support on ![Image 128: {\displaystyle \mathbb {R} ^{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1bcd8908c9fa46eb979ef7b67d1bb65eb3692cbb) or ![Image 129: {\displaystyle \mathbb {N} ^{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/17c589016c8f3ea30f528d9a1c6c5f6f67cfe0a0) are extremely useful to model a myriad of phenomena,[[7]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-ross-7)[[4]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-dekking-4) since most practical distributions are supported on relatively simple subsets, such as [hypercubes](https://en.wikipedia.org/wiki/Hypercubes "Hypercubes") or [balls](https://en.wikipedia.org/wiki/Ball_(mathematics) "Ball (mathematics)"). However, this is not always the case, and there exist phenomena with supports that are actually complicated curves ![Image 130: {\displaystyle \gamma :[a,b]\rightarrow \mathbb {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/58e103c376cd9ea50b5c12c8f5398ded4d2a3577) within some space ![Image 131: {\displaystyle \mathbb {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c510b63578322050121fe966f2e5770bea43308d) or similar. In these cases, the probability distribution is supported on the image of such curve, and is likely to be determined empirically, rather than finding a closed formula for it.[[25]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-alligood-25)

One example is shown in the figure to the right, which displays the evolution of a [system of differential equations](https://en.wikipedia.org/wiki/System_of_differential_equations "System of differential equations") (commonly known as the [Rabinovich–Fabrikant equations](https://en.wikipedia.org/wiki/Rabinovich%E2%80%93Fabrikant_equations "Rabinovich–Fabrikant equations")) that can be used to model the behaviour of [Langmuir waves](https://en.wikipedia.org/wiki/Langmuir_waves "Langmuir waves") in [plasma](https://en.wikipedia.org/wiki/Plasma_(physics) "Plasma (physics)").[[26]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-26) When this phenomenon is studied, the observed states from the subset are as indicated in red. So one could ask what is the probability of observing a state in a certain position of the red subset; if such a probability exists, it is called the probability measure of the system.[[27]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-27)[[25]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-alligood-25)

This kind of complicated support appears quite frequently in [dynamical systems](https://en.wikipedia.org/wiki/Dynamical_systems "Dynamical systems"). It is not simple to establish that the system has a probability measure, and the main problem is the following. Let ![Image 132: {\displaystyle t_{1}\ll t_{2}\ll t_{3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/98c79950cd68df63696c26a82b8bcf05ce78d576) be instants in time and ![Image 133: {\displaystyle O}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d70e1d0d87e2ef1092ea1ffe2923d9933ff18fc) a subset of the support; if the probability measure exists for the system, one would expect the frequency of observing states inside set ![Image 134: {\displaystyle O}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d70e1d0d87e2ef1092ea1ffe2923d9933ff18fc) would be equal in interval ![Image 135: {\displaystyle [t_{1},t_{2}]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e35e13fa8221f864808f15cafa3d1467b5d78ce) and ![Image 136: {\displaystyle [t_{2},t_{3}]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/82eae695d40fda9d1b713787d35efa48d9a95478), which might not happen; for example, it could oscillate similar to a sine, ![Image 137: {\displaystyle \sin(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0eb63cccca21b1edef50f707888e3204ab5fda1a), whose limit when ![Image 138: {\displaystyle t\rightarrow \infty }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b543f76f961ec3f52d78fa3d72c3d87a521dd3a7) does not converge. Formally, the measure exists only if the limit of the relative frequency converges when the system is observed into the infinite future.[[28]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-28) The branch of dynamical systems that studies the existence of a probability measure is [ergodic theory](https://en.wikipedia.org/wiki/Ergodic_theory "Ergodic theory").

Note that even in these cases, the probability distribution, if it exists, might still be termed "absolutely continuous" or "discrete" depending on whether the support is uncountable or countable, respectively.

Random number generation
------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=18 "Edit section: Random number generation")]

Most algorithms are based on a [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator "Pseudorandom number generator") that produces numbers ![Image 139: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) that are uniformly distributed in the [half-open interval](https://en.wikipedia.org/wiki/Half-open_interval "Half-open interval")[0, 1). These [random variates](https://en.wikipedia.org/wiki/Random_variate "Random variate")![Image 140: {\displaystyle X}](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab) are then transformed via some algorithm to create a new random variate having the required probability distribution. With this source of uniform pseudo-randomness, realizations of any random variable can be generated.[[29]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:0-29)

For example, suppose U has a uniform distribution between 0 and 1. To construct a random Bernoulli variable for some 0 < p < 1, define ![Image 141: {\displaystyle X={\begin{cases}1&{\text{if }}U<p\\0&{\text{if }}U\geq p.\end{cases}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e5819b3186ffc7a9facde7eac01863299cabc158) We thus have ![Image 142: {\displaystyle P(X=1)=P(U<p)=p,\quad P(X=0)=P(U\geq p)=1-p.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0be7cdb4c0c12dd65dd8586255c580613b164f44) Therefore, the random variable X has a Bernoulli distribution with parameter p.[[29]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:0-29)

This method can be adapted to generate real-valued random variables with any distribution: for be any cumulative distribution function F, let _F_ inv be the generalized left inverse of ![Image 143: {\displaystyle F,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed179a16e860b290a2c25c573d3fc0b2360f0fc1) also known in this context as the _[quantile function](https://en.wikipedia.org/wiki/Quantile\_function "Quantile function")_ or _inverse distribution function_: ![Image 144: {\displaystyle F^{\mathrm {inv} }(p)=\inf\{x\in \mathbb {R} :p\leq F(x)\}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ce0c606e6fa1a8278d9e80bee2dafa162f6ca536) Then, _F_ inv(_p_) ≤ _x_ if and only if _p_ ≤ _F_(_x_). As a result, if U is uniformly distributed on [0, 1], then the cumulative distribution function of _X_ = _F_ inv(_U_) is F.

For example, suppose we want to generate a random variable having an exponential distribution with parameter ![Image 145: {\displaystyle \lambda }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a) — that is, with cumulative distribution function ![Image 146: {\displaystyle F:x\mapsto 1-e^{-\lambda x}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d2ec4032de439386af0b3008808a1c76f1a2587c)![Image 147: {\displaystyle {\begin{aligned}F(x)=u&\Leftrightarrow 1-e^{-\lambda x}=u\\[2pt]&\Leftrightarrow e^{-\lambda x}=1-u\\[2pt]&\Leftrightarrow -\lambda x=\ln(1-u)\\[2pt]&\Leftrightarrow x={\frac {-1}{\lambda }}\ln(1-u)\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4fb889e8427ec79417200e4c016790ef0d20c446) so ![Image 148: {\displaystyle F^{\mathrm {inv} }(u)=-{\tfrac {1}{\lambda }}\ln(1-u)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/444c1872ea3039b129370e57a6f20e1d3150114d), and if U has a uniform distribution on [0, 1) then ![Image 149: {\displaystyle X=-{\tfrac {1}{\lambda }}\ln(1-U)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/98e2c0a3140d868a72c198a5dcc73e8eabcd3325) has an exponential distribution with parameter ![Image 150: {\displaystyle \lambda .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4bb9c58e3f6b2de892e10ef516f96f07da0423e0)[[29]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-:0-29)

Although from a theoretical point of view this method always works, in practice the inverse distribution function is unknown and/or cannot be computed efficiently. In this case, other methods (such as the [Monte Carlo method](https://en.wikipedia.org/wiki/Monte_Carlo_method "Monte Carlo method")) are used.

Common probability distributions and their applications
-------------------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=19 "Edit section: Common probability distributions and their applications")]

The concept of the probability distribution and the random variables which they describe underlies the mathematical discipline of probability theory, and the science of statistics. There is spread or variability in almost any value that can be measured in a population (e.g. height of people, durability of a metal, sales growth, traffic flow, etc.); almost all measurements are made with some intrinsic error; in physics, many processes are described probabilistically, from the [kinetic properties of gases](https://en.wikipedia.org/wiki/Kinetic_theory_of_gases "Kinetic theory of gases") to the [quantum mechanical](https://en.wikipedia.org/wiki/Quantum_mechanical "Quantum mechanical") description of [fundamental particles](https://en.wikipedia.org/wiki/Fundamental_particles "Fundamental particles"). For these and many other reasons, simple [numbers](https://en.wikipedia.org/wiki/Number "Number") are often inadequate for describing a quantity, while probability distributions are often more appropriate.

The following is a list of some of the most common probability distributions, grouped by the type of process that they are related to. For a more complete list, see [list of probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions "List of probability distributions"), which groups by the nature of the outcome being considered (discrete, absolutely continuous, multivariate, etc.)

All of the univariate distributions below are singly peaked; that is, it is assumed that the values cluster around a single point. In practice, actually observed quantities may cluster around multiple values. Such quantities can be modeled using a [mixture distribution](https://en.wikipedia.org/wiki/Mixture_distribution "Mixture distribution").

### Linear growth (e.g. errors, offsets)

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=20 "Edit section: Linear growth (e.g. errors, offsets)")]

*   [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution") (Gaussian distribution), for a single such quantity; the most commonly used absolutely continuous distribution

### Exponential growth (e.g. prices, incomes, populations)

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=21 "Edit section: Exponential growth (e.g. prices, incomes, populations)")]

*   [Log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution "Log-normal distribution"), for a single such quantity whose log is [normally](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution") distributed
*   [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution "Pareto distribution"), for a single such quantity whose log is [exponentially](https://en.wikipedia.org/wiki/Exponential_distribution "Exponential distribution") distributed; the prototypical [power law](https://en.wikipedia.org/wiki/Power_law "Power law") distribution

### Uniformly distributed quantities

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=22 "Edit section: Uniformly distributed quantities")]

*   [Discrete uniform distribution](https://en.wikipedia.org/wiki/Discrete_uniform_distribution "Discrete uniform distribution"), for a finite set of values (e.g. the outcome of a fair dice)
*   [Continuous uniform distribution](https://en.wikipedia.org/wiki/Continuous_uniform_distribution "Continuous uniform distribution"), for absolutely continuously distributed values

### Bernoulli trials (yes/no events, with a given probability)

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=23 "Edit section: Bernoulli trials (yes/no events, with a given probability)")]

*   Basic distributions: 
    *   [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution "Bernoulli distribution"), for the outcome of a single Bernoulli trial (e.g. success/failure, yes/no)
    *   [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution "Binomial distribution"), for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed total number of [independent](https://en.wikipedia.org/wiki/Independent_(statistics) "Independent (statistics)") occurrences
    *   [Negative binomial distribution](https://en.wikipedia.org/wiki/Negative_binomial_distribution "Negative binomial distribution"), for binomial-type observations but where the quantity of interest is the number of failures before a given number of successes occurs
    *   [Geometric distribution](https://en.wikipedia.org/wiki/Geometric_distribution "Geometric distribution"), for binomial-type observations but where the quantity of interest is the number of failures before the first success; a special case of the [negative binomial distribution](https://en.wikipedia.org/wiki/Negative_binomial_distribution "Negative binomial distribution")

*   Related to sampling schemes over a finite population: 
    *   [Hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution "Hypergeometric distribution"), for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed number of total occurrences, using [sampling without replacement](https://en.wikipedia.org/wiki/Sampling_without_replacement "Sampling without replacement")
    *   [Beta-binomial distribution](https://en.wikipedia.org/wiki/Beta-binomial_distribution "Beta-binomial distribution"), for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed number of total occurrences, sampling using a [Pólya urn model](https://en.wikipedia.org/wiki/P%C3%B3lya_urn_model "Pólya urn model") (in some sense, the "opposite" of [sampling without replacement](https://en.wikipedia.org/wiki/Sampling_without_replacement "Sampling without replacement"))

### Categorical outcomes (events with K possible outcomes)

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=24 "Edit section: Categorical outcomes (events with K possible outcomes)")]

*   [Categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution "Categorical distribution"), for a single categorical outcome (e.g. yes/no/maybe in a survey); a generalization of the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution "Bernoulli distribution")
*   [Multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution "Multinomial distribution"), for the number of each type of categorical outcome, given a fixed number of total outcomes; a generalization of the [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution "Binomial distribution")
*   [Multivariate hypergeometric distribution](https://en.wikipedia.org/wiki/Multivariate_hypergeometric_distribution "Multivariate hypergeometric distribution"), similar to the [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution "Multinomial distribution"), but using [sampling without replacement](https://en.wikipedia.org/wiki/Sampling_without_replacement "Sampling without replacement"); a generalization of the [hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution "Hypergeometric distribution")

### Poisson process (events that occur independently with a given rate)

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=25 "Edit section: Poisson process (events that occur independently with a given rate)")]

*   [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution "Poisson distribution"), for the number of occurrences of a Poisson-type event in a given period of time
*   [Exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution "Exponential distribution"), for the time before the next Poisson-type event occurs
*   [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution "Gamma distribution"), for the time before the next k Poisson-type events occur

### Absolute values of vectors with normally distributed components

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=26 "Edit section: Absolute values of vectors with normally distributed components")]

*   [Rayleigh distribution](https://en.wikipedia.org/wiki/Rayleigh_distribution "Rayleigh distribution"), for the distribution of vector magnitudes with Gaussian distributed orthogonal components. Rayleigh distributions are found in RF signals with Gaussian real and imaginary components.
*   [Rice distribution](https://en.wikipedia.org/wiki/Rice_distribution "Rice distribution"), a generalization of the Rayleigh distributions for where there is a stationary background signal component. Found in [Rician fading](https://en.wikipedia.org/wiki/Rician_fading "Rician fading") of radio signals due to multipath propagation and in MR images with noise corruption on non-zero NMR signals.

### Normally distributed quantities operated with sum of squares

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=27 "Edit section: Normally distributed quantities operated with sum of squares")]

*   [Chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution "Chi-squared distribution"), the distribution of a sum of squared [standard normal](https://en.wikipedia.org/wiki/Standard_normal "Standard normal") variables; useful e.g. for inference regarding the [sample variance](https://en.wikipedia.org/wiki/Sample_variance "Sample variance") of normally distributed samples (see [chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test "Chi-squared test"))
*   [Student's t distribution](https://en.wikipedia.org/wiki/Student%27s_t_distribution "Student's t distribution"), the distribution of the ratio of a [standard normal](https://en.wikipedia.org/wiki/Standard_normal "Standard normal") variable and the square root of a scaled [chi squared](https://en.wikipedia.org/wiki/Chi_squared_distribution "Chi squared distribution") variable; useful for inference regarding the [mean](https://en.wikipedia.org/wiki/Mean "Mean") of normally distributed samples with unknown variance (see [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test "Student's t-test"))
*   [F-distribution](https://en.wikipedia.org/wiki/F-distribution "F-distribution"), the distribution of the ratio of two scaled [chi squared](https://en.wikipedia.org/wiki/Chi_squared_distribution "Chi squared distribution") variables; useful e.g. for inferences that involve comparing variances or involving [R-squared](https://en.wikipedia.org/wiki/R-squared "R-squared") (the squared [correlation coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient "Pearson product-moment correlation coefficient"))

### As conjugate prior distributions in Bayesian inference

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=28 "Edit section: As conjugate prior distributions in Bayesian inference")]

*   [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution "Beta distribution"), for a single probability (real number between 0 and 1); conjugate to the [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution "Bernoulli distribution") and [binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution "Binomial distribution")
*   [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution "Gamma distribution"), for a non-negative scaling parameter; conjugate to the rate parameter of a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution "Poisson distribution") or [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution "Exponential distribution"), the [precision](https://en.wikipedia.org/wiki/Precision_(statistics) "Precision (statistics)") (inverse [variance](https://en.wikipedia.org/wiki/Variance "Variance")) of a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution "Normal distribution"), etc.
*   [Dirichlet distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution "Dirichlet distribution"), for a vector of probabilities that must sum to 1; conjugate to the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution "Categorical distribution") and [multinomial distribution](https://en.wikipedia.org/wiki/Multinomial_distribution "Multinomial distribution"); generalization of the [beta distribution](https://en.wikipedia.org/wiki/Beta_distribution "Beta distribution")
*   [Wishart distribution](https://en.wikipedia.org/wiki/Wishart_distribution "Wishart distribution"), for a symmetric [non-negative definite](https://en.wikipedia.org/wiki/Non-negative_definite "Non-negative definite") matrix; conjugate to the inverse of the [covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix "Covariance matrix") of a [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution "Multivariate normal distribution"); generalization of the [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution "Gamma distribution")[[30]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-30)

### Some specialized applications of probability distributions

[[edit](https://en.wikipedia.org/w/index.php?title=Probability_distribution&action=edit&section=29 "Edit section: Some specialized applications of probability distributions")]

*   The [cache language models](https://en.wikipedia.org/wiki/Cache_language_model "Cache language model") and other [statistical language models](https://en.wikipedia.org/wiki/Statistical_Language_Model "Statistical Language Model") used in [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing "Natural language processing") to assign probabilities to the occurrence of particular words and word sequences do so by means of probability distributions.
*   In quantum mechanics, the probability density of finding the particle at a given point is proportional to the square of the magnitude of the particle's [wavefunction](https://en.wikipedia.org/wiki/Wavefunction "Wavefunction") at that point (see [Born rule](https://en.wikipedia.org/wiki/Born_rule "Born rule")). Therefore, the probability distribution function of the position of a particle is described by ![Image 151: {\textstyle P_{a\leq x\leq b}(t)=\int _{a}^{b}dx\,|\Psi (x,t)|^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bcdd1d53d077c41f1f8fc0739dfa264ffeaf4e5f), probability that the particle's position _x_ will be in the interval _a_ ≤ _x_ ≤ _b_ in dimension one, and a similar [triple integral](https://en.wikipedia.org/wiki/Triple_integral "Triple integral") in dimension three. This is a key principle of quantum mechanics.[[31]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-31)
*   Probabilistic load flow in [power-flow study](https://en.wikipedia.org/wiki/Power-flow_study "Power-flow study") explains the uncertainties of input variables as probability distribution and provides the power flow calculation also in term of probability distribution.[[32]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-32)
*   Prediction of natural phenomena occurrences based on previous [frequency distributions](https://en.wikipedia.org/wiki/Frequency_distribution "Frequency distribution") such as [tropical cyclones](https://en.wikipedia.org/wiki/Tropical_cyclone "Tropical cyclone"), hail, time in between events, etc.[[33]](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_note-33)

[Probability distribution fitting](https://en.wikipedia.org/wiki/Probability_distribution_fitting "Probability distribution fitting") or simply distribution fitting is the fitting of a probability distribution to a series of data concerning the repeated measurement of a variable phenomenon. The aim of distribution fitting is to [predict](https://en.wikipedia.org/wiki/Prediction "Prediction") the [probability](https://en.wikipedia.org/wiki/Probability "Probability") or to [forecast](https://en.wikipedia.org/wiki/Forecasting "Forecasting") the [frequency](https://en.wikipedia.org/wiki/Frequency_(statistics) "Frequency (statistics)") of occurrence of the magnitude of the phenomenon in a certain interval.

There are many probability distributions (see [list of probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions "List of probability distributions")) of which some can be fitted more closely to the observed frequency of the data than others, depending on the characteristics of the phenomenon and of the distribution. The distribution giving a close fit is supposed to lead to good predictions.

In distribution fitting, therefore, one needs to select a distribution that suits the data well.

*   [Conditional probability distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution "Conditional probability distribution")
*   [Empirical probability distribution](https://en.wikipedia.org/wiki/Empirical_probability "Empirical probability")
*   [Histogram](https://en.wikipedia.org/wiki/Histogram "Histogram")
*   [Joint probability distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution "Joint probability distribution")
*   [Probability measure](https://en.wikipedia.org/wiki/Probability_measure "Probability measure")
*   [Quasiprobability distribution](https://en.wikipedia.org/wiki/Quasiprobability_distribution "Quasiprobability distribution")
*   [Riemann–Stieltjes integral application to probability theory](https://en.wikipedia.org/wiki/Riemann%E2%80%93Stieltjes_integral#Application_to_probability_theory "Riemann–Stieltjes integral")

*   [List of probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions "List of probability distributions")
*   [List of statistical topics](https://en.wikipedia.org/wiki/List_of_statistical_topics "List of statistical topics")

1.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:02_1-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:02_1-1)Everitt, Brian (2006). _The Cambridge dictionary of statistics_ (3rd ed.). Cambridge, UK: Cambridge University Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-511-24688-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-511-24688-3 "Special:BookSources/978-0-511-24688-3"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[161828328](https://search.worldcat.org/oclc/161828328).
2.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-2)**Ash, Robert B. (2008). _Basic probability theory_ (Dover ed.). Mineola, N.Y.: Dover Publications. pp.66–69. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-46628-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-46628-6 "Special:BookSources/978-0-486-46628-6"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[190785258](https://search.worldcat.org/oclc/190785258).
3.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:1_3-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:1_3-1)Evans, Michael; Rosenthal, Jeffrey S. (2010). _Probability and statistics: the science of uncertainty_ (2nd ed.). New York: W.H. Freeman and Co. p.38. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4292-2462-8](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4292-2462-8 "Special:BookSources/978-1-4292-2462-8"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[473463742](https://search.worldcat.org/oclc/473463742).
4.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-dekking_4-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-dekking_4-1)Dekking, Michel (1946–) (2005). _A Modern Introduction to Probability and Statistics: Understanding why and how_. London, UK: Springer. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-85233-896-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-85233-896-1 "Special:BookSources/978-1-85233-896-1"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[262680588](https://search.worldcat.org/oclc/262680588).`{{cite book}}`: CS1 maint: numeric names: authors list ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_numeric_names:_authors_list "Category:CS1 maint: numeric names: authors list"))
5.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:3_5-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:3_5-1)["1.3.6.1. What is a Probability Distribution"](https://www.itl.nist.gov/div898/handbook/eda/section3/eda361.htm). _www.itl.nist.gov_. Retrieved 2020-09-10.
6.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-6)**Walpole, R.E.; Myers, R.H.; Myers, S.L.; Ye, K. (1999). _Probability and statistics for engineers_. Prentice Hall.
7.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-ross_7-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-ross_7-1)[_**c**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-ross_7-2)[_**d**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-ross_7-3)Ross, Sheldon M. (2010). _A first course in probability_. Pearson.
8.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-degroot_8-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-degroot_8-1)DeGroot, Morris H.; Schervish, Mark J. (2002). _Probability and Statistics_. Addison-Wesley.
9.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-billingsley_9-0)**Billingsley, P. (1986). _Probability and measure_. Wiley. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780471804789](https://en.wikipedia.org/wiki/Special:BookSources/9780471804789 "Special:BookSources/9780471804789").
10.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-10)**Shephard, N.G. (1991). ["From characteristic function to distribution function: a simple framework for the theory"](https://ora.ox.ac.uk/objects/uuid:a4c3ad11-74fe-458c-8d58-6f74511a476c). _Econometric Theory_. **7** (4): 519–529. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1017/S0266466600004746](https://doi.org/10.1017%2FS0266466600004746). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[14668369](https://api.semanticscholar.org/CorpusID:14668369).
11.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-vapnik_11-0)**Chapters 1 and 2 of [Vapnik (1998)](https://en.wikipedia.org/wiki/Discrete_probability_distribution#CITEREFVapnik1998)
12.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-tail_12-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-tail_12-1)More information and examples can be found in the articles [Heavy-tailed distribution](https://en.wikipedia.org/wiki/Heavy-tailed_distribution "Heavy-tailed distribution"), [Long-tailed distribution](https://en.wikipedia.org/wiki/Long-tailed_distribution "Long-tailed distribution"), [fat-tailed distribution](https://en.wikipedia.org/wiki/Fat-tailed_distribution "Fat-tailed distribution")
13.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-13)**Erhan, Çınlar (2011). _Probability and stochastics_. New York: Springer. p.57. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387878584](https://en.wikipedia.org/wiki/Special:BookSources/9780387878584 "Special:BookSources/9780387878584").
14.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-14)**see [Lebesgue's decomposition theorem](https://en.wikipedia.org/wiki/Lebesgue%27s_decomposition_theorem "Lebesgue's decomposition theorem")
15.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-15)**Erhan, Çınlar (2011). _Probability and stochastics_. New York: Springer. p.51. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387878591](https://en.wikipedia.org/wiki/Special:BookSources/9780387878591 "Special:BookSources/9780387878591"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[710149819](https://search.worldcat.org/oclc/710149819).
16.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-16)**Cohn, Donald L. (1993). _Measure theory_. Birkhäuser.
17.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-17)**Khuri, André I. (March 2004). "Applications of Dirac's delta function in statistics". _International Journal of Mathematical Education in Science and Technology_. **35** (2): 185–195. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1080/00207390310001638313](https://doi.org/10.1080%2F00207390310001638313). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0020-739X](https://search.worldcat.org/issn/0020-739X). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[122501973](https://api.semanticscholar.org/CorpusID:122501973).
18.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-18)**Fisz, Marek (1963). _Probability Theory and Mathematical Statistics_ (3rd ed.). John Wiley & Sons. p.129. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-471-26250-1](https://en.wikipedia.org/wiki/Special:BookSources/0-471-26250-1 "Special:BookSources/0-471-26250-1").
19.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-19)**Jeffrey Seth Rosenthal (2000). _A First Look at Rigorous Probability Theory_. World Scientific.
20.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-20)**Chapter 3.2 of [DeGroot & Schervish (2002)](https://en.wikipedia.org/wiki/Discrete_probability_distribution#CITEREFDeGrootSchervish2002)
21.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-21)**Bourne, Murray. ["11. Probability Distributions - Concepts"](https://www.intmath.com/counting-probability/11-probability-distributions-concepts.php). _www.intmath.com_. Retrieved 2020-09-10.
22.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-22)**W., Stroock, Daniel (1999). _Probability theory: an analytic view_ (Rev.ed.). Cambridge [England]: Cambridge University Press. p.11. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0521663496](https://en.wikipedia.org/wiki/Special:BookSources/978-0521663496 "Special:BookSources/978-0521663496"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[43953136](https://search.worldcat.org/oclc/43953136).`{{cite book}}`: CS1 maint: multiple names: authors list ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list "Category:CS1 maint: multiple names: authors list"))
23.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-23)**Kolmogorov, Andrey (1950) [1933]. _Foundations of the theory of probability_. New York, USA: Chelsea Publishing Company. pp.21–24.
24.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-24)**Joyce, David (2014). ["Axioms of Probability"](https://mathcs.clarku.edu/~djoyce/ma217/axioms.pdf)(PDF). _Clark University_. Retrieved December 5, 2019.
25.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-alligood_25-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-alligood_25-1)Alligood, K.T.; Sauer, T.D.; Yorke, J.A. (1996). _Chaos: an introduction to dynamical systems_. Springer.
26.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-26)**Rabinovich, M.I.; Fabrikant, A.L. (1979). "Stochastic self-modulation of waves in nonequilibrium media". _J. Exp. Theor. Phys_. **77**: 617–629. [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1979JETP...50..311R](https://ui.adsabs.harvard.edu/abs/1979JETP...50..311R).
27.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-27)**Section 1.9 of Ross, S.M.; Peköz, E.A. (2007). [_A second course in probability_](http://people.bu.edu/pekoz/A_Second_Course_in_Probability-Ross-Pekoz.pdf)(PDF).
28.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-28)**Walters, Peter (2000). _An Introduction to Ergodic Theory_. Springer.
29.   ^ [_**a**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:0_29-0)[_**b**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:0_29-1)[_**c**_](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-:0_29-2)Dekking, Frederik Michel; Kraaikamp, Cornelis; Lopuhaä, Hendrik Paul; Meester, Ludolf Erwin (2005), "Why probability and statistics?", _A Modern Introduction to Probability and Statistics_, Springer London, pp.1–11, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/1-84628-168-7_1](https://doi.org/10.1007%2F1-84628-168-7_1), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-85233-896-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-85233-896-1 "Special:BookSources/978-1-85233-896-1")
30.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-30)**Bishop, Christopher M. (2006). _Pattern recognition and machine learning_. New York: Springer. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-387-31073-8](https://en.wikipedia.org/wiki/Special:BookSources/0-387-31073-8 "Special:BookSources/0-387-31073-8"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[71008143](https://search.worldcat.org/oclc/71008143).
31.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-31)**Chang, Raymond. (2014). _Physical chemistry for the chemical sciences_. Thoman, John W., Jr., 1960-. [Mill Valley, California]. pp.403–406. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-68015-835-9](https://en.wikipedia.org/wiki/Special:BookSources/978-1-68015-835-9 "Special:BookSources/978-1-68015-835-9"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[927509011](https://search.worldcat.org/oclc/927509011).`{{cite book}}`: CS1 maint: location missing publisher ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_location_missing_publisher "Category:CS1 maint: location missing publisher"))
32.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-32)**Chen, P.; Chen, Z.; Bak-Jensen, B. (April 2008). "Probabilistic load flow: A review". _2008 Third International Conference on Electric Utility Deregulation and Restructuring and Power Technologies_. pp.1586–1591. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/drpt.2008.4523658](https://doi.org/10.1109%2Fdrpt.2008.4523658). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-7-900714-13-8](https://en.wikipedia.org/wiki/Special:BookSources/978-7-900714-13-8 "Special:BookSources/978-7-900714-13-8"). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[18669309](https://api.semanticscholar.org/CorpusID:18669309).
33.   **[^](https://en.wikipedia.org/wiki/Discrete_probability_distribution#cite_ref-33)**Maity, Rajib (2018-04-30). _Statistical methods in hydrology and hydroclimatology_. Singapore. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-981-10-8779-0](https://en.wikipedia.org/wiki/Special:BookSources/978-981-10-8779-0 "Special:BookSources/978-981-10-8779-0"). [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[1038418263](https://search.worldcat.org/oclc/1038418263).`{{cite book}}`: CS1 maint: location missing publisher ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_location_missing_publisher "Category:CS1 maint: location missing publisher"))

*   den Dekker, A. J.; Sijbers, J. (2014). "Data distributions in magnetic resonance images: A review". _[Physica Medica](https://en.wikipedia.org/w/index.php?title=Physica\_Medica&action=edit&redlink=1 "Physica Medica (page does not exist)")_. **30** (7): 725–741. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.ejmp.2014.05.002](https://doi.org/10.1016%2Fj.ejmp.2014.05.002). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[25059432](https://pubmed.ncbi.nlm.nih.gov/25059432).
*   Vapnik, Vladimir Naumovich (1998). _Statistical Learning Theory_. John Wiley and Sons.

*   ["Probability distribution"](https://www.encyclopediaofmath.org/index.php?title=Probability_distribution), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society"), 2001 [1994]
*   [Field Guide to Continuous Probability Distributions](http://threeplusone.com/FieldGuide.pdf), Gavin E. Crooks.
*   [Distinguishing probability measure, function and distribution](https://math.stackexchange.com/q/1073744/29780), Math Stack Exchange
