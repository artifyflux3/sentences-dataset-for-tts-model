Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Principle 2 Example: 1D diffusion 3 Example: 1D diffusion with advection for steady flow, with multiple channel connections 4 Example: 2D diffusion 5 Crank–Nicolson for nonlinear problems 6 Application in financial mathematics 7 See also 8 References 9 External links Toggle the table of contents Crank–Nicolson method 9 languages Deutsch Español فارسی Français 한국어 Polski Português Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Finite difference method for numerically solving parabolic differential equations Differential equations Scope Fields Natural sciences Engineering Astronomy Physics Chemistry Biology Geology Applied mathematics Continuum mechanics Chaos theory Dynamical systems Social sciences Economics Population dynamics List of named differential equations Classification Types Ordinary Partial Differential-algebraic Integro-differential Fractional Linear Non-linear By variable type Dependent and independent variables Autonomous Coupled / Decoupled Exact Homogeneous / Nonhomogeneous Features Order Operator Notation Relation to processes Difference (discrete analogue) Stochastic Stochastic partial Delay Solution Existence and uniqueness Picard–Lindelöf theorem Peano existence theorem Carathéodory's existence theorem Cauchy–Kowalevski theorem General topics Initial conditions Boundary values Dirichlet Neumann Robin Cauchy problem Wronskian Phase portrait Lyapunov / Asymptotic / Exponential stability Rate of convergence Series / Integral solutions Numerical integration Dirac delta function Solution methods Inspection Method of characteristics Euler Exponential response formula Finite difference ( Crank–Nicolson ) Finite element Infinite element Finite volume Galerkin Petrov–Galerkin Green's function Integrating factor Integral transforms Perturbation theory Runge–Kutta Separation of variables Undetermined coefficients Variation of parameters People List Isaac Newton Gottfried Leibniz Jacob Bernoulli Leonhard Euler Joseph-Louis Lagrange Józef Maria Hoene-Wroński Joseph Fourier Augustin-Louis Cauchy George Green Carl David Tolmé Runge Martin Kutta Rudolf Lipschitz Ernst Lindelöf Émile Picard Phyllis Nicolson John Crank v t e In numerical analysis , the Crank–Nicolson method is a finite difference method used for numerically solving the heat equation and similar partial differential equations .

[ 1 ] It is a second-order method in time. It is implicit in time, can be written as an implicit Runge–Kutta method , and it is numerically stable . The method was developed by John Crank and Phyllis Nicolson in the 1940s.

[ 2 ] For diffusion equations (and many other equations), it can be shown the Crank–Nicolson method is unconditionally stable .

[ 3 ] However, the approximate solutions can still contain (decaying) spurious oscillations if the ratio of time step Δ Δ t {\displaystyle \Delta t} times the thermal diffusivity to the square of space step, Δ Δ x 2 {\displaystyle \Delta x^{2}} , is large (typically, larger than 1/2 per Von Neumann stability analysis ). For this reason, whenever large time steps or high spatial resolution is necessary, the less accurate backward Euler method is often used, which is both stable and immune to oscillations.

[ citation needed ] Principle [ edit ] The Crank–Nicolson stencil for a 1D problem The Crank–Nicolson method is based on the trapezoidal rule , giving second-order convergence in time. For linear equations, the trapezoidal rule is equivalent to the implicit midpoint method [ citation needed ] —the simplest example of a Gauss–Legendre implicit Runge–Kutta method—which also has the property of being a geometric integrator . For example, in one dimension, suppose the partial differential equation is ∂ ∂ u ∂ ∂ t = F ( u , x , t , ∂ ∂ u ∂ ∂ x , ∂ ∂ 2 u ∂ ∂ x 2 ) .

{\displaystyle {\frac {\partial u}{\partial t}}=F\left(u,x,t,{\frac {\partial u}{\partial x}},{\frac {\partial ^{2}u}{\partial x^{2}}}\right).} Letting u ( i Δ Δ x , n Δ Δ t ) = u i n {\displaystyle u(i\Delta x,n\Delta t)=u_{i}^{n}} and F i n = F {\displaystyle F_{i}^{n}=F} evaluated for i , n {\displaystyle i,n} and u i n {\displaystyle u_{i}^{n}} , the equation for Crank–Nicolson method is a combination of the forward Euler method at n {\displaystyle n} and the backward Euler method at n + 1 {\displaystyle n+1} (note, however, that the method itself is not simply the average of those two methods, as the backward Euler equation has an implicit dependence on the solution): u i n + 1 − − u i n Δ Δ t = F i n ( u , x , t , ∂ ∂ u ∂ ∂ x , ∂ ∂ 2 u ∂ ∂ x 2 ) {\displaystyle {\frac {u_{i}^{n+1}-u_{i}^{n}}{\Delta t}}=F_{i}^{n}\left(u,x,t,{\frac {\partial u}{\partial x}},{\frac {\partial ^{2}u}{\partial x^{2}}}\right)} forward Euler u i n + 1 − − u i n Δ Δ t = F i n + 1 ( u , x , t , ∂ ∂ u ∂ ∂ x , ∂ ∂ 2 u ∂ ∂ x 2 ) {\displaystyle {\frac {u_{i}^{n+1}-u_{i}^{n}}{\Delta t}}=F_{i}^{n+1}\left(u,x,t,{\frac {\partial u}{\partial x}},{\frac {\partial ^{2}u}{\partial x^{2}}}\right)} backward Euler u i n + 1 − − u i n Δ Δ t = 1 2 [ F i n + 1 ( u , x , t , ∂ ∂ u ∂ ∂ x , ∂ ∂ 2 u ∂ ∂ x 2 ) + F i n ( u , x , t , ∂ ∂ u ∂ ∂ x , ∂ ∂ 2 u ∂ ∂ x 2 ) ] {\displaystyle {\frac {u_{i}^{n+1}-u_{i}^{n}}{\Delta t}}={\frac {1}{2}}\left[F_{i}^{n+1}\left(u,x,t,{\frac {\partial u}{\partial x}},{\frac {\partial ^{2}u}{\partial x^{2}}}\right)+F_{i}^{n}\left(u,x,t,{\frac {\partial u}{\partial x}},{\frac {\partial ^{2}u}{\partial x^{2}}}\right)\right]} Crank–Nicolson Note that this is an implicit method : to get the "next" value of u {\displaystyle u} in time, a system of algebraic equations must be solved. If the partial differential equation is nonlinear, the discretization will also be nonlinear, so that advancing in time will involve the solution of a system of nonlinear algebraic equations, though linearizations are possible. In many problems, especially linear diffusion, the algebraic problem is tridiagonal and may be efficiently solved with the tridiagonal matrix algorithm , which gives a fast O ( N ) {\displaystyle {\mathcal {O}}(N)} direct solution, as opposed to the usual O ( N 3 ) {\displaystyle {\mathcal {O}}(N^{3})} for a full matrix, in which N {\displaystyle N} indicates the matrix size.

Example: 1D diffusion [ edit ] The Crank–Nicolson method is often applied to diffusion problems . As an example, for linear diffusion, ∂ ∂ u ∂ ∂ t = a ∂ ∂ 2 u ∂ ∂ x 2 , {\displaystyle {\frac {\partial u}{\partial t}}=a{\frac {\partial ^{2}u}{\partial x^{2}}},} applying a finite difference spatial discretization for the right-hand side, the Crank–Nicolson discretization is then u i n + 1 − − u i n Δ Δ t = a 2 ( Δ Δ x ) 2 ( ( u i + 1 n + 1 − − 2 u i n + 1 + u i − − 1 n + 1 ) + ( u i + 1 n − − 2 u i n + u i − − 1 n ) ) {\displaystyle {\frac {u_{i}^{n+1}-u_{i}^{n}}{\Delta t}}={\frac {a}{2(\Delta x)^{2}}}\left((u_{i+1}^{n+1}-2u_{i}^{n+1}+u_{i-1}^{n+1})+(u_{i+1}^{n}-2u_{i}^{n}+u_{i-1}^{n})\right)} or, letting r = a Δ Δ t 2 ( Δ Δ x ) 2 {\displaystyle r={\frac {a\Delta t}{2(\Delta x)^{2}}}} , − − r u i + 1 n + 1 + ( 1 + 2 r ) u i n + 1 − − r u i − − 1 n + 1 = r u i + 1 n + ( 1 − − 2 r ) u i n + r u i − − 1 n .

{\displaystyle -ru_{i+1}^{n+1}+(1+2r)u_{i}^{n+1}-ru_{i-1}^{n+1}=ru_{i+1}^{n}+(1-2r)u_{i}^{n}+ru_{i-1}^{n}.} Given that the terms on the right-hand side of the equation are known, this is a tridiagonal problem, so that u i n + 1 {\displaystyle u_{i}^{n+1}} may be efficiently solved by using the tridiagonal matrix algorithm in favor over the much more costly matrix inversion .

A quasilinear equation, such as (this is a minimalistic example and not general) ∂ ∂ u ∂ ∂ t = a ( u ) ∂ ∂ 2 u ∂ ∂ x 2 , {\displaystyle {\frac {\partial u}{\partial t}}=a(u){\frac {\partial ^{2}u}{\partial x^{2}}},} would lead to a nonlinear system of algebraic equations, which could not be easily solved as above; however, it is possible in some cases to linearize the problem by using the old value for a {\displaystyle a} , that is, a i n ( u ) {\displaystyle a_{i}^{n}(u)} instead of a i n + 1 ( u ) {\displaystyle a_{i}^{n+1}(u)} . Other times, it may be possible to estimate a i n + 1 ( u ) {\displaystyle a_{i}^{n+1}(u)} using an explicit method and maintain stability.

Example: 1D diffusion with advection for steady flow, with multiple channel connections [ edit ] This is a solution usually employed for many purposes when there is a contamination problem in streams or rivers under steady flow conditions, but information is given in one dimension only. Often the problem can be simplified into a 1-dimensional problem and still yield useful information.

Here we model the concentration of a solute contaminant in water. This problem is composed of three parts: the known diffusion equation ( D x {\displaystyle D_{x}} chosen as constant), an advective component (which means that the system is evolving in space due to a velocity field), which we choose to be a constant U x {\displaystyle U_{x}} , and a lateral interaction between longitudinal channels ( k {\displaystyle k} ): ∂ ∂ C ∂ ∂ t = D x ∂ ∂ 2 C ∂ ∂ x 2 − − U x ∂ ∂ C ∂ ∂ x − − k ( C − − C N ) − − k ( C − − C M ) , {\displaystyle {\frac {\partial C}{\partial t}}=D_{x}{\frac {\partial ^{2}C}{\partial x^{2}}}-U_{x}{\frac {\partial C}{\partial x}}-k(C-C_{N})-k(C-C_{M}),} 1 where C {\displaystyle C} is the concentration of the contaminant, and subscripts N {\displaystyle N} and M {\displaystyle M} correspond to previous and next channel.

The Crank–Nicolson method (where i {\displaystyle i} represents position, and j {\displaystyle j} time) transforms each component of the PDE into the following: ∂ ∂ C ∂ ∂ t ⇒ ⇒ C i j + 1 − − C i j Δ Δ t , {\displaystyle {\frac {\partial C}{\partial t}}\Rightarrow {\frac {C_{i}^{j+1}-C_{i}^{j}}{\Delta t}},} 2 ∂ ∂ 2 C ∂ ∂ x 2 ⇒ ⇒ 1 2 ( Δ Δ x ) 2 ( ( C i + 1 j + 1 − − 2 C i j + 1 + C i − − 1 j + 1 ) + ( C i + 1 j − − 2 C i j + C i − − 1 j ) ) , {\displaystyle {\frac {\partial ^{2}C}{\partial x^{2}}}\Rightarrow {\frac {1}{2(\Delta x)^{2}}}\left((C_{i+1}^{j+1}-2C_{i}^{j+1}+C_{i-1}^{j+1})+(C_{i+1}^{j}-2C_{i}^{j}+C_{i-1}^{j})\right),} 3 ∂ ∂ C ∂ ∂ x ⇒ ⇒ 1 2 ( ( C i + 1 j + 1 − − C i − − 1 j + 1 ) 2 ( Δ Δ x ) + ( C i + 1 j − − C i − − 1 j ) 2 ( Δ Δ x ) ) , {\displaystyle {\frac {\partial C}{\partial x}}\Rightarrow {\frac {1}{2}}\left({\frac {(C_{i+1}^{j+1}-C_{i-1}^{j+1})}{2(\Delta x)}}+{\frac {(C_{i+1}^{j}-C_{i-1}^{j})}{2(\Delta x)}}\right),} 4 C ⇒ ⇒ 1 2 ( C i j + 1 + C i j ) , {\displaystyle C\Rightarrow {\frac {1}{2}}(C_{i}^{j+1}+C_{i}^{j}),} 5 C N ⇒ ⇒ 1 2 ( C N i j + 1 + C N i j ) , {\displaystyle C_{N}\Rightarrow {\frac {1}{2}}(C_{Ni}^{j+1}+C_{Ni}^{j}),} 6 C M ⇒ ⇒ 1 2 ( C M i j + 1 + C M i j ) .

{\displaystyle C_{M}\Rightarrow {\frac {1}{2}}(C_{Mi}^{j+1}+C_{Mi}^{j}).} 7 Now we create the following constants to simplify the algebra: λ λ = D x Δ Δ t 2 Δ Δ x 2 , {\displaystyle \lambda ={\frac {D_{x}\,\Delta t}{2\,\Delta x^{2}}},} α α = U x Δ Δ t 4 Δ Δ x , {\displaystyle \alpha ={\frac {U_{x}\,\Delta t}{4\,\Delta x}},} β β = k Δ Δ t 2 , {\displaystyle \beta ={\frac {k\,\Delta t}{2}},} and substitute ( 2 ), ( 3 ), ( 4 ), ( 5 ), ( 6 ), ( 7 ), α α {\displaystyle \alpha } , β β {\displaystyle \beta } and λ λ {\displaystyle \lambda } into ( 1 ). We then put the new time terms on the left ( j + 1 {\displaystyle j+1} ) and the present time terms on the right ( j {\displaystyle j} ) to get − − β β C N i j + 1 − − ( λ λ + α α ) C i − − 1 j + 1 + ( 1 + 2 λ λ + 2 β β ) C i j + 1 − − ( λ λ − − α α ) C i + 1 j + 1 − − β β C M i j + 1 = {\displaystyle -\beta C_{Ni}^{j+1}-(\lambda +\alpha )C_{i-1}^{j+1}+(1+2\lambda +2\beta )C_{i}^{j+1}-(\lambda -\alpha )C_{i+1}^{j+1}-\beta C_{Mi}^{j+1}={}} β β C N i j + ( λ λ + α α ) C i − − 1 j + ( 1 − − 2 λ λ − − 2 β β ) C i j + ( λ λ − − α α ) C i + 1 j + β β C M i j .

{\displaystyle \qquad \beta C_{Ni}^{j}+(\lambda +\alpha )C_{i-1}^{j}+(1-2\lambda -2\beta )C_{i}^{j}+(\lambda -\alpha )C_{i+1}^{j}+\beta C_{Mi}^{j}.} To model the first channel, we realize that it can only be in contact with the following channel ( M {\displaystyle M} ), so the expression is simplified to − − ( λ λ + α α ) C i − − 1 j + 1 + ( 1 + 2 λ λ + β β ) C i j + 1 − − ( λ λ − − α α ) C i + 1 j + 1 − − β β C M i j + 1 = {\displaystyle -(\lambda +\alpha )C_{i-1}^{j+1}+(1+2\lambda +\beta )C_{i}^{j+1}-(\lambda -\alpha )C_{i+1}^{j+1}-\beta C_{Mi}^{j+1}={}} + ( λ λ + α α ) C i − − 1 j + ( 1 − − 2 λ λ − − β β ) C i j + ( λ λ − − α α ) C i + 1 j + β β C M i j .

{\displaystyle \qquad {}+(\lambda +\alpha )C_{i-1}^{j}+(1-2\lambda -\beta )C_{i}^{j}+(\lambda -\alpha )C_{i+1}^{j}+\beta C_{Mi}^{j}.} In the same way, to model the last channel, we realize that it can only be in contact with the previous channel ( N {\displaystyle N} ), so the expression is simplified to − − β β C N i j + 1 − − ( λ λ + α α ) C i − − 1 j + 1 + ( 1 + 2 λ λ + β β ) C i j + 1 − − ( λ λ − − α α ) C i + 1 j + 1 = {\displaystyle -\beta C_{Ni}^{j+1}-(\lambda +\alpha )C_{i-1}^{j+1}+(1+2\lambda +\beta )C_{i}^{j+1}-(\lambda -\alpha )C_{i+1}^{j+1}={}} β β C N i j + ( λ λ + α α ) C i − − 1 j + ( 1 − − 2 λ λ − − β β ) C i j + ( λ λ − − α α ) C i + 1 j .

{\displaystyle \qquad \beta C_{Ni}^{j}+(\lambda +\alpha )C_{i-1}^{j}+(1-2\lambda -\beta )C_{i}^{j}+(\lambda -\alpha )C_{i+1}^{j}.} To solve this linear system of equations, we must now see that boundary conditions must be given first to the beginning of the channels: C 0 j {\displaystyle C_{0}^{j}} : boundary condition for the channel at present time step, C 0 j + 1 {\displaystyle C_{0}^{j+1}} : boundary condition for the channel at next time step, C N 0 j {\displaystyle C_{N0}^{j}} : boundary condition for the previous channel to the one analyzed at present time step, C M 0 j {\displaystyle C_{M0}^{j}} : boundary condition for the next channel to the one analyzed at present time step.

For the last cell of the channels ( z {\displaystyle z} ), the most convenient condition becomes an adiabatic one, so ∂ ∂ C ∂ ∂ x | x = z = C i + 1 − − C i − − 1 2 Δ Δ x = 0.

{\displaystyle \left.{\frac {\partial C}{\partial x}}\right|_{x=z}={\frac {C_{i+1}-C_{i-1}}{2\,\Delta x}}=0.} This condition is satisfied if and only if (regardless of a null value) C i + 1 j + 1 = C i − − 1 j + 1 .

{\displaystyle C_{i+1}^{j+1}=C_{i-1}^{j+1}.} Let us solve this problem (in a matrix form) for the case of 3 channels and 5 nodes (including the initial boundary condition). We express this as a linear system problem: A A C j + 1 = B B C j + d , {\displaystyle \mathbf {AA} \,\mathbf {C^{j+1}} =\mathbf {BB} \,\mathbf {C^{j}} +\mathbf {d} ,} where C j + 1 = [ C 11 j + 1 C 12 j + 1 C 13 j + 1 C 14 j + 1 C 21 j + 1 C 22 j + 1 C 23 j + 1 C 24 j + 1 C 31 j + 1 C 32 j + 1 C 33 j + 1 C 34 j + 1 ] , C j = [ C 11 j C 12 j C 13 j C 14 j C 21 j C 22 j C 23 j C 24 j C 31 j C 32 j C 33 j C 34 j ] .

{\displaystyle \mathbf {C^{j+1}} ={\begin{bmatrix}C_{11}^{j+1}\\C_{12}^{j+1}\\C_{13}^{j+1}\\C_{14}^{j+1}\\C_{21}^{j+1}\\C_{22}^{j+1}\\C_{23}^{j+1}\\C_{24}^{j+1}\\C_{31}^{j+1}\\C_{32}^{j+1}\\C_{33}^{j+1}\\C_{34}^{j+1}\end{bmatrix}},\quad \mathbf {C^{j}} ={\begin{bmatrix}C_{11}^{j}\\C_{12}^{j}\\C_{13}^{j}\\C_{14}^{j}\\C_{21}^{j}\\C_{22}^{j}\\C_{23}^{j}\\C_{24}^{j}\\C_{31}^{j}\\C_{32}^{j}\\C_{33}^{j}\\C_{34}^{j}\end{bmatrix}}.} Now we must realize that AA and BB should be arrays made of four different subarrays (remember that only three channels are considered for this example, but it covers the main part discussed above): A A = [ A A 1 A A 3 0 A A 3 A A 2 A A 3 0 A A 3 A A 1 ] , B B = [ B B 1 − − A A 3 0 − − A A 3 B B 2 − − A A 3 0 − − A A 3 B B 1 ] , {\displaystyle \mathbf {AA} ={\begin{bmatrix}AA1&AA3&0\\AA3&AA2&AA3\\0&AA3&AA1\end{bmatrix}},\quad \mathbf {BB} ={\begin{bmatrix}BB1&-AA3&0\\-AA3&BB2&-AA3\\0&-AA3&BB1\end{bmatrix}},} where the elements mentioned above correspond to the next arrays, and an additional 4×4 full of zeros. Please note that the sizes of AA and BB are 12×12: A A 1 = [ ( 1 + 2 λ λ + β β ) − − ( λ λ − − α α ) 0 0 − − ( λ λ + α α ) ( 1 + 2 λ λ + β β ) − − ( λ λ − − α α ) 0 0 − − ( λ λ + α α ) ( 1 + 2 λ λ + β β ) − − ( λ λ − − α α ) 0 0 − − 2 λ λ ( 1 + 2 λ λ + β β ) ] , {\displaystyle \mathbf {AA1} ={\begin{bmatrix}(1+2\lambda +\beta )&-(\lambda -\alpha )&0&0\\-(\lambda +\alpha )&(1+2\lambda +\beta )&-(\lambda -\alpha )&0\\0&-(\lambda +\alpha )&(1+2\lambda +\beta )&-(\lambda -\alpha )\\0&0&-2\lambda &(1+2\lambda +\beta )\end{bmatrix}},} A A 2 = [ ( 1 + 2 λ λ + 2 β β ) − − ( λ λ − − α α ) 0 0 − − ( λ λ + α α ) ( 1 + 2 λ λ + 2 β β ) − − ( λ λ − − α α ) 0 0 − − ( λ λ + α α ) ( 1 + 2 λ λ + 2 β β ) − − ( λ λ − − α α ) 0 0 − − 2 λ λ ( 1 + 2 λ λ + 2 β β ) ] , {\displaystyle \mathbf {AA2} ={\begin{bmatrix}(1+2\lambda +2\beta )&-(\lambda -\alpha )&0&0\\-(\lambda +\alpha )&(1+2\lambda +2\beta )&-(\lambda -\alpha )&0\\0&-(\lambda +\alpha )&(1+2\lambda +2\beta )&-(\lambda -\alpha )\\0&0&-2\lambda &(1+2\lambda +2\beta )\end{bmatrix}},} A A 3 = [ − − β β 0 0 0 0 − − β β 0 0 0 0 − − β β 0 0 0 0 − − β β ] , {\displaystyle \mathbf {AA3} ={\begin{bmatrix}-\beta &0&0&0\\0&-\beta &0&0\\0&0&-\beta &0\\0&0&0&-\beta \end{bmatrix}},} B B 1 = [ ( 1 − − 2 λ λ − − β β ) ( λ λ − − α α ) 0 0 ( λ λ + α α ) ( 1 − − 2 λ λ − − β β ) ( λ λ − − α α ) 0 0 ( λ λ + α α ) ( 1 − − 2 λ λ − − β β ) ( λ λ − − α α ) 0 0 2 λ λ ( 1 − − 2 λ λ − − β β ) ] , {\displaystyle \mathbf {BB1} ={\begin{bmatrix}(1-2\lambda -\beta )&(\lambda -\alpha )&0&0\\(\lambda +\alpha )&(1-2\lambda -\beta )&(\lambda -\alpha )&0\\0&(\lambda +\alpha )&(1-2\lambda -\beta )&(\lambda -\alpha )\\0&0&2\lambda &(1-2\lambda -\beta )\end{bmatrix}},} B B 2 = [ ( 1 − − 2 λ λ − − 2 β β ) ( λ λ − − α α ) 0 0 ( λ λ + α α ) ( 1 − − 2 λ λ − − 2 β β ) ( λ λ − − α α ) 0 0 ( λ λ + α α ) ( 1 − − 2 λ λ − − 2 β β ) ( λ λ − − α α ) 0 0 2 λ λ ( 1 − − 2 λ λ − − 2 β β ) ] .

{\displaystyle \mathbf {BB2} ={\begin{bmatrix}(1-2\lambda -2\beta )&(\lambda -\alpha )&0&0\\(\lambda +\alpha )&(1-2\lambda -2\beta )&(\lambda -\alpha )&0\\0&(\lambda +\alpha )&(1-2\lambda -2\beta )&(\lambda -\alpha )\\0&0&2\lambda &(1-2\lambda -2\beta )\end{bmatrix}}.} The d vector here is used to hold the boundary conditions. In this example it is a 12×1 vector: d = [ ( λ λ + α α ) ( C 10 j + 1 + C 10 j ) 0 0 0 ( λ λ + α α ) ( C 20 j + 1 + C 20 j ) 0 0 0 ( λ λ + α α ) ( C 30 j + 1 + C 30 j ) 0 0 0 ] .

{\displaystyle \mathbf {d} ={\begin{bmatrix}(\lambda +\alpha )(C_{10}^{j+1}+C_{10}^{j})\\0\\0\\0\\(\lambda +\alpha )(C_{20}^{j+1}+C_{20}^{j})\\0\\0\\0\\(\lambda +\alpha )(C_{30}^{j+1}+C_{30}^{j})\\0\\0\\0\end{bmatrix}}.} To find the concentration at any time, one must iterate the following equation: C j + 1 = A A − − 1 ( B B C j + d ) .

{\displaystyle \mathbf {C^{j+1}} =\mathbf {AA} ^{-1}(\mathbf {BB} \,\mathbf {C^{j}} +\mathbf {d} ).} Example: 2D diffusion [ edit ] When extending into two dimensions on a uniform Cartesian grid , the derivation is similar and the results may lead to a system of band-diagonal equations rather than tridiagonal ones. The two-dimensional heat equation ∂ ∂ u ∂ ∂ t = a ∇ ∇ 2 u , {\displaystyle {\frac {\partial u}{\partial t}}=a\,\nabla ^{2}u,} ∂ ∂ u ∂ ∂ t = a ( ∂ ∂ 2 u ∂ ∂ x 2 + ∂ ∂ 2 u ∂ ∂ y 2 ) {\displaystyle {\frac {\partial u}{\partial t}}=a\left({\frac {\partial ^{2}u}{\partial x^{2}}}+{\frac {\partial ^{2}u}{\partial y^{2}}}\right)} can be solved with the Crank–Nicolson discretization of u i , j n + 1 = u i , j n + 1 2 a Δ Δ t ( Δ Δ x ) 2 [ ( u i + 1 , j n + 1 + u i − − 1 , j n + 1 + u i , j + 1 n + 1 + u i , j − − 1 n + 1 − − 4 u i , j n + 1 ) + ( u i + 1 , j n + u i − − 1 , j n + u i , j + 1 n + u i , j − − 1 n − − 4 u i , j n ) ] , {\displaystyle {\begin{aligned}u_{i,j}^{n+1}={}&u_{i,j}^{n}+{\frac {1}{2}}{\frac {a\Delta t}{(\Delta x)^{2}}}{\big [}(u_{i+1,j}^{n+1}+u_{i-1,j}^{n+1}+u_{i,j+1}^{n+1}+u_{i,j-1}^{n+1}-4u_{i,j}^{n+1})\\&+(u_{i+1,j}^{n}+u_{i-1,j}^{n}+u_{i,j+1}^{n}+u_{i,j-1}^{n}-4u_{i,j}^{n}){\big ]},\end{aligned}}} assuming that a square grid is used, so that Δ Δ x = Δ Δ y {\displaystyle \Delta x=\Delta y} . This equation can be simplified somewhat by rearranging terms and using the CFL number μ μ = a Δ Δ t ( Δ Δ x ) 2 .

{\displaystyle \mu ={\frac {a\,\Delta t}{(\Delta x)^{2}}}.} For the Crank–Nicolson numerical scheme, a low CFL number is not required for stability, however, it is required for numerical accuracy. We can now write the scheme as ( 1 + 2 μ μ ) u i , j n + 1 − − μ μ 2 ( u i + 1 , j n + 1 + u i − − 1 , j n + 1 + u i , j + 1 n + 1 + u i , j − − 1 n + 1 ) {\displaystyle (1+2\mu )u_{i,j}^{n+1}-{\frac {\mu }{2}}\left(u_{i+1,j}^{n+1}+u_{i-1,j}^{n+1}+u_{i,j+1}^{n+1}+u_{i,j-1}^{n+1}\right)} = ( 1 − − 2 μ μ ) u i , j n + μ μ 2 ( u i + 1 , j n + u i − − 1 , j n + u i , j + 1 n + u i , j − − 1 n ) .

{\displaystyle \qquad =(1-2\mu )u_{i,j}^{n}+{\frac {\mu }{2}}\left(u_{i+1,j}^{n}+u_{i-1,j}^{n}+u_{i,j+1}^{n}+u_{i,j-1}^{n}\right).} Solving such a linear system is costly. Hence an alternating-direction implicit method can be implemented to solve the numerical PDE, whereby one dimension is treated implicitly, and other dimension explicitly for half of the assigned time step and conversely for the remainder half of the time step. The benefit of this strategy is that the implicit solver only requires a tridiagonal matrix algorithm to be solved. The difference between the true Crank–Nicolson solution and ADI approximated solution has an order of accuracy of O ( Δ Δ t 4 ) {\displaystyle O(\Delta t^{4})} and hence can be ignored with a sufficiently small time step.

[ 4 ] Crank–Nicolson for nonlinear problems [ edit ] Because the Crank–Nicolson method is implicit , it is generally impossible to solve exactly. Instead, an iterative  technique should be used to converge to the solution. One option is to use Newton's method to converge on the prediction, but this requires the computation of the Jacobian . For a high-dimensional system like those in computational fluid dynamics or numerical relativity , it may be infeasible to compute this Jacobian.

A Jacobian-free alternative is fixed-point iteration . If f {\displaystyle f} is the velocity of the system, then the Crank–Nicolson prediction will be a fixed point of the map Φ Φ ( x ) = x 0 + h 2 [ f ( x 0 ) + f ( x ) ] .

{\displaystyle \Phi (x)=x_{0}+{\frac {h}{2}}\left[f(x_{0})+f(x)\right].} If the map iteration x ( i + 1 ) = Φ Φ ( x ( i ) ) {\displaystyle x^{(i+1)}=\Phi (x^{(i)})} does not converge, the parameterized map Θ Θ ( x , α α ) = α α x + ( 1 − − α α ) Φ Φ ( x ) {\displaystyle \Theta (x,\alpha )=\alpha x+(1-\alpha )\Phi (x)} , with α α ∈ ∈ ( 0 , 1 ) {\displaystyle \alpha \in (0,1)} , may be better behaved. In expanded form, the update formula is x i + 1 = α α x i + ( 1 − − α α ) [ x 0 + h 2 ( f ( x 0 ) + f ( x i ) ) ] , {\displaystyle x^{i+1}=\alpha x^{i}+(1-\alpha )\left[x_{0}+{\frac {h}{2}}\left(f(x_{0})+f(x^{i})\right)\right],} where x i {\displaystyle x^{i}} is the current guess and x i − − 1 {\displaystyle x_{i-1}} is the previous time-step.

Even for high-dimensional systems, iteration of this map can converge surprisingly quickly.

A numerical solution of the Navier–Stokes equations in the vorticity form. In this case α α = 7 / 8 {\displaystyle \alpha =7/8} was needed for fixed-point iteration of Crank–Nicolson to converge.

Application in financial mathematics [ edit ] Further information: Finite difference methods for option pricing Because a number of other phenomena can be modeled with the heat equation (often called the diffusion equation in financial mathematics ), the Crank–Nicolson method has been applied to those areas as well.

[ 5 ] Particularly, the Black–Scholes option pricing model's differential equation can be transformed into the heat equation, and thus numerical solutions for option pricing can be obtained with the Crank–Nicolson method.

The importance of this for finance is that option pricing problems, when extended beyond the standard assumptions (e.g. incorporating changing dividends), cannot be solved in closed form, but can be solved using this method.  Note however, that for non-smooth final conditions (which happen for most financial instruments), the Crank–Nicolson method is not satisfactory as numerical oscillations are not damped.  For vanilla options , this results in oscillation in the gamma value around the strike price .  Therefore, special damping initialization steps are necessary (e.g., fully implicit finite difference method).

See also [ edit ] Financial mathematics Trapezoidal rule References [ edit ] ^ Tuncer Cebeci (2002).

Convective Heat Transfer . Springer.

ISBN 0-9668461-4-1 .

^ Crank, J.

; Nicolson, P.

(1947). "A practical method for numerical evaluation of solutions of partial differential equations of the heat conduction type".

Mathematical Proceedings of the Cambridge Philosophical Society .

43 (1): 50– 67.

Bibcode : 1947PCPS...43...50C .

doi : 10.1017/S0305004100023197 .

S2CID 16676040 .

^ Thomas, J. W. (1995).

Numerical Partial Differential Equations: Finite Difference Methods . Texts in Applied Mathematics. Vol. 22. Berlin, New York: Springer-Verlag .

ISBN 978-0-387-97999-1 .

. Example 3.3.2 shows that Crank–Nicolson is unconditionally stable when applied to u t = a u x x {\displaystyle u_{t}=au_{xx}} .

^ "Multi-Dimensional Parabolic Problems" (PDF) .

Computer Science Department . RPI . Retrieved 29 May 2016 .

^ Wilmott, P.; Howison, S.; Dewynne, J. (1995).

The Mathematics of Financial Derivatives: A Student Introduction . Cambridge Univ. Press.

ISBN 0-521-49789-2 .

The Mathematics of Financial Derivatives Wilmott.

External links [ edit ] Numerical PDE Techniques for Scientists and Engineers , open access Lectures and Codes for Numerical PDEs An example of how to apply and implement the Crank–Nicolson method for the Advection equation v t e Numerical methods for ordinary differential equations First-order methods Euler method Backward Euler Semi-implicit Euler Exponential Euler Second-order methods Verlet integration Velocity Verlet Trapezoidal rule Beeman's algorithm Midpoint method Heun's method Newmark-beta method Leapfrog integration Higher-order methods Exponential integrator Runge–Kutta methods List of Runge–Kutta methods Linear multistep method General linear methods Backward differentiation formula Yoshida Gauss–Legendre method Theory Symplectic integrator Related Numerical methods for partial differential equations Numerical integration v t e Numerical methods for partial differential equations Finite difference Parabolic Forward-time central-space (FTCS) Crank–Nicolson Hyperbolic Lax–Friedrichs Lax–Wendroff MacCormack Upwind Method of characteristics Others Alternating direction-implicit (ADI) Finite-difference frequency-domain (FDFD) Finite-difference time-domain (FDTD) Finite volume Godunov High-resolution Monotonic upstream-centered (MUSCL) Advection upstream-splitting (AUSM) Riemann solver Essentially non-oscillatory (ENO) Weighted essentially non-oscillatory (WENO) Finite element hp-FEM Extended (XFEM) Discontinuous Galerkin (DG) Spectral element (SEM) Mortar Gradient discretisation (GDM) Loubignac iteration Smoothed (S-FEM) Meshless/Meshfree Smoothed-particle hydrodynamics (SPH) Peridynamics (PD) Moving particle semi-implicit method (MPS) Material point method (MPM) Particle-in-cell (PIC) Domain decomposition Schur complement Fictitious domain Schwarz alternating additive abstract additive Neumann–Dirichlet Neumann–Neumann Poincaré–Steklov operator Balancing (BDD) Balancing by constraints (BDDC) Tearing and interconnect (FETI) FETI-DP Others Spectral Pseudospectral (DVR) Method of lines Multigrid Collocation Level-set Boundary element Method of moments Immersed boundary Analytic element Isogeometric analysis Infinite difference method Infinite element method Galerkin method Petrov–Galerkin method Validated numerics Computer-assisted proof Integrable algorithm Method of fundamental solutions Related Numerical methods for ordinary differential equations Numerical integration Retrieved from " https://en.wikipedia.org/w/index.php?title=Crank–Nicolson_method&oldid=1281643372 " Categories : Mathematical finance Numerical differential equations Finite differences Hidden categories: Articles with short description Short description matches Wikidata All articles with unsourced statements Articles with unsourced statements from July 2016 Articles with unsourced statements from September 2019 This page was last edited on 21 March 2025, at 16:22 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Crank–Nicolson method 9 languages Add topic

