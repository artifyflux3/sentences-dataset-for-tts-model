Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Experimental research Toggle Experimental research subsection 1.1 Two-urns paradox 1.2 One-urn paradox 1.2.1 Utility theory interpretation 1.2.2 Numerical demonstration 1.2.3 The generality of the paradox 1.2.4 Possible explanations 2 Decisions under uncertainty aversion 3 Alternative explanations 4 Daniel Ellsberg's 1962 paper, "Risk, Ambiguity, and Decision" 5 See also 6 References 7 Further reading Toggle the table of contents Ellsberg paradox 12 languages Català Deutsch Español Français Հայերեն Italiano עברית Polski Português Русский Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Paradox in decision theory You can help expand this article with text translated from the corresponding article in German .

(June 2025) Click [show] for important translation instructions.

Machine translation, like DeepL or Google Translate , is a useful starting point for translations, but translators must revise errors as necessary and confirm that the translation is accurate, rather than simply copy-pasting machine-translated text into the English Wikipedia.

Do not translate text that appears unreliable or low-quality. If possible, verify the text with references provided in the foreign-language article.

You must provide copyright attribution in the edit summary accompanying your translation by providing an interlanguage link to the source of your translation. A model attribution edit summary is Content in this edit is translated from the existing German Wikipedia article at [[:de:Ellsberg-Paradoxon]]; see its history for attribution.

You may also add the template {{Translated|de|Ellsberg-Paradoxon}} to the talk page .

For more guidance, see Wikipedia:Translation .

This article includes a list of general references , but it lacks sufficient corresponding inline citations .

Please help to improve this article by introducing more precise citations.

( August 2015 ) ( Learn how and when to remove this message ) Daniel Ellsberg (1931–2023), after whom the paradox is named In decision theory , the Ellsberg paradox (or Ellsberg's paradox ) is a paradox in which people's decisions are inconsistent with subjective expected utility theory.

John Maynard Keynes published a version of the paradox in 1921.

[ 1 ] Daniel Ellsberg popularized the paradox in his 1961 paper, "Risk, Ambiguity, and the Savage Axioms".

[ 2 ] It is generally taken to be evidence of ambiguity aversion , in which a person tends to prefer choices with quantifiable risks over those with unknown, incalculable risks.

Ellsberg's findings indicate that choices with an underlying level of risk are favored in instances where the likelihood of risk is clear, rather than instances in which the likelihood of risk is unknown. A decision-maker will overwhelmingly favor a choice with a transparent likelihood of risk, even in instances where the unknown alternative will likely produce greater utility . When offered choices with varying risk , people prefer choices with calculable risk, even when those choices have less utility.

[ 3 ] Experimental research [ edit ] Ellsberg's experimental research involved two separate thought experiments: the 2-urn 2-color scenario and the 1-urn 3-color scenario.

Two-urns paradox [ edit ] There are two urns each containing 100 balls. It is known that urn A contains 50 red and 50 black, but urn B contains an unknown mix of red and black balls.

The following bets are offered to a participant: Bet 1A: get $1 if red is drawn from urn A , $0 otherwise Bet 2A: get $1 if black is drawn from urn A , $0 otherwise Bet 1B: get $1 if red is drawn from urn B , $0 otherwise Bet 2B: get $1 if black is drawn from urn B , $0 otherwise Typically, participants were seen to be indifferent between bet 1A and bet 2A (consistent with expected utility theory) but were seen to strictly prefer Bet 1A to Bet 1B and Bet 2A to 2B. This result is generally interpreted to be a consequence of ambiguity aversion (also known as uncertainty aversion); people intrinsically dislike situations where they cannot attach probabilities to outcomes, in this case favoring the bet in which they know the probability and utility outcome (0.5 and $1 respectively).

One-urn paradox [ edit ] There is one urn containing 90 balls: 30 balls are red, while the remaining 60 balls are either black or yellow in unknown proportions. The balls are well mixed so that each ball is as likely to be drawn as any other. The participants then choose a gambling scenario: Gamble A Gamble B You receive $100 if you draw a red ball You receive $100 if you draw a black ball Additionally, the participant may choose a separate gamble scenario within the same situational parameters: Gamble C Gamble D You receive $100 if you draw a red or yellow ball You receive $100 if you draw a black or yellow ball The experimental conditions manufactured by Ellsberg serve to rely upon two economic principles: Knightian uncertainty , the unquantifiable nature of the mix between both yellow and black balls within the single urn, and probability , of which red balls are drawn at ⁠ 1 / 3 ⁠ vs.

⁠ 2 / 3 ⁠ .

Utility theory interpretation [ edit ] Utility theory models the choice by assuming that in choosing between these gambles, people assume a probability that the non-red balls are yellow versus black, and then compute the expected utility of the two gambles individually.

Since the prizes are the same, it follows that the participant will strictly prefer Gamble A to Gamble B if and only if they believe that drawing a red ball is more likely than drawing a black ball (according to expected utility theory ). Also, there would be indifference between the choices if the participant thought that a red ball was as likely as a black ball. Similarly, it follows the participant will strictly prefer Gamble C to Gamble D if and only if the participant believes that drawing a red or yellow ball is more likely than drawing a black or yellow ball. It might seem intuitive that if drawing a red ball is more likely than drawing a black ball, drawing a red or yellow ball is also more likely than drawing a black or yellow ball. So, supposing the participant strictly prefers Gamble A to Gamble B, it follows that he/she will also strictly prefer Gamble C to Gamble D, and similarly conversely.

However, ambiguity aversion would predict that people would strictly prefer Gamble A to Gamble B, and Gamble D to Gamble C.

Ellsberg's findings violate assumptions made within common Expected Utility Theory, with participants strictly preferring Gamble A to Gamble B and Gamble D to Gamble C.

Numerical demonstration [ edit ] (1) An urn filled with yellow balls stands for decision under certainty; (2) An urn filled with yellow and green balls stands for decision under risk; (3) An urn filled with yellow, green and a black ball stands for " Black swan "; (4) An urn filled with grey, one yellow and one green ball stands for Knightian uncertainty; and (5) An urn filled only with gray balls stands for Radical Uncertainty.  In (1) and (2) possible outcomes and probabilities are known, while in (4) only the possible outcomes are known, but no probabilities. In (3), the urn contains an extremely momentous result, which can be either extremely good ('diamond') or extremely bad ('bomb'). In the case of (5), neither possible realisations nor probabilities are known. Where (4) and (5) represent decisions under ambiguity.

Mathematically, the estimated probabilities of each color ball can be represented as R , Y , and B . If the participant strictly prefers Gamble A to Gamble B, by utility theory, it is presumed this preference is reflected by the expected utilities of the two gambles. We reach a contradiction in our utility calculations. This contradiction indicates that the participant's preferences are inconsistent with the expected-utility theory.

The generality of the paradox [ edit ] The result holds regardless of the utility function . Indeed, the amount of the payoff is likewise irrelevant. Whichever gamble is selected, the prize for winning it is the same, and the cost of losing it is the same (no cost), so ultimately there are only two outcomes: receive a specific amount of money or nothing. Therefore, it is sufficient to assume that the preference is to receive some money to nothing (this assumption is not necessary: in the mathematical treatment above, it was assumed U ($100) > U ($0), but a contradiction can still be obtained for U ($100) < U ($0) and for U ($100) = U ($0)).

In addition, the result holds regardless of risk aversion —all gambles involve risk. By choosing Gamble D, the participant has a 1 in 3 chance of receiving nothing, and by choosing Gamble A, a 2 in 3 chance of receiving nothing. If Gamble A was less risky than Gamble B, it would follow [ 4 ] that Gamble C was less risky than Gamble D (and vice versa), so the risk is not averted in this way.

However, because the exact chances of winning are known for Gambles A and D and not known for Gambles B and C, this can be taken as evidence for some sort of ambiguity aversion , which cannot be accounted for in expected utility theory. It has been demonstrated that this phenomenon occurs only when the choice set permits the comparison of the ambiguous proposition with a less vague proposition (but not when ambiguous propositions are evaluated in isolation).

[ 5 ] Possible explanations [ edit ] There have been various attempts to provide decision-theoretic explanations of Ellsberg's observation. Since the probabilistic information available to the decision-maker is incomplete, these attempts sometimes focus on quantifying the non-probabilistic ambiguity that the decision-maker faces – see Knightian uncertainty . That is, these alternative approaches sometimes suppose that the agent formulates a subjective (though not necessarily Bayesian ) probability for possible outcomes.

One such attempt is based on info-gap decision theory . The agent is told precise probabilities of some outcomes, though the practical meaning of the probability numbers is not entirely clear. For instance, in the gambles discussed above, the probability of a red ball is ⁠ 30 / 90 ⁠ , which is a precise number. Nonetheless, the participant may not distinguish intuitively between this and e.g.

⁠ 30 / 91 ⁠ . No probability information whatsoever is provided regarding other outcomes, so the participant has very unclear subjective impressions of these probabilities.

In light of the ambiguity in the probabilities of the outcomes, the agent is unable to evaluate a precise expected utility. Consequently, a choice based on maximizing the expected utility is also impossible. The info-gap approach supposes that the agent implicitly formulates info-gap models for the subjectively uncertain probabilities. The agent then tries to satisfice the expected utility and maximize the robustness against uncertainty in the imprecise probabilities. This robust-satisficing approach can be developed explicitly to show that the choices of decision-makers should display precisely the preference reversal that Ellsberg observed.

[ 6 ] Another possible explanation is that this type of game triggers a deceit aversion mechanism. Many humans naturally assume in real-world situations that if they are not told the probability of a certain event, it is to deceive them. Participants make the same decisions in the experiment as they would about related but not identical real-life problems where the experimenter would be likely to be a deceiver acting against the subject's interests. When faced with the choice between a red ball and a black ball, the probability of ⁠ 30 / 90 ⁠ is compared to the lower part of the ⁠ 0 / 90 ⁠ – ⁠ 60 / 90 ⁠ range (the probability of getting a black ball). The average person expects there to be fewer black balls than yellow balls because, in most real-world situations, it would be to the advantage of the experimenter to put fewer black balls in the urn when offering such a gamble. On the other hand, when offered a choice between red and yellow balls and black and yellow balls, people assume that there must be fewer than 30 yellow balls as would be necessary to deceive them. When making the decision, it is quite possible that people simply neglect to consider that the experimenter does not have a chance to modify the contents of the urn in between the draws. In real-life situations, even if the urn is not to be modified, people would be afraid of being deceived on that front as well.

[ 7 ] Decisions under uncertainty aversion [ edit ] Chart probability relationship [ clarification needed ] To describe how an individual would take decisions in a world where uncertainty aversion exists, modifications of the expected utility framework have been proposed. These include: Choquet expected utility : Created by French mathematician Gustave Choquet was a subadditive integral used as a way of measuring expected utility in situations with unknown parameters. The mathematical principle is seen as a way in which the contradiction between rational choice theory , Expected utility theory , and Ellsberg's seminal findings can be reconciled.

Maxmin expected utility: Axiomatized by Gilboa and Schmeidler [ 8 ] is a widely received alternative to utility maximization, taking into account ambiguity-averse preferences. This model reconciles the notion that intuitive decisions may violate the ambiguity neutrality, established within both the Ellsberg Paradox and Allais Paradox .

Alternative explanations [ edit ] Other alternative explanations include the competence hypothesis [ 9 ] and the comparative ignorance hypothesis.

[ 5 ] Both theories attribute the source of the ambiguity aversion to the participant's pre-existing knowledge.

Daniel Ellsberg's 1962 paper, "Risk, Ambiguity, and Decision" [ edit ] Upon graduating in Economics from Harvard in 1952, Ellsberg left immediately to serve as a US Marine before coming back to Harvard in 1957 to complete his post-graduate studies on decision-making under uncertainty.

[ 10 ] Ellsberg left his graduate studies to join the RAND Corporation as a strategic analyst but continued to do academic work on the side. He presented his breakthrough paper at the December 1960 meeting of the Econometric Society . Ellsberg's work built upon previous works by both J.M. Keynes and F.H Knight , challenging the dominant rational choice theory . The work was made public in 2001, [ clarification needed ] some 40 years after being published, because of the Pentagon Papers scandal then encircling Ellsberg's life.

[ clarification needed ] The book [ clarification needed ] is considered a highly-influential paper [ clarification needed ] and is still considered influential within economic academia about risk ambiguity and uncertainty.

See also [ edit ] Allais paradox Ambiguity aversion Experimental economics Subjective expected utility Utility theory References [ edit ] ^ Keynes 1921 , pp. 75–76, paragraph 315, footnote 2.

^ Ellsberg, Daniel (1961).

"Risk, Ambiguity, and the Savage Axioms" (PDF) .

Quarterly Journal of Economics .

75 (4): 643– 669.

doi : 10.2307/1884324 .

JSTOR 1884324 .

^ "Experimental Discussion of the Ellsberg Paradox" .

EconPort . Experimental Economics Center, Georgia State University. 2006 . Retrieved 28 May 2022 .

^ Segal, Uzi (1987).

"The Ellsberg Paradox and Risk Aversion: An Anticipated Utility Approach" (PDF) .

International Economic Review .

28 (1): 175– 202.

doi : 10.2307/2526866 .

JSTOR 2526866 .

^ a b Fox, Craig R.; Tversky, Amos (1995). "Ambiguity Aversion and Comparative Ignorance".

Quarterly Journal of Economics .

110 (3): 585– 603.

CiteSeerX 10.1.1.395.8835 .

doi : 10.2307/2946693 .

JSTOR 2946693 .

^ Ben-Haim, Yakov (2006).

Info-gap Decision Theory: Decisions Under Severe Uncertainty (2nd ed.). Academic Press. section 11.1.

ISBN 978-0-12-373552-2 .

^ Lima Filho, Roberto (2 July 2009).

"Rationality Intertwined: Classical vs Institutional View" .

SSRN 2389751 .

^ I. Gilboa and D. Schmeidler. Maxmin expected utility with non-unique prior. Journal of Mathematical Economics, 18(2):141–153, 1989.

^ Heath, Chip; Tversky, Amos (1991). "Preference and Belief: Ambiguity and Competence in Choice under Uncertainty".

Journal of Risk and Uncertainty .

4 : 5– 28.

CiteSeerX 10.1.1.138.6159 .

doi : 10.1007/bf00057884 .

S2CID 146410959 .

^ Yasuhiro Sakai, Daniel Ellsberg on J.M. Keynes and F.H. Knight: risk ambiguity and uncertainty. Evolutionary and Institutional Economics Review. 2018. (16): 1-18 Further reading [ edit ] Anand, Paul (1993).

Foundations of Rational Choice Under Risk . Oxford University Press.

ISBN 978-0-19-823303-9 .

Keynes, John Maynard (1921).

A Treatise on Probability . London: Macmillan. pp.

75– 76 . Retrieved 17 February 2020 – via Internet Archive.

Schmeidler, D.

(1989). "Subjective Probability and Expected Utility without Additivity".

Econometrica .

57 (3): 571– 587.

CiteSeerX 10.1.1.295.4096 .

doi : 10.2307/1911053 .

JSTOR 1911053 .

v t e Paradoxes Philosophical Analysis Buridan's bridge Dream argument Epicurean Fiction Fitch's knowability Free will Goodman's Hedonism Liberal Meno's Mere addition Moore's Newcomb's Nihilism Omnipotence Preface Rule-following Sorites Theseus' ship White horse Zeno's Logical Barber Berry Bhartrhari's Burali-Forti Court Crocodile Curry's Epimenides Free choice paradox Grelling–Nelson Kleene–Rosser Liar Card No-no Pinocchio Quine's Yablo's Opposite Day Paradoxes of set theory Richard's Russell's Socratic Hilbert's Hotel Temperature paradox Barbershop Catch-22 Chicken or the egg Drinker Entailment Lottery Plato's beard Raven Ross's Unexpected hanging " What the Tortoise Said to Achilles " Heat death paradox Olbers's paradox Economic Allais Antitrust Arrow information Bertrand Braess' Competition Income and fertility Downs–Thomson Easterlin Edgeworth Ellsberg European Gibson's Giffen good Icarus Jevons Leontief Lerner Lucas Mandeville's Mayfield's Metzler Plenty Productivity Prosperity Scitovsky Service recovery St. Petersburg Thrift Toil Tullock Value Decision theory Abilene Apportionment Alabama New states Population Arrow's Buridan's ass Chainstore Condorcet's Decision-making Downs Ellsberg Fenno's Fredkin's Green Hedgehog's Inventor's Kavka's toxin puzzle Morton's fork Navigation Newcomb's Parrondo's Preparedness Prevention Prisoner's dilemma Tolerance Willpower List Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Ellsberg_paradox&oldid=1300229298 " Categories : Decision-making paradoxes Statistical paradoxes Paradoxes in utility theory Probability theory paradoxes Thought experiments Hidden categories: Articles with short description Short description matches Wikidata Use dmy dates from May 2025 Use Oxford spelling from May 2025 Government and politics articles needing translation from German Wikipedia Articles lacking in-text citations from August 2015 All articles lacking in-text citations Wikipedia articles needing clarification from July 2025 This page was last edited on 13 July 2025, at 02:11 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Ellsberg paradox 12 languages Add topic

