Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Overview Toggle Overview subsection 1.1 Notation 1.2 Motivation 2 Complex matrices Toggle Complex matrices subsection 2.1 Example 2.2 Example: Obtaining the normal form 3 Generalized eigenvectors Toggle Generalized eigenvectors subsection 3.1 A proof 3.2 Uniqueness 4 Real matrices 5 Matrices with entries in a field 6 Consequences Toggle Consequences subsection 6.1 Spectral mapping theorem 6.2 Characteristic polynomial 6.3 Cayley–Hamilton theorem 6.4 Minimal polynomial 6.5 Invariant subspace decompositions 6.6 Plane (flat) normal form 7 Matrix functions 8 Compact operators Toggle Compact operators subsection 8.1 Holomorphic functional calculus 8.2 The finite-dimensional case 8.3 Poles of an operator 9 Numerical analysis 10 See also 11 Notes 12 References Toggle the table of contents Jordan normal form 21 languages العربية Català Čeština Deutsch Español Esperanto Français Galego 한국어 Italiano עברית Magyar Nederlands 日本語 Polski Português Suomi Svenska Українська Tiếng Việt 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Jordan canonical form ) Form of a matrix indicating its eigenvalues and their algebraic multiplicities ( ⌜ ⌜ λ λ 1 1 λ λ 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌞ ⌞ λ λ 1 1 λ λ 1 λ λ 1 ⌟ ⌟ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 n ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌟ ⌟ ⌞ ⌞ λ λ 2 λ λ 2 ⌟ ⌟ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 λ λ n ⌝ ⌝ ⌜ ⌜ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌜ ⌜ λ λ n 1 n ⌝ ⌝ ⌞ ⌞ λ λ 1 1 λ λ 1 1 λ λ 1 ⌝ ⌝ ⌜ ⌜ λ λ 2 1 λ λ 2 ⌝ ⌝ [ λ λ 3 ] ⋱ ⋱ ⌞ ⌞ λ λ n λ λ n ⌟ ⌟ ) {\displaystyle {\begin{pmatrix}{\color {red}\ulcorner }\lambda _{1}1{\hphantom {\lambda _{1}\lambda _{1}}}{\color {red}\urcorner }{\hphantom {\ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1}}\lambda _{1}1{\hphantom {\lambda _{1}\urcorner \ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\color {red}\llcorner }{\hphantom {\lambda _{1}1\lambda _{1}}}\lambda _{1}{\color {red}\lrcorner }{\hphantom {\ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\urcorner }}{\color {red}\ulcorner }\lambda _{2}1{\hphantom {n}}{\color {red}\urcorner }{\hphantom {[\lambda _{3}]\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\lrcorner }}{\color {red}\llcorner }{\hphantom {\lambda _{2}}}\lambda _{2}{\color {red}\lrcorner }{\hphantom {[\lambda _{3}]\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\urcorner \ulcorner \lambda _{2}1\lambda _{2}\urcorner }}{\color {red}[}\lambda _{3}{\color {red}]}{\hphantom {\ddots \ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\urcorner \ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]}}\ddots {\hphantom {\ulcorner \lambda _{n}1\lambda _{n}\urcorner }}\\{\hphantom {\ulcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\urcorner \ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]\ddots }}{\color {red}\ulcorner }\lambda _{n}1{\hphantom {n}}{\color {red}\urcorner }\\{\hphantom {\llcorner \lambda _{1}1\lambda _{1}1\lambda _{1}\urcorner \ulcorner \lambda _{2}1\lambda _{2}\urcorner [\lambda _{3}]\ddots }}{\color {red}\llcorner }{\hphantom {\lambda _{n}}}\lambda _{n}{\color {red}\lrcorner }\end{pmatrix}}} Example of a matrix in Jordan normal form.

All matrix entries not shown are zero. The outlined squares are known as "Jordan blocks".

Each Jordan block contains one number λ i on its main diagonal, and 1s directly above the main diagonal. The λ i s are the eigenvalues of the matrix; they need not be distinct.

In linear algebra , a Jordan normal form , also known as a Jordan canonical form , [ 1 ] [ 2 ] is an upper triangular matrix of a particular form called a Jordan matrix representing a linear operator on a finite-dimensional vector space with respect to some basis . Such a matrix has each non-zero off-diagonal entry equal to 1, immediately above the main diagonal (on the superdiagonal ), and with identical diagonal entries to the left and below them.

Let V be a vector space over a field K . Then a basis with respect to which the matrix has the required form exists if and only if all eigenvalues of the matrix lie in K , or equivalently if the characteristic polynomial of the operator splits into linear factors over K . This condition is always satisfied if K is algebraically closed (for instance, if it is the field of complex numbers ). The diagonal entries of the normal form are the eigenvalues (of the operator), and the number of times each eigenvalue occurs is called the algebraic multiplicity of the eigenvalue.

[ 3 ] [ 4 ] [ 5 ] If the operator is originally given by a square matrix M , then its Jordan normal form is also called the Jordan normal form of M . Any square matrix has a Jordan normal form if the field of coefficients is extended to one containing all the eigenvalues of the matrix. In spite of its name, the normal form for a given M is not entirely unique, as it is a block diagonal matrix formed of Jordan blocks , the order of which is not fixed; it is conventional to group blocks for the same eigenvalue together, but no ordering is imposed among the eigenvalues, nor among the blocks for a given eigenvalue, although the latter could for instance be ordered by weakly decreasing size.

[ 3 ] [ 4 ] [ 5 ] The Jordan–Chevalley decomposition is particularly simple with respect to a basis for which the operator takes its Jordan normal form. The diagonal form for diagonalizable matrices, for instance normal matrices , is a special case of the Jordan normal form.

[ 6 ] [ 7 ] [ 8 ] The Jordan normal form is named after Camille Jordan , who first stated the Jordan decomposition theorem in 1870.

[ 9 ] Overview [ edit ] Notation [ edit ] Some textbooks have the ones on the subdiagonal ; that is, immediately below the main diagonal instead of on the superdiagonal. The eigenvalues are still on the main diagonal.

[ 10 ] [ 11 ] Motivation [ edit ] An n × n matrix A is diagonalizable if and only if the sum of the dimensions of the eigenspaces is n . Or, equivalently, if and only if A has n linearly independent eigenvectors . Not all matrices are diagonalizable; matrices that are not diagonalizable are called defective matrices. Consider the following matrix: A = [ 5 4 2 1 0 1 − − 1 − − 1 − − 1 − − 1 3 0 1 1 − − 1 2 ] .

{\displaystyle A=\left[{\begin{array}{*{20}{r}}5&4&2&1\\[2pt]0&1&-1&-1\\[2pt]-1&-1&3&0\\[2pt]1&1&-1&2\end{array}}\right].} Including multiplicity, the eigenvalues of A are λ = 1, 2, 4, 4. The dimension of the eigenspace corresponding to the eigenvalue 4 is 1 (and not 2), so A is not diagonalizable. However, there is an invertible matrix P such that J = P −1 AP , where J = [ 1 0 0 0 0 2 0 0 0 0 4 1 0 0 0 4 ] .

{\displaystyle J={\begin{bmatrix}1&0&0&0\\[2pt]0&2&0&0\\[2pt]0&0&4&1\\[2pt]0&0&0&4\end{bmatrix}}.} The matrix J {\displaystyle J} is almost diagonal. This is the Jordan normal form of A . The section Example below fills in the details of the computation.

Complex matrices [ edit ] In general, a square complex matrix A is similar to a block diagonal matrix J = [ J 1 ⋱ ⋱ J p ] {\displaystyle J={\begin{bmatrix}J_{1}&\;&\;\\\;&\ddots &\;\\\;&\;&J_{p}\end{bmatrix}}} where each block J i is a square matrix of the form J i = [ λ λ i 1 λ λ i ⋱ ⋱ ⋱ ⋱ 1 λ λ i ] .

{\displaystyle J_{i}={\begin{bmatrix}\lambda _{i}&1&\;&\;\\\;&\lambda _{i}&\ddots &\;\\\;&\;&\ddots &1\\\;&\;&\;&\lambda _{i}\end{bmatrix}}.} So there exists an invertible matrix P such that P −1 AP = J is such that the only non-zero entries of J are on the diagonal and the superdiagonal.

J is called the Jordan normal form of A . Each J i is called a Jordan block of A . In a given Jordan block, every entry on the superdiagonal is 1.

Assuming this result, we can deduce the following properties: Counting multiplicities, the eigenvalues of J , and therefore of A , are the diagonal entries.

Given an eigenvalue λ i , its geometric multiplicity is the dimension of ker( A − λ i I ), where I is the identity matrix , and it is the number of Jordan blocks corresponding to λ i .

[ 12 ] The sum of the sizes of all Jordan blocks corresponding to an eigenvalue λ i is its algebraic multiplicity .

[ 12 ] A is diagonalizable if and only if, for every eigenvalue λ of A , its geometric and algebraic multiplicities coincide. In particular, the Jordan blocks in this case are 1 × 1 matrices; that is, scalars.

The Jordan block corresponding to λ is of the form λI + N , where N is a nilpotent matrix defined as N ij = δ i , j −1 (where δ is the Kronecker delta ). The nilpotency of N can be exploited when calculating f ( A ) where f is a complex analytic function. For example, in principle the Jordan form could give a closed-form expression for the exponential exp( A ).

The number of Jordan blocks corresponding to λ i of size at least j is dim ker( A − λ i I ) j − dim ker( A − λ i I ) j −1 .

Thus, the number of Jordan blocks of size j is 2 dim ⁡ ⁡ ker ⁡ ⁡ ( A − − λ λ i I ) j − − dim ⁡ ⁡ ker ⁡ ⁡ ( A − − λ λ i I ) j + 1 − − dim ⁡ ⁡ ker ⁡ ⁡ ( A − − λ λ i I ) j − − 1 {\displaystyle 2\dim \ker(A-\lambda _{i}I)^{j}-\dim \ker(A-\lambda _{i}I)^{j+1}-\dim \ker(A-\lambda _{i}I)^{j-1}} Given an eigenvalue λ i , its multiplicity in the minimal polynomial is the size of its largest Jordan block.

Example [ edit ] Consider the matrix A {\displaystyle A} from the example in the previous section. The Jordan normal form is obtained by some similarity transformation : P − − 1 A P = J ; {\displaystyle P^{-1}AP=J;} that is, A P = P J .

{\displaystyle AP=PJ.} Let P {\displaystyle P} have column vectors p i {\displaystyle p_{i}} , i = 1 , … … , 4 {\displaystyle i=1,\ldots ,4} , then A [ p 1 p 2 p 3 p 4 ] = [ p 1 p 2 p 3 p 4 ] [ 1 0 0 0 0 2 0 0 0 0 4 1 0 0 0 4 ] = [ p 1 2 p 2 4 p 3 p 3 + 4 p 4 ] .

{\displaystyle A{\begin{bmatrix}p_{1}&p_{2}&p_{3}&p_{4}\end{bmatrix}}={\begin{bmatrix}p_{1}&p_{2}&p_{3}&p_{4}\end{bmatrix}}{\begin{bmatrix}1&0&0&0\\0&2&0&0\\0&0&4&1\\0&0&0&4\end{bmatrix}}={\begin{bmatrix}p_{1}&2p_{2}&4p_{3}&p_{3}+4p_{4}\end{bmatrix}}.} We see that ( A − − 1 I ) p 1 = 0 {\displaystyle (A-1I)p_{1}=0} ( A − − 2 I ) p 2 = 0 {\displaystyle (A-2I)p_{2}=0} ( A − − 4 I ) p 3 = 0 {\displaystyle (A-4I)p_{3}=0} ( A − − 4 I ) p 4 = p 3 .

{\displaystyle (A-4I)p_{4}=p_{3}.} For i = 1 , 2 , 3 {\displaystyle i=1,2,3} we have p i ∈ ∈ ker ⁡ ⁡ ( A − − λ λ i I ) {\displaystyle p_{i}\in \ker(A-\lambda _{i}I)} , that is, p i {\displaystyle p_{i}} is an eigenvector of A {\displaystyle A} corresponding to the eigenvalue λ λ i {\displaystyle \lambda _{i}} . For i = 4 {\displaystyle i=4} , multiplying both sides by ( A − − 4 I ) {\displaystyle (A-4I)} gives ( A − − 4 I ) 2 p 4 = ( A − − 4 I ) p 3 .

{\displaystyle (A-4I)^{2}p_{4}=(A-4I)p_{3}.} But ( A − − 4 I ) p 3 = 0 {\displaystyle (A-4I)p_{3}=0} , so ( A − − 4 I ) 2 p 4 = 0.

{\displaystyle (A-4I)^{2}p_{4}=0.} Thus, p 4 ∈ ∈ ker ⁡ ⁡ ( A − − 4 I ) 2 .

{\displaystyle p_{4}\in \ker(A-4I)^{2}.} Vectors such as p 4 {\displaystyle p_{4}} are called generalized eigenvectors of A .

Example: Obtaining the normal form [ edit ] This example shows how to calculate the Jordan normal form of a given matrix.

Consider the matrix A = [ 5 4 2 1 0 1 − − 1 − − 1 − − 1 − − 1 3 0 1 1 − − 1 2 ] {\displaystyle A=\left[{\begin{array}{rrrr}5&4&2&1\\0&1&-1&-1\\-1&-1&3&0\\1&1&-1&2\end{array}}\right]} which is mentioned in the beginning of the article.

The characteristic polynomial of A is χ χ ( λ λ ) = det ( λ λ I − − A ) = λ λ 4 − − 11 λ λ 3 + 42 λ λ 2 − − 64 λ λ + 32 = ( λ λ − − 1 ) ( λ λ − − 2 ) ( λ λ − − 4 ) 2 .

{\displaystyle {\begin{aligned}\chi (\lambda )&=\det(\lambda I-A)\\&=\lambda ^{4}-11\lambda ^{3}+42\lambda ^{2}-64\lambda +32\\&=(\lambda -1)(\lambda -2)(\lambda -4)^{2}.\,\end{aligned}}} This shows that the eigenvalues are 1, 2, 4 and 4, according to algebraic multiplicity. The eigenspace corresponding to the eigenvalue 1 can be found by solving the equation Av = 1 v .

It is spanned by the column vector v = (−1, 1, 0, 0) T . Similarly, the eigenspace corresponding to the eigenvalue 2 is spanned by w = (1, −1, 0, 1) T . Finally, the eigenspace corresponding to the eigenvalue 4 is also one-dimensional (even though this is a double eigenvalue) and is spanned by x = (1, 0, −1, 1) T . So, the geometric multiplicity (that is, the dimension of the eigenspace of the given eigenvalue) of each of the three eigenvalues is one. Therefore, the two eigenvalues equal to 4 correspond to a single Jordan block, and the Jordan normal form of the matrix A is the direct sum J = J 1 ( 1 ) ⊕ ⊕ J 1 ( 2 ) ⊕ ⊕ J 2 ( 4 ) = [ 1 0 0 0 0 2 0 0 0 0 4 1 0 0 0 4 ] .

{\displaystyle J=J_{1}(1)\oplus J_{1}(2)\oplus J_{2}(4)={\begin{bmatrix}1&0&0&0\\0&2&0&0\\0&0&4&1\\0&0&0&4\end{bmatrix}}.} There are three Jordan chains . Two have length one: { v } and { w }, corresponding to the eigenvalues 1 and 2, respectively. There is one chain of length two corresponding to the eigenvalue 4. To find this chain, calculate ker ⁡ ⁡ ( A − − 4 I ) 2 = span { [ 1 0 0 0 ] , [ 1 0 − − 1 1 ] } {\displaystyle \ker(A-4I)^{2}=\operatorname {span} \,\left\{{\begin{bmatrix}1\\0\\0\\0\end{bmatrix}},\left[{\begin{array}{r}1\\0\\-1\\1\end{array}}\right]\right\}} where I is the 4 × 4 identity matrix. Pick a vector in the above span that is not in the kernel of A − 4 I ; for example, y = (1,0,0,0) T . Now, ( A − 4 I ) y = x and ( A − 4 I ) x = 0 , so { y , x } is a chain of length two corresponding to the eigenvalue 4.

The transition matrix P such that P −1 AP = J is formed by putting these vectors next to each other as follows P = [ v w x y ] = [ − − 1 1 1 1 1 − − 1 0 0 0 0 − − 1 0 0 1 1 0 ] .

{\displaystyle P=\left[{\begin{array}{c|c|c|c}v&w&x&y\end{array}}\right]=\left[{\begin{array}{rrrr}-1&1&1&1\\1&-1&0&0\\0&0&-1&0\\0&1&1&0\end{array}}\right].} A computation shows that the equation P −1 AP = J indeed holds.

P − − 1 A P = J = [ 1 0 0 0 0 2 0 0 0 0 4 1 0 0 0 4 ] .

{\displaystyle P^{-1}AP=J={\begin{bmatrix}1&0&0&0\\0&2&0&0\\0&0&4&1\\0&0&0&4\end{bmatrix}}.} If we had interchanged the order in which the chain vectors appeared, that is, changing the order of v , w and { x , y } together, the Jordan blocks would be interchanged. However, the Jordan forms are equivalent Jordan forms.

Generalized eigenvectors [ edit ] Main article: Generalized eigenvector Given an eigenvalue λ , every corresponding Jordan block gives rise to a Jordan chain of linearly independent vectors p i , i = 1, ..., b , where b is the size of the Jordan block. The generator , or lead vector , p b of the chain is a generalized eigenvector such that ⁠ ( A − − λ λ I ) b p b = 0 {\displaystyle (A-\lambda I)^{b}p_{b}=0} ⁠ . The vector ⁠ p 1 = ( A − − λ λ I ) b − − 1 p b {\displaystyle p_{1}=(A-\lambda I)^{b-1}p_{b}} ⁠ is an ordinary eigenvector corresponding to λ . In general, p i is a preimage of p i −1 under ⁠ A − − λ λ I {\displaystyle A-\lambda I} ⁠ . So the lead vector generates the chain via multiplication by ⁠ A − − λ λ I {\displaystyle A-\lambda I} ⁠ .

[ 13 ] [ 2 ] Therefore, the statement that every square matrix A can be put in Jordan normal form is equivalent to the claim that the underlying vector space has a basis composed of Jordan chains.

A proof [ edit ] We give a proof by induction that any complex-valued square matrix A may be put in Jordan normal form. Since the underlying vector space can be shown [ 14 ] to be the direct sum of invariant subspaces associated with the eigenvalues, A can be assumed to have just one eigenvalue λ . The 1 × 1 case is trivial. Let A be an n × n matrix. The range of ⁠ A − − λ λ I {\displaystyle A-\lambda I} ⁠ , denoted by ⁠ Ran ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \operatorname {Ran} (A-\lambda I)} ⁠ , is an invariant subspace of A . Also, since λ is an eigenvalue of A , the dimension of ⁠ Ran ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \operatorname {Ran} (A-\lambda I)} ⁠ , r , is strictly less than n , so, by the inductive hypothesis, ⁠ Ran ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \operatorname {Ran} (A-\lambda I)} ⁠ has a basis { p 1 , ..., p r } composed of Jordan chains.

Next consider the kernel , that is, the subspace ⁠ ker ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \ker(A-\lambda I)} ⁠ . If Ran ⁡ ⁡ ( A − − λ λ I ) ∩ ∩ ker ⁡ ⁡ ( A − − λ λ I ) = { 0 } , {\displaystyle \operatorname {Ran} (A-\lambda I)\cap \ker(A-\lambda I)=\{0\},} the desired result follows immediately from the rank–nullity theorem . (This would be the case, for example, if A were Hermitian .) Otherwise, if Q = Ran ⁡ ⁡ ( A − − λ λ I ) ∩ ∩ ker ⁡ ⁡ ( A − − λ λ I ) ≠ ≠ { 0 } , {\displaystyle Q=\operatorname {Ran} (A-\lambda I)\cap \ker(A-\lambda I)\neq \{0\},} let the dimension of Q be s ≤ r . Each vector in Q is an eigenvector, so ⁠ Ran ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \operatorname {Ran} (A-\lambda I)} ⁠ must contain s Jordan chains corresponding to s linearly independent eigenvectors. Therefore the basis { p 1 , ..., p r } must contain s vectors, say { p 1 , ..., p s }, that are lead vectors of these Jordan chains. We can "extend the chains" by taking the preimages of these lead vectors. (This is the key step.) Let q i be such that ( A − − λ λ I ) q i = p i for i = 1 , … … , s .

{\displaystyle \;(A-\lambda I)q_{i}=p_{i}{\mbox{ for }}i=1,\ldots ,s.} Finally, we can pick any basis for ker ⁡ ⁡ ( A − − λ λ I ) / Q {\displaystyle \ker(A-\lambda I)/Q} and then lift to vectors  { z 1 , ..., z t } in ⁠ ker ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \ker(A-\lambda I)} ⁠ . Each z i forms a Jordan chain of length 1. We just need to show that the union of { p 1 , ..., p r }, { z 1 , ..., z t }, and { q 1 , ..., q s } forms a basis for the vector space.

By the rank-nullity theorem, ⁠ dim ⁡ ⁡ ( ker ⁡ ⁡ ( A − − λ λ I ) ) ) = n − − r {\displaystyle \dim(\ker(A-\lambda I)))=n-r} ⁠ , so ⁠ t = n − − r − − s {\displaystyle t=n-r-s} ⁠ , and so the number of vectors in the potential basis is equal to n. To show linear independence, suppose some linear combination of the vectors is 0. Applying ⁠ A − − λ λ I , {\displaystyle A-\lambda I,} ⁠ we get some linear combination of p i , with the q i becoming lead vectors among the p i.

From linear independence of p i, it follows that the coefficients of the vectors q i must be zero. Furthermore, no non-trivial linear combination of the z i can equal a linear combination of p i , because then it would belong to ⁠ Ran ⁡ ⁡ ( A − − λ λ I ) {\displaystyle \operatorname {Ran} (A-\lambda I)} ⁠ and thus Q , which is impossible by the construction of z i . Therefore the coefficients of the z i will also be 0. This leaves in the original linear combination just the p i terms, which are assumed to be linearly independent, and so their coefficients must be zero too. We have found a basis composed of Jordan chains, and this shows A can be put in Jordan normal form.

Uniqueness [ edit ] It can be shown that the Jordan normal form of a given matrix A is unique up to the order of the Jordan blocks.

Knowing the algebraic and geometric multiplicities of the eigenvalues is not sufficient to determine the Jordan normal form of A . Assuming the algebraic multiplicity m ( λ ) of an eigenvalue λ is known, the structure of the Jordan form can be ascertained by analyzing the ranks of the powers ( A − λI ) m ( λ ) . To see this, suppose an n × n matrix A has only one eigenvalue λ . So m ( λ ) = n . The smallest integer k 1 such that ( A − − λ λ I ) k 1 = 0 {\displaystyle (A-\lambda I)^{k_{1}}=0} is the size of the largest Jordan block in the Jordan form of A . (This number k 1 is also called the index of λ . See discussion in a following section.) The rank of ( A − − λ λ I ) k 1 − − 1 {\displaystyle (A-\lambda I)^{k_{1}-1}} is the number of Jordan blocks of size k 1 . Similarly, the rank of ( A − − λ λ I ) k 1 − − 2 {\displaystyle (A-\lambda I)^{k_{1}-2}} is twice the number of Jordan blocks of size k 1 plus the number of Jordan blocks of size k 1 − 1. The general case is similar.

This can be used to show the uniqueness of the Jordan form. Let J 1 and J 2 be two Jordan normal forms of A . Then J 1 and J 2 are similar and have the same spectrum, including algebraic multiplicities of the eigenvalues. The procedure outlined in the previous paragraph can be used to determine the structure of these matrices. Since the rank of a matrix is preserved by similarity transformation, there is a bijection between the Jordan blocks of J 1 and J 2 . This proves the uniqueness part of the statement.

Real matrices [ edit ] If A is a real matrix, its Jordan form can still be non-real. Instead of representing it with complex eigenvalues and ones on the superdiagonal, as discussed above, there exists a real invertible matrix P such that P −1 AP = J is a real block diagonal matrix with each block being a real Jordan block.

[ 15 ] A real Jordan block is either identical to a complex Jordan block (if the corresponding eigenvalue λ λ i {\displaystyle \lambda _{i}} is real), or is a block matrix itself, consisting of 2×2 blocks (for non-real eigenvalue λ λ i = a i + i b i {\displaystyle \lambda _{i}=a_{i}+ib_{i}} with given algebraic multiplicity) of the form C i = [ a i − − b i b i a i ] {\displaystyle C_{i}=\left[{\begin{array}{rr}a_{i}&-b_{i}\\b_{i}&a_{i}\\\end{array}}\right]} and describe multiplication by λ λ i {\displaystyle \lambda _{i}} in the complex plane. The superdiagonal blocks are 2×2 identity matrices and hence in this representation the matrix dimensions are larger than the complex Jordan form. The full real Jordan block is given by J i = [ C i I C i ⋱ ⋱ ⋱ ⋱ I C i ] .

{\displaystyle J_{i}={\begin{bmatrix}C_{i}&I&&\\&C_{i}&\ddots &\\&&\ddots &I\\&&&C_{i}\end{bmatrix}}.} This real Jordan form is a consequence of the complex Jordan form. For a real matrix the nonreal eigenvectors and generalized eigenvectors can always be chosen to form complex conjugate pairs. Taking the real and imaginary part (linear combination of the vector and its conjugate), the matrix has this form with respect to the new basis.

Matrices with entries in a field [ edit ] Jordan reduction can be extended to any square matrix M whose entries lie in a field K .  The result states that any M can be written as a sum D + N where D is semisimple , N is nilpotent , and DN = ND . This is called the Jordan–Chevalley decomposition . Whenever K contains the eigenvalues of M , in particular when K is algebraically closed , the normal form can be expressed explicitly as the direct sum of Jordan blocks.

Similar to the case when K is the complex numbers, knowing the dimensions of the kernels of ( M − λI ) k for 1 ≤ k ≤ m , where m is the algebraic multiplicity of the eigenvalue λ , allows one to determine the Jordan form of M . We may view the underlying vector space V as a K [ x ]- module by regarding the action of x on V as application of M and extending by K -linearity. Then the polynomials ( x − λ ) k are the elementary divisors of M , and the Jordan normal form is concerned with representing M in terms of blocks associated to the elementary divisors.

The proof of the Jordan normal form is usually carried out as an application to the ring K [ x ] of the structure theorem for finitely generated modules over a principal ideal domain , of which it is a corollary.

Consequences [ edit ] One can see that the Jordan normal form is essentially a classification result for square matrices, and as such several important results from linear algebra can be viewed as its consequences.

Spectral mapping theorem [ edit ] Using the Jordan normal form, direct calculation gives a spectral mapping theorem for the polynomial functional calculus : Let A be an n × n matrix with eigenvalues λ 1 , ..., λ n , then for any polynomial p , p ( A ) has eigenvalues p ( λ 1 ), ..., p ( λ n ).

Characteristic polynomial [ edit ] The characteristic polynomial of A is p A ( λ λ ) = det ( λ λ I − − A ) {\displaystyle p_{A}(\lambda )=\det(\lambda I-A)} .

Similar matrices have the same characteristic polynomial.
Therefore, p A ( λ λ ) = p J ( λ λ ) = ∏ ∏ i ( λ λ − − λ λ i ) m i {\textstyle p_{A}(\lambda )=p_{J}(\lambda )=\prod _{i}(\lambda -\lambda _{i})^{m_{i}}} ,
where λ λ i {\displaystyle \lambda _{i}} is the i th root of p J {\textstyle p_{J}} and m i {\displaystyle m_{i}} is its multiplicity, because this is clearly the characteristic polynomial of the Jordan form of A .

Cayley–Hamilton theorem [ edit ] The Cayley–Hamilton theorem asserts that every matrix A satisfies its characteristic equation: if p is the characteristic polynomial of A , then p A ( A ) = 0 {\displaystyle p_{A}(A)=0} . This can be shown via direct calculation in the Jordan form, since if λ λ i {\displaystyle \lambda _{i}} is an eigenvalue of multiplicity m i {\displaystyle m_{i}} ,
then its Jordan block J i {\displaystyle J_{i}} clearly satisfies ( J i − − λ λ i I ) m i = 0 {\displaystyle (J_{i}-\lambda _{i}I)^{m_{i}}=0} .
As the diagonal blocks do not affect each other, the i {\displaystyle i} th diagonal block of ( A − − λ λ i I ) m i {\displaystyle (A-\lambda _{i}I)^{m_{i}}} is ( J i − − λ λ i I ) m i {\displaystyle (J_{i}-\lambda _{i}I)^{m_{i}}} ; hence p A ( A ) = ∏ ∏ i ( A − − λ λ i I ) m i = 0 {\textstyle p_{A}(A)=\prod _{i}(A-\lambda _{i}I)^{m_{i}}=0} .

The Jordan form can be assumed to exist over a field extending the base field of the matrix, for instance over the splitting field of p ; this field extension does not change the matrix p ( A ) in any way.

Minimal polynomial [ edit ] The minimal polynomial P of a square matrix A is the unique monic polynomial of least degree, m , such that P ( A ) = 0. Alternatively, the set of polynomials that annihilate a given A form an ideal I in C [ x ], the principal ideal domain of polynomials with complex coefficients. The monic element that generates I is precisely P .

Let λ 1 , ..., λ q be the distinct eigenvalues of A , and s i be the size of the largest Jordan block corresponding to λ i . It is clear from the Jordan normal form that the minimal polynomial of A has degree Σ s i .

While the Jordan normal form determines the minimal polynomial, the converse is not true. This leads to the notion of elementary divisors . The elementary divisors of a square matrix A are the characteristic polynomials of its Jordan blocks. The factors of the minimal polynomial m are the elementary divisors of the largest degree corresponding to distinct eigenvalues.

The degree of an elementary divisor is the size of the corresponding Jordan block, therefore the dimension of the corresponding invariant subspace. If all elementary divisors are linear, A is diagonalizable.

Invariant subspace decompositions [ edit ] The Jordan form of a n × n matrix A is block diagonal, and therefore gives a decomposition of the n dimensional Euclidean space into invariant subspaces of A . Every Jordan block J i corresponds to an invariant subspace X i . Symbolically, we put C n = ⨁ ⨁ i = 1 k X i {\displaystyle \mathbb {C} ^{n}=\bigoplus _{i=1}^{k}X_{i}} where each X i is the span of the corresponding Jordan chain, and k is the number of Jordan chains.

One can also obtain a slightly different decomposition via the Jordan form. Given an eigenvalue λ i , the size of its largest corresponding Jordan block s i is called the index of λ i and denoted by v ( λ i ) . (Therefore, the degree of the minimal polynomial is the sum of all indices.) Define a subspace Y i by Y i = ker ⁡ ⁡ ( λ λ i I − − A ) v ( λ λ i ) .

{\displaystyle Y_{i}=\ker(\lambda _{i}I-A)^{v(\lambda _{i})}.} This gives the decomposition C n = ⨁ ⨁ i = 1 l Y i {\displaystyle \mathbb {C} ^{n}=\bigoplus _{i=1}^{l}Y_{i}} where l is the number of distinct eigenvalues of A . Intuitively, we glob together the Jordan block invariant subspaces corresponding to the same eigenvalue. In the extreme case where A is a multiple of the identity matrix we have k = n and l = 1.

The projection onto Y i and along all the other Y j ( j ≠ i ) is called the spectral projection of A at v i and is usually denoted by P ( λ i ; A ) . Spectral projections are mutually orthogonal in the sense that P ( λ i ; A ) P (v j ; A ) = 0 if i ≠ j . Also they commute with A and their sum is the identity matrix. Replacing every v i in the Jordan matrix J by one and zeroing all other entries gives P (v i ; J ) , moreover if U J U −1 is the similarity transformation such that A = U J U −1 then P ( λ i ; A ) = U P ( λ i ; J ) U −1 . They are not confined to finite dimensions. See below for their application to compact operators, and in holomorphic functional calculus for a more general discussion.

Comparing the two decompositions, notice that, in general, l ≤ k . When A is normal, the subspaces X i 's in the first decomposition are one-dimensional and mutually orthogonal. This is the spectral theorem for normal operators. The second decomposition generalizes more easily for general compact operators on Banach spaces.

It might be of interest here to note some properties of the index, ν ( λ ) . More generally, for a complex number λ , its index can be defined as the least non-negative integer ν ( λ ) such that ker ⁡ ⁡ ( A − − λ λ I ) ν ν ( λ λ ) = ker ⁡ ⁡ ( A − − λ λ I ) m , ∀ ∀ m ≥ ≥ ν ν ( λ λ ) .

{\displaystyle \ker(A-\lambda I)^{\nu (\lambda )}=\ker(A-\lambda I)^{m},\;\forall m\geq \nu (\lambda ).} So ν (v) > 0 if and only if λ is an eigenvalue of A . In the finite-dimensional case, ν (v) ≤ the algebraic multiplicity of v .

Plane (flat) normal form [ edit ] The Jordan form is used to find a normal form of matrices up to conjugacy such that normal matrices make up an algebraic variety of a low fixed degree in the ambient matrix space.

Sets of representatives of matrix conjugacy classes for Jordan normal form or rational canonical forms in general do not constitute linear or 
affine subspaces in the ambient matrix spaces.

Vladimir Arnold posed [ 16 ] a problem:
Find a canonical form of matrices over a field for which the set of representatives of matrix conjugacy classes is a union of affine linear subspaces (flats). In other words, map the set of matrix conjugacy classes injectively back into the initial set of matrices so that the image of this embedding—the set of all normal matrices, has the lowest possible degree—it is a union of shifted linear subspaces.

It was solved for algebraically closed fields by Peteris Daugulis.

[ 17 ] The construction of a uniquely defined plane normal form of a matrix starts by considering its Jordan normal form.

Matrix functions [ edit ] Main article: Matrix function Iteration of the Jordan chain motivates various extensions to more abstract settings. For finite matrices, one gets matrix functions; this can be extended to compact operators and the holomorphic functional calculus, as described further below.

The Jordan normal form is the most convenient for computation of the matrix functions (though it may be not the best choice for computer computations). Let f ( z ) be an analytical function of a complex argument. Applying the function on a n × n Jordan block J with eigenvalue λ results in an upper triangular matrix: f ( J ) = [ f ( λ λ ) f ′ ( λ λ ) f ″ ( λ λ ) 2 ⋯ ⋯ f ( n − − 1 ) ( λ λ ) ( n − − 1 ) !

0 f ( λ λ ) f ′ ( λ λ ) ⋯ ⋯ f ( n − − 2 ) ( λ λ ) ( n − − 2 ) !

⋮ ⋮ ⋮ ⋮ ⋱ ⋱ ⋱ ⋱ ⋮ ⋮ 0 0 0 f ( λ λ ) f ′ ( λ λ ) 0 0 0 0 f ( λ λ ) ] , {\displaystyle f(J)={\begin{bmatrix}f(\lambda )&f'(\lambda )&{\tfrac {f''(\lambda )}{2}}&\cdots &{\tfrac {f^{(n-1)}(\lambda )}{(n-1)!}}\\0&f(\lambda )&f'(\lambda )&\cdots &{\tfrac {f^{(n-2)}(\lambda )}{(n-2)!}}\\\vdots &\vdots &\ddots &\ddots &\vdots \\0&0&0&f(\lambda )&f'(\lambda )\\0&0&0&0&f(\lambda )\end{bmatrix}},} so that the elements of the k -th superdiagonal of the resulting matrix are f ( k ) ( λ λ ) k !

{\displaystyle {\tfrac {f^{(k)}(\lambda )}{k!}}} . For a matrix of general Jordan normal form the above expression shall be applied to each Jordan block.

The following example shows the application to the power function f ( z ) = z n : [ λ λ 1 1 0 0 0 0 λ λ 1 1 0 0 0 0 λ λ 1 0 0 0 0 0 λ λ 2 1 0 0 0 0 λ λ 2 ] n = [ λ λ 1 n ( n 1 ) λ λ 1 n − − 1 ( n 2 ) λ λ 1 n − − 2 0 0 0 λ λ 1 n ( n 1 ) λ λ 1 n − − 1 0 0 0 0 λ λ 1 n 0 0 0 0 0 λ λ 2 n ( n 1 ) λ λ 2 n − − 1 0 0 0 0 λ λ 2 n ] , {\displaystyle {\begin{bmatrix}\lambda _{1}&1&0&0&0\\0&\lambda _{1}&1&0&0\\0&0&\lambda _{1}&0&0\\0&0&0&\lambda _{2}&1\\0&0&0&0&\lambda _{2}\end{bmatrix}}^{n}={\begin{bmatrix}\lambda _{1}^{n}&{\tbinom {n}{1}}\lambda _{1}^{n-1}&{\tbinom {n}{2}}\lambda _{1}^{n-2}&0&0\\0&\lambda _{1}^{n}&{\tbinom {n}{1}}\lambda _{1}^{n-1}&0&0\\0&0&\lambda _{1}^{n}&0&0\\0&0&0&\lambda _{2}^{n}&{\tbinom {n}{1}}\lambda _{2}^{n-1}\\0&0&0&0&\lambda _{2}^{n}\end{bmatrix}},} where the binomial coefficients are defined as ( n k ) = ∏ ∏ i = 1 k n + 1 − − i i {\textstyle {\binom {n}{k}}=\prod _{i=1}^{k}{\frac {n+1-i}{i}}} . For integer positive n it reduces to standard definition
of the coefficients. For negative n the identity ( − − n k ) = ( − − 1 ) k ( n + k − − 1 k ) {\textstyle {\binom {-n}{k}}=(-1)^{k}{\binom {n+k-1}{k}}} may be of use.

Compact operators [ edit ] A result analogous to the Jordan normal form holds for compact operators on a Banach space . One restricts to compact operators because every point x in the spectrum of a compact operator T is an eigenvalue; The only exception is when x is the limit point of the spectrum. This is not true for bounded operators in general. To give some idea of this generalization, we first reformulate the Jordan decomposition in the language of functional analysis .

Holomorphic functional calculus [ edit ] Further information: holomorphic functional calculus Let X be a Banach space, L ( X ) be the bounded operators on X , and σ ( T ) denote the spectrum of T ∈ L ( X ). The holomorphic functional calculus is defined as follows: Fix a bounded operator T . Consider the family Hol( T ) of complex functions that is holomorphic on some open set G containing σ ( T ). Let Γ = { γ i } be a finite collection of Jordan curves such that σ ( T ) lies in the inside of Γ, we define f ( T ) by f ( T ) = 1 2 π π i ∫ ∫ Γ Γ f ( z ) ( z − − T ) − − 1 d z .

{\displaystyle f(T)={\frac {1}{2\pi i}}\int _{\Gamma }f(z)(z-T)^{-1}\,dz.} The open set G could vary with f and need not be connected. The integral is defined as the limit of the Riemann sums, as in the scalar case. Although the integral makes sense for continuous f , we restrict to holomorphic functions to apply the machinery from classical function theory (for example, the Cauchy integral formula). The assumption that σ ( T ) lie in the inside of Γ ensures f ( T ) is well defined; it does not depend on the choice of Γ. The functional calculus is the mapping Φ from Hol( T ) to L ( X ) given by Φ Φ ( f ) = f ( T ) .

{\displaystyle \;\Phi (f)=f(T).} We will require the following properties of this functional calculus: Φ extends the polynomial functional calculus.

The spectral mapping theorem holds: σ ( f ( T )) = f ( σ ( T )).

Φ is an algebra homomorphism.

The finite-dimensional case [ edit ] In the finite-dimensional case, σ ( T ) = { λ i } is a finite discrete set in the complex plane. Let e i be the function that is 1 in some open neighborhood of λ i and 0 elsewhere. By property 3 of the functional calculus, the operator e i ( T ) {\displaystyle e_{i}(T)} is a projection. Moreover, let ν i be the index of λ i and f ( z ) = ( z − − λ λ i ) ν ν i .

{\displaystyle f(z)=(z-\lambda _{i})^{\nu _{i}}.} The spectral mapping theorem tells us f ( T ) e i ( T ) = ( T − − λ λ i ) ν ν i e i ( T ) {\displaystyle f(T)e_{i}(T)=(T-\lambda _{i})^{\nu _{i}}e_{i}(T)} has spectrum {0}. By property 1, f ( T ) can be directly computed in the Jordan form, and by inspection, we see that the operator f ( T ) e i ( T ) is the zero matrix.

By property 3, f ( T ) e i ( T ) = e i ( T ) f ( T ). So e i ( T ) is precisely the projection onto the subspace Ran ⁡ ⁡ e i ( T ) = ker ⁡ ⁡ ( T − − λ λ i ) ν ν i .

{\displaystyle \operatorname {Ran} e_{i}(T)=\ker(T-\lambda _{i})^{\nu _{i}}.} The relation ∑ ∑ i e i = 1 {\displaystyle \sum _{i}e_{i}=1} implies C n = ⨁ ⨁ i Ran ⁡ ⁡ e i ( T ) = ⨁ ⨁ i ker ⁡ ⁡ ( T − − λ λ i ) ν ν i {\displaystyle \mathbb {C} ^{n}=\bigoplus _{i}\;\operatorname {Ran} e_{i}(T)=\bigoplus _{i}\ker(T-\lambda _{i})^{\nu _{i}}} where the index i runs through the distinct eigenvalues of T . This is the invariant subspace decomposition C n = ⨁ ⨁ i Y i {\displaystyle \mathbb {C} ^{n}=\bigoplus _{i}Y_{i}} given in a previous section. Each e i ( T ) is the projection onto the subspace spanned by the Jordan chains corresponding to λ i and along the subspaces spanned by the Jordan chains corresponding to v j for j ≠ i . In other words, e i ( T ) = P ( λ i ; T ). This explicit identification of the operators e i ( T ) in turn gives an explicit form of holomorphic functional calculus for matrices: For all f ∈ Hol( T ), f ( T ) = ∑ ∑ λ λ i ∈ ∈ σ σ ( T ) ∑ ∑ k = 0 ν ν i − − 1 f ( k ) k !

( T − − λ λ i ) k e i ( T ) .

{\displaystyle f(T)=\sum _{\lambda _{i}\in \sigma (T)}\sum _{k=0}^{\nu _{i}-1}{\frac {f^{(k)}}{k!}}(T-\lambda _{i})^{k}e_{i}(T).} Notice that the expression of f ( T ) is a finite sum because, on each neighborhood of v i , we have chosen the Taylor series expansion of f centered at v i .

Poles of an operator [ edit ] Let T be a bounded operator λ be an isolated point of σ ( T ). (As stated above, when T is compact, every point in its spectrum is an isolated point, except possibly the limit point 0.) The point λ is called a pole of operator T with order ν if the resolvent function R T defined by R T ( λ λ ) = ( λ λ − − T ) − − 1 {\displaystyle R_{T}(\lambda )=(\lambda -T)^{-1}} has a pole of order ν at λ .

We will show that, in the finite-dimensional case, the order of an eigenvalue coincides with its index. The result also holds for compact operators.

Consider the annular region A centered at the eigenvalue λ with sufficiently small radius ε such that the intersection of the open disc B ε ( λ ) and σ ( T ) is { λ }. The resolvent function R T is holomorphic on A .
Extending a result from classical function theory, R T has a Laurent series representation on A : R T ( z ) = ∑ ∑ − − ∞ ∞ ∞ ∞ a m ( λ λ − − z ) m {\displaystyle R_{T}(z)=\sum _{-\infty }^{\infty }a_{m}(\lambda -z)^{m}} where a − − m = − − 1 2 π π i ∫ ∫ C ( λ λ − − z ) m − − 1 ( z − − T ) − − 1 d z {\displaystyle a_{-m}=-{\frac {1}{2\pi i}}\int _{C}(\lambda -z)^{m-1}(z-T)^{-1}dz} and C is a small circle centered at λ .

By the previous discussion on the functional calculus, a − − m = − − ( λ λ − − T ) m − − 1 e λ λ ( T ) {\displaystyle a_{-m}=-(\lambda -T)^{m-1}e_{\lambda }(T)} where e λ λ {\displaystyle e_{\lambda }} is 1 on B ε ε ( λ λ ) {\displaystyle B_{\varepsilon }(\lambda )} and 0 elsewhere.

But we have shown that the smallest positive integer m such that a − − m ≠ ≠ 0 {\displaystyle a_{-m}\neq 0} and a − − l = 0 ∀ ∀ l ≥ ≥ m {\displaystyle a_{-l}=0\;\;\forall \;l\geq m} is precisely the index of λ , ν ( λ ). In other words, the function R T has a pole of order ν ( λ ) at λ .

Numerical analysis [ edit ] If the matrix A has multiple eigenvalues, or is close to a matrix with multiple eigenvalues, then its Jordan normal form is very sensitive to perturbations. Consider for instance the matrix A = [ 1 1 ε ε 1 ] .

{\displaystyle A={\begin{bmatrix}1&1\\\varepsilon &1\end{bmatrix}}.} If ε = 0, then the Jordan normal form is simply [ 1 1 0 1 ] .

{\displaystyle {\begin{bmatrix}1&1\\0&1\end{bmatrix}}.} However, for ε ≠ 0, the Jordan normal form is [ 1 + ε ε 0 0 1 − − ε ε ] .

{\displaystyle {\begin{bmatrix}1+{\sqrt {\varepsilon }}&0\\0&1-{\sqrt {\varepsilon }}\end{bmatrix}}.} This ill conditioning makes it very hard to develop a robust numerical algorithm for the Jordan normal form, as the result depends critically on whether two eigenvalues are deemed to be equal. For this reason, the Jordan normal form is usually avoided in numerical analysis ; the stable Schur decomposition [ 18 ] or pseudospectra [ 19 ] are better alternatives.

See also [ edit ] Canonical basis Canonical form Frobenius normal form Jordan matrix Jordan–Chevalley decomposition Matrix decomposition Modal matrix Weyr canonical form Notes [ edit ] ^ Shilov defines the term Jordan canonical form and in a footnote says that Jordan normal form is synonymous.
These terms are sometimes shortened to Jordan form . (Shilov)
The term Classical canonical form is also sometimes used in the sense of this article. (James & James, 1976) ^ a b Holt & Rumynin (2009 , p. 9) ^ a b Beauregard & Fraleigh (1973 , pp. 310–316) ^ a b Golub & Van Loan (1996 , p. 355) ^ a b Nering (1970 , pp. 118–127) ^ Beauregard & Fraleigh (1973 , pp. 270–274) ^ Golub & Van Loan (1996 , p. 353) ^ Nering (1970 , pp. 113–118) ^ Brechenmacher, "Histoire du théorème de Jordan de la décomposition matricielle (1870-1930). Formes de représentation et méthodes de décomposition" , Thesis, 2007 ^ Cullen (1966 , p. 114) ^ Franklin (1968 , p. 122) ^ a b Horn & Johnson (1985 , §3.2.1) ^ Bronson (1970 , pp. 189, 194) ^ Roe Goodman and Nolan R. Wallach, Representations and Invariants of Classical Groups , Cambridge UP 1998, Appendix B.1.

^ Horn & Johnson (1985 , Theorem 3.4.5) ^ Arnold, Vladimir I.

(2004), "1998-25", in Arnold, Vladimir I. (ed.), Arnold's Problems , Berlin: Springer-Verlag, p. 127, doi : 10.1007/b138219 , ISBN 3-540-20614-0 , MR 2078115 . See also comment, p. 613.

^ Peteris Daugulis (2012), "A parametrization of matrix conjugacy orbit sets as unions of affine planes", Linear Algebra and Its Applications , 436 (3): 709– 721, arXiv : 1110.0907 , doi : 10.1016/j.laa.2011.07.032 , S2CID 119649768 ^ See Golub & Van Loan (2014), §7.6.5; or Golub & Wilkinson (1976) for details.

^ See Golub & Van Loan (2014), §7.9 References [ edit ] Beauregard, Raymond A.; Fraleigh, John B. (1973), A First Course In Linear Algebra: with Optional Introduction to Groups, Rings, and Fields , Boston: Houghton Mifflin Co.

, ISBN 0-395-14017-X Bronson, Richard (1970), Matrix Methods: An Introduction , New York: Academic Press , LCCN 70097490 Cullen, Charles G. (1966), Matrices and Linear Transformations , Reading: Addison-Wesley , LCCN 66021267 Dunford, N.; Schwartz, J. T. (1958), Linear Operators, Part I: General Theory , Interscience Finkbeiner II, Daniel T. (1978), Introduction to Matrices and Linear Transformations (3rd ed.), W. H. Freeman and Company Franklin, Joel N. (1968), Matrix Theory , Englewood Cliffs: Prentice-Hall , LCCN 68016345 Golub, Gene H.; Van Loan, Charles F. (1996), Matrix Computations (3rd ed.), Baltimore: Johns Hopkins University Press , ISBN 0-8018-5414-8 Golub, Gene H.; Wilkinson, J. H. (1976), "Ill-conditioned eigensystems and the computation of the Jordan normal form", SIAM Review , 18 (4): 578– 619, doi : 10.1137/1018113 Holt, Derek; Rumynin, Dmitriy (2009), Algebra I – Advanced Linear Algebra (MA251) Lecture Notes (PDF) Horn, Roger A.; Johnson, Charles R. (1985), Matrix Analysis , Cambridge University Press , ISBN 978-0-521-38632-6 James, Glenn; James, Robert C.

(1976), Mathematics Dictionary (2nd ed.), Van Nostrand Reinhold MacLane, Saunders; Birkhoff, Garrett (1967), Algebra , Macmillan Publishers Michel, Anthony N.; Herget, Charles J. (1993), Applied Algebra and Functional Analysis , Dover Publications Nering, Evar D. (1970), Linear Algebra and Matrix Theory (2nd ed.), New York: Wiley , LCCN 76091646 Shafarevich, I. R.; Remizov, A. O. (2012), Linear Algebra and Geometry , Springer , ISBN 978-3-642-30993-9 Shilov, Georgi E. (1977), Linear Algebra , Dover Publications Jordan Canonical Form article at mathworld.wolfram.com v t e Matrix classes Explicitly constrained entries Alternant Anti-diagonal Anti-Hermitian Anti-symmetric Arrowhead Band Bidiagonal Bisymmetric Block-diagonal Block Block tridiagonal Boolean Cauchy Centrosymmetric Conference Complex Hadamard Copositive Diagonally dominant Diagonal Discrete Fourier Transform Elementary Equivalent Frobenius Generalized permutation Hadamard Hankel Hermitian Hessenberg Hollow Integer Logical Matrix unit Metzler Moore Nonnegative Pentadiagonal Permutation Persymmetric Polynomial Quaternionic Signature Skew-Hermitian Skew-symmetric Skyline Sparse Sylvester Symmetric Toeplitz Triangular Tridiagonal Vandermonde Walsh Z Constant Exchange Hilbert Identity Lehmer Of ones Pascal Pauli Redheffer Shift Zero Conditions on eigenvalues or eigenvectors Companion Convergent Defective Definite Diagonalizable Hurwitz-stable Positive-definite Stieltjes Satisfying conditions on products or inverses Congruent Idempotent or Projection Invertible Involutory Nilpotent Normal Orthogonal Unimodular Unipotent Unitary Totally unimodular Weighing With specific applications Adjugate Alternating sign Augmented Bézout Carleman Cartan Circulant Cofactor Commutation Confusion Coxeter Distance Duplication and elimination Euclidean distance Fundamental (linear differential equation) Generator Gram Hessian Householder Jacobian Moment Payoff Pick Random Rotation Routh-Hurwitz Seifert Shear Similarity Symplectic Totally positive Transformation Used in statistics Centering Correlation Covariance Design Doubly stochastic Fisher information Hat Precision Stochastic Transition Used in graph theory Adjacency Biadjacency Degree Edmonds Incidence Laplacian Seidel adjacency Tutte Used in science and engineering Cabibbo–Kobayashi–Maskawa Density Fundamental (computer vision) Fuzzy associative Gamma Gell-Mann Hamiltonian Irregular Overlap S State transition Substitution Z (chemistry) Related terms Jordan normal form Linear independence Matrix exponential Matrix representation of conic sections Perfect matrix Pseudoinverse Row echelon form Wronskian Mathematics portal List of matrices Category:Matrices (mathematics) NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐xhvrc
Cached time: 20250812002701
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.623 seconds
Real time usage: 0.838 seconds
Preprocessor visited node count: 3630/1000000
Revision size: 46169/2097152 bytes
Post‐expand include size: 63064/2097152 bytes
Template argument size: 3594/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 5/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 65483/5000000 bytes
Lua time usage: 0.338/10.000 seconds
Lua memory usage: 9399340/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  532.772      1 -total
 31.46%  167.602     16 Template:Citation
 17.17%   91.467      1 Template:Short_description
 16.30%   86.858      1 Template:Matrix_classes
 15.83%   84.318      1 Template:Navbox
 10.41%   55.485      2 Template:Pagetype
  9.19%   48.935     12 Template:Harvtxt
  5.87%   31.247      2 Template:Val
  4.76%   25.336     27 Template:Math
  4.75%   25.331     29 Template:Main_other Saved in parser cache with key enwiki:pcache:312877:|#|:idhash:canonical and timestamp 20250812002701 and revision id 1296176982. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Jordan_normal_form&oldid=1296176982 " Categories : Linear algebra Matrix theory Matrix normal forms Matrix decompositions Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 18 June 2025, at 09:50 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Jordan normal form 21 languages Add topic

