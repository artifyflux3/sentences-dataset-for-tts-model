Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 Variance 3 Stationarity 4 Example 5 Covariance functions Toggle Covariance functions subsection 5.1 Usual covariance functions 6 Continuity Toggle Continuity subsection 6.1 Stationary case 7 Brownian motion as the integral of Gaussian processes 8 RKHS structure and Gaussian process 9 Linearly constrained Gaussian processes 10 Applications Toggle Applications subsection 10.1 Gaussian process prediction, or Kriging 10.2 Bayesian neural networks as Gaussian processes 11 Computational issues 12 See also 13 References 14 External links Toggle External links subsection 14.1 Literature 14.2 Software 14.3 Video tutorials Toggle the table of contents Gaussian process 17 languages Català Deutsch Español فارسی Français 한국어 Italiano עברית Magyar 日本語 Polski Português Русский Sunda Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Statistical model In probability theory and statistics , a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution . The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.

The concept of Gaussian processes is named after Carl Friedrich Gauss because it is based on the notion of the Gaussian distribution ( normal distribution ). Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions.

Gaussian processes are useful in statistical modelling , benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly. Such quantities include the average value of the process over a range of times and the error in estimating the average using sample values at a small set of times. While exact models often scale poorly as the amount of data increases, multiple approximation methods have been developed which often retain good accuracy while drastically reducing computation time.

Definition [ edit ] A time continuous stochastic process { X t ; t ∈ ∈ T } {\displaystyle \left\{X_{t};t\in T\right\}} is Gaussian if and only if for every finite set of indices t 1 , … … , t k {\displaystyle t_{1},\ldots ,t_{k}} in the index set T {\displaystyle T} X t 1 , … … , t k = ( X t 1 , … … , X t k ) {\displaystyle \mathbf {X} _{t_{1},\ldots ,t_{k}}=(X_{t_{1}},\ldots ,X_{t_{k}})} is a multivariate Gaussian random variable .

[ 1 ] As the sum of independent and Gaussian distributed random variables is again Gaussian distributed, that is the same as saying every linear combination of ( X t 1 , … … , X t k ) {\displaystyle (X_{t_{1}},\ldots ,X_{t_{k}})} has a univariate Gaussian (or normal) distribution.

Using characteristic functions of random variables with i {\displaystyle i} denoting the imaginary unit such that i 2 = − − 1 {\displaystyle i^{2}=-1} , the Gaussian property can be formulated as follows: { X t ; t ∈ ∈ T } {\displaystyle \left\{X_{t};t\in T\right\}} is Gaussian if and only if, for every finite set of indices t 1 , … … , t k {\displaystyle t_{1},\ldots ,t_{k}} , there are real-valued σ σ ℓ ℓ j {\displaystyle \sigma _{\ell j}} , μ μ ℓ ℓ {\displaystyle \mu _{\ell }} with σ σ j j > 0 {\displaystyle \sigma _{jj}>0} such that the following equality holds for all s 1 , s 2 , … … , s k ∈ ∈ R {\displaystyle s_{1},s_{2},\ldots ,s_{k}\in \mathbb {R} } , E [ exp ⁡ ⁡ ( i ∑ ∑ ℓ ℓ = 1 k s ℓ ℓ X t ℓ ℓ ) ] = exp ⁡ ⁡ ( − − 1 2 ∑ ∑ ℓ ℓ , j σ σ ℓ ℓ j s ℓ ℓ s j + i ∑ ∑ ℓ ℓ μ μ ℓ ℓ s ℓ ℓ ) , {\displaystyle {\mathbb {E} }\left[\exp \left(i\sum _{\ell =1}^{k}s_{\ell }\,\mathbf {X} _{t_{\ell }}\right)\right]=\exp \left(-{\tfrac {1}{2}}\sum _{\ell ,j}\sigma _{\ell j}s_{\ell }s_{j}+i\sum _{\ell }\mu _{\ell }s_{\ell }\right),} or E [ e i s ( X t − − μ μ ) ] = e − − s σ σ s / 2 {\displaystyle {\mathbb {E} }\left[{\mathrm {e} }^{i\,\mathbf {s} \,(\mathbf {X} _{t}-\mathbf {\mu } )}\right]={\mathrm {e} }^{-\mathbf {s} \,\sigma \,\mathbf {s} /2}} . 
The numbers σ σ ℓ ℓ j {\displaystyle \sigma _{\ell j}} and μ μ ℓ ℓ {\displaystyle \mu _{\ell }} can be shown to be the covariances and means of the variables in the process.

[ 2 ] Variance [ edit ] The variance of a Gaussian process is finite at any time t {\displaystyle t} , formally [ 3 ] : p. 515 var ⁡ ⁡ [ X ( t ) ] = E [ | X ( t ) − − E ⁡ ⁡ [ X ( t ) ] | 2 ] < ∞ ∞ for all t ∈ ∈ T .

{\displaystyle \operatorname {var} [X(t)]={\mathbb {E} }\left[\left|X(t)-\operatorname {E} [X(t)]\right|^{2}\right]<\infty \quad {\text{for all }}t\in T.} Stationarity [ edit ] For general stochastic processes strict-sense stationarity implies wide-sense stationarity but not every wide-sense stationary stochastic process is strict-sense stationary. However, for a Gaussian stochastic process the two concepts are equivalent.

[ 3 ] : p. 518 A Gaussian stochastic process is strict-sense stationary if and only if it is wide-sense stationary.

Example [ edit ] There is an explicit representation for stationary Gaussian processes.

[ 4 ] A simple example of this representation is X t = cos ⁡ ⁡ ( a t ) ξ ξ 1 + sin ⁡ ⁡ ( a t ) ξ ξ 2 {\displaystyle X_{t}=\cos(at)\,\xi _{1}+\sin(at)\,\xi _{2}} where ξ ξ 1 {\displaystyle \xi _{1}} and ξ ξ 2 {\displaystyle \xi _{2}} are independent random variables with  the standard normal distribution .

Covariance functions [ edit ] Main article: Covariance function Further information: Variogram A key fact of Gaussian processes is that they can be completely defined by their second-order statistics.

[ 5 ] Thus, if a Gaussian process is assumed to have mean zero, defining the covariance function completely defines the process' behaviour. Importantly the non-negative definiteness of  this function enables its spectral decomposition using the Karhunen–Loève expansion . Basic aspects that can be defined through the covariance function are the process' stationarity , isotropy , smoothness and periodicity .

[ 6 ] [ 7 ] Stationarity refers to the process' behaviour regarding the separation of any two points x {\displaystyle x} and x ′ {\displaystyle x'} . If the process is stationary, the covariance function depends only on x − − x ′ {\displaystyle x-x'} . For example, the Ornstein–Uhlenbeck process is stationary.

If the process depends only on | x − − x ′ | {\displaystyle |x-x'|} , the Euclidean distance (not the direction) between x {\displaystyle x} and x ′ {\displaystyle x'} ,  then the process is considered isotropic. A process that is concurrently stationary and isotropic is considered to be homogeneous ; [ 8 ] in practice these properties reflect the differences (or rather the lack of them) in the behaviour of the process given the location of the observer.

Ultimately Gaussian processes translate as taking priors on functions and the smoothness of these priors can be induced by the covariance function.

[ 6 ] If we expect that for "near-by" input points x {\displaystyle x} and x ′ {\displaystyle x'} their corresponding output points y {\displaystyle y} and y ′ {\displaystyle y'} to be "near-by" also, then the assumption of continuity is present. If we wish to allow for significant displacement then we might choose a rougher covariance function. Extreme examples of the behaviour is the Ornstein–Uhlenbeck covariance function and the squared exponential where the former is never differentiable and the latter infinitely differentiable.

Periodicity refers to inducing periodic patterns within the behaviour of the process. Formally, this is achieved by mapping the input x {\displaystyle x} to a two dimensional vector u ( x ) = ( cos ⁡ ⁡ ( x ) , sin ⁡ ⁡ ( x ) ) {\displaystyle u(x)=\left(\cos(x),\sin(x)\right)} .

Usual covariance functions [ edit ] The effect of choosing different kernels on the prior function distribution of the Gaussian process. Left is a squared exponential kernel. Middle is Brownian. Right is quadratic.

There are a number of common covariance functions: [ 7 ] Constant : K C ( x , x ′ ) = C {\displaystyle K_{\operatorname {C} }(x,x')=C} Linear: K L ( x , x ′ ) = x T x ′ {\displaystyle K_{\operatorname {L} }(x,x')=x^{\mathsf {T}}x'} white Gaussian noise: K GN ( x , x ′ ) = σ σ 2 δ δ x , x ′ {\displaystyle K_{\operatorname {GN} }(x,x')=\sigma ^{2}\delta _{x,x'}} Squared exponential: K SE ( x , x ′ ) = exp ⁡ ⁡ ( − − d 2 2 ℓ ℓ 2 ) {\displaystyle K_{\operatorname {SE} }(x,x')=\exp \left(-{\tfrac {d^{2}}{2\ell ^{2}}}\right)} Ornstein–Uhlenbeck: K OU ( x , x ′ ) = exp ⁡ ⁡ ( − − d ℓ ℓ ) {\displaystyle K_{\operatorname {OU} }(x,x')=\exp \left(-{\tfrac {d}{\ell }}\right)} Matérn: K Matern ( x , x ′ ) = 2 1 − − ν ν Γ Γ ( ν ν ) ( 2 ν ν d ℓ ℓ ) ν ν K ν ν ( 2 ν ν d ℓ ℓ ) {\displaystyle K_{\operatorname {Matern} }(x,x')={\tfrac {2^{1-\nu }}{\Gamma (\nu )}}\left({\tfrac {{\sqrt {2\nu }}d}{\ell }}\right)^{\nu }K_{\nu }\left({\tfrac {{\sqrt {2\nu }}d}{\ell }}\right)} Periodic: K P ( x , x ′ ) = exp ⁡ ⁡ ( − − 2 ℓ ℓ 2 sin 2 ⁡ ⁡ ( d / 2 ) ) {\displaystyle K_{\operatorname {P} }(x,x')=\exp \left(-{\tfrac {2}{\ell ^{2}}}\sin ^{2}(d/2)\right)} Rational quadratic: K RQ ( x , x ′ ) = ( 1 + d 2 ) − − α α , α α ≥ ≥ 0 {\displaystyle K_{\operatorname {RQ} }(x,x')=\left(1+d^{2}\right)^{-\alpha },\quad \alpha \geq 0} Here d = | x − − x ′ | {\displaystyle d=|x-x'|} , which is a result of the stationary process property, that is, for nay stationary process the covariance function will only depend on d {\displaystyle d} . The parameter ℓ ℓ {\displaystyle \ell } is the characteristic length-scale of the process (practically, "how close" two points x {\displaystyle x} and x ′ {\displaystyle x'} have to be to influence each other significantly), δ δ {\displaystyle \delta } is the Kronecker delta and σ σ {\displaystyle \sigma } the standard deviation of the noise fluctuations. Moreover, K ν ν {\displaystyle K_{\nu }} is the modified Bessel function of order ν ν {\displaystyle \nu } and Γ Γ ( ν ν ) {\displaystyle \Gamma (\nu )} is the gamma function evaluated at ν ν {\displaystyle \nu } . Importantly, a complicated covariance function can be defined as a linear combination of other simpler covariance functions in order to incorporate different insights about the data-set at hand.

The inferential results are dependent on the values of the hyperparameters θ θ {\displaystyle \theta } (e.g.

ℓ ℓ {\displaystyle \ell } and σ σ {\displaystyle \sigma } ) defining the model's behaviour. A popular choice for θ θ {\displaystyle \theta } is to provide maximum a posteriori (MAP) estimates of it with some chosen prior. If the prior is very near uniform, this is the same as maximizing the marginal likelihood of the process; the  marginalization being done over the observed process values y {\displaystyle y} .

[ 7 ] This approach is also known as maximum likelihood II , evidence maximization , or empirical Bayes .

[ 9 ] Continuity [ edit ] For a Gaussian process, continuity in probability is equivalent to mean-square continuity [ 10 ] : 145 : 91 "Gaussian processes are discontinuous at fixed points." [ 11 ] and continuity with probability one is equivalent to sample continuity .

[ 12 ] The latter implies, but is not implied by, continuity in probability.
Continuity in probability holds if and only if the mean and autocovariance are continuous functions. In contrast, sample continuity was challenging even for stationary Gaussian processes (as probably noted first by Andrey Kolmogorov ), and more challenging for more general processes.

[ 13 ] : Sect. 2.8 [ 14 ] : 69, 81 [ 15 ] : 80 [ 16 ] As usual, by a sample continuous process one means a process that admits a sample continuous modification .

[ 17 ] : 292 [ 18 ] : 424 Stationary case [ edit ] For a stationary Gaussian process X = ( X t ) t ∈ ∈ R , {\displaystyle X=(X_{t})_{t\in \mathbb {R} },} some conditions on its spectrum are sufficient for sample continuity, but fail to be necessary. A necessary and sufficient condition, sometimes called Dudley–Fernique theorem, involves the function σ σ {\displaystyle \sigma } defined by σ σ ( h ) = E [ X ( t + h ) − − X ( t ) ] 2 {\displaystyle \sigma (h)={\sqrt {{\mathbb {E} }{\big [}X(t+h)-X(t){\big ]}^{2}}}} (the right-hand side does not depend on t {\displaystyle t} due to stationarity). Continuity of X {\displaystyle X} in probability is equivalent to continuity of σ σ {\displaystyle \sigma } at 0.

{\displaystyle 0.} When convergence of σ σ ( h ) {\displaystyle \sigma (h)} to 0 {\displaystyle 0} (as h → → 0 {\displaystyle h\to 0} ) is too slow, sample continuity of X {\displaystyle X} may fail. Convergence of the following integrals matters: I ( σ σ ) = ∫ ∫ 0 1 σ σ ( h ) h log ⁡ ⁡ ( 1 / h ) d h = ∫ ∫ 0 ∞ ∞ 2 σ σ ( e − − x 2 ) d x , {\displaystyle I(\sigma )=\int _{0}^{1}{\frac {\sigma (h)}{h{\sqrt {\log(1/h)}}}}\,dh=\int _{0}^{\infty }2\sigma (e^{-x^{2}})\,dx,} these two integrals being equal according to integration by substitution h = e − − x 2 , {\textstyle h=e^{-x^{2}},} x = log ⁡ ⁡ ( 1 / h ) .

{\textstyle x={\sqrt {\log(1/h)}}.} The first integrand need not be bounded as h → → 0 + , {\displaystyle h\to 0+,} thus the integral may converge ( I ( σ σ ) < ∞ ∞ {\displaystyle I(\sigma )<\infty } ) or diverge ( I ( σ σ ) = ∞ ∞ {\displaystyle I(\sigma )=\infty } ). Taking for example σ σ ( e − − x 2 ) = 1 x a {\textstyle \sigma (e^{-x^{2}})={\tfrac {1}{x^{a}}}} for large x , {\displaystyle x,} that is, σ σ ( h ) = ( log ⁡ ⁡ ( 1 / h ) ) − − a / 2 {\textstyle \sigma (h)=(\log(1/h))^{-a/2}} for small h , {\displaystyle h,} one obtains I ( σ σ ) < ∞ ∞ {\displaystyle I(\sigma )<\infty } when a > 1 , {\displaystyle a>1,} and I ( σ σ ) = ∞ ∞ {\displaystyle I(\sigma )=\infty } when 0 < a ≤ ≤ 1.

{\displaystyle 0<a\leq 1.} In these two cases the function σ σ {\displaystyle \sigma } is increasing on [ 0 , ∞ ∞ ) , {\displaystyle [0,\infty ),} but generally it is not. Moreover, the condition (*) there exists ε ε > 0 {\displaystyle \varepsilon >0} such that σ σ {\displaystyle \sigma } is monotone on [ 0 , ε ε ] {\displaystyle [0,\varepsilon ]} does not follow from continuity of σ σ {\displaystyle \sigma } and the evident relations σ σ ( h ) ≥ ≥ 0 {\displaystyle \sigma (h)\geq 0} (for all h {\displaystyle h} ) and σ σ ( 0 ) = 0.

{\displaystyle \sigma (0)=0.} Theorem 1 — Let σ σ {\displaystyle \sigma } be continuous and satisfy (*) . Then the condition I ( σ σ ) < ∞ ∞ {\displaystyle I(\sigma )<\infty } is necessary and sufficient for sample continuity of X .

{\displaystyle X.} Some history.

[ 18 ] : 424 Sufficiency was announced by Xavier Fernique in 1964, but the first proof was published by Richard M. Dudley in 1967.

[ 17 ] : Theorem 7.1 Necessity was proved by Michael B. Marcus and Lawrence Shepp in 1970.

[ 19 ] : 380 There exist sample continuous processes X {\displaystyle X} such that I ( σ σ ) = ∞ ∞ ; {\displaystyle I(\sigma )=\infty ;} they violate condition (*) . An example found by Marcus and Shepp [ 19 ] : 387 is a random lacunary Fourier series X t = ∑ ∑ n = 1 ∞ ∞ c n ( ξ ξ n cos ⁡ ⁡ λ λ n t + η η n sin ⁡ ⁡ λ λ n t ) , {\displaystyle X_{t}=\sum _{n=1}^{\infty }c_{n}(\xi _{n}\cos \lambda _{n}t+\eta _{n}\sin \lambda _{n}t),} where ξ ξ 1 , η η 1 , ξ ξ 2 , η η 2 , … … {\displaystyle \xi _{1},\eta _{1},\xi _{2},\eta _{2},\dots } are independent random variables with standard normal distribution ; frequencies 0 < λ λ 1 < λ λ 2 < … … {\displaystyle 0<\lambda _{1}<\lambda _{2}<\dots } are a fast growing sequence; and coefficients c n > 0 {\displaystyle c_{n}>0} satisfy ∑ ∑ n c n < ∞ ∞ .

{\textstyle \sum _{n}c_{n}<\infty .} The latter relation implies E ∑ ∑ n c n ( | ξ ξ n | + | η η n | ) = ∑ ∑ n c n E [ | ξ ξ n | + | η η n | ] = const ⋅ ⋅ ∑ ∑ n c n < ∞ ∞ , {\textstyle {\mathbb {E} }\sum _{n}c_{n}(|\xi _{n}|+|\eta _{n}|)=\sum _{n}c_{n}{\mathbb {E} }[|\xi _{n}|+|\eta _{n}|]={\text{const}}\cdot \sum _{n}c_{n}<\infty ,} whence ∑ ∑ n c n ( | ξ ξ n | + | η η n | ) < ∞ ∞ {\textstyle \sum _{n}c_{n}(|\xi _{n}|+|\eta _{n}|)<\infty } almost surely, which ensures uniform convergence of the Fourier series almost surely, and sample continuity of X .

{\displaystyle X.} Autocorrelation of a random lacunary Fourier series Its autocovariation function E [ X t X t + h ] = ∑ ∑ n = 1 ∞ ∞ c n 2 cos ⁡ ⁡ λ λ n h {\displaystyle {\mathbb {E} }[X_{t}X_{t+h}]=\sum _{n=1}^{\infty }c_{n}^{2}\cos \lambda _{n}h} is nowhere monotone (see the picture), as well as the corresponding function σ σ , {\displaystyle \sigma ,} σ σ ( h ) = 2 E [ X t X t ] − − 2 E [ X t X t + h ] = 2 ∑ ∑ n = 1 ∞ ∞ c n 2 sin 2 ⁡ ⁡ λ λ n h 2 .

{\displaystyle \sigma (h)={\sqrt {2{\mathbb {E} }[X_{t}X_{t}]-2{\mathbb {E} }[X_{t}X_{t+h}]}}=2{\sqrt {\sum _{n=1}^{\infty }c_{n}^{2}\sin ^{2}{\frac {\lambda _{n}h}{2}}}}.} Brownian motion as the integral of Gaussian processes [ edit ] A Wiener process (also known as Brownian motion) is the integral of a white noise generalized Gaussian process . It is not stationary , but it has stationary increments .

The Ornstein–Uhlenbeck process is a stationary Gaussian process.

The Brownian bridge is (like the Ornstein–Uhlenbeck process) an example of a Gaussian process whose increments are not independent .

The fractional Brownian motion is a Gaussian process whose covariance function is a generalisation of that of the Wiener process.

RKHS structure and Gaussian process [ edit ] Let f {\displaystyle f} be a mean-zero Gaussian process { X t ; t ∈ ∈ T } {\displaystyle \left\{X_{t};t\in T\right\}} with a non-negative definite covariance function K {\displaystyle K} and let R {\displaystyle R} be a symmetric and positive semidefinite function. Then, there exists a Gaussian process X {\displaystyle X} which has the covariance R {\displaystyle R} . Moreover, the reproducing kernel Hilbert space (RKHS) associated to R {\displaystyle R} coincides with the Cameron–Martin theorem associated space R ( H ) {\displaystyle R(H)} of X {\displaystyle X} , and all the spaces R ( H ) {\displaystyle R(H)} , H X {\displaystyle H_{X}} , and H ( K ) {\displaystyle {\mathcal {H}}(K)} are isometric.

[ 20 ] From now on, let H ( R ) {\displaystyle {\mathcal {H}}(R)} be a reproducing kernel Hilbert space with positive definite kernel R {\displaystyle R} .

Driscoll's zero-one law is a result characterizing the sample functions generated by a Gaussian process: lim n → → ∞ ∞ tr ⁡ ⁡ [ K n R n − − 1 ] < ∞ ∞ , {\displaystyle \lim _{n\to \infty }\operatorname {tr} [K_{n}R_{n}^{-1}]<\infty ,} where K n {\displaystyle K_{n}} and R n {\displaystyle R_{n}} are the covariance matrices of all possible pairs of n {\displaystyle n} points, implies Pr [ f ∈ ∈ H ( R ) ] = 1.

{\displaystyle \Pr[f\in {\mathcal {H}}(R)]=1.} Moreover, lim n → → ∞ ∞ tr ⁡ ⁡ [ K n R n − − 1 ] = ∞ ∞ {\displaystyle \lim _{n\to \infty }\operatorname {tr} [K_{n}R_{n}^{-1}]=\infty } implies [ 21 ] Pr [ f ∈ ∈ H ( R ) ] = 0.

{\displaystyle \Pr[f\in {\mathcal {H}}(R)]=0.} This has significant implications when K = R {\displaystyle K=R} , as lim n → → ∞ ∞ tr ⁡ ⁡ [ R n R n − − 1 ] = lim n → → ∞ ∞ tr ⁡ ⁡ [ I ] = lim n → → ∞ ∞ n = ∞ ∞ .

{\displaystyle \lim _{n\to \infty }\operatorname {tr} [R_{n}R_{n}^{-1}]=\lim _{n\to \infty }\operatorname {tr} [I]=\lim _{n\to \infty }n=\infty .} As such, almost all sample paths of a mean-zero Gaussian process with positive definite kernel K {\displaystyle K} will lie outside of the Hilbert space H ( K ) {\displaystyle {\mathcal {H}}(K)} .

Linearly constrained Gaussian processes [ edit ] For many applications of interest some pre-existing knowledge about the system at hand is already given. Consider e.g. the case where the output of the Gaussian process corresponds to a magnetic field; here, the real magnetic field is bound by Maxwell's equations and a way to incorporate this constraint into the Gaussian process formalism would be desirable as this would likely improve the accuracy of the algorithm.

A method on how to incorporate linear constraints into Gaussian processes already exists: [ 22 ] Consider the (vector valued) output function f ( x ) {\displaystyle f(x)} which is known to obey the linear constraint (i.e.

F X {\displaystyle {\mathcal {F}}_{X}} is a linear operator) F X ( f ( x ) ) = 0.

{\displaystyle {\mathcal {F}}_{X}(f(x))=0.} Then the constraint F X {\displaystyle {\mathcal {F}}_{X}} can be fulfilled by choosing f ( x ) = G X ( g ( x ) ) {\displaystyle f(x)={\mathcal {G}}_{X}(g(x))} , where g ( x ) ∼ ∼ G P ( μ μ g , K g ) {\displaystyle g(x)\sim {\mathcal {GP}}(\mu _{g},K_{g})} is modelled as a Gaussian process, and finding G X {\displaystyle {\mathcal {G}}_{X}} such that F X ( G X ( g ) ) = 0 ∀ ∀ g .

{\displaystyle {\mathcal {F}}_{X}({\mathcal {G}}_{X}(g))=0\qquad \forall g.} Given G X {\displaystyle {\mathcal {G}}_{X}} and using the fact that Gaussian processes are closed under linear transformations, the Gaussian process for f {\displaystyle f} obeying constraint F X {\displaystyle {\mathcal {F}}_{X}} becomes f ( x ) = G X g ∼ ∼ G P ( G X μ μ g , G X K g G X ′ T ) .

{\displaystyle f(x)={\mathcal {G}}_{X}g\sim {\mathcal {GP}}({\mathcal {G}}_{X}\mu _{g},{\mathcal {G}}_{X}K_{g}{\mathcal {G}}_{X'}^{\mathsf {T}}).} Hence, linear constraints can be encoded into the mean and covariance function of a Gaussian process.

Applications [ edit ] An example of Gaussian Process Regression (prediction) compared with other regression models.

[ 23 ] A Gaussian process can be used as a prior probability distribution over functions in Bayesian inference .

[ 7 ] [ 24 ] Given any set of N points in the desired domain of your functions, take a multivariate Gaussian whose covariance matrix parameter is the Gram matrix of your N points with some desired kernel , and sample from that Gaussian.  For solution of the multi-output prediction problem, Gaussian process regression for vector-valued function was developed. In this method, a 'big' covariance is constructed, which describes the correlations between all the input and output variables taken in N points  in the desired domain.

[ 25 ] This approach was elaborated in detail for the matrix-valued Gaussian processes and generalised to processes with 'heavier tails' like Student-t processes .

[ 26 ] Inference of continuous values with a Gaussian process prior is known as Gaussian process regression, or kriging ; extending Gaussian process regression to multiple target variables is known as cokriging .

[ 27 ] Gaussian processes are thus useful as a powerful non-linear multivariate interpolation tool. Kriging is also used to extend Gaussian process in the case of mixed integer inputs.

[ 28 ] Gaussian processes are also commonly used to tackle numerical analysis problems such as numerical integration, solving differential equations, or optimisation in the field of probabilistic numerics .

Gaussian processes can also be used in the context of mixture of experts models, for example.

[ 29 ] [ 30 ] The underlying rationale of such a learning framework consists in the assumption that a given mapping cannot be well captured by a single Gaussian process model. Instead, the observation space is divided into subsets, each of which is characterized by a different mapping function; each of these is learned via a different Gaussian process component in the postulated mixture.

In the natural sciences, Gaussian processes have found use as probabilistic models of astronomical time series and as predictors of molecular properties.

[ 31 ] They are also being increasingly used as surrogate models for force field optimization.

[ 32 ] Gaussian process prediction, or Kriging [ edit ] Further information: Kriging Gaussian Process Regression (prediction) with a squared exponential kernel. Left plot are draws from the prior function distribution. Middle are draws from the posterior. Right is mean prediction with one standard deviation shaded.

When concerned with a general Gaussian process regression problem (Kriging), it is assumed that for a Gaussian process f {\displaystyle f} observed at coordinates x {\displaystyle x} , the vector of values ⁠ f ( x ) {\displaystyle f(x)} ⁠ is just one sample from a multivariate Gaussian distribution of dimension equal to number of observed coordinates ⁠ n {\displaystyle n} ⁠ . Therefore, under the assumption of a zero-mean distribution, ⁠ f ( x ′ ) ∼ ∼ N ( 0 , K ( θ θ , x , x ′ ) ) {\displaystyle f(x')\sim N(0,K(\theta ,x,x'))} ⁠ , where ⁠ K ( θ θ , x , x ′ ) {\displaystyle K(\theta ,x,x')} ⁠ is the covariance matrix between all possible pairs ⁠ ( x , x ′ ) {\displaystyle (x,x')} ⁠ for a given set of hyperparameters θ .

[ 7 ] As such the log marginal likelihood is: log ⁡ ⁡ p ( f ( x ′ ) ∣ ∣ θ θ , x ) = − − 1 2 ( f ( x ) T K ( θ θ , x , x ′ ) − − 1 f ( x ′ ) + log ⁡ ⁡ det ( K ( θ θ , x , x ′ ) ) + n log ⁡ ⁡ 2 π π ) {\displaystyle \log p(f(x')\mid \theta ,x)=-{\frac {1}{2}}\left(f(x)^{\mathsf {T}}K(\theta ,x,x')^{-1}f(x')+\log \det(K(\theta ,x,x'))+n\log 2\pi \right)} and maximizing this marginal likelihood towards θ provides the complete specification of the Gaussian process f . One can briefly note at this point that the first term corresponds to a penalty term for a model's failure to fit observed values and the second term to a penalty term that increases proportionally to a model's complexity. Having specified θ , making predictions about unobserved values ⁠ f ( x ∗ ∗ ) {\displaystyle f(x^{*})} ⁠ at coordinates x * is then only a matter of drawing samples from the predictive distribution p ( y ∗ ∗ ∣ ∣ x ∗ ∗ , f ( x ) , x ) = N ( y ∗ ∗ ∣ ∣ A , B ) {\displaystyle p(y^{*}\mid x^{*},f(x),x)=N(y^{*}\mid A,B)} where the posterior mean estimate A is defined as A = K ( θ θ , x ∗ ∗ , x ) K ( θ θ , x , x ′ ) − − 1 f ( x ) {\displaystyle A=K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}f(x)} and the posterior variance estimate B is defined as: B = K ( θ θ , x ∗ ∗ , x ∗ ∗ ) − − K ( θ θ , x ∗ ∗ , x ) K ( θ θ , x , x ′ ) − − 1 K ( θ θ , x ∗ ∗ , x ) T {\displaystyle B=K(\theta ,x^{*},x^{*})-K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}K(\theta ,x^{*},x)^{\mathsf {T}}} where ⁠ K ( θ θ , x ∗ ∗ , x ) {\displaystyle K(\theta ,x^{*},x)} ⁠ is the covariance between the new coordinate of estimation x * and all other observed coordinates x for a given hyperparameter vector θ , ⁠ K ( θ θ , x , x ′ ) {\displaystyle K(\theta ,x,x')} ⁠ and ⁠ f ( x ) {\displaystyle f(x)} ⁠ are defined as before and ⁠ K ( θ θ , x ∗ ∗ , x ∗ ∗ ) {\displaystyle K(\theta ,x^{*},x^{*})} ⁠ is the variance at point x * as dictated by θ . It is important to note that practically the posterior mean estimate of ⁠ f ( x ∗ ∗ ) {\displaystyle f(x^{*})} ⁠ (the "point estimate") is just a linear combination of the observations ⁠ f ( x ) {\displaystyle f(x)} ⁠ ; in a similar manner the variance of ⁠ f ( x ∗ ∗ ) {\displaystyle f(x^{*})} ⁠ is actually independent of the observations ⁠ f ( x ) {\displaystyle f(x)} ⁠ . A known bottleneck in Gaussian process prediction is that the computational complexity of inference and likelihood evaluation is cubic in the number of points | x |, and as such can become unfeasible for larger data sets.

[ 6 ] [ 33 ] Works on sparse Gaussian processes, that usually are based on the idea of building a representative set for the given process f , try to circumvent this issue.

[ 34 ] [ 35 ] [ 36 ] The kriging method can be used in the latent level of a nonlinear mixed-effects model for a spatial functional prediction: this technique is called the latent kriging.

[ 37 ] Other classes of scalable Gaussian process for analyzing massive datasets have emerged from the Vecchia approximation and Nearest Neighbor Gaussian Processes (NNGP).

[ 38 ] [ 33 ] Often, the covariance has the form K ( θ θ , x , x ′ ) = 1 σ σ 2 K ~ ~ ( θ θ , x , x ′ ) {\textstyle K(\theta ,x,x')={\frac {1}{\sigma ^{2}}}{\tilde {K}}(\theta ,x,x')} , where σ σ 2 {\displaystyle \sigma ^{2}} is a scaling parameter. Examples are the Matérn class covariance functions. If this scaling parameter σ σ 2 {\displaystyle \sigma ^{2}} is either known or unknown (i.e. must be marginalized), then the posterior probability, p ( θ θ ∣ ∣ D ) {\displaystyle p(\theta \mid D)} , i.e. the probability for the hyperparameters θ θ {\displaystyle \theta } given a set of data pairs D {\displaystyle D} of observations of x {\displaystyle x} and f ( x ) {\displaystyle f(x)} , admits an analytical expression.

[ 39 ] Bayesian neural networks as Gaussian processes [ edit ] Further information: Neural network Gaussian process Bayesian neural networks are a particular type of Bayesian network that results from treating deep learning and artificial neural network models probabilistically, and assigning a prior distribution to their parameters . Computation in artificial neural networks is usually organized into sequential layers of artificial neurons . The number of neurons in a layer is called the layer width. As layer width grows large, many Bayesian neural networks reduce to a Gaussian process with a closed form compositional kernel. This Gaussian process is called the Neural Network Gaussian Process (NNGP) (not to be confused with the Nearest Neighbor Gaussian Process [ 38 ] ).

[ 7 ] [ 40 ] [ 41 ] It allows predictions from Bayesian neural networks to be more efficiently evaluated, and provides an analytic tool to understand deep learning models.

Computational issues [ edit ] See also: Gaussian process approximations In practical applications, Gaussian process models are often evaluated on a grid leading to multivariate normal distributions. Using these models for prediction or parameter estimation using maximum likelihood requires evaluating a multivariate Gaussian density, which involves calculating the determinant and the inverse of the covariance matrix. Both of these operations have cubic computational complexity which means that even for grids of modest sizes, both operations can have a prohibitive computational cost. This drawback led to the development of multiple approximation methods .

[ 33 ] See also [ edit ] Bayes linear statistics Bayesian interpretation of regularization Kriging Gaussian free field Gauss–Markov process Gradient-enhanced kriging (GEK) Student's t-process References [ edit ] ^ MacKay, David J.C.

(2003).

Information Theory, Inference, and Learning Algorithms (PDF) .

Cambridge University Press . p. 540.

ISBN 9780521642989 .

The probability distribution of a function y ( x ) {\displaystyle y(\mathbf {x} )} is a Gaussian processes if for any finite selection of points x ( 1 ) , x ( 2 ) , … … , x ( N ) {\displaystyle \mathbf {x} ^{(1)},\mathbf {x} ^{(2)},\ldots ,\mathbf {x} ^{(N)}} , the density P ( y ( x ( 1 ) ) , y ( x ( 2 ) ) , … … , y ( x ( N ) ) ) {\displaystyle P(y(\mathbf {x} ^{(1)}),y(\mathbf {x} ^{(2)}),\ldots ,y(\mathbf {x} ^{(N)}))} is a Gaussian ^ Dudley, R.M. (1989).

Real Analysis and Probability . Wadsworth and Brooks/Cole.

ISBN 0-534-10050-3 .

^ a b Amos Lapidoth (8 February 2017).

A Foundation in Digital Communication . Cambridge University Press.

ISBN 978-1-107-17732-1 .

^ Kac, M.; Siegert, A.J.F (1947).

"An Explicit Representation of a Stationary Gaussian Process" .

The Annals of Mathematical Statistics .

18 (3): 438– 442.

doi : 10.1214/aoms/1177730391 .

^ Bishop, C.M. (2006).

Pattern Recognition and Machine Learning .

Springer .

ISBN 978-0-387-31073-2 .

^ a b c Barber, David (2012).

Bayesian Reasoning and Machine Learning .

Cambridge University Press .

ISBN 978-0-521-51814-7 .

^ a b c d e f Rasmussen, C.E.; Williams, C.K.I (2006).

Gaussian Processes for Machine Learning .

MIT Press .

ISBN 978-0-262-18253-9 .

^ Grimmett, Geoffrey; David Stirzaker (2001).

Probability and Random Processes .

Oxford University Press .

ISBN 978-0198572220 .

^ Seeger, Matthias (2004). "Gaussian Processes for Machine Learning".

International Journal of Neural Systems .

14 (2): 69– 104.

CiteSeerX 10.1.1.71.1079 .

doi : 10.1142/s0129065704001899 .

PMID 15112367 .

S2CID 52807317 .

^ Dudley, R. M.

(1975).

"The Gaussian process and how to approach it" (PDF) .

Proceedings of the International Congress of Mathematicians . Vol. 2. pp.

143– 146.

^ Banerjee, Sudipto; Gelfand, Alan E. (2003).

"On smoothness properties of spatial processes" .

Journal of Multivariate Analysis .

84 (1): 85– 100.

doi : 10.1016/S0047-259X(02)00016-7 .

^ Dudley, R. M.

(2010).

"Sample Functions of the Gaussian Process" .

Selected Works of R.M. Dudley . Vol. 1. pp.

66– 103.

doi : 10.1007/978-1-4419-5821-1_13 .

ISBN 978-1-4419-5820-4 .

{{ cite book }} : |journal= ignored ( help ) ^ Talagrand, Michel (2014).

Upper and lower bounds for stochastic processes: modern methods and classical problems . Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge / A Series of Modern Surveys in Mathematics. Springer, Heidelberg.

ISBN 978-3-642-54074-5 .

^ Ledoux, Michel (1996), "Isoperimetry and Gaussian analysis", in Dobrushin, Roland; Groeneboom, Piet; Ledoux, Michel (eds.), Lectures on Probability Theory and Statistics: Ecole d'Eté de Probabilités de Saint-Flour XXIV–1994 , Lecture Notes in Mathematics, vol. 1648, Berlin: Springer, pp.

165– 294, doi : 10.1007/BFb0095676 , ISBN 978-3-540-62055-6 , MR 1600888 ^ Adler, Robert J. (1990).

An Introduction to Continuity, Extrema, and Related Topics for General Gaussian Processes . Vol. 12. Hayward, California: Institute of Mathematical Statistics.

ISBN 0-940600-17-X .

JSTOR 4355563 .

MR 1088478 .

{{ cite book }} : |journal= ignored ( help ) ^ Berman, Simeon M. (1992). "Review of: Adler 1990 'An introduction to continuity...' ".

Mathematical Reviews .

MR 1088478 .

^ a b Dudley, R. M.

(1967).

"The sizes of compact subsets of Hilbert space and continuity of Gaussian processes" .

Journal of Functional Analysis .

1 (3): 290– 330.

doi : 10.1016/0022-1236(67)90017-1 .

^ a b Marcus, M.B.; Shepp, Lawrence A.

(1972).

"Sample behavior of Gaussian processes" .

Proceedings of the sixth Berkeley symposium on mathematical statistics and probability, vol. II: probability theory . Vol. 6. Univ. California, Berkeley. pp.

423– 441.

^ a b Marcus, Michael B.; Shepp, Lawrence A.

(1970).

"Continuity of Gaussian processes" .

Transactions of the American Mathematical Society .

151 (2): 377– 391.

doi : 10.1090/s0002-9947-1970-0264749-1 .

JSTOR 1995502 .

^ Azmoodeh, Ehsan; Sottinen, Tommi; Viitasaari, Lauri; Yazigi, Adil (2014). "Necessary and sufficient conditions for Hölder continuity of Gaussian processes".

Statistics & Probability Letters .

94 : 230– 235.

arXiv : 1403.2215 .

doi : 10.1016/j.spl.2014.07.030 .

^ Driscoll, Michael F. (1973).

"The reproducing kernel Hilbert space structure of the sample paths of a Gaussian process" .

Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete .

26 (4): 309– 316.

doi : 10.1007/BF00534894 .

ISSN 0044-3719 .

S2CID 123348980 .

^ Jidling, Carl; Wahlström, Niklas; Wills, Adrian; Schön, Thomas B. (2017-09-19). "Linearly constrained Gaussian processes".

arXiv : 1703.00787 [ stat.ML ].

^ The documentation for scikit-learn also has similar examples .

^ Liu, W.; Principe, J.C.; Haykin, S. (2010).

Kernel Adaptive Filtering: A Comprehensive Introduction .

John Wiley .

ISBN 978-0-470-44753-6 . Archived from the original on 2016-03-04 . Retrieved 2010-03-26 .

^ Álvarez, Mauricio A.; Rosasco, Lorenzo; Lawrence, Neil D. (2012).

"Kernels for vector-valued functions: A review" (PDF) .

Foundations and Trends in Machine Learning .

4 (3): 195– 266.

doi : 10.1561/2200000036 .

S2CID 456491 .

^ Chen, Zexun; Wang, Bo; Gorban, Alexander N. (2019).

"Multivariate Gaussian and Student-t process regression for multi-output prediction" .

Neural Computing and Applications .

32 (8): 3005– 3028.

arXiv : 1703.04455 .

doi : 10.1007/s00521-019-04687-8 .

^ Stein, M.L. (1999).

Interpolation of Spatial Data: Some Theory for Kriging .

Springer .

^ Saves, Paul; Diouane, Youssef; Bartoli, Nathalie; Lefebvre, Thierry; Morlier, Joseph (2023). "A mixed-categorical correlation kernel for Gaussian process".

Neurocomputing .

550 : 126472.

arXiv : 2211.08262 .

doi : 10.1016/j.neucom.2023.126472 .

^ Platanios, Emmanouil A.; Chatzis, Sotirios P. (2014). "Gaussian Process-Mixture Conditional Heteroscedasticity".

IEEE Transactions on Pattern Analysis and Machine Intelligence .

36 (5): 888– 900.

doi : 10.1109/TPAMI.2013.183 .

PMID 26353224 .

S2CID 10424638 .

^ Chatzis, Sotirios P. (2013). "A latent variable Gaussian process model with Pitman–Yor process priors for multiclass classification".

Neurocomputing .

120 : 482– 489.

doi : 10.1016/j.neucom.2013.04.029 .

^ Griffiths, Ryan-Rhys (2022).

Applications of Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes (PhD thesis). University of Cambridge.

arXiv : 2303.14291 .

doi : 10.17863/CAM.93643 .

^ Shanks, B. L.; Sullivan, H. W.; Shazed, A. R.; Hoepfner, M. P. (2024).

"Accelerated Bayesian Inference for Molecular Simulations using Local Gaussian Process Surrogate Models" .

Journal of Chemical Theory and Computation .

20 (9): 3798– 3808.

arXiv : 2310.19108 .

doi : 10.1021/acs.jctc.3c01358 .

PMID 38551198 .

^ a b c Banerjee, Sudipto (2017).

"High-dimensional Bayesian Geostatistics" .

Bayesian Analysis .

12 (2): 583– 614.

doi : 10.1214/17-BA1056R .

PMC 5790125 .

PMID 29391920 .

^ Smola, A.J.; Schoellkopf, B. (2000). "Sparse greedy matrix approximation for machine learning".

Proceedings of the Seventeenth International Conference on Machine Learning : 911– 918.

CiteSeerX 10.1.1.43.3153 .

^ Csato, L.; Opper, M. (2002). "Sparse on-line Gaussian processes".

Neural Computation .

14 (3): 641– 668.

CiteSeerX 10.1.1.335.9713 .

doi : 10.1162/089976602317250933 .

PMID 11860686 .

S2CID 11375333 .

^ Banerjee, Sudipto; Gelfand, Alan E.; Finley, Andrew O.; Sang, Huiyan (2008).

"Gaussian Predictive Process Models for large spatial datasets" .

Journal of the Royal Statistical Society, Series B (Statistical Methodology) .

70 (4): 825– 848.

doi : 10.1111/j.1467-9868.2008.00663.x .

PMC 2741335 .

PMID 19750209 .

^ Lee, Se Yoon; Mallick, Bani (2021).

"Bayesian Hierarchical Modeling: Application Towards Production Results in the Eagle Ford Shale of South Texas" .

Sankhya B .

84 : 1– 43.

doi : 10.1007/s13571-020-00245-8 .

^ a b Datta, Abhirup; Banerjee, Sudipto; Finley, Andrew; Gelfand, Alan (2016).

"Hierarchical Nearest-Neighbor Gaussian Process Models for Large Spatial Data" .

Journal of the American Statistical Association .

111 (514): 800– 812.

doi : 10.1080/01621459.2015.1044091 .

PMC 5927603 .

PMID 29720777 .

^ Ranftl, Sascha; Melito, Gian Marco; Badeli, Vahid; Reinbacher-Köstinger, Alice; Ellermann, Katrin; von der Linden, Wolfgang (2019-12-31).

"Bayesian Uncertainty Quantification with Multi-Fidelity Data and Gaussian Processes for Impedance Cardiography of Aortic Dissection" .

Entropy .

22 (1): 58.

Bibcode : 2019Entrp..22...58R .

doi : 10.3390/e22010058 .

ISSN 1099-4300 .

PMC 7516489 .

PMID 33285833 .

^ Novak, Roman; Xiao, Lechao; Hron, Jiri; Lee, Jaehoon; Alemi, Alexander A.; Sohl-Dickstein, Jascha; Schoenholz, Samuel S. (2020). "Neural Tangents: Fast and Easy Infinite Neural Networks in Python".

International Conference on Learning Representations .

arXiv : 1912.02803 .

^ Neal, Radford M. (2012).

Bayesian Learning for Neural Networks . Springer Science and Business Media.

External links [ edit ] Wikibooks has a book on the topic of: Gaussian process Literature [ edit ] The Gaussian Processes Web Site, including the text of Rasmussen and Williams' Gaussian Processes for Machine Learning Ebden, Mark (2015). "Gaussian Processes: A Quick Introduction".

arXiv : 1505.02965 [ math.ST ].

A Review of Gaussian Random Fields and Correlation Functions Efficient Reinforcement Learning using Gaussian Processes Software [ edit ] Further information: Comparison of Gaussian process software GPML: A comprehensive Matlab toolbox for GP regression and classification STK: a Small (Matlab/Octave) Toolbox for Kriging and GP modeling Kriging module in UQLab framework (Matlab) CODES Toolbox: implementations of Kriging, variational kriging and multi-fidelity models (Matlab) [ permanent dead link ] Matlab/Octave function for stationary Gaussian fields [ permanent dead link ] Yelp MOE – A black box optimization engine using Gaussian process learning ooDACE Archived 2020-08-09 at the Wayback Machine – A flexible object-oriented Kriging Matlab toolbox.

GPstuff – Gaussian process toolbox for Matlab and Octave GPy – A Gaussian processes framework in Python GSTools - A geostatistical toolbox, including Gaussian process regression, written in Python Interactive Gaussian process regression demo Basic Gaussian process library written in C++11 scikit-learn – A machine learning library for Python which includes Gaussian process regression and classification SAMBO Optimization library for Python supports sequential optimization driven by Gaussian process regressor from scikit-learn .

[1] - The Kriging toolKit (KriKit) is developed at the Institute of Bio- and Geosciences 1 (IBG-1) of Forschungszentrum Jülich (FZJ) Video tutorials [ edit ] Gaussian Process Basics by David MacKay Learning with Gaussian Processes by Carl Edward Rasmussen Bayesian inference and Gaussian processes by Carl Edward Rasmussen v t e Stochastic processes Discrete time Bernoulli process Branching process Chinese restaurant process Galton–Watson process Independent and identically distributed random variables Markov chain Moran process Random walk Loop-erased Self-avoiding Biased Maximal entropy Continuous time Additive process Airy process Bessel process Birth–death process pure birth Brownian motion Bridge Dyson Excursion Fractional Geometric Meander Cauchy process Contact process Continuous-time random walk Cox process Diffusion process Empirical process Feller process Fleming–Viot process Gamma process Geometric process Hawkes process Hunt process Interacting particle systems Itô diffusion Itô process Jump diffusion Jump process Lévy process Local time Markov additive process McKean–Vlasov process Ornstein–Uhlenbeck process Poisson process Compound Non-homogeneous Quasimartingale Schramm–Loewner evolution Semimartingale Sigma-martingale Stable process Superprocess Telegraph process Variance gamma process Wiener process Wiener sausage Both Branching process Gaussian process Hidden Markov model (HMM) Markov process Martingale Differences Local Sub- Super- Random dynamical system Regenerative process Renewal process Stochastic chains with memory of variable length White noise Fields and other Dirichlet process Gaussian random field Gibbs measure Hopfield model Ising model Potts model Boolean network Markov random field Percolation Pitman–Yor process Point process Cox Determinantal Poisson Random field Random graph Time series models Autoregressive conditional heteroskedasticity (ARCH) model Autoregressive integrated moving average (ARIMA) model Autoregressive (AR) model Autoregressive–moving-average (ARMA) model Generalized autoregressive conditional heteroskedasticity (GARCH) model Moving-average (MA) model Financial models Binomial options pricing model Black–Derman–Toy Black–Karasinski Black–Scholes Chan–Karolyi–Longstaff–Sanders (CKLS) Chen Constant elasticity of variance (CEV) Cox–Ingersoll–Ross (CIR) Garman–Kohlhagen Heath–Jarrow–Morton (HJM) Heston Ho–Lee Hull–White Korn-Kreer-Lenssen LIBOR market Rendleman–Bartter SABR volatility Vašíček Wilkie Actuarial models Bühlmann Cramér–Lundberg Risk process Sparre–Anderson Queueing models Bulk Fluid Generalized queueing network M/G/1 M/M/1 M/M/c Properties Càdlàg paths Continuous Continuous paths Ergodic Exchangeable Feller-continuous Gauss–Markov Markov Mixing Piecewise-deterministic Predictable Progressively measurable Self-similar Stationary Time-reversible Limit theorems Central limit theorem Donsker's theorem Doob's martingale convergence theorems Ergodic theorem Fisher–Tippett–Gnedenko theorem Large deviation principle Law of large numbers (weak/strong) Law of the iterated logarithm Maximal ergodic theorem Sanov's theorem Zero–one laws ( Blumenthal , Borel–Cantelli , Engelbert–Schmidt , Hewitt–Savage , Kolmogorov , Lévy ) Inequalities Burkholder–Davis–Gundy Doob's martingale Doob's upcrossing Kunita–Watanabe Marcinkiewicz–Zygmund Tools Cameron–Martin formula Convergence of random variables Doléans-Dade exponential Doob decomposition theorem Doob–Meyer decomposition theorem Doob's optional stopping theorem Dynkin's formula Feynman–Kac formula Filtration Girsanov theorem Infinitesimal generator Itô integral Itô's lemma Karhunen–Loève theorem Kolmogorov continuity theorem Kolmogorov extension theorem Lévy–Prokhorov metric Malliavin calculus Martingale representation theorem Optional stopping theorem Prokhorov's theorem Quadratic variation Reflection principle Skorokhod integral Skorokhod's representation theorem Skorokhod space Snell envelope Stochastic differential equation Tanaka Stopping time Stratonovich integral Uniform integrability Usual hypotheses Wiener space Classical Abstract Disciplines Actuarial mathematics Control theory Econometrics Ergodic theory Extreme value theory (EVT) Large deviations theory Mathematical finance Mathematical statistics Probability theory Queueing theory Renewal theory Ruin theory Signal processing Statistics Stochastic analysis Time series analysis Machine learning List of topics Category Authority control databases National United States France BnF data Japan Israel Other Yale LUX NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐lwj9s
Cached time: 20250812000415
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.951 seconds
Real time usage: 1.328 seconds
Preprocessor visited node count: 7902/1000000
Revision size: 44959/2097152 bytes
Post‐expand include size: 155785/2097152 bytes
Template argument size: 5484/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 182504/5000000 bytes
Lua time usage: 0.509/10.000 seconds
Lua memory usage: 6161911/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  781.514      1 -total
 50.17%  392.092      1 Template:Reflist
 20.70%  161.812     15 Template:Cite_book
 20.64%  161.341     22 Template:Cite_journal
  9.82%   76.774     13 Template:Rp
  9.52%   74.424      1 Template:Stochastic_processes
  9.30%   72.702      1 Template:Navbox
  9.10%   71.144     13 Template:R/superscript
  8.48%   66.272      1 Template:Short_description
  5.81%   45.368      2 Template:Pagetype Saved in parser cache with key enwiki:pcache:302944:|#|:idhash:canonical and timestamp 20250812000415 and revision id 1305420965. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Gaussian_process&oldid=1305420965 " Categories : Stochastic processes Kernel methods for machine learning Nonparametric Bayesian statistics Normal distribution Hidden categories: CS1 errors: periodical ignored Articles with short description Short description is different from Wikidata All articles with dead external links Articles with dead external links from August 2025 Articles with permanently dead external links Webarchive template wayback links This page was last edited on 12 August 2025, at 00:03 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Gaussian process 17 languages Add topic

