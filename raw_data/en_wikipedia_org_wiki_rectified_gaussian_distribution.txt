Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Density function 2 Mean and variance 3 Generating values 4 Application 5 Extension to general bounds 6 See also 7 References Toggle the table of contents Rectified Gaussian distribution 2 languages Català Français Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Mixture of discrete and continuous distributions Not to be confused with truncated Gaussian distribution .

In probability theory , the rectified Gaussian distribution is a modification of the Gaussian distribution when its negative elements are reset to 0 (analogous to an electronic rectifier ). It is essentially a mixture of a discrete distribution (constant 0) and a continuous distribution (a truncated Gaussian distribution with interval ( 0 , ∞ ∞ ) {\displaystyle (0,\infty )} ) as a result of censoring .

Density function [ edit ] The probability density function of a rectified Gaussian distribution, for which random variables X having this distribution, derived from the normal distribution N ( μ μ , σ σ 2 ) , {\displaystyle {\mathcal {N}}(\mu ,\sigma ^{2}),} are displayed as X ∼ ∼ N R ( μ μ , σ σ 2 ) {\displaystyle X\sim {\mathcal {N}}^{\textrm {R}}(\mu ,\sigma ^{2})} ,   is given by f ( x ; μ μ , σ σ 2 ) = Φ Φ ( − − μ μ σ σ ) δ δ ( x ) + 1 2 π π σ σ 2 e − − ( x − − μ μ ) 2 2 σ σ 2 U ( x ) .

{\displaystyle f(x;\mu ,\sigma ^{2})=\Phi {\left(-{\frac {\mu }{\sigma }}\right)}\delta (x)+{\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\;e^{-{\frac {(x-\mu )^{2}}{2\sigma ^{2}}}}{\textrm {U}}(x).} A comparison of Gaussian distribution, rectified Gaussian distribution, and truncated Gaussian distribution.

Here, Φ Φ ( x ) {\displaystyle \Phi (x)} is the cumulative distribution function (cdf) of the standard normal distribution : Φ Φ ( x ) = 1 2 π π ∫ ∫ − − ∞ ∞ x e − − t 2 / 2 d t x ∈ ∈ R , {\displaystyle \Phi (x)={\frac {1}{\sqrt {2\pi }}}\int _{-\infty }^{x}e^{-t^{2}/2}\,dt\quad x\in \mathbb {R} ,} δ δ ( x ) {\displaystyle \delta (x)} is the Dirac delta function δ δ ( x ) = { + ∞ ∞ , x = 0 0 , x ≠ ≠ 0 {\displaystyle \delta (x)={\begin{cases}+\infty ,&x=0\\0,&x\neq 0\end{cases}}} and, U ( x ) {\displaystyle {\textrm {U}}(x)} is the unit step function : U ( x ) = { 0 , x ≤ ≤ 0 , 1 , x > 0.

{\displaystyle {\textrm {U}}(x)={\begin{cases}0,&x\leq 0,\\1,&x>0.\end{cases}}} Mean and variance [ edit ] Since the unrectified normal distribution has mean μ μ {\displaystyle \mu } and since in transforming it to the rectified distribution some probability mass has been shifted to a higher value (from negative values to 0), the mean of the rectified distribution is greater than μ μ .

{\displaystyle \mu .} Since the rectified distribution is formed by moving some of the probability mass toward the rest of the probability mass, the rectification is a mean-preserving contraction combined with a mean-changing rigid shift of the distribution, and thus the variance is decreased; therefore the variance of the rectified distribution is less than σ σ 2 .

{\displaystyle \sigma ^{2}.} Generating values [ edit ] To generate values computationally, one can use s ∼ ∼ N ( μ μ , σ σ 2 ) , x = max ( 0 , s ) , {\displaystyle s\sim {\mathcal {N}}(\mu ,\sigma ^{2}),\quad x={\textrm {max}}(0,s),} and then x ∼ ∼ N R ( μ μ , σ σ 2 ) .

{\displaystyle x\sim {\mathcal {N}}^{\textrm {R}}(\mu ,\sigma ^{2}).} Application [ edit ] A rectified Gaussian distribution is semi-conjugate to the Gaussian likelihood, and it has been recently applied to factor analysis , or particularly, (non-negative) rectified factor analysis.
Harva [ 1 ] proposed a variational learning algorithm for the rectified factor model, where the factors follow a mixture of rectified Gaussian; and later Meng [ 2 ] proposed an infinite rectified factor model coupled with its Gibbs sampling solution, where the factors follow a Dirichlet process mixture of rectified Gaussian distribution, and applied it in computational biology for reconstruction of gene regulatory networks .

Extension to general bounds [ edit ] An extension to the rectified Gaussian distribution was proposed by Palmer et al., [ 3 ] allowing rectification between arbitrary lower and upper bounds. For lower and upper bounds a {\displaystyle a} and b {\displaystyle b} respectively, the cdf, F R ( x | μ μ , σ σ 2 ) {\displaystyle F_{R}(x|\mu ,\sigma ^{2})} is given by: F R ( x | μ μ , σ σ 2 ) = { 0 , x < a , Φ Φ ( x | μ μ , σ σ 2 ) , a ≤ ≤ x < b , 1 , x ≥ ≥ b , {\displaystyle F_{R}(x|\mu ,\sigma ^{2})={\begin{cases}0,&x<a,\\\Phi (x|\mu ,\sigma ^{2}),&a\leq x<b,\\1,&x\geq b,\\\end{cases}}} where Φ Φ ( x | μ μ , σ σ 2 ) {\displaystyle \Phi (x|\mu ,\sigma ^{2})} is the cdf of a normal distribution with mean μ μ {\displaystyle \mu } and variance σ σ 2 {\displaystyle \sigma ^{2}} . The mean and variance of the rectified distribution is calculated by first transforming the constraints to be acting on a standard normal distribution: c = a − − μ μ σ σ , d = b − − μ μ σ σ .

{\displaystyle c={\frac {a-\mu }{\sigma }},\qquad d={\frac {b-\mu }{\sigma }}.} Using the transformed constraints, the mean and variance, μ μ R {\displaystyle \mu _{R}} and σ σ R 2 {\displaystyle \sigma _{R}^{2}} respectively, are then given by: μ μ t = 1 2 π π ( e ( − − c 2 2 ) − − e ( − − d 2 2 ) ) + c 2 ( 1 + erf ( c 2 ) ) + d 2 ( 1 − − erf ( d 2 ) ) , {\displaystyle \mu _{t}={\frac {1}{\sqrt {2\pi }}}\left(e^{\left(-{\frac {c^{2}}{2}}\right)}-e^{\left(-{\frac {d^{2}}{2}}\right)}\right)+{\frac {c}{2}}\left(1+{\textrm {erf}}\left({\frac {c}{\sqrt {2}}}\right)\right)+{\frac {d}{2}}\left(1-{\textrm {erf}}\left({\frac {d}{\sqrt {2}}}\right)\right),} σ σ t 2 = μ μ t 2 + 1 2 ( erf ( d 2 ) − − erf ( c 2 ) ) − − 1 2 π π ( ( d − − 2 μ μ t ) e ( − − d 2 2 ) − − ( c − − 2 μ μ t ) e ( − − c 2 2 ) ) + ( c − − μ μ t ) 2 2 ( 1 + erf ( c 2 ) ) + ( d − − μ μ t ) 2 2 ( 1 − − erf ( d 2 ) ) , {\displaystyle {\begin{aligned}\sigma _{t}^{2}&={\frac {\mu _{t}^{2}+1}{2}}\left({\textrm {erf}}\left({\frac {d}{\sqrt {2}}}\right)-{\textrm {erf}}\left({\frac {c}{\sqrt {2}}}\right)\right)-{\frac {1}{\sqrt {2\pi }}}\left(\left(d-2\mu _{t}\right)e^{\left(-{\frac {d^{2}}{2}}\right)}-\left(c-2\mu _{t}\right)e^{\left(-{\frac {c^{2}}{2}}\right)}\right)\\&+{\frac {\left(c-\mu _{t}\right)^{2}}{2}}\left(1+{\textrm {erf}}\left({\frac {c}{\sqrt {2}}}\right)\right)+{\frac {\left(d-\mu _{t}\right)^{2}}{2}}\left(1-{\textrm {erf}}\left({\frac {d}{\sqrt {2}}}\right)\right),\end{aligned}}} μ μ R = μ μ + σ σ μ μ t , {\displaystyle \mu _{R}=\mu +\sigma \mu _{t},} σ σ R 2 = σ σ 2 σ σ t 2 , {\displaystyle \sigma _{R}^{2}=\sigma ^{2}\sigma _{t}^{2},} where erf is the error function . This distribution was used by Palmer et al. for modelling physical resource levels, such as the quantity of liquid in a vessel, which is bounded by both 0 and the capacity of the vessel.

See also [ edit ] Folded normal distribution Half-normal distribution Half- t distribution Modified half-normal distribution [ 4 ] Truncated normal distribution References [ edit ] ^ Harva, M.; Kaban, A. (2007). "Variational learning for rectified factor analysis☆".

Signal Processing .

87 (3): 509.

doi : 10.1016/j.sigpro.2006.06.006 .

^ Meng, Jia; Zhang, Jianqiu (Michelle); Chen, Yidong; Huang, Yufei (2011).

"Bayesian non-negative factor analysis for reconstructing transcription factor mediated regulatory networks" .

Proteome Science .

9 (Suppl 1): S9.

doi : 10.1186/1477-5956-9-S1-S9 .

ISSN 1477-5956 .

PMC 3289087 .

PMID 22166063 .

^ Palmer, Andrew W.; Hill, Andrew J.; Scheding, Steven J. (2017).

"Methods for Stochastic Collection and Replenishment (SCAR) optimisation for persistent autonomy" .

Robotics and Autonomous Systems .

87 : 51– 65.

arXiv : 1603.01419 .

doi : 10.1016/j.robot.2016.09.011 .

^ Sun, Jingchao; Kong, Maiying; Pal, Subhadip (22 June 2021).

"The Modified-Half-Normal distribution: Properties and an efficient sampling scheme" (PDF) .

Communications in Statistics - Theory and Methods .

52 (5): 1591– 1613.

doi : 10.1080/03610926.2021.1934700 .

ISSN 0361-0926 .

S2CID 237919587 .

v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Rectified_Gaussian_distribution&oldid=1294922315 " Categories : Probability distributions Normal distribution Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 10 June 2025, at 16:22 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Rectified Gaussian distribution 2 languages Add topic

