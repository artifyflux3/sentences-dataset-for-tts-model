Title: Dot product

URL Source: https://en.wikipedia.org/wiki/Scalar_product

Published Time: 2002-12-12T01:12:30Z

Markdown Content:
From Wikipedia, the free encyclopedia

In [mathematics](https://en.wikipedia.org/wiki/Mathematics "Mathematics"), the **dot product** or **scalar product**[[note 1]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-1) is an [algebraic operation](https://en.wikipedia.org/wiki/Algebraic_operation "Algebraic operation") that takes two equal-length sequences of numbers (usually [coordinate vectors](https://en.wikipedia.org/wiki/Coordinate_vector "Coordinate vector")), and returns a single number. In [Euclidean geometry](https://en.wikipedia.org/wiki/Euclidean_geometry "Euclidean geometry"), the dot product of the [Cartesian coordinates](https://en.wikipedia.org/wiki/Cartesian_coordinates "Cartesian coordinates") of two [vectors](https://en.wikipedia.org/wiki/Euclidean_vector "Euclidean vector") is widely used. It is often called the **inner product** (or rarely the **projection product**) of [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space"), even though it is not the only inner product that can be defined on Euclidean space (see _[Inner product space](https://en.wikipedia.org/wiki/Inner\_product\_space "Inner product space")_ for more). It should not be confused with the [cross product](https://en.wikipedia.org/wiki/Cross_product "Cross product").

Algebraically, the dot product is the sum of the [products](https://en.wikipedia.org/wiki/Product_(mathematics) "Product (mathematics)") of the corresponding entries of the two sequences of numbers. Geometrically, it is the product of the [Euclidean magnitudes](https://en.wikipedia.org/wiki/Euclidean_vector#Length "Euclidean vector") of the two vectors and the [cosine](https://en.wikipedia.org/wiki/Cosine "Cosine") of the angle between them. These definitions are equivalent when using Cartesian coordinates. In modern [geometry](https://en.wikipedia.org/wiki/Geometry "Geometry"), [Euclidean spaces](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space") are often defined by using [vector spaces](https://en.wikipedia.org/wiki/Vector_space "Vector space"). In this case, the dot product is used for defining lengths (the length of a vector is the [square root](https://en.wikipedia.org/wiki/Square_root "Square root") of the dot product of the vector by itself) and angles (the cosine of the angle between two vectors is the [quotient](https://en.wikipedia.org/wiki/Quotient "Quotient") of their dot product by the product of their lengths).

The name "dot product" is derived from the [dot operator](https://en.wikipedia.org/wiki/Dot_operator "Dot operator") "**⋅**" that is often used to designate this operation;[[1]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-:1-2) the alternative name "scalar product" emphasizes that the result is a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)"), rather than a vector (as with the [vector product](https://en.wikipedia.org/wiki/Vector_product "Vector product") in three-dimensional space).

The dot product may be defined algebraically or geometrically. The geometric definition is based on the notions of angle and distance ([magnitude](https://en.wikipedia.org/wiki/Magnitude_(mathematics) "Magnitude (mathematics)")) of vectors. The equivalence of these two definitions relies on having a [Cartesian coordinate system](https://en.wikipedia.org/wiki/Cartesian_coordinate_system "Cartesian coordinate system") for Euclidean space.

In modern presentations of [Euclidean geometry](https://en.wikipedia.org/wiki/Euclidean_geometry "Euclidean geometry"), the points of space are defined in terms of their [Cartesian coordinates](https://en.wikipedia.org/wiki/Cartesian_coordinates "Cartesian coordinates"), and [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space") itself is commonly identified with the [real coordinate space](https://en.wikipedia.org/wiki/Real_coordinate_space "Real coordinate space")![Image 1: {\displaystyle \mathbf {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5ed657d7f0d7aa156e7b9b171f22b4a3aa6482c3). In such a presentation, the notions of length and angle are defined by means of the dot product. The length of a vector is defined as the [square root](https://en.wikipedia.org/wiki/Square_root "Square root") of the dot product of the vector by itself, and the [cosine](https://en.wikipedia.org/wiki/Cosine "Cosine") of the (non oriented) angle between two vectors of length one is defined as their dot product. So the equivalence of the two definitions of the dot product is a part of the equivalence of the classical and the modern formulations of Euclidean geometry.

### Coordinate definition

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=2 "Edit section: Coordinate definition")]

The dot product of two vectors ![Image 2: {\displaystyle \mathbf {a} =[a_{1},a_{2},\cdots ,a_{n}]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5284f6fd0c1181f08a22db25e7a51668b0621db0) and ![Image 3: {\displaystyle \mathbf {b} =[b_{1},b_{2},\cdots ,b_{n}]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6049394efd0b0a5bedeafa4fcbd0fd35a4d8846f), specified with respect to an [orthonormal basis](https://en.wikipedia.org/wiki/Orthonormal_basis "Orthonormal basis"), is defined as:[[2]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Lipschutz2009-3)![Image 4: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\sum _{i=1}^{n}a_{i}b_{i}=a_{1}b_{1}+a_{2}b_{2}+\cdots +a_{n}b_{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/69f8ac1d2b7ffb9ef70bb6b151a4b931f20087a5) where ![Image 5: {\displaystyle \Sigma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e1f558f53cda207614abdf90162266c70bc5c1e) ([sigma](https://en.wikipedia.org/wiki/Sigma "Sigma")) denotes [summation](https://en.wikipedia.org/wiki/Summation "Summation") and ![Image 6: {\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) is the [dimension](https://en.wikipedia.org/wiki/Dimension "Dimension") of the [vector space](https://en.wikipedia.org/wiki/Vector_space "Vector space"). For instance, in [three-dimensional space](https://en.wikipedia.org/wiki/Three-dimensional_space_(mathematics) "Three-dimensional space (mathematics)"), the dot product of vectors ![Image 7: {\displaystyle [1,3,-5]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/34361be3217025716bc493edaf428109cdde996a) and ![Image 8: {\displaystyle [4,-2,-1]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1aa56bf9b7ea1fc8fdb00b036c4c246b5f653a9c) is: ![Image 9: {\displaystyle {\begin{aligned}\ [1,3,-5]\cdot [4,-2,-1]&=(1\times 4)+(3\times -2)+(-5\times -1)\\&=4-6+5\\&=3\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a6f1f0d7669d35eb1220c3256ea458319c80f713)

Likewise, the dot product of the vector ![Image 10: {\displaystyle [1,3,-5]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/34361be3217025716bc493edaf428109cdde996a) with itself is: ![Image 11: {\displaystyle {\begin{aligned}\ [1,3,-5]\cdot [1,3,-5]&=(1\times 1)+(3\times 3)+(-5\times -5)\\&=1+9+25\\&=35\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9f1e6ff09018948273e2f6375b7d0c6196ee1c23)

If vectors are identified with [column vectors](https://en.wikipedia.org/wiki/Column_matrix "Column matrix"), the dot product can also be written as a [matrix product](https://en.wikipedia.org/wiki/Matrix_multiplication "Matrix multiplication")![Image 12: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\mathbf {a} ^{\mathsf {T}}\mathbf {b} ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/730b0c5d8ee397842e852cc1526c840b5cadebf7) where ![Image 13: {\displaystyle \mathbf {a} {^{\mathsf {T}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7c56eac771e4da711efa6263c7a00a89bcb3d1d4) denotes the [transpose](https://en.wikipedia.org/wiki/Transpose "Transpose") of ![Image 14: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d).

Expressing the above example in this way, a 1 × 3 matrix ([row vector](https://en.wikipedia.org/wiki/Row_vector "Row vector")) is multiplied by a 3 × 1 matrix ([column vector](https://en.wikipedia.org/wiki/Column_vector "Column vector")) to get a 1 × 1 matrix that is identified with its unique entry: ![Image 15: {\displaystyle {\begin{bmatrix}1&3&-5\end{bmatrix}}{\begin{bmatrix}4\\-2\\-1\end{bmatrix}}=3\,.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bc58988d7f3be84ba748c8e16a95cb679494586c)

### Geometric definition

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=3 "Edit section: Geometric definition")]

[![Image 16](https://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Inner-product-angle.svg/250px-Inner-product-angle.svg.png)](https://en.wikipedia.org/wiki/File:Inner-product-angle.svg)

Illustration showing how to find the angle between vectors using the dot product

[![Image 17](https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Tetrahedral_angle_calculation.svg/250px-Tetrahedral_angle_calculation.svg.png)](https://en.wikipedia.org/wiki/File:Tetrahedral_angle_calculation.svg)

 Calculating bond angles of a symmetrical [tetrahedral molecular geometry](https://en.wikipedia.org/wiki/Tetrahedral_molecular_geometry "Tetrahedral molecular geometry") using a dot product

In [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space"), a [Euclidean vector](https://en.wikipedia.org/wiki/Euclidean_vector "Euclidean vector") is a geometric object that possesses both a magnitude and a direction. A vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction to which the arrow points. The [magnitude](https://en.wikipedia.org/wiki/Magnitude_(mathematics) "Magnitude (mathematics)") of a vector ![Image 18: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) is denoted by ![Image 19: {\displaystyle \left\|\mathbf {a} \right\|}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ec49df2fa8265066b59f02d363bbc490ba023c23). The dot product of two Euclidean vectors ![Image 20: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 21: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9) is defined by[[3]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Spiegel2009-4)[[4]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-5)[[1]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-:1-2)![Image 22: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|\cos \theta ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2ed1f590c477f4f86793ed25a3f20c3633f742ee) where ![Image 23: {\displaystyle \theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af) is the [angle](https://en.wikipedia.org/wiki/Angle "Angle") between ![Image 24: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 25: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9).

In particular, if the vectors ![Image 26: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 27: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9) are [orthogonal](https://en.wikipedia.org/wiki/Orthogonal "Orthogonal") (i.e., their angle is ![Image 28: {\displaystyle {\frac {\pi }{2}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/98f98bef5d4981ff6e2aa827d4699e347fb30db2) or ![Image 29: {\displaystyle 90^{\circ }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c326d317eddef3ad3e6625e018a708e290a039f6)), then ![Image 30: {\displaystyle \cos {\frac {\pi }{2}}=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/82a42c21d362dc99b3986486f963a3cce908269d), which implies that ![Image 31: {\displaystyle \mathbf {a} \cdot \mathbf {b} =0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ffe01527f19f9dee4c44eb76180ed04cfae7b02a) At the other extreme, if they are [codirectional](https://en.wikipedia.org/wiki/Codirectional "Codirectional"), then the angle between them is zero with ![Image 32: {\displaystyle \cos 0=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e9946942d786042c531c821bec01e8bf09f8bab2) and ![Image 33: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\left\|\mathbf {a} \right\|\,\left\|\mathbf {b} \right\|}](https://wikimedia.org/api/rest_v1/media/math/render/svg/11d59f442438a6f8c8af9a0882b57350d991b6f3) This implies that the dot product of a vector ![Image 34: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) with itself is ![Image 35: {\displaystyle \mathbf {a} \cdot \mathbf {a} =\left\|\mathbf {a} \right\|^{2},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3d670295f64b1f8de1a98aa2782590aa20a64415) which gives ![Image 36: {\displaystyle \left\|\mathbf {a} \right\|={\sqrt {\mathbf {a} \cdot \mathbf {a} }},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3dbaf4a9a824c63de38a24d569fd58d8286c9c29) the formula for the [Euclidean length](https://en.wikipedia.org/wiki/Euclidean_length "Euclidean length") of the vector.

### Scalar projection and first properties

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=4 "Edit section: Scalar projection and first properties")]

[![Image 37](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/250px-Dot_Product.svg.png)](https://en.wikipedia.org/wiki/File:Dot_Product.svg)

Scalar projection

The [scalar projection](https://en.wikipedia.org/wiki/Scalar_projection "Scalar projection") (or scalar component) of a Euclidean vector ![Image 38: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) in the direction of a Euclidean vector ![Image 39: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9) is given by ![Image 40: {\displaystyle a_{b}=\left\|\mathbf {a} \right\|\cos \theta ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1620f14cb0739585d7013ff4abd9cf0874c962ed) where ![Image 41: {\displaystyle \theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af) is the angle between ![Image 42: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 43: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9).

In terms of the geometric definition of the dot product, this can be rewritten as ![Image 44: {\displaystyle a_{b}=\mathbf {a} \cdot {\widehat {\mathbf {b} }},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/84fa0688896ec16c21b0f3021ebe4d4813696205) where ![Image 45: {\displaystyle {\widehat {\mathbf {b} }}=\mathbf {b} /\left\|\mathbf {b} \right\|}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0e9a7b4b711f861ac65f797a7baf9127c258a6ef) is the [unit vector](https://en.wikipedia.org/wiki/Unit_vector "Unit vector") in the direction of ![Image 46: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9).

[![Image 47](https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Dot_product_distributive_law.svg/250px-Dot_product_distributive_law.svg.png)](https://en.wikipedia.org/wiki/File:Dot_product_distributive_law.svg)

Distributive law for the dot product

The dot product is thus characterized geometrically by[[5]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-6)![Image 48: {\displaystyle \mathbf {a} \cdot \mathbf {b} =a_{b}\left\|\mathbf {b} \right\|=b_{a}\left\|\mathbf {a} \right\|.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e40c8cd2581e53a24d5122e875886286b9a010c2) The dot product, defined in this manner, is [homogeneous](https://en.wikipedia.org/wiki/Homogeneous_function "Homogeneous function") under scaling in each variable, meaning that for any scalar ![Image 49: {\displaystyle \alpha }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3), ![Image 50: {\displaystyle (\alpha \mathbf {a} )\cdot \mathbf {b} =\alpha (\mathbf {a} \cdot \mathbf {b} )=\mathbf {a} \cdot (\alpha \mathbf {b} ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0b80d5386614d5f639201f8c09bfcd152e3b3f5e) It also satisfies the [distributive law](https://en.wikipedia.org/wiki/Distributive_law "Distributive law"), meaning that ![Image 51: {\displaystyle \mathbf {a} \cdot (\mathbf {b} +\mathbf {c} )=\mathbf {a} \cdot \mathbf {b} +\mathbf {a} \cdot \mathbf {c} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5f483a3722bee6d25aaee76359d3c80a15898086)

These properties may be summarized by saying that the dot product is a [bilinear form](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form"). Moreover, this bilinear form is [positive definite](https://en.wikipedia.org/wiki/Positive_definite_bilinear_form "Positive definite bilinear form"), which means that ![Image 52: {\displaystyle \mathbf {a} \cdot \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/53b63cfbf45880e7dcdb600ee18bc4aa80f3f645) is never negative, and is zero if and only if ![Image 53: {\displaystyle \mathbf {a} =\mathbf {0} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/966e2b83e48cb9c815b1e13aeda3a64141fa38b1), the [zero vector](https://en.wikipedia.org/wiki/Zero_element "Zero element").

### Equivalence of the definitions

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=5 "Edit section: Equivalence of the definitions")]

If ![Image 54: {\displaystyle \mathbf {e} _{1},\cdots ,\mathbf {e} _{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ae852919d901d8c4194d1c9a491b52cac2f24245) are the [standard basis vectors](https://en.wikipedia.org/wiki/Standard_basis "Standard basis") in ![Image 55: {\displaystyle \mathbf {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5ed657d7f0d7aa156e7b9b171f22b4a3aa6482c3), then we may write ![Image 56: {\displaystyle {\begin{aligned}\mathbf {a} &=[a_{1},\dots ,a_{n}]=\sum _{i}a_{i}\mathbf {e} _{i}\\\mathbf {b} &=[b_{1},\dots ,b_{n}]=\sum _{i}b_{i}\mathbf {e} _{i}.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b154ac2bb09512c81d917db83c273055c093571f) The vectors ![Image 57: {\displaystyle \mathbf {e} _{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ba77c5a75ef9e230d1a36183785477a2eb3c5c1e) are an [orthonormal basis](https://en.wikipedia.org/wiki/Orthonormal_basis "Orthonormal basis"), which means that they have unit length and are at right angles to each other. Since these vectors have unit length, ![Image 58: {\displaystyle \mathbf {e} _{i}\cdot \mathbf {e} _{i}=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e968dd877c8aa0c60a2832ff9a9a4ef841f9c80a) and since they form right angles with each other, if ![Image 59: {\displaystyle i\neq j}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d95aeb406bb427ac96806bc00c30c91d31b858be), ![Image 60: {\displaystyle \mathbf {e} _{i}\cdot \mathbf {e} _{j}=0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ba6c4baae0f5df2f41e9f97879178b41f3ffce71) Thus in general, we can say that: ![Image 61: {\displaystyle \mathbf {e} _{i}\cdot \mathbf {e} _{j}=\delta _{ij},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f8a60c5fe44c7e7bdc1c19155208c42773fbefbc) where ![Image 62: {\displaystyle \delta _{ij}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fa75d04c11480d976e1396951e02cbb3c4f71568) is the [Kronecker delta](https://en.wikipedia.org/wiki/Kronecker_delta "Kronecker delta").

[![Image 63](https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Skalarprodukt_geometrisch.svg/250px-Skalarprodukt_geometrisch.svg.png)](https://en.wikipedia.org/wiki/File:Skalarprodukt_geometrisch.svg)

Vector components in an orthonormal basis

Also, by the geometric definition, for any vector ![Image 64: {\displaystyle \mathbf {e} _{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ba77c5a75ef9e230d1a36183785477a2eb3c5c1e) and a vector ![Image 65: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d), we note that ![Image 66: {\displaystyle \mathbf {a} \cdot \mathbf {e} _{i}=\left\|\mathbf {a} \right\|\left\|\mathbf {e} _{i}\right\|\cos \theta _{i}=\left\|\mathbf {a} \right\|\cos \theta _{i}=a_{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9979b76116eda958d5eb2570e4d45bec412e7284) where ![Image 67: {\displaystyle a_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0bc77764b2e74e64a63341054fa90f3e07db275f) is the component of vector ![Image 68: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) in the direction of ![Image 69: {\displaystyle \mathbf {e} _{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ba77c5a75ef9e230d1a36183785477a2eb3c5c1e). The last step in the equality can be seen from the figure.

Now applying the distributivity of the geometric version of the dot product gives ![Image 70: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\mathbf {a} \cdot \sum _{i}b_{i}\mathbf {e} _{i}=\sum _{i}b_{i}(\mathbf {a} \cdot \mathbf {e} _{i})=\sum _{i}b_{i}a_{i}=\sum _{i}a_{i}b_{i},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/21fbe5ff2fc6283622fc48371048b12ada4ed043) which is precisely the algebraic definition of the dot product. So the geometric dot product equals the algebraic dot product.

The dot product fulfills the following properties if ![Image 71: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d), ![Image 72: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9), ![Image 73: {\displaystyle \mathbf {c} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/8798d172f59e21f2ce193a3118d4063d19353ded) and ![Image 74: {\displaystyle \mathbf {d} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/8ec3b626fc045b6ff579316e29978fccfed884c2) are real [vectors](https://en.wikipedia.org/wiki/Vector_(geometry) "Vector (geometry)") and ![Image 75: {\displaystyle \alpha }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3), ![Image 76: {\displaystyle \beta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/7ed48a5e36207156fb792fa79d29925d2f7901e8), ![Image 77: {\displaystyle \gamma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a) and ![Image 78: {\displaystyle \delta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/c5321cfa797202b3e1f8620663ff43c4660ea03a) are [scalars](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)").[[2]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Lipschutz2009-3)[[3]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Spiegel2009-4)

[Commutative](https://en.wikipedia.org/wiki/Commutative "Commutative")![Image 79: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\mathbf {b} \cdot \mathbf {a} ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/23da9e9ff4be4e3c6abcc7b7678f63383423a47d) which follows from the definition (![Image 80: {\displaystyle \theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af) is the angle between ![Image 81: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 82: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9)):[[6]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-7)![Image 83: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|\cos \theta =\left\|\mathbf {b} \right\|\left\|\mathbf {a} \right\|\cos \theta =\mathbf {b} \cdot \mathbf {a} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/88b573eb991220abffbfacc70ee1431f2306f2f3) The commutative property can also be easily proven with the algebraic definition, and in [more general spaces](https://en.wikipedia.org/wiki/Inner_product_space "Inner product space") (where the notion of angle might not be geometrically intuitive but an analogous product can be defined) the angle between two vectors can be defined as
![Image 84: {\displaystyle \theta =\operatorname {arccos} \left({\frac {\mathbf {a} \cdot \mathbf {b} }{\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|}}\right).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e74e3223460491c89f8e9b4f0823349b3f49efcd)

[Bilinear](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form") (additive, distributive and scalar-multiplicative in both arguments)![Image 85: {\displaystyle {\begin{aligned}(\alpha \mathbf {a} +\beta \mathbf {b} )&\cdot (\gamma \mathbf {c} +\delta \mathbf {d} )\\&=\alpha \gamma (\mathbf {a} \cdot \mathbf {c} )+\alpha \delta (\mathbf {a} \cdot \mathbf {d} )+\beta \gamma (\mathbf {b} \cdot \mathbf {c} )+\beta \delta (\mathbf {b} \cdot \mathbf {d} ).\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87a2e8a88c5298141c84345e66ea5007161dc712)Not [associative](https://en.wikipedia.org/wiki/Associative "Associative")Because the dot product is not defined between a scalar ![Image 86: {\displaystyle \mathbf {a} \cdot \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/494aed3b5e94f1c0ee071debc707d2700c0e0390) and a vector ![Image 87: {\displaystyle \mathbf {c} ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/eefe03f336fcebb5bb4107afb0241df3ad598d90) associativity is meaningless.[[7]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-8) However, bilinearity implies ![Image 88: {\displaystyle c(\mathbf {a} \cdot \mathbf {b} )=(c\mathbf {a} )\cdot \mathbf {b} =\mathbf {a} \cdot (c\mathbf {b} ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/339c3e45e50e09ba3b62d2467740fd054eb05c37) This property is sometimes called the "associative law for scalar and dot product",[[8]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-BanchoffWermer1983-9) and one may say that "the dot product is associative with respect to scalar multiplication".[[9]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-BedfordFowler2008-10)[Orthogonal](https://en.wikipedia.org/wiki/Orthogonal "Orthogonal")Two non-zero vectors ![Image 89: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 90: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9) are _orthogonal_ if and only if ![Image 91: {\displaystyle \mathbf {a} \cdot \mathbf {b} =0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c416b33910828e0941fec78eec1170c79e7ca146).No [cancellation](https://en.wikipedia.org/wiki/Cancellation_law "Cancellation law")Unlike multiplication of ordinary numbers, where if ![Image 92: {\displaystyle ab=ac}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c66bc658be9d643119e9b7fc0df7f0bbe37b99d2), then ![Image 93: {\displaystyle b}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f11423fbb2e967f986e36804a8ae4271734917c3) always equals ![Image 94: {\displaystyle c}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455) unless ![Image 95: {\displaystyle a}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ffd2487510aa438433a2579450ab2b3d557e5edc) is zero, the dot product does not obey the [cancellation law](https://en.wikipedia.org/wiki/Cancellation_law "Cancellation law"): If ![Image 96: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\mathbf {a} \cdot \mathbf {c} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/28ef6fab228b0e35c52d1c80ed024fdfe4bc25f4) and ![Image 97: {\displaystyle \mathbf {a} \neq \mathbf {0} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0fbd86f21598eb5c1c24152737ed1c22835368e0), then we can write: ![Image 98: {\displaystyle \mathbf {a} \cdot (\mathbf {b} -\mathbf {c} )=0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bcc4c343455359751e77d16ff1efa7737c8915d1) by the [distributive law](https://en.wikipedia.org/wiki/Distributive_law "Distributive law"); the result above says this just means that ![Image 99: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) is perpendicular to ![Image 100: {\displaystyle (\mathbf {b} -\mathbf {c} )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2438332cf0cef7a424101c79a241b8d797f3de9e), which still allows ![Image 101: {\displaystyle (\mathbf {b} -\mathbf {c} )\neq \mathbf {0} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac6043c901bf44ab6e0078dcd8119e5432629b81), and therefore allows ![Image 102: {\displaystyle \mathbf {b} \neq \mathbf {c} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/3bd7fe932f086de06c1b134c3a43790c215aaa2a).[Product rule](https://en.wikipedia.org/wiki/Product_rule "Product rule")If ![Image 103: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d) and ![Image 104: {\displaystyle \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/13ebf4628a1adf07133a6009e4a78bdd990c6eb9) are vector-valued [differentiable functions](https://en.wikipedia.org/wiki/Differentiable_function "Differentiable function"), then the derivative ([denoted by a prime](https://en.wikipedia.org/wiki/Notation_for_differentiation#Lagrange's_notation "Notation for differentiation")![Image 105: {\displaystyle {}'}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9ea6544b21c7df37230227c33a42eda9aa3f078e)) of ![Image 106: {\displaystyle \mathbf {a} \cdot \mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/494aed3b5e94f1c0ee071debc707d2700c0e0390) is given by the rule ![Image 107: {\displaystyle (\mathbf {a} \cdot \mathbf {b} )'=\mathbf {a} '\cdot \mathbf {b} +\mathbf {a} \cdot \mathbf {b} '.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7ef7a8a0489f4844895df1ade3e9f02810600070)

### Application to the law of cosines

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=7 "Edit section: Application to the law of cosines")]

[![Image 108](https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Dot_product_cosine_rule.svg/100px-Dot_product_cosine_rule.svg.png)](https://en.wikipedia.org/wiki/File:Dot_product_cosine_rule.svg)

Triangle with vector edges **a** and **b**, separated by angle _θ_

Given two vectors ![Image 109: {\displaystyle {\color {red}\mathbf {a} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bc5791a6b67777df8db7d6f2508967d7ebb6ed07) and ![Image 110: {\displaystyle {\color {blue}\mathbf {b} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/95b392ac93e227c2eae68b47eb927547fa6c4812) separated by angle ![Image 111: {\displaystyle \theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af) (see the upper image), they form a triangle with a third side ![Image 112: {\displaystyle {\color {orange}\mathbf {c} }={\color {red}\mathbf {a} }-{\color {blue}\mathbf {b} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7dcd6288734559d216bf776b403d47dd87b5cc8c). Let ![Image 113: {\displaystyle \color {red}a}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5fdc164a136678042293a26df6ad4d039046da8e), ![Image 114: {\displaystyle \color {blue}b}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1b7ac5da3fa86298ae44c7129738d7db0b3d46de) and ![Image 115: {\displaystyle \color {orange}c}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aa200d62434afb27fd6a43e8912719da5b419688) denote the lengths of ![Image 116: {\displaystyle {\color {red}\mathbf {a} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bc5791a6b67777df8db7d6f2508967d7ebb6ed07), ![Image 117: {\displaystyle {\color {blue}\mathbf {b} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/95b392ac93e227c2eae68b47eb927547fa6c4812), and ![Image 118: {\displaystyle {\color {orange}\mathbf {c} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3d928cc0bbfa8ee90f5f5fa49debc12705e5581c), respectively. The dot product of ![Image 119: {\displaystyle {\color {orange}\mathbf {c} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3d928cc0bbfa8ee90f5f5fa49debc12705e5581c) with itself is: ![Image 120: {\displaystyle {\begin{aligned}\mathbf {\color {orange}c} \cdot \mathbf {\color {orange}c} &=(\mathbf {\color {red}a} -\mathbf {\color {blue}b} )\cdot (\mathbf {\color {red}a} -\mathbf {\color {blue}b} )\\&=\mathbf {\color {red}a} \cdot \mathbf {\color {red}a} -\mathbf {\color {red}a} \cdot \mathbf {\color {blue}b} -\mathbf {\color {blue}b} \cdot \mathbf {\color {red}a} +\mathbf {\color {blue}b} \cdot \mathbf {\color {blue}b} \\&={\color {red}a}^{2}-\mathbf {\color {red}a} \cdot \mathbf {\color {blue}b} -\mathbf {\color {red}a} \cdot \mathbf {\color {blue}b} +{\color {blue}b}^{2}\\&={\color {red}a}^{2}-2\mathbf {\color {red}a} \cdot \mathbf {\color {blue}b} +{\color {blue}b}^{2}\\{\color {orange}c}^{2}&={\color {red}a}^{2}+{\color {blue}b}^{2}-2{\color {red}a}{\color {blue}b}\cos \mathbf {\color {purple}\theta } \\\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8c729be2c3b2d9881787b32492412a0322b217ea) which is the [law of cosines](https://en.wikipedia.org/wiki/Law_of_cosines "Law of cosines").

There are two [ternary operations](https://en.wikipedia.org/wiki/Ternary_operation "Ternary operation") involving dot product and [cross product](https://en.wikipedia.org/wiki/Cross_product "Cross product").

The **scalar triple product** of three vectors is defined as ![Image 121: {\displaystyle \mathbf {a} \cdot (\mathbf {b} \times \mathbf {c} )=\mathbf {b} \cdot (\mathbf {c} \times \mathbf {a} )=\mathbf {c} \cdot (\mathbf {a} \times \mathbf {b} ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5bb8e0667620c09d9e39fbec1dab2002734af461) Its value is the [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") of the matrix whose columns are the [Cartesian coordinates](https://en.wikipedia.org/wiki/Cartesian_coordinates "Cartesian coordinates") of the three vectors. It is the signed [volume](https://en.wikipedia.org/wiki/Volume "Volume") of the [parallelepiped](https://en.wikipedia.org/wiki/Parallelepiped "Parallelepiped") defined by the three vectors, and is [isomorphic](https://en.wikipedia.org/wiki/Isomorphism "Isomorphism") to the three-dimensional special case of the [exterior product](https://en.wikipedia.org/wiki/Exterior_product "Exterior product") of three vectors.

The **vector triple product** is defined by[[2]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Lipschutz2009-3)[[3]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Spiegel2009-4)![Image 122: {\displaystyle \mathbf {a} \times (\mathbf {b} \times \mathbf {c} )=(\mathbf {a} \cdot \mathbf {c} )\,\mathbf {b} -(\mathbf {a} \cdot \mathbf {b} )\,\mathbf {c} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f3b73c3f5ef2dda1a07b609d6660d39d3cc8d76f) This identity, also known as _Lagrange's formula_, [may be remembered](https://en.wikipedia.org/wiki/Mnemonic "Mnemonic") as "ACB minus ABC", keeping in mind which vectors are dotted together. This formula has applications in simplifying vector calculations in [physics](https://en.wikipedia.org/wiki/Physics "Physics").

In [physics](https://en.wikipedia.org/wiki/Physics "Physics"), the dot product takes two vectors and returns a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)") quantity. It is also known as the "scalar product". The dot product of two vectors can be defined as the product of the magnitudes of the two vectors and the cosine of the angle between the two vectors. Thus, ![Image 123: {\displaystyle \mathbf {a} \cdot \mathbf {b} =|\mathbf {a} |\,|\mathbf {b} |\cos \theta }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0be2212e50fab5c2791e4622ba266d79203b316e) Alternatively, it is defined as the product of the projection of the first vector onto the second vector and the magnitude of the second vector.

For example:[[10]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Riley2010-11)[[11]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-12)

*   [Mechanical work](https://en.wikipedia.org/wiki/Mechanical_work "Mechanical work") is the dot product of [force](https://en.wikipedia.org/wiki/Force "Force") and [displacement](https://en.wikipedia.org/wiki/Displacement_(vector) "Displacement (vector)") vectors,
*   [Power](https://en.wikipedia.org/wiki/Power_(physics) "Power (physics)") is the dot product of [force](https://en.wikipedia.org/wiki/Force "Force") and [velocity](https://en.wikipedia.org/wiki/Velocity "Velocity").

For vectors with [complex](https://en.wikipedia.org/wiki/Complex_number "Complex number") entries, using the given definition of the dot product would lead to quite different properties. For instance, the dot product of a vector with itself could be zero without the vector being the zero vector (e.g. this would happen with the vector ![Image 124: {\displaystyle \mathbf {a} =[1\ i]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f68c1771ca29419b14a5e2334f03687f6e2670d6)). This in turn would have consequences for notions like length and angle. Properties such as the positive-definite norm can be salvaged at the cost of giving up the symmetric and bilinear properties of the dot product, through the alternative definition[[12]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-13)[[2]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Lipschutz2009-3)![Image 125: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\sum _{i}{{a_{i}}\,{\overline {b_{i}}}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9792a404848060f7abcc48440f962af352d345d8) where ![Image 126: {\displaystyle {\overline {b_{i}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b58e2932864d974e413edb4859836f03dfacff46) is the [complex conjugate](https://en.wikipedia.org/wiki/Complex_conjugate "Complex conjugate") of ![Image 127: {\displaystyle b_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/40a8c2db2990a53c683e75961826167c5adac7c3). When vectors are represented by [column vectors](https://en.wikipedia.org/wiki/Column_vector "Column vector"), the dot product can be expressed as a [matrix product](https://en.wikipedia.org/wiki/Matrix_product "Matrix product") involving a [conjugate transpose](https://en.wikipedia.org/wiki/Conjugate_transpose "Conjugate transpose"), denoted with the superscript H: ![Image 128: {\displaystyle \mathbf {a} \cdot \mathbf {b} =\mathbf {b} ^{\mathsf {H}}\mathbf {a} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4063873c19fbcebf4fffff02847ce6171821019a)

In the case of vectors with real components, this definition is the same as in the real case. The dot product of any vector with itself is a non-negative real number, and it is nonzero except for the zero vector. However, the complex dot product is [sesquilinear](https://en.wikipedia.org/wiki/Sesquilinear "Sesquilinear") rather than bilinear, as it is [conjugate linear](https://en.wikipedia.org/wiki/Conjugate_linear "Conjugate linear") and not linear in ![Image 129: {\displaystyle \mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1a957216653a9ee0d0133dcefd13fb75e36b8b9d). The dot product is not symmetric, since ![Image 130: {\displaystyle \mathbf {a} \cdot \mathbf {b} ={\overline {\mathbf {b} \cdot \mathbf {a} }}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c8f01d7bb3c93db4eaf7f4c6b2d0babf70df843a) The angle between two complex vectors is then given by ![Image 131: {\displaystyle \cos \theta ={\frac {\operatorname {Re} (\mathbf {a} \cdot \mathbf {b} )}{\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0585eca7d0ea9871b3cd2f8bd8d3c4c33ff73245)

The complex dot product leads to the notions of [Hermitian forms](https://en.wikipedia.org/wiki/Hermitian_form "Hermitian form") and general [inner product spaces](https://en.wikipedia.org/wiki/Inner_product_space "Inner product space"), which are widely used in mathematics and [physics](https://en.wikipedia.org/wiki/Physics "Physics").

The self dot product of a complex vector ![Image 132: {\displaystyle \mathbf {a} \cdot \mathbf {a} =\mathbf {a} ^{\mathsf {H}}\mathbf {a} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/b76e91b99ff5d91de67dfadfeab0154f6a519d68), involving the conjugate transpose of a row vector, is also known as the **norm squared**, ![Image 133: {\textstyle \mathbf {a} \cdot \mathbf {a} =\|\mathbf {a} \|^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fbbaa385d13650966d8e2d5aee79ba4943653f66), after the [Euclidean norm](https://en.wikipedia.org/wiki/Euclidean_norm "Euclidean norm"); it is a vector generalization of the _[absolute square](https://en.wikipedia.org/wiki/Absolute\_square "Absolute square")_ of a complex scalar (see also: _[Squared Euclidean distance](https://en.wikipedia.org/wiki/Squared\_Euclidean\_distance "Squared Euclidean distance")_).

The inner product generalizes the dot product to [abstract vector spaces](https://en.wikipedia.org/wiki/Vector_space "Vector space") over a [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)") of [scalars](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)"), being either the field of [real numbers](https://en.wikipedia.org/wiki/Real_number "Real number")![Image 134: {\displaystyle \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/786849c765da7a84dbc3cce43e96aad58a5868dc) or the field of [complex numbers](https://en.wikipedia.org/wiki/Complex_number "Complex number")![Image 135: {\displaystyle \mathbb {C} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/f9add4085095b9b6d28d045fd9c92c2c09f549a7). It is usually denoted using [angular brackets](https://en.wikipedia.org/wiki/Angular_brackets "Angular brackets") by ![Image 136: {\displaystyle \left\langle \mathbf {a} \,,\mathbf {b} \right\rangle }](https://wikimedia.org/api/rest_v1/media/math/render/svg/cd499eaede342b362c9933cbf9192139b62dc9c3).

The inner product of two vectors over the field of complex numbers is, in general, a complex number, and is [sesquilinear](https://en.wikipedia.org/wiki/Sesquilinear_form "Sesquilinear form") instead of bilinear. An inner product space is a [normed vector space](https://en.wikipedia.org/wiki/Normed_vector_space "Normed vector space"), and the inner product of a vector with itself is real and positive-definite.

The dot product is defined for vectors that have a finite number of [entries](https://en.wikipedia.org/wiki/Coordinate_vector "Coordinate vector"). Thus these vectors can be regarded as [discrete functions](https://en.wikipedia.org/wiki/Discrete_function "Discrete function"): a length-![Image 137: {\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) vector ![Image 138: {\displaystyle u}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8) is, then, a function with [domain](https://en.wikipedia.org/wiki/Domain_of_a_function "Domain of a function")![Image 139: {\displaystyle \{k\in \mathbb {N} :1\leq k\leq n\}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b63ec989c455e3c5c032381c84e8010bdfdf2277), and ![Image 140: {\displaystyle u_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/14f13cb025ff2e136dcbd2fc81ddf965b728e3d7) is a notation for the image of ![Image 141: {\displaystyle i}](https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20) by the function/vector ![Image 142: {\displaystyle u}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8).

This notion can be generalized to [square-integrable functions](https://en.wikipedia.org/wiki/Square-integrable_function "Square-integrable function"): just as the inner product on vectors uses a sum over corresponding components, the inner product on functions is defined as an integral over some [measure space](https://en.wikipedia.org/wiki/Measure_space "Measure space")![Image 143: {\displaystyle (X,{\mathcal {A}},\mu )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d634d210e57700027029694595ffea10410bf0d5):[[2]](https://en.wikipedia.org/wiki/Scalar_product#cite_note-Lipschutz2009-3)![Image 144: {\displaystyle \left\langle u,v\right\rangle =\int _{X}uv\,{\text{d}}\mu .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c76f1f07eea48de885d8c9db584424c1e7758010)

For example, if ![Image 145: {\displaystyle f}](https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61) and ![Image 146: {\displaystyle g}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77) are [continuous functions](https://en.wikipedia.org/wiki/Continuous_function "Continuous function") over a [compact subset](https://en.wikipedia.org/wiki/Compact_space "Compact space")![Image 147: {\displaystyle K}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2b76fce82a62ed5461908f0dc8f037de4e3686b0) of ![Image 148: {\displaystyle \mathbb {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c510b63578322050121fe966f2e5770bea43308d) with the standard [Lebesgue measure](https://en.wikipedia.org/wiki/Lebesgue_measure "Lebesgue measure"), the above definition becomes: ![Image 149: {\displaystyle \left\langle f,g\right\rangle =\int _{K}f(\mathbf {x} )g(\mathbf {x} )\,\operatorname {d} ^{n}\mathbf {x} .}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86baa5b9630ff1eede1ee7ba408e2b745cf67017)

Generalized further to [complex continuous functions](https://en.wikipedia.org/wiki/Complex_function "Complex function")![Image 150: {\displaystyle \psi }](https://wikimedia.org/api/rest_v1/media/math/render/svg/45e5789e5d9c8f7c79744f43ecaaf8ba42a8553a) and ![Image 151: {\displaystyle \chi }](https://wikimedia.org/api/rest_v1/media/math/render/svg/656111758322ace96d80a9371771aa6d3de25437), by analogy with the complex inner product above, gives: ![Image 152: {\displaystyle \left\langle \psi ,\chi \right\rangle =\int _{K}\psi (z){\overline {\chi (z)}}\,{\text{d}}z.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ecdc5da5f91b8c3c29f5f1fd1efb4c563cde4c17)

Inner products can have a [weight function](https://en.wikipedia.org/wiki/Weight_function "Weight function") (i.e., a function which weights each term of the inner product with a value). Explicitly, the inner product of functions ![Image 153: {\displaystyle u(x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b1e5ff65a28eed29d36ddae9c6ae3b596fd14370) and ![Image 154: {\displaystyle v(x)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b371a381e15c71d8fc4ec43cf14b156f02a0d35a) with respect to the weight function ![Image 155: {\displaystyle r(x)>0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b90e9d1f2e8bdc710f70488daeacd79779eccf53) is ![Image 156: {\displaystyle \left\langle u,v\right\rangle _{r}=\int _{a}^{b}r(x)u(x)v(x)\,dx.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/85528387c2431138234b20cc025da3f51611faa8)

### Dyadics and matrices

[[edit](https://en.wikipedia.org/w/index.php?title=Dot_product&action=edit&section=15 "Edit section: Dyadics and matrices")]

A double-dot product for [matrices](https://en.wikipedia.org/wiki/Matrix_(mathematics) "Matrix (mathematics)") is the [Frobenius inner product](https://en.wikipedia.org/wiki/Frobenius_inner_product "Frobenius inner product"), which is analogous to the dot product on vectors. It is defined as the sum of the products of the corresponding components of two matrices ![Image 157: {\displaystyle \mathbf {A} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0795cc96c75d81520a120482662b90f024c9a1a1) and ![Image 158: {\displaystyle \mathbf {B} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/cafb0ef39b0f5ffa23c170aa7f7b4e718327c4d1) of the same size: ![Image 159: {\displaystyle \mathbf {A} :\mathbf {B} =\sum _{i}\sum _{j}A_{ij}{\overline {B_{ij}}}=\operatorname {tr} (\mathbf {B} ^{\mathsf {H}}\mathbf {A} )=\operatorname {tr} (\mathbf {A} \mathbf {B} ^{\mathsf {H}}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2edbf428405f7eefbf27bc2d037500f90fc57c84) And for real matrices, ![Image 160: {\displaystyle \mathbf {A} :\mathbf {B} =\sum _{i}\sum _{j}A_{ij}B_{ij}=\operatorname {tr} (\mathbf {B} ^{\mathsf {T}}\mathbf {A} )=\operatorname {tr} (\mathbf {A} \mathbf {B} ^{\mathsf {T}})=\operatorname {tr} (\mathbf {A} ^{\mathsf {T}}\mathbf {B} )=\operatorname {tr} (\mathbf {B} \mathbf {A} ^{\mathsf {T}}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5e91348a4da0691b8ee65e2a543c04565f716c4a)

Writing a matrix as a [dyadic](https://en.wikipedia.org/wiki/Dyadics "Dyadics"), we can define a different double-dot product (see _[Dyadics §Product of dyadic and dyadic](https://en.wikipedia.org/wiki/Dyadics#Product\_of\_dyadic\_and\_dyadic "Dyadics")_) however it is not an inner product.

The inner product between a [tensor](https://en.wikipedia.org/wiki/Tensor "Tensor") of order ![Image 161: {\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) and a tensor of order ![Image 162: {\displaystyle m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc) is a tensor of order ![Image 163: {\displaystyle n+m-2}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f8604ae5565d646f51a448ba8f8a6d8723e4e1ce), see _[Tensor contraction](https://en.wikipedia.org/wiki/Tensor\_contraction "Tensor contraction")_ for details.

The straightforward algorithm for calculating a floating-point dot product of vectors can suffer from [catastrophic cancellation](https://en.wikipedia.org/wiki/Catastrophic_cancellation "Catastrophic cancellation"). To avoid this, approaches such as the [Kahan summation algorithm](https://en.wikipedia.org/wiki/Kahan_summation_algorithm "Kahan summation algorithm") are used.

A dot product function is included in:

*   [BLAS](https://en.wikipedia.org/wiki/BLAS "BLAS") level 1 real `SDOT`, `DDOT`; complex `CDOTU`, `ZDOTU = X^T * Y`, `CDOTC`, `ZDOTC = X^H * Y`
*   [Fortran](https://en.wikipedia.org/wiki/Fortran "Fortran") as `dot_product(A,B)` or `sum(conjg(A) * B)`
*   [Julia](https://en.wikipedia.org/wiki/Julia_(programming_language) "Julia (programming language)") as `A' * B` or standard library LinearAlgebra as `dot(A, B)`
*   [R (programming language)](https://en.wikipedia.org/wiki/R_(programming_language) "R (programming language)") as `sum(A * B)` for vectors or, more generally for matrices, as `A %*% B`
*   [Matlab](https://en.wikipedia.org/wiki/Matlab "Matlab") as `A' * B` or `conj(transpose(A)) * B` or `sum(conj(A) .* B)` or `dot(A, B)`
*   [Python](https://en.wikipedia.org/wiki/Python_(programming_language) "Python (programming language)") (package [NumPy](https://en.wikipedia.org/wiki/NumPy "NumPy")) as `np.matmul(A, B)` or `np.dot(A, B)` or `np.inner(A, B)`
*   [GNU Octave](https://en.wikipedia.org/wiki/GNU_Octave "GNU Octave") as `sum(conj(X) .* Y, dim)`, and similar code as Matlab
*   Intel oneAPI Math Kernel Library real p?dot `dot  = sub(x)'*sub(y)`; complex p?dotc `dotc  = conjg(sub(x)')*sub(y)`

*   [Cauchy–Schwarz inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality "Cauchy–Schwarz inequality")
*   [Cross product](https://en.wikipedia.org/wiki/Cross_product "Cross product")
*   [Dot product representation of a graph](https://en.wikipedia.org/wiki/Dot_product_representation_of_a_graph "Dot product representation of a graph")
*   [Euclidean norm](https://en.wikipedia.org/wiki/Euclidean_norm "Euclidean norm"), the square-root of the self dot product
*   [Matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication "Matrix multiplication")
*   [Metric tensor](https://en.wikipedia.org/wiki/Metric_tensor "Metric tensor")
*   [Multiplication of vectors](https://en.wikipedia.org/wiki/Multiplication_of_vectors "Multiplication of vectors")
*   [Outer product](https://en.wikipedia.org/wiki/Outer_product "Outer product")

1.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-1)**The term _scalar product_ means literally "product with a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)") as a result". It is also used for other [symmetric bilinear forms](https://en.wikipedia.org/wiki/Symmetric_bilinear_form "Symmetric bilinear form"), for example in a [pseudo-Euclidean space](https://en.wikipedia.org/wiki/Pseudo-Euclidean_space "Pseudo-Euclidean space"). Not to be confused with [scalar multiplication](https://en.wikipedia.org/wiki/Scalar_multiplication "Scalar multiplication").

1.   ^ [_**a**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-:1_2-0)[_**b**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-:1_2-1)["Dot Product"](https://www.mathsisfun.com/algebra/vectors-dot-product.html). _www.mathsisfun.com_. Retrieved 2020-09-06.
2.   ^ [_**a**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Lipschutz2009_3-0)[_**b**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Lipschutz2009_3-1)[_**c**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Lipschutz2009_3-2)[_**d**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Lipschutz2009_3-3)[_**e**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Lipschutz2009_3-4)S. Lipschutz; M. Lipson (2009). _Linear Algebra (Schaum's Outlines)_ (4th ed.). McGraw Hill. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-154352-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-154352-1 "Special:BookSources/978-0-07-154352-1").
3.   ^ [_**a**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Spiegel2009_4-0)[_**b**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Spiegel2009_4-1)[_**c**_](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Spiegel2009_4-2)M.R. Spiegel; S. Lipschutz; D. Spellman (2009). _Vector Analysis (Schaum's Outlines)_ (2nd ed.). McGraw Hill. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-161545-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-161545-7 "Special:BookSources/978-0-07-161545-7").
4.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-5)**A I Borisenko; I E Taparov (1968). _Vector and tensor analysis with applications_. Translated by Richard Silverman. Dover. p.14.
5.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-6)**Arfken, G. B.; Weber, H. J. (2000). _Mathematical Methods for Physicists_ (5th ed.). Boston, MA: [Academic Press](https://en.wikipedia.org/wiki/Academic_Press "Academic Press"). pp.14–15. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-12-059825-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-12-059825-0 "Special:BookSources/978-0-12-059825-0").
6.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-7)**Nykamp, Duane. ["The dot product"](https://mathinsight.org/dot_product). _Math Insight_. Retrieved September 6, 2020.
7.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-8)**Weisstein, Eric W. "Dot Product". From MathWorld--A Wolfram Web Resource. [http://mathworld.wolfram.com/DotProduct.html](http://mathworld.wolfram.com/DotProduct.html)
8.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-BanchoffWermer1983_9-0)**T. Banchoff; J. Wermer (1983). [_Linear Algebra Through Geometry_](https://archive.org/details/linearalgebrathr00banc_0/page/12/mode/2up). Springer Science & Business Media. p.12. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4684-0161-5](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4684-0161-5 "Special:BookSources/978-1-4684-0161-5").
9.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-BedfordFowler2008_10-0)**A. Bedford; Wallace L. Fowler (2008). _Engineering Mechanics: Statics_ (5th ed.). Prentice Hall. p.60. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-612915-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-612915-8 "Special:BookSources/978-0-13-612915-8").
10.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-Riley2010_11-0)**K.F. Riley; M.P. Hobson; S.J. Bence (2010). [_Mathematical methods for physics and engineering_](https://archive.org/details/mathematicalmeth00rile) (3rd ed.). Cambridge University Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-86153-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-86153-3 "Special:BookSources/978-0-521-86153-3").
11.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-12)**M. Mansfield; C. O'Sullivan (2011). _Understanding Physics_ (4th ed.). John Wiley & Sons. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-47-0746370](https://en.wikipedia.org/wiki/Special:BookSources/978-0-47-0746370 "Special:BookSources/978-0-47-0746370").
12.   **[^](https://en.wikipedia.org/wiki/Scalar_product#cite_ref-13)**Berberian, Sterling K. (2014) [1992]. _Linear Algebra_. Dover. p.287. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-78055-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-78055-9 "Special:BookSources/978-0-486-78055-9").

*   ["Inner product"](https://www.encyclopediaofmath.org/index.php?title=Inner_product), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society"), 2001 [1994]
*   [Explanation of dot product including with complex vectors](http://www.mathreference.com/la,dot.html)
*   ["Dot Product"](http://demonstrations.wolfram.com/DotProduct/) by Bruce Torrence, [Wolfram Demonstrations Project](https://en.wikipedia.org/wiki/Wolfram_Demonstrations_Project "Wolfram Demonstrations Project"), 2007.
