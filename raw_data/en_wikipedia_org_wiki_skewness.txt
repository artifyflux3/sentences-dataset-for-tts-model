Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Introduction 2 Relationship of mean and median 3 Definition Toggle Definition subsection 3.1 Fisher's moment coefficient of skewness 3.2 Examples 3.3 Sample skewness 4 Applications 5 Other measures of skewness Toggle Other measures of skewness subsection 5.1 Pearson's first skewness coefficient (mode skewness) 5.2 Pearson's second skewness coefficient (median skewness) 5.3 Quantile-based measures 5.4 Groeneveld and Meeden's coefficient 5.5 L-moments 5.6 Distance skewness 5.7 Medcouple 6 See also 7 References Toggle References subsection 7.1 Citations 7.2 Sources 8 External links Toggle the table of contents Skewness 38 languages العربية Беларуская Català Čeština Deutsch Eesti Español Euskara فارسی Français 한국어 हिन्दी Italiano עברית Latviešu Lietuvių Magyar Македонски Nederlands 日本語 Norsk bokmål Polski Português Русский Shqip Slovenčina Slovenščina Српски / srpski Sunda Suomi Svenska தமிழ் తెలుగు Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Measure of the asymmetry of random variables For the planarity measure in graph theory, see Graph skewness .

Example distribution with positive skewness. These data are from experiments on wheat grass growth.

In probability theory and statistics , skewness is a measure of the asymmetry of the probability distribution of a real -valued random variable about its mean. The skewness value can be positive, zero, negative, or undefined.

For a unimodal distribution (a distribution with a single peak), negative skew commonly indicates that the tail is on the left side of the distribution, and positive skew indicates that the tail is on the right. In cases where one tail is long but the other tail is fat, skewness does not obey a simple rule. For example, a zero value in skewness means that the tails on both sides of the mean balance out overall; this is the case for a symmetric distribution but can also be true for an asymmetric distribution where one tail is long and thin, and the other is short but fat. Thus, the judgement on the symmetry of a given distribution by using only its skewness is risky; the distribution shape must be taken into account.

Introduction [ edit ] Consider the two distributions in the figure just below. Within each graph, the values on the right side of the distribution taper differently from the values on the left side. These tapering sides are called tails , and they provide a visual means to determine which of the two kinds of skewness a distribution has: negative skew : The left tail is longer; the mass of the distribution is concentrated on the right of the figure. The distribution is said to be left-skewed , left-tailed , or skewed to the left , despite the fact that the curve itself appears to be skewed or leaning to the right; left instead refers to the left tail being drawn out and, often, the mean being skewed to the left of a typical center of the data. A left-skewed distribution usually appears as a right-leaning curve.

[ 1 ] positive skew : The right tail is longer; the mass of the distribution is concentrated on the left of the figure. The distribution is said to be right-skewed , right-tailed , or skewed to the right , despite the fact that the curve itself appears to be skewed or leaning to the left; right instead refers to the right tail being drawn out and, often, the mean being skewed to the right of a typical center of the data. A right-skewed distribution usually appears as a left-leaning curve.

[ 1 ] Skewness in a data series may sometimes be observed not only graphically but by simple inspection of the values. For instance, consider the numeric sequence (49, 50, 51), whose values are evenly distributed around a central value of 50. We can transform this sequence into a negatively skewed distribution by adding a value far below the mean, which is probably a negative outlier , e.g. (40, 49, 50, 51). Therefore, the mean of the sequence becomes 47.5, and the median is 49.5. Based on the formula of nonparametric skew , defined as ( μ μ − − ν ν ) / σ σ , {\displaystyle (\mu -\nu )/\sigma ,} the skew is negative. Similarly, we can make the sequence positively skewed by adding a value far above the mean, which is probably a positive outlier, e.g. (49, 50, 51, 60), where the mean is 52.5, and the median is 50.5.

As mentioned earlier, a unimodal distribution with zero value of skewness does not imply that this distribution is symmetric necessarily. However, a symmetric unimodal or multimodal distribution always has zero skewness.

Example of an asymmetric distribution with zero skewness. This figure serves as a counterexample that zero skewness does not imply symmetric distribution necessarily. (Skewness was calculated by Pearson's moment coefficient of skewness.) Relationship of mean and median [ edit ] The skewness is not directly related to the relationship between the mean and median: a distribution with negative skew can have its mean greater than or less than the median, and likewise for positive skew.

[ 2 ] A general relationship of mean and median under differently skewed unimodal distribution.

In the older notion of nonparametric skew , defined as ( μ μ − − ν ν ) / σ σ , {\displaystyle (\mu -\nu )/\sigma ,} where μ μ {\displaystyle \mu } is the mean , ν ν {\displaystyle \nu } is the median , and σ σ {\displaystyle \sigma } is the standard deviation , the skewness is defined in terms of this relationship: positive/right nonparametric skew means the mean is greater than (to the right of) the median, while negative/left nonparametric skew means the mean is less than (to the left of) the median. However, the modern definition of skewness and the traditional nonparametric definition do not always have the same sign: while they agree for some families of distributions, they differ in some of the cases, and conflating them is misleading.

If the distribution is symmetric , then the mean is equal to the median, and the distribution has zero skewness.

[ 3 ] If the distribution is both symmetric and unimodal , then the mean = median = mode . This is the case of a coin toss or the series 1,2,3,4,... Note, however, that the converse is not true in general, i.e. zero skewness (defined below) does not imply that the mean is equal to the median.

A 2005 journal article points out: [ 2 ] Many textbooks teach a rule of thumb stating that the mean is right of the median under right skew, and left of the median under left skew. This rule fails with surprising frequency. It can fail in multimodal distributions , or in distributions where one tail is long but the other is heavy . Most commonly, though, the rule fails in discrete distributions where the areas to the left and right of the median are not equal. Such distributions not only contradict the textbook relationship between mean, median, and skew, they also contradict the textbook interpretation of the median.

Distribution of adult residents across US households For example, in the distribution of adult residents across US households, the skew is to the right. However, since the majority of cases is less than or equal to the mode, which is also the median, the mean sits in the heavier left tail. As a result, the rule of thumb that the mean is right of the median under right skew failed.

[ 2 ] Definition [ edit ] Fisher's moment coefficient of skewness [ edit ] The skewness γ γ 1 {\displaystyle \gamma _{1}} of a random variable X is the third standardized moment μ μ ~ ~ 3 {\displaystyle {\tilde {\mu }}_{3}} , defined as: [ 4 ] [ 5 ] γ γ 1 := μ μ ~ ~ 3 = E ⁡ ⁡ [ ( X − − μ μ σ σ ) 3 ] = μ μ 3 σ σ 3 = E ⁡ ⁡ [ ( X − − μ μ ) 3 ] ( E ⁡ ⁡ [ ( X − − μ μ ) 2 ] ) 3 / 2 = κ κ 3 κ κ 2 3 / 2 {\displaystyle \gamma _{1}:={\tilde {\mu }}_{3}=\operatorname {E} \left[\left({\frac {X-\mu }{\sigma }}\right)^{3}\right]={\frac {\mu _{3}}{\sigma ^{3}}}={\frac {\operatorname {E} \left[(X-\mu )^{3}\right]}{\left(\operatorname {E} \left[(X-\mu )^{2}\right]\right)^{3/2}}}={\frac {\kappa _{3}}{\kappa _{2}^{3/2}}}} where μ is the mean, σ is the standard deviation , E is the expectation operator , μ 3 is the third central moment , and κ t are the t -th cumulants . It is sometimes referred to as Pearson's moment coefficient of skewness , [ 5 ] or simply the moment coefficient of skewness , [ 4 ] but should not be confused with Pearson's other skewness statistics (see below). The last equality expresses skewness in terms of the ratio of the third cumulant κ 3 to the 1.5th power of the second cumulant κ 2 . This is analogous to the definition of kurtosis as the fourth cumulant normalized by the square of the second cumulant. 
The skewness is also sometimes denoted Skew[ X ] .

If σ is finite and μ is finite too, then skewness can be expressed in terms of the non-central moment E[ X 3 ] by expanding the previous formula: μ μ ~ ~ 3 = E ⁡ ⁡ [ ( X − − μ μ σ σ ) 3 ] = E ⁡ ⁡ [ X 3 ] − − 3 μ μ E ⁡ ⁡ [ X 2 ] + 3 μ μ 2 E ⁡ ⁡ [ X ] − − μ μ 3 σ σ 3 = E ⁡ ⁡ [ X 3 ] − − 3 μ μ ( E ⁡ ⁡ [ X 2 ] − − μ μ E ⁡ ⁡ [ X ] ) − − μ μ 3 σ σ 3 = E ⁡ ⁡ [ X 3 ] − − 3 μ μ σ σ 2 − − μ μ 3 σ σ 3 .

{\displaystyle {\begin{aligned}{\tilde {\mu }}_{3}&=\operatorname {E} \left[\left({\frac {X-\mu }{\sigma }}\right)^{3}\right]\\&={\frac {\operatorname {E} [X^{3}]-3\mu \operatorname {E} [X^{2}]+3\mu ^{2}\operatorname {E} [X]-\mu ^{3}}{\sigma ^{3}}}\\&={\frac {\operatorname {E} [X^{3}]-3\mu (\operatorname {E} [X^{2}]-\mu \operatorname {E} [X])-\mu ^{3}}{\sigma ^{3}}}\\&={\frac {\operatorname {E} [X^{3}]-3\mu \sigma ^{2}-\mu ^{3}}{\sigma ^{3}}}.\end{aligned}}} Examples [ edit ] Skewness can be infinite, as when Pr [ X > x ] = x − − 2 for x > 1 , Pr [ X < 1 ] = 0 {\displaystyle \Pr \left[X>x\right]=x^{-2}{\mbox{ for }}x>1,\ \Pr[X<1]=0} where the third cumulants are infinite, or as when Pr [ X < x ] = { 1 2 ( 1 − − x ) − − 3 for x < 0 , 1 2 ( 1 + x ) − − 3 for x > 0.

{\displaystyle \Pr[X<x]={\begin{cases}{\frac {1}{2}}(1-x)^{-3}&{\text{ for }}x<0,\\[2pt]{\frac {1}{2}}(1+x)^{-3}&{\text{ for }}x>0.\end{cases}}} where the third cumulant is undefined.

Examples of distributions with finite skewness include the following.

A normal distribution and any other symmetric distribution with finite third moment has a skewness of 0 A half-normal distribution has a skewness just below 1 An exponential distribution has a skewness of 2 A lognormal distribution can have a skewness of any positive value, depending on its parameters Sample skewness [ edit ] For a sample of n values, two natural estimators of the population skewness are [ 6 ] b 1 = m 3 s 3 = 1 n ∑ ∑ i = 1 n ( x i − − x ¯ ¯ ) 3 [ 1 n − − 1 ∑ ∑ i = 1 n ( x i − − x ¯ ¯ ) 2 ] 3 / 2 {\displaystyle b_{1}={\frac {m_{3}}{s^{3}}}={\frac {{\tfrac {1}{n}}\sum _{i=1}^{n}\left(x_{i}-{\bar {x}}\right)^{3}}{\left[{\tfrac {1}{n-1}}\sum _{i=1}^{n}\left(x_{i}-{\bar {x}}\right)^{2}\right]^{3/2}}}} and g 1 = m 3 m 2 3 / 2 = 1 n ∑ ∑ i = 1 n ( x i − − x ¯ ¯ ) 3 [ 1 n ∑ ∑ i = 1 n ( x i − − x ¯ ¯ ) 2 ] 3 / 2 , {\displaystyle g_{1}={\frac {m_{3}}{m_{2}^{3/2}}}={\frac {{\tfrac {1}{n}}\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{3}}{\left[{\tfrac {1}{n}}\sum _{i=1}^{n}\left(x_{i}-{\bar {x}}\right)^{2}\right]^{3/2}}},} where x ¯ ¯ {\displaystyle {\bar {x}}} is the sample mean , s is the sample standard deviation , m 2 is the (biased) sample second central moment , and m 3 is the (biased) sample third central moment.

[ 6 ] g 1 {\displaystyle g_{1}} is a method of moments estimator.

Another common definition of the sample skewness is [ 6 ] [ 7 ] G 1 = k 3 k 2 3 / 2 = n 2 ( n − − 1 ) ( n − − 2 ) b 1 = n ( n − − 1 ) n − − 2 g 1 , {\displaystyle {\begin{aligned}G_{1}&={\frac {k_{3}}{k_{2}^{3/2}}}={\frac {n^{2}}{(n-1)(n-2)}}\;b_{1}={\frac {\sqrt {n(n-1)}}{n-2}}\;g_{1},\\\end{aligned}}} where k 3 {\displaystyle k_{3}} is the unique symmetric unbiased estimator of the third cumulant and k 2 = s 2 {\displaystyle k_{2}=s^{2}} is the symmetric unbiased estimator of the second cumulant (i.e. the sample variance ). This adjusted Fisher–Pearson standardized moment coefficient G 1 {\displaystyle G_{1}} is the version found in Excel and several statistical packages including Minitab , SAS and SPSS .

[ 7 ] Under the assumption that the underlying random variable X {\displaystyle X} is normally distributed, it can be shown that all three ratios b 1 {\displaystyle b_{1}} , g 1 {\displaystyle g_{1}} and G 1 {\displaystyle G_{1}} are unbiased and consistent estimators of the population skewness γ γ 1 = 0 {\displaystyle \gamma _{1}=0} , with n b 1 → d N ( 0 , 6 ) {\displaystyle {\sqrt {n}}b_{1}\mathrel {\xrightarrow {d} } N(0,6)} , i.e., their distributions converge to a normal distribution with mean 0 and variance 6 ( Fisher , 1930).

[ 6 ] The variance of the sample skewness is thus approximately 6 / n {\displaystyle 6/n} for sufficiently large samples. More precisely, in a random sample of size n from a normal distribution, [ 8 ] [ 9 ] var ⁡ ⁡ ( G 1 ) = 6 n ( n − − 1 ) ( n − − 2 ) ( n + 1 ) ( n + 3 ) .

{\displaystyle \operatorname {var} (G_{1})={\frac {6n(n-1)}{(n-2)(n+1)(n+3)}}.} In normal samples, b 1 {\displaystyle b_{1}} has the smaller variance of the three estimators, with [ 6 ] var ⁡ ⁡ ( b 1 ) < var ⁡ ⁡ ( g 1 ) < var ⁡ ⁡ ( G 1 ) .

{\displaystyle \operatorname {var} (b_{1})<\operatorname {var} (g_{1})<\operatorname {var} (G_{1}).} For non-normal distributions, b 1 {\displaystyle b_{1}} , g 1 {\displaystyle g_{1}} and G 1 {\displaystyle G_{1}} are generally biased estimators of the population skewness γ γ 1 {\displaystyle \gamma _{1}} ; their expected values can even have the opposite sign from the true skewness. For instance, a mixed distribution consisting of very thin Gaussians centred at −99, 0.5, and 2 with weights 0.01, 0.66, and 0.33 has a skewness γ γ 1 {\displaystyle \gamma _{1}} of about −9.77, but in a sample of 3 G 1 {\displaystyle G_{1}} has an expected value of about 0.32, since usually all three samples are in the positive-valued part of the distribution, which is skewed the other way.

Applications [ edit ] Skewness is a descriptive statistic that can be used in conjunction with the histogram and the normal quantile plot to characterize the data or distribution.

Skewness indicates the direction and relative magnitude of a distribution's deviation from the normal distribution.

With pronounced skewness, standard statistical inference procedures such as a confidence interval for a mean will be not only incorrect, in the sense that the true coverage level will differ from the nominal (e.g., 95%) level, but they will also result in unequal error probabilities on each side.

Skewness can be used to obtain approximate probabilities and quantiles of distributions (such as value at risk in finance) via the Cornish–Fisher expansion .

Many models assume normal distribution; i.e., data are symmetric about the mean. The normal distribution has a skewness of zero. But in reality, data points may not be perfectly symmetric. So, an understanding of the skewness of the dataset indicates whether deviations from the mean are going to be positive or negative.

D'Agostino's K-squared test is a goodness-of-fit normality test based on sample skewness and sample kurtosis.

Other measures of skewness [ edit ] Comparison of mean , median and mode of two log-normal distributions with the same medians and different skewnesses.

Other measures of skewness have been used, including simpler calculations suggested by Karl Pearson [ 10 ] (not to be confused with Pearson's moment coefficient of skewness, see above). These other measures are: Pearson's first skewness coefficient (mode skewness) [ edit ] The Pearson mode skewness, [ 11 ] or first skewness coefficient, is defined as ⁠ mean − mode / standard deviation ⁠ .

Pearson's second skewness coefficient (median skewness) [ edit ] The Pearson median skewness, or second skewness coefficient, [ 12 ] [ 13 ] is defined as ⁠ 3 ( mean − median ) / standard deviation ⁠ .

Which is a simple multiple of the nonparametric skew .

Quantile-based measures [ edit ] Bowley's measure of skewness (from 1901), [ 14 ] [ 15 ] also called Yule's coefficient (from 1912) [ 16 ] [ 17 ] is defined as: Q ( 3 / 4 ) + Q ( 1 / 4 ) 2 − − Q ( 1 / 2 ) Q ( 3 / 4 ) − − Q ( 1 / 4 ) 2 = Q ( 3 / 4 ) + Q ( 1 / 4 ) − − 2 Q ( 1 / 2 ) Q ( 3 / 4 ) − − Q ( 1 / 4 ) , {\displaystyle {\frac {{\frac {Q(3/4)+Q(1/4)}{2}}-Q(1/2)}{\frac {Q(3/4)-Q(1/4)}{2}}}={\frac {Q(3/4)+Q(1/4)-2Q(1/2)}{Q(3/4)-Q(1/4)}},} where Q is the quantile function (i.e., the inverse of the cumulative distribution function ). The numerator is difference between the average of the upper and lower quartiles (a measure of location) and the median (another measure of location), while the denominator is the semi-interquartile range ( Q ( 3 / 4 ) − − Q ( 1 / 4 ) ) / 2 {\displaystyle (Q(3/4)}-{Q(1/4))/2} , which for symmetric distributions is equal to the MAD measure of dispersion .

[ citation needed ] Other names for this measure are Galton's measure of skewness, [ 18 ] the Yule–Kendall index [ 19 ] and the quartile skewness, [ 20 ] Similarly, Kelly's measure of skewness is defined as [ 21 ] Q ( 9 / 10 ) + Q ( 1 / 10 ) − − 2 Q ( 1 / 2 ) Q ( 9 / 10 ) − − Q ( 1 / 10 ) .

{\displaystyle {\frac {Q(9/10)+Q(1/10)-2Q(1/2)}{Q(9/10)-Q(1/10)}}.} A more general formulation of a skewness function was described by Groeneveld, R. A. and Meeden, G. (1984): [ 22 ] [ 23 ] [ 24 ] γ γ ( u ) = Q ( u ) + Q ( 1 − − u ) − − 2 Q ( 1 / 2 ) Q ( u ) − − Q ( 1 − − u ) {\displaystyle \gamma (u)={\frac {Q(u)+Q(1-u)-2Q(1/2)}{Q(u)-Q(1-u)}}} The function γ ( u ) satisfies −1 ≤ γ ( u ) ≤ 1 and is well defined without requiring the existence of any moments of the distribution.

[ 22 ] Bowley's measure of skewness is γ ( u ) evaluated at u = 3/4 while Kelly's measure of skewness is γ ( u ) evaluated at u = 9/10 . This definition leads to a corresponding overall measure of skewness [ 23 ] defined as the supremum of this over the range 1/2 ≤ u < 1 . Another measure can be obtained by integrating the numerator and denominator of this expression.

[ 22 ] Quantile-based skewness measures are at first glance easy to interpret, but they often show significantly larger sample variations than moment-based methods. This means that often samples from a symmetric distribution (like the uniform distribution) have a large quantile-based skewness, just by chance.

Groeneveld and Meeden's coefficient [ edit ] Groeneveld and Meeden have suggested, as an alternative measure of skewness, [ 22 ] skew ⁡ ⁡ ( X ) = μ μ − − ν ν E ⁡ ⁡ ( | X − − ν ν | ) , {\displaystyle \operatorname {skew} (X)={\frac {\mu -\nu }{\operatorname {E} (|X-\nu |)}},} where μ is the mean, ν is the median, | ...

| is the absolute value , and E() is the expectation operator. This is closely related in form to Pearson's second skewness coefficient .

L-moments [ edit ] Use of L-moments in place of moments provides a measure of skewness known as the L-skewness.

[ 25 ] Distance skewness [ edit ] A value of skewness equal to zero does not imply that the probability distribution is symmetric. Thus there is a need for another measure of asymmetry that has this property: such a measure was introduced in 2000.

[ 26 ] It is called distance skewness and denoted by dSkew . If X is a random variable taking values in the d -dimensional Euclidean space, X has finite expectation, X ' is an independent identically distributed copy of X , and ‖ ‖ ⋅ ⋅ ‖ ‖ {\displaystyle \|\cdot \|} denotes the norm in the Euclidean space, then a simple measure of asymmetry with respect to location parameter θ is dSkew ⁡ ⁡ ( X ) := 1 − − E ⁡ ⁡ ‖ ‖ X − − X ′ ‖ ‖ E ⁡ ⁡ ‖ ‖ X + X ′ − − 2 θ θ ‖ ‖ if Pr ( X = θ θ ) ≠ ≠ 1 {\displaystyle \operatorname {dSkew} (X):=1-{\frac {\operatorname {E} \|X-X'\|}{\operatorname {E} \|X+X'-2\theta \|}}{\text{ if }}\Pr(X=\theta )\neq 1} and dSkew( X ) := 0 for X = θ (with probability 1). Distance skewness is always between 0 and 1, equals 0 if and only if X is diagonally symmetric with respect to θ ( X and 2 θ − X have the same probability distribution) and equals 1 if and only if X is a constant c ( c ≠ ≠ θ θ {\displaystyle c\neq \theta } ) with probability one.

[ 27 ] Thus there is a simple consistent statistical test of diagonal symmetry based on the sample distance skewness : dSkew n ⁡ ⁡ ( X ) := 1 − − ∑ ∑ i , j ‖ ‖ x i − − x j ‖ ‖ ∑ ∑ i , j ‖ ‖ x i + x j − − 2 θ θ ‖ ‖ .

{\displaystyle \operatorname {dSkew} _{n}(X):=1-{\frac {\sum _{i,j}\|x_{i}-x_{j}\|}{\sum _{i,j}\|x_{i}+x_{j}-2\theta \|}}.} Medcouple [ edit ] The medcouple is a scale-invariant robust measure of skewness, with a breakdown point of 25%.

[ 28 ] It is the median of the values of the kernel function h ( x i , x j ) = ( x i − − x m ) − − ( x m − − x j ) x i − − x j {\displaystyle h(x_{i},x_{j})={\frac {(x_{i}-x_{m})-(x_{m}-x_{j})}{x_{i}-x_{j}}}} taken over all couples ( x i , x j ) {\displaystyle (x_{i},x_{j})} such that x i ≥ ≥ x m ≥ ≥ x j {\displaystyle x_{i}\geq x_{m}\geq x_{j}} , where x m {\displaystyle x_{m}} is the median of the sample { x 1 , x 2 , … … , x n } {\displaystyle \{x_{1},x_{2},\ldots ,x_{n}\}} . It can be seen as the median of all possible quantile skewness measures.

See also [ edit ] Mathematics portal Bragg peak Coskewness Kurtosis Shape parameters Skew normal distribution Skewness risk References [ edit ] Citations [ edit ] ^ a b Illowsky, Barbara; Dean, Susan (27 March 2020).

"2.6 Skewness and the Mean, Median, and Mode – Statistics" .

OpenStax . Retrieved 21 December 2022 .

^ a b c von Hippel, Paul T. (2005).

"Mean, Median, and Skew: Correcting a Textbook Rule" .

Journal of Statistics Education .

13 (2). Archived from the original on 20 February 2016.

^ "1.3.5.11. Measures of Skewness and Kurtosis" . NIST . Retrieved 18 March 2012 .

^ a b "Measures of Shape: Skewness and Kurtosis" , 2008–2016 by Stan Brown, Oak Road Systems ^ a b Pearson's moment coefficient of skewness , FXSolver.com ^ a b c d e Joanes, D. N.; Gill, C. A. (1998). "Comparing measures of sample skewness and kurtosis".

Journal of the Royal Statistical Society, Series D .

47 (1): 183– 189.

doi : 10.1111/1467-9884.00122 .

^ a b Doane, David P., and Lori E. Seward.

"Measuring skewness: a forgotten statistic." Journal of Statistics Education 19.2 (2011): 1-18. (Page 7) ^ Duncan Cramer (1997) Fundamental Statistics for Social Research. Routledge.

ISBN 9780415172042 (p 85) ^ Kendall, M.G.; Stuart, A. (1969) The Advanced Theory of Statistics, Volume 1: Distribution Theory, 3rd Edition , Griffin.

ISBN 0-85264-141-9 (Ex 12.9) ^ "Archived copy" (PDF) . Archived from the original (PDF) on 5 July 2010 . Retrieved 9 April 2010 .

{{ cite web }} :  CS1 maint: archived copy as title ( link ) ^ Weisstein, Eric W.

"Pearson Mode Skewness" .

MathWorld .

^ Weisstein, Eric W.

"Pearson's skewness coefficients" .

MathWorld .

^ Doane, David P.; Seward, Lori E. (2011).

"Measuring Skewness: A Forgotten Statistic?" (PDF) .

Journal of Statistics Education .

19 (2): 1– 18.

doi : 10.1080/10691898.2011.11889611 .

^ Bowley, A. L. (1901). Elements of Statistics, P.S. King & Son, Laondon.  Or in a later edition: BOWLEY, AL. "Elements of Statistics, 4th Edn (New York, Charles Scribner)."(1920).

^ Kenney JF and Keeping ES (1962) Mathematics of Statistics, Pt. 1, 3rd ed.

, Van Nostrand, (page 102).

^ Yule, George Udny. An introduction to the theory of statistics. C. Griffin, limited, 1912.

^ Groeneveld, Richard A (1991). "An influence function approach to describing the skewness of a distribution".

The American Statistician .

45 (2): 97– 102.

doi : 10.2307/2684367 .

JSTOR 2684367 .

^ Johnson, NL, Kotz, S & Balakrishnan, N (1994) p. 3 and p. 40 ^ Wilks DS (1995) Statistical Methods in the Atmospheric Sciences , p 27. Academic Press.

ISBN 0-12-751965-3 ^ Weisstein, Eric W.

"Skewness" .

mathworld.wolfram.com . Retrieved 21 November 2019 .

^ A.W.L. Pubudu Thilan.

"Applied Statistics I: Chapter 5: Measures of skewness" (PDF) .

University of Ruhuna . p. 21.

^ a b c d Groeneveld, R.A.; Meeden, G. (1984). "Measuring Skewness and Kurtosis".

The Statistician .

33 (4): 391– 399.

doi : 10.2307/2987742 .

JSTOR 2987742 .

^ a b MacGillivray (1992) ^ Hinkley DV (1975) "On power transformations to symmetry", Biometrika , 62, 101–111 ^ Hosking, J.R.M. (1992). "Moments or L moments? An example comparing two measures of distributional shape".

The American Statistician .

46 (3): 186– 189.

doi : 10.2307/2685210 .

JSTOR 2685210 .

^ Szekely, G.J. (2000).  "Pre-limit and post-limit theorems for statistics", In: Statistics for the 21st Century (eds.

C. R. Rao and G. J. Szekely), Dekker, New York, pp. 411–422.

^ Szekely, G. J. and Mori, T. F. (2001) "A characteristic measure of asymmetry and its application for testing diagonal symmetry", Communications in Statistics – Theory and Methods 30/8&9, 1633–1639.

^ G. Brys; M. Hubert ; A. Struyf (November 2004). "A Robust Measure of Skewness".

Journal of Computational and Graphical Statistics .

13 (4): 996– 1017.

doi : 10.1198/106186004X12632 .

S2CID 120919149 .

Sources [ edit ] Johnson, NL; Kotz, S; Balakrishnan, N (1994).

Continuous Univariate Distributions . Vol. 1 (2 ed.). Wiley.

ISBN 0-471-58495-9 .

MacGillivray, HL (1992). "Shape properties of the g- and h- and Johnson families".

Communications in Statistics – Theory and Methods .

21 (5): 1244– 1250.

doi : 10.1080/03610929208830842 .

Premaratne, G., Bera, A. K. (2001). Adjusting the Tests for Skewness and Kurtosis for Distributional Misspecifications. Working Paper Number 01-0116, University of Illinois. Forthcoming in Comm in Statistics, Simulation and Computation. 2016 1–15 Premaratne, G., Bera, A. K. (2000). Modeling Asymmetry and Excess Kurtosis in Stock Return Data. Office of Research Working Paper Number 00-0123, University of Illinois.

Skewness Measures for the Weibull Distribution External links [ edit ] Wikiversity has learning resources about Skewness Wikimedia Commons has media related to Skewness (statistics) .

"Asymmetry coefficient" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] An Asymmetry Coefficient for Multivariate Distributions by Michel Petitjean On More Robust Estimation of Skewness and Kurtosis Comparison of skew estimators by Kim and White.

Closed-skew Distributions — Simulation, Inversion and Parameter Estimation v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject v t e Theory of probability distributions probability mass function (pmf) probability density function (pdf) cumulative distribution function (cdf) quantile function raw moment central moment mean variance standard deviation skewness kurtosis L-moment moment-generating function (mgf) characteristic function probability-generating function (pgf) cumulant combinant NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐pp8m7
Cached time: 20250811235736
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.600 seconds
Real time usage: 0.798 seconds
Preprocessor visited node count: 4762/1000000
Revision size: 28368/2097152 bytes
Post‐expand include size: 198656/2097152 bytes
Template argument size: 5988/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 102249/5000000 bytes
Lua time usage: 0.302/10.000 seconds
Lua memory usage: 8482986/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  561.072      1 -total
 32.45%  182.091      1 Template:Reflist
 20.11%  112.804      1 Template:Statistics
 19.80%  111.095      1 Template:Navbox_with_collapsible_groups
 13.46%   75.516      5 Template:Cite_web
 10.30%   57.804      1 Template:Short_description
  8.32%   46.681     12 Template:Navbox
  6.87%   38.536      8 Template:Cite_journal
  6.66%   37.384      2 Template:Pagetype
  5.51%   30.923      2 Template:Sister_project Saved in parser cache with key enwiki:pcache:28212:|#|:idhash:canonical and timestamp 20250811235736 and revision id 1286215659. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Skewness&oldid=1286215659 " Categories : Moments (mathematics) Statistical deviation and dispersion Hidden categories: CS1 maint: archived copy as title Articles with short description Short description matches Wikidata Use American English from January 2019 All Wikipedia articles written in American English Use dmy dates from October 2020 All articles with unsourced statements Articles with unsourced statements from May 2024 Commons category link is on Wikidata This page was last edited on 18 April 2025, at 13:28 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Skewness 38 languages Add topic

