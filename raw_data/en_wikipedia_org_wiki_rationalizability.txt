Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition 2 Iterated elimination of strictly dominated strategies (IESDS) 3 Iterated elimination by mixed strategy 4 Constraints on beliefs 5 Rationalizability and Nash equilibria 6 See also 7 Footnotes 8 References Toggle the table of contents Rationalizable strategy 5 languages Deutsch فارسی Français 日本語 Русский Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Rationalizability ) Solution concept in game theory Rationalizability Solution concept in game theory Relationship Subset of Dominant strategy equilibrium Superset of Nash equilibrium Significance Proposed by Douglas Bernheim and David Pearce Example Matching pennies Rationalizability is a solution concept in game theory . It is the most permissive possible solution concept that still requires both players to be at least somewhat rational and know the other players are also somewhat rational, i.e. that they do not play dominated strategies . A strategy is rationalizable if there exists some possible set of beliefs both players could have about each other's actions, that would still result in the strategy being played.

Rationalizability is a broader concept than a Nash equilibrium . Both require players to respond optimally to some belief about their opponents' actions, but Nash equilibrium requires these beliefs to be correct, while rationalizability does not. Rationalizability was first defined, independently, by Bernheim (1984) and Pearce (1984).

Definition [ edit ] Starting with a normal-form game , the rationalizable set of actions can be computed as follows: Start with the full action set for each player.

Remove all dominated strategies , i.e. strategies that "never make sense" (are never a best reply to any belief about the opponents' actions). The motivation for this step is no rational player would ever choose such actions.

Remove all actions which are never a best reply to any belief about the opponents' remaining actions—this second step is justified because each player knows that the other players are rational.

Continue the process until no further actions can be eliminated.

In a game with finitely many actions, this process always terminates and leaves a non-empty set of actions for each player. These are the rationalizable actions.

Iterated elimination of strictly dominated strategies (IESDS) [ edit ] The iterated elimination (or deletion, or removal) of dominated strategies (also denominated as IESDS, or IDSDS, or IRSDS) is one common technique for solving games that involves iteratively removing dominated strategies. In the first step, at most one dominated strategy is removed from the strategy space of each of the players since no rational player would ever play these strategies. This results in a new, smaller game. Some strategies—that were not dominated before—may be dominated in the smaller game. The first step is repeated, creating a new even smaller game, and so on. The process stops when no dominated strategy is found for any player. This process is valid since it is assumed that rationality among players is common knowledge , that is, each player knows that the rest of the players are rational, and each player knows that the rest of the players know that he knows that the rest of the players are rational, and so on ad infinitum (see Aumann, 1976).

There are two versions of this process. One version involves only eliminating strictly dominated strategies. If, after completing this process, there is only one strategy for each player remaining, that strategy set is the unique Nash equilibrium.

[ 1 ] Moreover, iterated elimination of strictly dominated strategies is path independent. That is, if at any point in the process there are multiple strictly dominated strategies, then it doesn't matter for the end result which strategies we remove first.

[ 2 ] Strict Dominance Deletion Step-by-Step Example: C is strictly dominated by A for Player 1. Therefore, Player 1 will never play strategy C. Player 2 knows this. (see IESDS Figure 1) Of the remaining strategies (see IESDS Figure 2), Z is strictly dominated by Y and X for Player 2. Therefore, Player 2 will never play strategy Z. Player 1 knows this.

Of the remaining strategies (see IESDS Figure 3), B is strictly dominated by A for Player 1. Therefore, Player 1 will never play B. Player 2 knows this.

Of the remaining strategies (see IESDS Figure 4), Y is strictly dominated by X for Player 2. Therefore, Player 2 will never play Y. Player 1 knows this.

Only one rationalizable strategy is left {A,X} which results in a payoff of (10,4). This is the single Nash Equilibrium for this game.

Another version involves eliminating both strictly and weakly dominated strategies. If, at the end of the process, there is a single strategy for each player, this strategy set is also a Nash equilibrium . However, unlike the first process, elimination of weakly dominated strategies may eliminate some Nash equilibria. As a result, the Nash equilibrium found by eliminating weakly dominated strategies may not be the only Nash equilibrium. (In some games, if we remove weakly dominated strategies in a different order, we may end up with a different Nash equilibrium.) Weak Dominance Deletion Step-by-Step Example: O is strictly dominated by N for Player 1. Therefore, Player 1 will never play strategy O. Player 2 knows this. (see IESDS Figure 5) U is weakly dominated by T for Player 2. If Player 2 chooses T, then the final equilibrium is (N,T) O is strictly dominated by N for Player 1. Therefore, Player 1 will never play strategy O. Player 2 knows this. (see IESDS Figure 6) T is weakly dominated by U for Player 2. If Player 2 chooses U, then the final equilibrium is (N,U) In any case, if by iterated elimination of dominated strategies there is only one strategy left for each player, the game is called a dominance-solvable game.

Iterated elimination by mixed strategy [ edit ] There are instances when there is no pure strategy that dominates another pure strategy, but a mixture of two or more pure strategies can dominate another strategy. This is called Strictly Dominant Mixed Strategies. Some authors allow for elimination of strategies dominated by a mixed strategy in this way.

Example 1: In this scenario, for player 1, there is no pure strategy that dominates another pure strategy. Let's define the probability of player 1 playing up as p, and let p = ⁠ 1 / 2 ⁠ . We can set a mixed strategy where player 1 plays up and down with probabilities ( ⁠ 1 / 2 ⁠ , ⁠ 1 / 2 ⁠ ). When player 2 plays left, then the payoff for player 1 playing the mixed strategy of up and down is 1, when player 2 plays right, the payoff for player 1 playing the mixed strategy is 0.5. Thus regardless of whether player 2 chooses left or right, player 1 gets more from playing this mixed strategy between up and down than if the player were to play the middle strategy. In this case, we should eliminate the middle strategy for player 1 since it's been dominated by the mixed strategy of playing up and down with probability ( ⁠ 1 / 2 ⁠ , ⁠ 1 / 2 ⁠ ).

Example 2: We can demonstrate the same methods on a more complex game and solve for the rational strategies. In this scenario, the blue coloring represents the dominating numbers in the particular strategy.

Step-by-step solving: For Player 2, X is dominated by the mixed strategy ⁠ 1 / 2 ⁠ Y and ⁠ 1 / 2 ⁠ Z.

The expected payoff for playing strategy ⁠ 1 / 2 ⁠ Y + ⁠ 1 / 2 ⁠ Z must be greater than the expected payoff for playing pure strategy X, assigning ⁠ 1 / 2 ⁠ and ⁠ 1 / 2 ⁠ as tester values. The argument for mixed strategy dominance can be made if there is at least one mixed strategy that allows for dominance.

Testing with ⁠ 1 / 2 ⁠ and ⁠ 1 / 2 ⁠ gets the following: Expected average payoff of ⁠ 1 / 2 ⁠ Strategy Y: ⁠ 1 / 2 ⁠ (4+0+4) = 4 Expected average payoff of ⁠ 1 / 2 ⁠ Strategy Z: ⁠ 1 / 2 ⁠ (0+5+5) = 5 Expected average payoff of pure strategy X: (1+1+3) = 5 Set up the inequality to determine whether the mixed strategy will dominate the pure strategy based on expected payoffs.

u ⁠ 1 / 2 ⁠ Y + u ⁠ 1 / 2 ⁠ Z ⩼ u X 4 + 5 > 5 Mixed strategy ⁠ 1 / 2 ⁠ Y and ⁠ 1 / 2 ⁠ Z will dominate pure strategy X for Player 2, and thus X can be eliminated from the rationalizable strategies for P2.

For Player 1, U is dominated by the pure strategy D.

For player 2, Y is dominated by the pure strategy Z.

This leaves M dominating D for Player 1.

The only rationalizable strategy for Players 1 and 2 is then (M,Z) or (3,5).

Constraints on beliefs [ edit ] Coordination game A B a 1, 1 0, 0 b 0, 0 1, 1 Consider a simple coordination game (the payoff matrix is to the right). The row player can play a if he can reasonably believe that the column player could play A , since a is a best response to A . He can reasonably believe that the column player can play A if it is reasonable for the column player to believe that the row player could play a . She can believe that he will play a if it is reasonable for her to believe that he could play a , etc.

Prisoner's Dilemma C D c 2, 2 0, 3 d 3, 0 1, 1 This provides an infinite chain of consistent beliefs that result in the players playing ( a , A ). This makes ( a , A ) a rationalizable pair of actions. A similar process can be repeated for ( b , B ).

As an example where not all strategies are rationalizable, consider a prisoner's dilemma pictured to the left. Row player would never play c , since c is not a best response to any strategy by the column player. For this reason, c is not rationalizable.

L R t 3, - 0, - m 0, - 3, - b 1, - 1, - Conversely, for two-player games, the set of all rationalizable strategies can be found by iterated elimination of strictly dominated strategies. For this method to hold however, one also needs to consider strict domination by mixed strategies . Consider the game on the right with payoffs of the column player omitted for simplicity. Notice that "b" is not strictly dominated by either "t" or "m" in the pure strategy sense, but it is still dominated by a strategy that would mix "t" and "m" with probability of each equal to 1/2. This is due to the fact that given any belief about the action of the column player, the mixed strategy will always yield higher expected payoff.

[ 3 ] This implies that "b" is not rationalizable.

Moreover, "b" is not a best response to either "L" or "R" or any mix of the two. This is because an action that is not rationalizable can never be a best response to any opponent's strategy (pure or mixed). This would imply another version of the previous method of finding rationalizable strategies as those that survive the iterated elimination of strategies that are never a best response (in pure or mixed sense).

In games with more than two players, however, there may be strategies that are not strictly dominated, but which can never be the best response. By the iterated elimination of all such strategies one can find the rationalizable strategies for a multiplayer game.

Rationalizability and Nash equilibria [ edit ] It can be easily proved that a Nash equilibrium is a rationalizable equilibrium; however, the converse is not true. Some rationalizable equilibria are not Nash equilibria. This makes the rationalizability concept a generalization of Nash equilibrium concept.

Matching pennies H T h 1, -1 -1, 1 t -1, 1 1, -1 As an example, consider the game matching pennies pictured to the right. In this game the only Nash equilibrium is row playing h and t with equal probability and column playing H and T with equal probability. However, all pure strategies in this game are rationalizable.

Consider the following reasoning: row can play h if it is reasonable for her to believe that column will play H . Column can play H if its reasonable for him to believe that row will play t . Row can play t if it is reasonable for her to believe that column will play T . Column can play T if it is reasonable for him to believe that row will play h (beginning the cycle again). This provides an infinite set of consistent beliefs that results in row playing h . A similar argument can be given for row playing t , and for column playing either H or T .

See also [ edit ] Self-confirming equilibrium Strategic dominance Footnotes [ edit ] ^ Joel., Watson,. Strategy : an introduction to game theory (Second ed.). New York.

ISBN 9780393929348 .

^ Gilboa, I.; Kalai, E.; Zemel, E. (1990).

"On the order of eliminating dominated strategies" (PDF) .

Operations Research Letters .

9 (2): 85– 89.

doi : 10.1016/0167-6377(90)90046-8 .

^ Gibbons, Robert (1992).

A Primer in Game Theory . pp.

32– 33.

References [ edit ] Bernheim, D. (1984) Rationalizable Strategic Behavior.

Econometrica 52: 1007–1028.

Fudenberg, Drew and Jean Tirole (1993) Game Theory.

Cambridge: MIT Press.

Pearce, D. (1984) Rationalizable Strategic Behavior and the Problem of Perfection.

Econometrica 52: 1029–1050.

Ratcliff, J. (1992–1997) lecture notes on game theory, §2.2: "Iterated Dominance and Rationalizability" v t e Game theory Glossary Game theorists Games Traditional game theory Definitions Asynchrony Bayesian regret Best response Bounded rationality Cheap talk Coalition Complete contract Complete information Complete mixing Confrontation analysis Conjectural variation Contingent cooperator Coopetition Cooperative game theory Dynamic inconsistency Escalation of commitment Farsightedness Game semantics Hierarchy of beliefs Imperfect information Incomplete information Information set Move by nature Mutual knowledge Non-cooperative game theory Non-credible threat Outcome Perfect information Perfect recall Ply Preference Rationality Sequential game Simultaneous action selection Spite Strategic complements Strategic dominance Strategic form Strategic interaction Strategic move Strategy Subgame Succinct game Topological game Tragedy of the commons Uncorrelated asymmetry Equilibrium concepts Backward induction Bayes correlated equilibrium Bayesian efficiency Bayesian game Bayesian Nash equilibrium Berge equilibrium Bertrand–Edgeworth model Coalition-proof Nash equilibrium Core Correlated equilibrium Cursed equilibrium Edgeworth price cycle Epsilon-equilibrium Gibbs equilibrium Incomplete contracts Inequity aversion Individual rationality Iterated elimination of dominated strategies Markov perfect equilibrium Mertens-stable equilibrium Nash equilibrium Open-loop model Pareto efficiency Payoff dominance Perfect Bayesian equilibrium Price of anarchy Program equilibrium Proper equilibrium Quantal response equilibrium Quasi-perfect equilibrium Rational agent Rationalizability Rationalizable strategy Satisfaction equilibrium Self-confirming equilibrium Sequential equilibrium Shapley value Strong Nash equilibrium Subgame perfect equilibrium Trembling hand equilibrium Strategies Appeasement Bid shading Cheap talk Collusion Commitment device De-escalation Deterrence Escalation Fictitious play Focal point Grim trigger Hobbesian trap Markov strategy Max-dominated strategy Mixed strategy Pure strategy Tit for tat Win–stay, lose–switch Games All-pay auction Battle of the sexes Nash bargaining game Bertrand competition Blotto game Centipede game Coordination game Cournot competition Deadlock Dictator game Trust game Diner's dilemma Dollar auction El Farol Bar problem Electronic mail game Gift-exchange game Guess 2/3 of the average Keynesian beauty contest Kuhn poker Lewis signaling game Matching pennies Obligationes Optional prisoner's dilemma Pirate game Prisoner's dilemma Public goods game Rendezvous problem Rock paper scissors Stackelberg competition Stag hunt Traveler's dilemma Ultimatum game Volunteer's dilemma War of attrition Theorems Arrow's impossibility theorem Aumann's agreement theorem Brouwer fixed-point theorem Competitive altruism Folk theorem Gibbard–Satterthwaite theorem Gibbs lemma Glicksberg's theorem Kakutani fixed-point theorem Kuhn's theorem One-shot deviation principle Prim–Read theory Rational ignorance Rational irrationality Sperner's lemma Zermelo's theorem Subfields Algorithmic game theory Behavioral game theory Behavioral strategy Compositional game theory Contract theory Drama theory Graphical game theory Heresthetic Mean-field game theory Negotiation theory Quantum game theory Social software Key people Albert W. Tucker Alvin E. Roth Amos Tversky Antoine Augustin Cournot Ariel Rubinstein David Gale David K. Levine David M. Kreps Donald B. Gillies Drew Fudenberg Eric Maskin Harold W. Kuhn Herbert Simon Herbert Scarf Hervé Moulin Jean Tirole Jean-François Mertens Jennifer Tour Chayes Ken Binmore Kenneth Arrow Leonid Hurwicz Lloyd Shapley Martin Shubik Melvin Dresher Merrill M. Flood Olga Bondareva Oskar Morgenstern Paul Milgrom Peyton Young Reinhard Selten Robert Aumann Robert Axelrod Robert B. Wilson Roger Myerson Samuel Bowles Suzanne Scotchmer Thomas Schelling William Vickrey Combinatorial game theory Core concepts Combinatorial explosion Determinacy Disjunctive sum First-player and second-player win Game complexity Game tree Impartial game Misère Partisan game Solved game Sprague–Grundy theorem Strategy-stealing argument Zugzwang Games Chess Chomp Clobber Cram Domineering Hackenbush Nim Notakto Subtract a square Sylver coinage Toads and Frogs Mathematical tools Mex Nimber On Numbers and Games Star Surreal number Winning Ways for Your Mathematical Plays Search algorithms Alpha–beta pruning Expectiminimax Minimax Monte Carlo tree search Negamax Paranoid algorithm Principal variation search Key people Claude Shannon John Conway John von Neumann Evolutionary game theory Core concepts Bishop–Cannings theorem Evolution and the Theory of Games Evolutionarily stable set Evolutionarily stable state Evolutionarily stable strategy Replicator equation Risk dominance Stochastically stable equilibrium Weak evolutionarily stable strategy Games Chicken Stag hunt Applications Cultural group selection Fisher's principle Mobbing Terminal investment hypothesis Key people John Maynard Smith Robert Axelrod Mechanism design Core concepts Algorithmic mechanism design Bayesian-optimal mechanism Incentive compatibility Market design Monotonicity Participation constraint Revelation principle Strategyproofness Vickrey–Clarke–Groves mechanism Theorems Myerson–Satterthwaite theorem Revenue equivalence Applications Digital goods auction Knapsack auction Truthful cake-cutting Other topics Bertrand paradox Chainstore paradox Computational complexity of games Helly metric Multi-agent system PPAD-complete Mathematics portal Commons WikiProject Category Retrieved from " https://en.wikipedia.org/w/index.php?title=Rationalizable_strategy&oldid=1293302374 " Category : Game theory Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 31 May 2025, at 23:29 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Rationalizable strategy 5 languages Add topic

