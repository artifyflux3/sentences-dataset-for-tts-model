Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Bose–Einstein distribution 2 History 3 Derivation Toggle Derivation subsection 3.1 Derivation from the microcanonical ensemble 3.2 Derivation from the grand canonical ensemble 3.3 Derivation in the canonical approach 4 Interdisciplinary applications 5 See also 6 Notes 7 References Toggle the table of contents Bose–Einstein statistics 49 languages العربية অসমীয়া বাংলা Български Bosanski Català Čeština Deutsch Eesti Español Esperanto Euskara فارسی Français Gaeilge Galego ગુજરાતી 한국어 Հայերեն हिन्दी Hrvatski Bahasa Indonesia Italiano עברית ಕನ್ನಡ ქართული Қазақша Magyar Nederlands 日本語 Norsk bokmål Norsk nynorsk ଓଡ଼ିଆ Oʻzbekcha / ўзбекча Polski Português Română Русский Simple English Slovenčina Slovenščina Srpskohrvatski / српскохрватски Suomi Svenska தமிழ் Татарча / tatarça Українська Tiếng Việt 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Bose–Einstein distribution ) Description of the behaviour of bosons Statistical mechanics Thermodynamics Kinetic theory Particle statistics Spin–statistics theorem Indistinguishable particles Maxwell–Boltzmann Bose–Einstein Fermi–Dirac Parastatistics Anyonic statistics Braid statistics Thermodynamic ensembles NVE Microcanonical NVT Canonical µVT Grand canonical NPH Isoenthalpic–isobaric NPT Isothermal–isobaric Models Debye Einstein Ising Potts Potentials Internal energy Enthalpy Helmholtz free energy Gibbs free energy Grand potential / Landau free energy Scientists Maxwell Boltzmann Helmholtz Bose Gibbs Einstein Dirac Ehrenfest von Neumann Tolman Debye Fermi Synge Ising Landau v t e In quantum statistics , Bose–Einstein statistics ( B–E statistics ) describes one of two possible ways in which a collection of non-interacting identical particles may occupy a set of available discrete energy states at thermodynamic equilibrium . The aggregation of particles in the same state, which is a characteristic of particles obeying Bose–Einstein statistics, accounts for the cohesive streaming of laser light and the frictionless creeping of superfluid helium . The theory of this behaviour was developed (1924–25) by Satyendra Nath Bose , who recognized that a collection of identical and indistinguishable particles could be distributed in this way. The idea was later adopted and extended by Albert Einstein in collaboration with Bose.

Bose–Einstein statistics apply only to particles that do not follow the Pauli exclusion principle restrictions. Particles that follow Bose-Einstein statistics are called bosons , which have integer values of spin . In contrast, particles that follow Fermi-Dirac statistics are called fermions and have half-integer spins.

Equilibrium thermal distributions for particles with integer spin (bosons), half integer spin (fermions), and classical (spinless) particles. Average occupancy ⟨ ⟨ n ⟩ ⟩ {\displaystyle \langle n\rangle } is shown versus energy ϵ ϵ {\displaystyle \epsilon } relative to the system chemical potential μ μ {\displaystyle \mu } , where T {\displaystyle T} is the system temperature, and k B {\displaystyle k_{\text{B}}} is the Boltzmann constant.

Bose–Einstein distribution [ edit ] At low temperatures, bosons behave differently from fermions (which obey the Fermi–Dirac statistics ) in a way that an unlimited number of them can "condense" into the same energy state. This apparently unusual property also gives rise to the special state of matter – the Bose–Einstein condensate . Fermi–Dirac and Bose–Einstein statistics apply when quantum effects are important and the particles are " indistinguishable ". Quantum effects appear if the concentration of particles satisfies N V ≥ ≥ n q , {\displaystyle {\frac {N}{V}}\geq n_{\text{q}},} where N is the number of particles, V is the volume, and n q is the quantum concentration , for which the interparticle distance is equal to the thermal de Broglie wavelength , so that the wavefunctions of the particles are barely overlapping.

Fermi–Dirac statistics applies to fermions (particles that obey the Pauli exclusion principle ), and Bose–Einstein statistics applies to bosons . As the quantum concentration depends on temperature, most systems at high temperatures obey the classical (Maxwell–Boltzmann) limit, unless they also have a very high density, as for a white dwarf . Both Fermi–Dirac and Bose–Einstein become Maxwell–Boltzmann statistics at high temperature or at low concentration.

Bose–Einstein statistics was introduced for photons in 1924 by Bose and generalized to atoms by Einstein in 1924–25.

The expected number of particles in an energy state i for Bose–Einstein statistics is: n ¯ ¯ i = g i e ( ε ε i − − μ μ ) / k B T − − 1 {\displaystyle {\bar {n}}_{i}={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}-1}}} with ε i > μ and where n i is the occupation number (the number of particles) in state i , g i {\displaystyle g_{i}} is the degeneracy of energy level i , ε i is the energy of the i th state, μ is the chemical potential (zero for a photon gas ), k B is the Boltzmann constant , and T is the absolute temperature .

The variance of this distribution V ( n ) {\displaystyle V(n)} is calculated directly from the expression above for the average number.

[ 1 ] V ( n ) = k T ∂ ∂ ∂ ∂ μ μ n ¯ ¯ i = ⟨ ⟨ n ⟩ ⟩ ( 1 + ⟨ ⟨ n ⟩ ⟩ ) = n ¯ ¯ + n ¯ ¯ 2 {\displaystyle V(n)=kT{\frac {\partial }{\partial \mu }}{\bar {n}}_{i}=\langle n\rangle (1+\langle n\rangle )={\bar {n}}+{\bar {n}}^{2}} For comparison, the average number of fermions with energy ε ε i {\displaystyle \varepsilon _{i}} given by Fermi–Dirac particle-energy distribution has a similar form: n ¯ ¯ i ( ε ε i ) = g i e ( ε ε i − − μ μ ) / k B T + 1 .

{\displaystyle {\bar {n}}_{i}(\varepsilon _{i})={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}+1}}.} As mentioned above, both the Bose–Einstein distribution and the Fermi–Dirac distribution approaches the Maxwell–Boltzmann distribution in the limit of high temperature and low particle density, without the need for any ad hoc assumptions: In the limit of low particle density, n ¯ ¯ i = g i e ( ε ε i − − μ μ ) / k B T ± ± 1 ≪ ≪ 1 {\displaystyle {\bar {n}}_{i}={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}\pm 1}}\ll 1} , therefore e ( ε ε i − − μ μ ) / k B T ± ± 1 ≫ ≫ 1 {\displaystyle e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}\pm 1\gg 1} or equivalently e ( ε ε i − − μ μ ) / k B T ≫ ≫ 1 {\displaystyle e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}\gg 1} . In that case, n ¯ ¯ i ≈ ≈ g i e ( ε ε i − − μ μ ) / k B T = 1 Z e − − ( ε ε i − − μ μ ) / k B T {\displaystyle {\bar {n}}_{i}\approx {\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}}}={\frac {1}{Z}}e^{-(\varepsilon _{i}-\mu )/k_{\text{B}}T}} , which is the result from Maxwell–Boltzmann statistics.

In the limit of high temperature, the particles are distributed over a large range of energy values, therefore the occupancy on each state (especially the high energy ones with ε ε i − − μ μ ≫ ≫ k B T {\displaystyle \varepsilon _{i}-\mu \gg k_{\text{B}}T} ) is again very small, n ¯ ¯ i = g i e ( ε ε i − − μ μ ) / k B T ± ± 1 ≪ ≪ 1 {\displaystyle {\bar {n}}_{i}={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}\pm 1}}\ll 1} . This again reduces to Maxwell–Boltzmann statistics.

In addition to reducing to the Maxwell–Boltzmann distribution in the limit of high T {\displaystyle T} and low density, Bose–Einstein statistics also reduces to Rayleigh–Jeans law distribution for low energy states with ε ε i − − μ μ ≪ ≪ k B T {\displaystyle \varepsilon _{i}-\mu \ll k_{\text{B}}T} , namely n ¯ ¯ i = g i e ( ε ε i − − μ μ ) / k B T − − 1 ≈ ≈ g i ( ε ε i − − μ μ ) / k B T = g i k B T ε ε i − − μ μ .

{\displaystyle {\begin{aligned}{\bar {n}}_{i}&={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}-1}}\\&\approx {\frac {g_{i}}{(\varepsilon _{i}-\mu )/k_{\text{B}}T}}={\frac {g_{i}k_{\text{B}}T}{\varepsilon _{i}-\mu }}.\end{aligned}}} History [ edit ] In 1900, Max Planck derived the Planck law to explain blackbody radiation . For this purpose, he introduced the concept of quanta of energy.

Władysław Natanson in 1911 concluded that Planck's law requires indistinguishability of "units of energy", although he did not frame this in terms of Einstein's light quanta.

[ 2 ] [ 3 ] While presenting a lecture at the University of Dhaka (in what was then British India and is now Bangladesh ) on the theory of radiation and the ultraviolet catastrophe , Satyendra Nath Bose intended to show his students that the contemporary theory was inadequate, because it predicted results not in accordance with experimental results. During this lecture, Bose committed an error in applying the theory, which unexpectedly gave a prediction that agreed with the experiment. The error was a simple mistake – similar to arguing that flipping two fair coins will produce two heads one-third of the time – that would appear obviously wrong to anyone with a basic understanding of statistics (remarkably, this error resembled the famous blunder by Jean le Rond d'Alembert known from his Croix ou Pile article [ 4 ] [ 5 ] ). However, the results it predicted agreed with experiment, and Bose realized it might not be a mistake after all. For the first time, he took the position that the Maxwell–Boltzmann distribution would not be true for all microscopic particles at all scales. Thus, he studied the probability of finding particles in various states in phase space, where each state is a little patch having phase volume of h 3 , and the position and momentum of the particles are not kept particularly separate but are considered as one variable.

[ citation needed ] Bose adapted this lecture into a short article called "Planck's law and the hypothesis of light quanta" [ 6 ] [ 7 ] and submitted it to the Philosophical Magazine . However, the referee's report was negative, and the paper was rejected. Undaunted, he sent the manuscript to Albert Einstein requesting publication in the Zeitschrift für Physik . Einstein immediately agreed, personally translated the article from English into German (Bose had earlier translated Einstein's article on the general theory of relativity from German to English), and saw to it that it was published. Bose's theory achieved respect when Einstein sent his own paper in support of Bose's to Zeitschrift für Physik , asking that they be published together. The paper came out in 1924.

[ 8 ] The reason Bose produced accurate results was that since photons are indistinguishable from each other, one cannot treat any two photons having equal quantum numbers (e.g., polarization and momentum vector) as being two distinct identifiable photons. Bose originally had a factor of 2 for the possible spin states, but Einstein changed it to polarization.

[ 9 ] By analogy, if in an alternate universe coins were to behave like photons and other bosons, the probability of producing two heads would indeed be one-third, and so is the probability of getting a head and a tail which equals one-half for the conventional (classical, distinguishable) coins. Bose's "error" leads to what is now called Bose–Einstein statistics.

Bose and Einstein extended the idea to atoms and this led to the prediction of the existence of phenomena which became known as Bose–Einstein condensate, a dense collection of bosons (which are particles with integer spin, named after Bose), which was demonstrated to exist by experiment in 1995.

Derivation [ edit ] Derivation from the microcanonical ensemble [ edit ] In the microcanonical ensemble , one considers a system with fixed energy, volume, and number of particles. We take a system composed of N = ∑ ∑ i n i {\textstyle N=\sum _{i}n_{i}} identical bosons, n i {\displaystyle n_{i}} of which have energy ε ε i {\displaystyle \varepsilon _{i}} and are distributed over g i {\displaystyle g_{i}} levels or states with the same energy ε ε i {\displaystyle \varepsilon _{i}} , i.e.

g i {\displaystyle g_{i}} is the degeneracy associated with energy ε ε i {\displaystyle \varepsilon _{i}} . The total energy of the system is E = ∑ ∑ i n i ε ε i {\textstyle E=\sum _{i}n_{i}\varepsilon _{i}} . Calculation of the number of arrangements of n i {\displaystyle n_{i}} particles distributed among g i {\displaystyle g_{i}} states is a problem of combinatorics . Since particles are indistinguishable in the quantum mechanical context here, the number of ways for arranging n i {\displaystyle n_{i}} particles in g i {\displaystyle g_{i}} boxes (for the i {\displaystyle i} th energy level), where each box is capable of containing an infinite number of bosons (because for bosons the Pauli exclusion principle does not apply), would be (see image): The image represents one possible distribution of bosonic particles in different boxes. The box partitions (green) can be moved around to change the size of the boxes and as a result of the number of bosons each box can contain.

w i , BE = ( n i + g i − − 1 ) !

n i !

( g i − − 1 ) !

= C n i n i + g i − − 1 , {\displaystyle w_{i,{\text{BE}}}={\frac {(n_{i}+g_{i}-1)!}{n_{i}!(g_{i}-1)!}}=C_{n_{i}}^{n_{i}+g_{i}-1},} where C k m {\displaystyle C_{k}^{m}} is the k -combination of a set with m elements (Note also that w i , BE {\displaystyle w_{i,{\text{BE}}}} represents the absolute non-normalized probability of an energy state with n i {\displaystyle n_{i}} bosons and a degeneracy of g i {\displaystyle g_{i}} , it is not the same as the w i {\displaystyle w_{i}} associated with the Gibbs formulation of entropy). The total number of arrangements in an ensemble of bosons is simply the product of the binomial coefficients C n i n i + g i − − 1 {\displaystyle C_{n_{i}}^{n_{i}+g_{i}-1}} above over all the energy levels, i.e.

W BE = ∏ ∏ i w i , BE = ∏ ∏ i ( n i + g i − − 1 ) !

( g i − − 1 ) !

n i !

, {\displaystyle W_{\text{BE}}=\prod _{i}w_{i,{\text{BE}}}=\prod _{i}{\frac {(n_{i}+g_{i}-1)!}{(g_{i}-1)!n_{i}!}},} which for very large n i {\displaystyle n_{i}} and g i {\displaystyle g_{i}} can be simplified using Stirling's approximation to W BE = ∏ ∏ i ( n i + g i − − 1 e ) n i + g i − − 1 ( g i − − 1 e ) g i − − 1 ( n i e ) n i .

{\displaystyle W_{\text{BE}}=\prod _{i}{\frac {({\frac {n_{i}+g_{i}-1}{e}})^{n_{i}+g_{i}-1}}{({\frac {g_{i}-1}{e}})^{g_{i}-1}({\frac {n_{i}}{e}})^{n_{i}}}}.} The entropy of the system can then be expressed as S BE = k B ln W BE = k B ∑ ∑ i [ ( n i + g i − − 1 ) ( ln ( n i + g i − − 1 ) − − 1 ) − − ( g i − − 1 ) ( ln ( g i − − 1 ) − − 1 ) − − n i ( ln n i − − 1 ) ] .

{\displaystyle S_{\text{BE}}=k_{B}{\text{ln}}W_{\text{BE}}=k_{B}\sum _{i}[(n_{i}+g_{i}-1)({\text{ln}}(n_{i}+g_{i}-1)-1)-(g_{i}-1)({\text{ln}}(g_{i}-1)-1)-n_{i}({\text{ln}}n_{i}-1)].} The three constraints we can impose on the system can be expressed as ∑ ∑ i δ δ n i = 0 {\displaystyle \sum _{i}\delta n_{i}=0} (conservation of N), ∑ ∑ i ϵ ϵ i δ δ n i = 0 {\displaystyle \sum _{i}\epsilon _{i}\delta n_{i}=0} (conservation of E), and δ δ S BE = 0 {\displaystyle \delta S_{\text{BE}}=0} ( second law of thermodynamics for a system at equilibrium).

This final constraint can be expanded to be in terms of n i {\displaystyle n_{i}} : δ δ S BE = ∂ ∂ ∂ ∂ n i S BE δ δ n i = k B ∑ ∑ i [ ln ( n i + g i − − 1 ) − − ln n i ] δ δ n i = 0.

{\displaystyle \delta S_{\text{BE}}={\frac {\partial }{\partial n_{i}}}S_{\text{BE}}\delta n_{i}=k_{B}\sum _{i}[{\text{ln}}(n_{i}+g_{i}-1)-{\text{ln}}n_{i}]\delta n_{i}=0.} Now we can write ∑ ∑ i [ ln ( n i + g i − − 1 ) − − ln n i ] δ δ n i + C ∑ ∑ i δ δ n i − − β β ∑ ∑ i ϵ ϵ i δ δ n i = 0 , {\displaystyle \sum _{i}[{\text{ln}}(n_{i}+g_{i}-1)-{\text{ln}}n_{i}]\delta n_{i}+C\sum _{i}\delta n_{i}-\beta \sum _{i}\epsilon _{i}\delta n_{i}=0,} for which to be true, because of Fermat's theorem (stationary points) it must be the case that for any i ln ( n i + g i − − 1 ) − − ln n i + C − − β β ϵ ϵ i = 0.

{\displaystyle {\text{ln}}(n_{i}+g_{i}-1)-{\text{ln}}n_{i}+C-\beta \epsilon _{i}=0.} By solving for n i {\displaystyle n_{i}} and simplifying we obtain n i = g i − − 1 α α e β β ϵ ϵ i − − 1 , {\displaystyle n_{i}={\frac {g_{i}-1}{\alpha e^{\beta \epsilon _{i}}-1}},} which for sufficiently large g i {\displaystyle g_{i}} reduces to n i = g i α α e β β ϵ ϵ i − − 1 , {\displaystyle n_{i}={\frac {g_{i}}{\alpha e^{\beta \epsilon _{i}}-1}},} which is the form of the Bose-Einstein distribution. Unfortunately, to go further, we need to be in the grand canonical ensemble so that we can specify an exact value for the chemical potential of the system and thereby calculate α α {\displaystyle \alpha } and β β {\displaystyle \beta } . Note that this form holds even for a system of interacting bosons.

Derivation from the grand canonical ensemble [ edit ] The Bose–Einstein distribution, which applies only to a quantum system of non-interacting bosons, is naturally derived from the grand canonical ensemble without any approximations.

[ 10 ] In this ensemble, the system is able to exchange energy and exchange particles with a reservoir (temperature T and chemical potential μ fixed by the reservoir).

Due to the non-interacting quality, each available single-particle level (with energy level ϵ ) forms a separate thermodynamic system in contact with the reservoir. That is, the number of particles within the overall system that occupy a given single particle state form a sub-ensemble that is also grand canonical ensemble; hence, it may be analysed through the construction of a grand partition function .

Every single-particle state is of a fixed energy, ε ε {\displaystyle \varepsilon } . As the sub-ensemble associated with a single-particle state varies by the number of particles only, it is clear that the total energy of the sub-ensemble is also directly proportional to the number of particles in the single-particle state; where N {\displaystyle N} is the number of particles, the total energy of the sub-ensemble will then be N ε ε {\displaystyle N\varepsilon } . Beginning with the standard expression for a grand partition function and replacing E {\displaystyle E} with N ε ε {\displaystyle N\varepsilon } , the grand partition function takes the form Z = ∑ ∑ N exp ⁡ ⁡ ( ( N μ μ − − N ε ε ) / k B T ) = ∑ ∑ N exp ⁡ ⁡ ( N ( μ μ − − ε ε ) / k B T ) {\displaystyle {\mathcal {Z}}=\sum _{N}\exp((N\mu -N\varepsilon )/k_{\text{B}}T)=\sum _{N}\exp(N(\mu -\varepsilon )/k_{\text{B}}T)} This formula applies to fermionic systems as well as bosonic systems. Fermi–Dirac statistics arises when considering the effect of the Pauli exclusion principle : whilst the number of fermions occupying the same single-particle state can only be either 1 or 0, the number of bosons occupying a single particle state may be any integer. Thus, the grand partition function for bosons can be considered a geometric series and may be evaluated as such: Z = ∑ ∑ N = 0 ∞ ∞ exp ⁡ ⁡ ( N ( μ μ − − ε ε ) / k B T ) = ∑ ∑ N = 0 ∞ ∞ [ exp ⁡ ⁡ ( ( μ μ − − ε ε ) / k B T ) ] N = 1 1 − − exp ⁡ ⁡ ( ( μ μ − − ε ε ) / k B T ) .

{\displaystyle {\begin{aligned}{\mathcal {Z}}&=\sum _{N=0}^{\infty }\exp(N(\mu -\varepsilon )/k_{\text{B}}T)=\sum _{N=0}^{\infty }[\exp((\mu -\varepsilon )/k_{\text{B}}T)]^{N}\\&={\frac {1}{1-\exp((\mu -\varepsilon )/k_{\text{B}}T)}}.\end{aligned}}} Note that the geometric series is convergent only if e ( μ μ − − ε ε ) / k B T < 1 {\displaystyle e^{(\mu -\varepsilon )/k_{\text{B}}T}<1} , including the case where ε ε = 0 {\displaystyle \varepsilon =0} . This implies that the chemical potential for the Bose gas must be negative, i.e., μ μ < 0 {\displaystyle \mu <0} , whereas the Fermi gas is allowed to take both positive and negative values for the chemical potential.

[ 11 ] The average particle number for that single-particle substate is given by ⟨ ⟨ N ⟩ ⟩ = k B T 1 Z ( ∂ ∂ Z ∂ ∂ μ μ ) V , T = 1 exp ⁡ ⁡ ( ( ε ε − − μ μ ) / k B T ) − − 1 {\displaystyle \langle N\rangle =k_{\text{B}}T{\frac {1}{\mathcal {Z}}}\left({\frac {\partial {\mathcal {Z}}}{\partial \mu }}\right)_{V,T}={\frac {1}{\exp((\varepsilon -\mu )/k_{\text{B}}T)-1}}} This result applies for each single-particle level and thus forms the Bose–Einstein distribution for the entire state of the system.

[ 12 ] [ 13 ] The variance in particle number, σ σ N 2 = ⟨ ⟨ N 2 ⟩ ⟩ − − ⟨ ⟨ N ⟩ ⟩ 2 {\textstyle \sigma _{N}^{2}=\langle N^{2}\rangle -\langle N\rangle ^{2}} , is: σ σ N 2 = k B T ( d ⟨ ⟨ N ⟩ ⟩ d μ μ ) V , T = exp ⁡ ⁡ ( ( ε ε − − μ μ ) / k B T ) ( exp ⁡ ⁡ ( ( ε ε − − μ μ ) / k B T ) − − 1 ) 2 = ⟨ ⟨ N ⟩ ⟩ ( 1 + ⟨ ⟨ N ⟩ ⟩ ) .

{\displaystyle \sigma _{N}^{2}=k_{\text{B}}T\left({\frac {d\langle N\rangle }{d\mu }}\right)_{V,T}={\frac {\exp((\varepsilon -\mu )/k_{\text{B}}T)}{(\exp((\varepsilon -\mu )/k_{\text{B}}T)-1)^{2}}}=\langle N\rangle (1+\langle N\rangle ).} As a result, for highly occupied states the standard deviation of the particle number of an energy level is very large, slightly larger than the particle number itself: σ σ N ≈ ≈ ⟨ ⟨ N ⟩ ⟩ {\displaystyle \sigma _{N}\approx \langle N\rangle } . This large uncertainty is due to the fact that the probability distribution for the number of bosons in a given energy level is a geometric distribution ; somewhat counterintuitively, the most probable value for N is always 0. (In contrast, classical particles have instead a Poisson distribution in particle number for a given state, with a much smaller uncertainty of σ σ N , c l a s s i c a l = ⟨ ⟨ N ⟩ ⟩ {\textstyle \sigma _{N,{\rm {classical}}}={\sqrt {\langle N\rangle }}} , and with the most-probable N value being near ⟨ ⟨ N ⟩ ⟩ {\displaystyle \langle N\rangle } .) Derivation in the canonical approach [ edit ] It is also possible to derive approximate Bose–Einstein statistics in the canonical ensemble . These derivations are lengthy and only yield the above results in the asymptotic limit of a large number of particles. The reason is that the total number of bosons is fixed in the canonical ensemble. The Bose–Einstein distribution in this case can be derived as in most texts by maximization, but the mathematically best derivation is by the Darwin–Fowler method of mean values as emphasized by Dingle.

[ 14 ] See also Müller-Kirsten.

[ 15 ] The fluctuations of the ground state in the condensed region are however markedly different in the canonical and grand-canonical ensembles.

[ 16 ] Derivation Suppose we have a number of energy levels, labeled by index i {\displaystyle i} , each level having energy ε ε i {\displaystyle \varepsilon _{i}} and containing a total of n i {\displaystyle n_{i}} particles.  Suppose each level contains g i {\displaystyle g_{i}} distinct sublevels, all of which have the same energy, and which are distinguishable. For example, two particles may have different momenta, in which case they are distinguishable from each other, yet they can still have the same energy. 
The value of g i {\displaystyle g_{i}} associated with level i {\displaystyle i} is called the "degeneracy" of that energy level. Any number of bosons can occupy the same sublevel.

Let w ( n , g ) {\displaystyle w(n,g)} be the number of ways of distributing n {\displaystyle n} particles among the g {\displaystyle g} sublevels of an energy level. There is only one way of distributing n {\displaystyle n} particles with one sublevel, therefore w ( n , 1 ) = 1 {\displaystyle w(n,1)=1} . It is easy to see that there are ( n + 1 ) {\displaystyle (n+1)} ways of distributing n {\displaystyle n} particles in two sublevels which we will write as: w ( n , 2 ) = ( n + 1 ) !

n !

1 !

.

{\displaystyle w(n,2)={\frac {(n+1)!}{n!1!}}.} With a little thought (see Notes below) it can be seen that the number of ways of distributing n {\displaystyle n} particles in three sublevels is w ( n , 3 ) = w ( n , 2 ) + w ( n − − 1 , 2 ) + ⋯ ⋯ + w ( 1 , 2 ) + w ( 0 , 2 ) {\displaystyle w(n,3)=w(n,2)+w(n-1,2)+\cdots +w(1,2)+w(0,2)} so that w ( n , 3 ) = ∑ ∑ k = 0 n w ( n − − k , 2 ) = ∑ ∑ k = 0 n ( n − − k + 1 ) !

( n − − k ) !

1 !

= ( n + 2 ) !

n !

2 !

{\displaystyle w(n,3)=\sum _{k=0}^{n}w(n-k,2)=\sum _{k=0}^{n}{\frac {(n-k+1)!}{(n-k)!1!}}={\frac {(n+2)!}{n!2!}}} where we have used the following theorem involving binomial coefficients : ∑ ∑ k = 0 n ( k + a ) !

k !

a !

= ( n + a + 1 ) !

n !

( a + 1 ) !

.

{\displaystyle \sum _{k=0}^{n}{\frac {(k+a)!}{k!a!}}={\frac {(n+a+1)!}{n!(a+1)!}}.} Continuing this process, we can see that w ( n , g ) {\displaystyle w(n,g)} is just a binomial coefficient
(See Notes below) w ( n , g ) = ( n + g − − 1 ) !

n !

( g − − 1 ) !

.

{\displaystyle w(n,g)={\frac {(n+g-1)!}{n!(g-1)!}}.} For example, the population numbers for two particles in three sublevels are 200, 110, 101, 020, 011, or 002 for a total of six which equals 4!/(2!2!). The number of ways that a set of occupation numbers n i {\displaystyle n_{i}} can be realized is the product of the ways that each individual energy level can be populated: W = ∏ ∏ i w ( n i , g i ) = ∏ ∏ i ( n i + g i − − 1 ) !

n i !

( g i − − 1 ) !

≈ ≈ ∏ ∏ i ( n i + g i ) !

n i !

( g i ) !

{\displaystyle W=\prod _{i}w(n_{i},g_{i})=\prod _{i}{\frac {(n_{i}+g_{i}-1)!}{n_{i}!(g_{i}-1)!}}\approx \prod _{i}{\frac {(n_{i}+g_{i})!}{n_{i}!(g_{i})!}}} where the approximation assumes that n i ≫ ≫ 1 {\displaystyle n_{i}\gg 1} .

Following the same procedure used in deriving the Maxwell–Boltzmann statistics , we wish to find the set of n i {\displaystyle n_{i}} for which W is maximised, subject to the constraint that there be a fixed total number of particles, and a fixed total energy. The maxima of W {\displaystyle W} and ln ⁡ ⁡ ( W ) {\displaystyle \ln(W)} occur at the same value of n i {\displaystyle n_{i}} and, since it is easier to accomplish mathematically, we will maximise the latter function instead. We constrain our solution using Lagrange multipliers forming the function: f ( n i ) = ln ⁡ ⁡ ( W ) + α α ( N − − ∑ ∑ n i ) + β β ( E − − ∑ ∑ n i ε ε i ) {\displaystyle f(n_{i})=\ln(W)+\alpha (N-\sum n_{i})+\beta (E-\sum n_{i}\varepsilon _{i})} Using the n i ≫ ≫ 1 {\displaystyle n_{i}\gg 1} approximation and using Stirling's approximation for the factorials ( x !

≈ ≈ x x e − − x 2 π π x ) {\displaystyle \left(x!\approx x^{x}\,e^{-x}\,{\sqrt {2\pi x}}\right)} gives f ( n i ) = ∑ ∑ i ( n i + g i ) ln ⁡ ⁡ ( n i + g i ) − − n i ln ⁡ ⁡ ( n i ) + α α ( N − − ∑ ∑ n i ) + β β ( E − − ∑ ∑ n i ε ε i ) + K , {\displaystyle f(n_{i})=\sum _{i}(n_{i}+g_{i})\ln(n_{i}+g_{i})-n_{i}\ln(n_{i})+\alpha \left(N-\sum n_{i}\right)+\beta \left(E-\sum n_{i}\varepsilon _{i}\right)+K,} where K is the sum of a number of terms which are not functions of the n i {\displaystyle n_{i}} . Taking the derivative with respect to n i {\displaystyle n_{i}} , and setting the result to zero and solving for n i {\displaystyle n_{i}} , yields the Bose–Einstein population numbers: n i = g i e α α + β β ε ε i − − 1 .

{\displaystyle n_{i}={\frac {g_{i}}{e^{\alpha +\beta \varepsilon _{i}}-1}}.} By a process similar to that outlined in the Maxwell–Boltzmann statistics article, it can be seen that: d ln ⁡ ⁡ W = α α d N + β β d E {\displaystyle d\ln W=\alpha \,dN+\beta \,dE} which, using Boltzmann's famous relationship S = k B ln ⁡ ⁡ W {\displaystyle S=k_{\text{B}}\,\ln W} becomes a statement of the second law of thermodynamics at constant volume, and it follows that β β = 1 k B T {\displaystyle \beta ={\frac {1}{k_{\text{B}}T}}} and α α = − − μ μ k B T {\displaystyle \alpha =-{\frac {\mu }{k_{\text{B}}T}}} where S is the entropy , μ μ {\displaystyle \mu } is the chemical potential , k B is the Boltzmann constant and T is the temperature , so that finally: n i = g i e ( ε ε i − − μ μ ) / k B T − − 1 .

{\displaystyle n_{i}={\frac {g_{i}}{e^{(\varepsilon _{i}-\mu )/k_{\text{B}}T}-1}}.} Note that the above formula is sometimes written: n i = g i e ε ε i / k B T / z − − 1 , {\displaystyle n_{i}={\frac {g_{i}}{e^{\varepsilon _{i}/k_{\text{B}}T}/z-1}},} where z = exp ⁡ ⁡ ( μ μ / k B T ) {\displaystyle z=\exp(\mu /k_{\text{B}}T)} is the absolute activity , as noted by McQuarrie.

[ 17 ] Also note that when the particle numbers are not conserved, removing the conservation of particle numbers constraint is equivalent to setting α α {\displaystyle \alpha } and therefore the chemical potential μ μ {\displaystyle \mu } to zero. This will be the case for photons and massive particles in mutual equilibrium and the resulting distribution will be the Planck distribution .

Notes A much simpler way to think of Bose–Einstein distribution function is to consider that n particles are denoted by identical balls and g shells are marked by g-1 line partitions.

It is clear that the permutations of these n balls and g − 1 partitions will give different ways of arranging bosons in different energy levels. Say, for 3 (= n ) particles and 3 (= g ) shells, therefore ( g − 1) = 2 , the arrangement might be |●●|● , or ||●●● , or |●|●● , etc. Hence the number of distinct permutations of n + ( g − 1) objects which have n identical items and ( g − 1) identical items will be: ( g − − 1 + n ) !

( g − − 1 ) !

n !

{\displaystyle {\frac {(g-1+n)!}{(g-1)!n!}}} See the image for a visual representation of one such distribution of n particles in g boxes that can be represented as g − 1 partitions.

The image represents one possible distribution of bosonic particles in different boxes. The box partitions (green) can be moved around to change the size of the boxes and as a result of the number of bosons each box can contain.

OR The purpose of these notes is to clarify some aspects of the derivation of the Bose–Einstein distribution for beginners. The enumeration of cases (or ways) in the Bose–Einstein distribution can be recast as follows. Consider a game of dice throwing in which there are n {\displaystyle n} dice, with each die taking values in the set { 1 , … … , g } {\displaystyle \{1,\dots ,g\}} , for g ≥ ≥ 1 {\displaystyle g\geq 1} . The constraints of the game are that the value of a die i {\displaystyle i} , denoted by m i {\displaystyle m_{i}} , has to be greater than or equal to the value of die ( i − − 1 ) {\displaystyle (i-1)} , denoted by m i − − 1 {\displaystyle m_{i-1}} , in the previous throw, i.e., m i ≥ ≥ m i − − 1 {\displaystyle m_{i}\geq m_{i-1}} .  Thus a valid sequence of die throws can be described by an n -tuple ( m 1 , m 2 , … … , m n ) {\displaystyle (m_{1},m_{2},\dots ,m_{n})} , such that m i ≥ ≥ m i − − 1 {\displaystyle m_{i}\geq m_{i-1}} . Let S ( n , g ) {\displaystyle S(n,g)} denote the set of these valid n -tuples: S ( n , g ) = { ( m 1 , m 2 , … … , m n ) | m i ≥ ≥ m i − − 1 , m i ∈ ∈ { 1 , … … , g } , ∀ ∀ i = 1 , … … , n } .

{\displaystyle S(n,g)=\left\{(m_{1},m_{2},\dots ,m_{n})\,{\Big |}\,m_{i}\geq m_{i-1},m_{i}\in \left\{1,\ldots ,g\right\},\forall i=1,\dots ,n\right\}.} 1 Then the quantity w ( n , g ) {\displaystyle w(n,g)} ( defined above as the number of ways to distribute n {\displaystyle n} particles among the g {\displaystyle g} sublevels of an energy level) is the cardinality of S ( n , g ) {\displaystyle S(n,g)} , i.e., the number of elements (or valid n -tuples) in S ( n , g ) {\displaystyle S(n,g)} . Thus the problem of finding an expression for w ( n , g ) {\displaystyle w(n,g)} becomes the problem of counting the elements in S ( n , g ) {\displaystyle S(n,g)} .

Example n = 4, g = 3: S ( 4 , 3 ) = { ( 1111 ) , ( 1112 ) , ( 1113 ) ⏟ ⏟ ( a ) , ( 1122 ) , ( 1123 ) , ( 1133 ) ⏟ ⏟ ( b ) , ( 1222 ) , ( 1223 ) , ( 1233 ) , ( 1333 ) ⏟ ⏟ ( c ) , ( 2222 ) , ( 2223 ) , ( 2233 ) , ( 2333 ) , ( 3333 ) ⏟ ⏟ ( d ) } {\displaystyle S(4,3)=\left\{\underbrace {(1111),(1112),(1113)} _{(a)},\underbrace {(1122),(1123),(1133)} _{(b)},\underbrace {(1222),(1223),(1233),(1333)} _{(c)},\underbrace {(2222),(2223),(2233),(2333),(3333)} _{(d)}\right\}} w ( 4 , 3 ) = 15 {\displaystyle w(4,3)=15} (there are 15 {\displaystyle 15} elements in S ( 4 , 3 ) {\displaystyle S(4,3)} ) Subset ( a ) {\displaystyle (a)} is obtained by fixing all indices m i {\displaystyle m_{i}} to 1 {\displaystyle 1} , except for the last index, m n {\displaystyle m_{n}} , which is incremented from 1 {\displaystyle 1} to g = 3 {\displaystyle g=3} . Subset ( b ) {\displaystyle (b)} is obtained by fixing m 1 = m 2 = 1 {\displaystyle m_{1}=m_{2}=1} , and incrementing m 3 {\displaystyle m_{3}} from 2 {\displaystyle 2} to g = 3 {\displaystyle g=3} . Due to the constraint m i ≥ ≥ m i − − 1 {\displaystyle m_{i}\geq m_{i-1}} on the indices in S ( n , g ) {\displaystyle S(n,g)} , the index m 4 {\displaystyle m_{4}} must automatically take values in { 2 , 3 } {\displaystyle \left\{2,3\right\}} . The construction of subsets ( c ) {\displaystyle (c)} and ( d ) {\displaystyle (d)} follows in the same manner.

Each element of S ( 4 , 3 ) {\displaystyle S(4,3)} can be thought of as a multiset of cardinality n = 4 {\displaystyle n=4} ; the elements of such multiset are taken from the set { 1 , 2 , 3 } {\displaystyle \left\{1,2,3\right\}} of cardinality g = 3 {\displaystyle g=3} , and the number of such multisets is the multiset coefficient ⟨ 3 4 ⟩ = ( 3 + 4 − − 1 3 − − 1 ) = ( 3 + 4 − − 1 4 ) = 6 !

4 !

2 !

= 15 {\displaystyle \left\langle {\begin{matrix}3\\4\end{matrix}}\right\rangle ={3+4-1 \choose 3-1}={3+4-1 \choose 4}={\frac {6!}{4!2!}}=15} More generally, each element of S ( n , g ) {\displaystyle S(n,g)} is a multiset of cardinality n {\displaystyle n} (number of dice) with elements taken from the set { 1 , … … , g } {\displaystyle \left\{1,\dots ,g\right\}} of cardinality g {\displaystyle g} (number of possible values of each die), and the number of such multisets, i.e., w ( n , g ) {\displaystyle w(n,g)} is the multiset coefficient w ( n , g ) = ⟨ g n ⟩ = ( g + n − − 1 g − − 1 ) = ( g + n − − 1 n ) = ( g + n − − 1 ) !

n !

( g − − 1 ) !

{\displaystyle w(n,g)=\left\langle {\begin{matrix}g\\n\end{matrix}}\right\rangle ={g+n-1 \choose g-1}={g+n-1 \choose n}={\frac {(g+n-1)!}{n!(g-1)!}}} 2 which is exactly the same as the formula for w ( n , g ) {\displaystyle w(n,g)} , as derived above with the aid of a theorem involving binomial coefficients, namely ∑ ∑ k = 0 n ( k + a ) !

k !

a !

= ( n + a + 1 ) !

n !

( a + 1 ) !

.

{\displaystyle \sum _{k=0}^{n}{\frac {(k+a)!}{k!a!}}={\frac {(n+a+1)!}{n!(a+1)!}}.} 3 To understand the decomposition w ( n , g ) = ∑ ∑ k = 0 n w ( n − − k , g − − 1 ) = w ( n , g − − 1 ) + w ( n − − 1 , g − − 1 ) + ⋯ ⋯ + w ( 1 , g − − 1 ) + w ( 0 , g − − 1 ) {\displaystyle w(n,g)=\sum _{k=0}^{n}w(n-k,g-1)=w(n,g-1)+w(n-1,g-1)+\dots +w(1,g-1)+w(0,g-1)} 4 or for example, n = 4 {\displaystyle n=4} and g = 3 {\displaystyle g=3} w ( 4 , 3 ) = w ( 4 , 2 ) + w ( 3 , 2 ) + w ( 2 , 2 ) + w ( 1 , 2 ) + w ( 0 , 2 ) , {\displaystyle w(4,3)=w(4,2)+w(3,2)+w(2,2)+w(1,2)+w(0,2),} let us rearrange the elements of S ( 4 , 3 ) {\displaystyle S(4,3)} as follows S ( 4 , 3 ) = { ( 1111 ) , ( 1112 ) , ( 1122 ) , ( 1222 ) , ( 2222 ) ⏟ ⏟ ( α α ) , ( 111 3 = ) , ( 112 3 = ) , ( 122 3 = ) , ( 222 3 = ) ⏟ ⏟ ( β β ) , ( 11 33 == ) , ( 12 33 == ) , ( 22 33 == ) ⏟ ⏟ ( γ γ ) , ( 1 333 === ) , ( 2 333 === ) ⏟ ⏟ ( δ δ ) ( 3333 ==== ) ⏟ ⏟ ( ω ω ) } .

{\displaystyle S(4,3)=\left\{\underbrace {(1111),(1112),(1122),(1222),(2222)} _{(\alpha )},\underbrace {(111{\color {Red}{\underset {=}{3}}}),(112{\color {Red}{\underset {=}{3}}}),(122{\color {Red}{\underset {=}{3}}}),(222{\color {Red}{\underset {=}{3}}})} _{(\beta )},\underbrace {(11{\color {Red}{\underset {==}{33}}}),(12{\color {Red}{\underset {==}{33}}}),(22{\color {Red}{\underset {==}{33}}})} _{(\gamma )},\underbrace {(1{\color {Red}{\underset {===}{333}}}),(2{\color {Red}{\underset {===}{333}}})} _{(\delta )}\underbrace {({\color {Red}{\underset {====}{3333}}})} _{(\omega )}\right\}.} Clearly, the subset ( α α ) {\displaystyle (\alpha )} of S ( 4 , 3 ) {\displaystyle S(4,3)} is the same as the set S ( 4 , 2 ) = { ( 1111 ) , ( 1112 ) , ( 1122 ) , ( 1222 ) , ( 2222 ) } .

{\displaystyle S(4,2)=\left\{(1111),(1112),(1122),(1222),(2222)\right\}.} By deleting the index m 4 = 3 {\displaystyle m_{4}=3} (shown in red with double underline ) in the subset ( β β ) {\displaystyle (\beta )} of S ( 4 , 3 ) {\displaystyle S(4,3)} , one obtains the set S ( 3 , 2 ) = { ( 111 ) , ( 112 ) , ( 122 ) , ( 222 ) } .

{\displaystyle S(3,2)=\left\{(111),(112),(122),(222)\right\}.} In other words, there is a one-to-one correspondence between the subset ( β β ) {\displaystyle (\beta )} of S ( 4 , 3 ) {\displaystyle S(4,3)} and the set S ( 3 , 2 ) {\displaystyle S(3,2)} . We write ( β β ) ⟷ ⟷ S ( 3 , 2 ) .

{\displaystyle (\beta )\longleftrightarrow S(3,2).} Similarly, it is easy to see that ( γ γ ) ⟷ ⟷ S ( 2 , 2 ) = { ( 11 ) , ( 12 ) , ( 22 ) } {\displaystyle (\gamma )\longleftrightarrow S(2,2)=\left\{(11),(12),(22)\right\}} ( δ δ ) ⟷ ⟷ S ( 1 , 2 ) = { ( 1 ) , ( 2 ) } {\displaystyle (\delta )\longleftrightarrow S(1,2)=\left\{(1),(2)\right\}} ( ω ω ) ⟷ ⟷ S ( 0 , 2 ) = { } = ∅ ∅ .

{\displaystyle (\omega )\longleftrightarrow S(0,2)=\{\}=\varnothing .} Thus we can write S ( 4 , 3 ) = ⋃ ⋃ k = 0 4 S ( 4 − − k , 2 ) {\displaystyle S(4,3)=\bigcup _{k=0}^{4}S(4-k,2)} or more generally, S ( n , g ) = ⋃ ⋃ k = 0 n S ( n − − k , g − − 1 ) ; {\displaystyle S(n,g)=\bigcup _{k=0}^{n}S(n-k,g-1);} 5 and since the sets S ( i , g − − 1 ) , for i = 0 , … … , n {\displaystyle S(i,g-1),{\text{ for }}i=0,\dots ,n} are non-intersecting, we thus have w ( n , g ) = ∑ ∑ k = 0 n w ( n − − k , g − − 1 ) , {\displaystyle w(n,g)=\sum _{k=0}^{n}w(n-k,g-1),} 6 with the convention that w ( 0 , g ) = 1 , ∀ ∀ g , and w ( n , 0 ) = 1 , ∀ ∀ n .

{\displaystyle w(0,g)=1\ ,\forall g,{\text{ and }}w(n,0)=1\ ,\forall n.} 7 Continuing the process, we arrive at the following formula w ( n , g ) = ∑ ∑ k 1 = 0 n ∑ ∑ k 2 = 0 n − − k 1 w ( n − − k 1 − − k 2 , g − − 2 ) = ∑ ∑ k 1 = 0 n ∑ ∑ k 2 = 0 n − − k 1 ⋯ ⋯ ∑ ∑ k g = 0 n − − ∑ ∑ j = 1 g − − 1 k j w ( n − − ∑ ∑ i = 1 g k i , 0 ) .

{\displaystyle w(n,g)=\sum _{k_{1}=0}^{n}\sum _{k_{2}=0}^{n-k_{1}}w(n-k_{1}-k_{2},g-2)=\sum _{k_{1}=0}^{n}\sum _{k_{2}=0}^{n-k_{1}}\cdots \sum _{k_{g}=0}^{n-\sum _{j=1}^{g-1}k_{j}}w(n-\sum _{i=1}^{g}k_{i},0).} Using the convention (7) 2 above, we obtain the formula w ( n , g ) = ∑ ∑ k 1 = 0 n ∑ ∑ k 2 = 0 n − − k 1 ⋯ ⋯ ∑ ∑ k g = 0 n − − ∑ ∑ j = 1 g − − 1 k j 1 , {\displaystyle w(n,g)=\sum _{k_{1}=0}^{n}\sum _{k_{2}=0}^{n-k_{1}}\cdots \sum _{k_{g}=0}^{n-\sum _{j=1}^{g-1}k_{j}}1,} 8 keeping in mind that for q {\displaystyle q} and p {\displaystyle p} being constants, we have ∑ ∑ k = 0 q p = q p .

{\displaystyle \sum _{k=0}^{q}p=qp.} 9 It can then be verified that (8) and (2) give the same result for w ( 4 , 3 ) {\displaystyle w(4,3)} , w ( 3 , 3 ) {\displaystyle w(3,3)} , w ( 3 , 2 ) {\displaystyle w(3,2)} , etc.

Interdisciplinary applications [ edit ] Main article: Bose–Einstein condensation (network theory) Viewed as a pure probability distribution , the Bose–Einstein distribution has found application in other fields: In recent years, Bose–Einstein statistics has also been used as a method for term weighting in information retrieval . The method is one of a collection of DFR ("Divergence From Randomness") models, [ 18 ] the basic notion being that Bose–Einstein statistics may be a useful indicator in cases where a particular term and a particular document have a significant relationship that would not have occurred purely by chance. Source code for implementing this model is available from the Terrier project at the University of Glasgow.

The evolution of many complex systems, including the World Wide Web , business, and citation networks, is encoded in the dynamic web describing the interactions between the system's constituents. Despite their irreversible and nonequilibrium nature these networks follow Bose statistics and can undergo Bose–Einstein condensation. Addressing the dynamical properties of these nonequilibrium systems within the framework of equilibrium quantum gases predicts that the "first-mover-advantage", "fit-get-rich" (FGR) and "winner-takes-all" phenomena observed in competitive systems are thermodynamically distinct phases of the underlying evolving networks.

[ 19 ] See also [ edit ] Bose–Einstein correlations Bose–Einstein condensate Bose gas Einstein solid Higgs boson Parastatistics Planck's law of black body radiation Superconductivity Fermi–Dirac statistics Maxwell–Boltzmann statistics Kompaneyets equation Notes [ edit ] ^ Pearsall, Thomas (2020).

Quantum Photonics, 2nd edition . Graduate Texts in Physics. Springer.

doi : 10.1007/978-3-030-47325-9 .

ISBN 978-3-030-47324-2 .

^ Jammer, Max (1966).

The conceptual development of quantum mechanics . McGraw-Hill. p. 51.

ISBN 0-88318-617-9 .

^ Passon, Oliver; Grebe-Ellis, Johannes (2017-05-01).

"Planck's radiation law, the light quantum, and the prehistory of indistinguishability in the teaching of quantum mechanics" .

European Journal of Physics .

38 (3): 035404.

arXiv : 1703.05635 .

Bibcode : 2017EJPh...38c5404P .

doi : 10.1088/1361-6404/aa6134 .

ISSN 0143-0807 .

S2CID 119091804 .

^ d'Alembert, Jean (1754). "Croix ou pile".

L'Encyclopédie (in French).

4 .

^ d'Alembert, Jean (1754).

"Croix ou pile" (PDF) .

Xavier University . Translated by Richard J. Pulskamp . Retrieved 2019-01-14 .

^ See p. 14, note 3, of the thesis: Michelangeli, Alessandro (October 2007).

Bose–Einstein condensation: Analysis of problems and rigorous results (PDF) (Ph.D.).

International School for Advanced Studies .

Archived (PDF) from the original on 3 November 2018 . Retrieved 14 February 2019 .

^ Bose (2 July 1924).

"Planck's law and the hypothesis of light quanta" (PostScript) .

University of Oldenburg . Retrieved 30 November 2016 .

^ Bose (1924), "Plancks Gesetz und Lichtquantenhypothese", Zeitschrift für Physik (in German), 26 (1): 178– 181, Bibcode : 1924ZPhy...26..178B , doi : 10.1007/BF01327326 , S2CID 186235974 ^ Ghose, Partha (2023). "The Story of Bose, Photon Spin and Indistinguishability".

arXiv : 2308.01909 [ physics.hist-ph ].

^ Srivastava, R. K.; Ashok, J. (2005). "Chapter 7".

Statistical Mechanics .

New Delhi : PHI Learning Pvt. Ltd.

ISBN 9788120327825 .

^ Landau, L. D., Lifšic, E. M., Lifshitz, E. M., & Pitaevskii, L. P. (1980). Statistical physics (Vol. 5). Pergamon Press.

^ "Chapter 6".

Statistical Mechanics . PHI Learning Pvt. January 2005.

ISBN 9788120327825 .

^ The BE distribution can be derived also from thermal field theory.

^ R. B. Dingle, Asymptotic Expansions: Their Derivation and Interpretation , Academic Press (1973), pp. 267–271.

^ H. J. W. Müller-Kirsten, Basics of Statistical Physics , 2nd ed., World Scientific (2013), ISBN 978-981-4449-53-3 .

^ Ziff R. M.;  Kac, M.; Uhlenbeck, G. E. (1977).

"The ideal Bose–Einstein gas, revisited" .

Physics Reports 32 : 169–248.

^ See McQuarrie in citations ^ Amati, G.; C. J. Van Rijsbergen (2002). " Probabilistic models of information retrieval based on measuring the divergence from randomness " ACM TOIS 20 (4):357–389.

^ Bianconi, G.

;  Barabási, A.-L. (2001). " Bose–Einstein Condensation in Complex Networks ".

Physical Review Letters 86 : 5632–5635.

References [ edit ] Annett, James F. (2004).

Superconductivity, Superfluids and Condensates . New York: Oxford University Press.

ISBN 0-19-850755-0 .

Carter, Ashley H. (2001).

Classical and Statistical Thermodynamics . Upper Saddle River, NJ: Prentice Hall.

ISBN 0-13-779208-5 .

Griffiths, David J. (2005).

Introduction to Quantum Mechanics (2nd ed.). Upper Saddle River, NJ: Pearson, Prentice Hall.

ISBN 0-13-191175-9 .

McQuarrie, Donald A. (2000).

Statistical Mechanics (1st ed.). Sausalito, CA: University Science Books. p.

55 .

ISBN 1-891389-15-7 .

v t e Statistical mechanics Theory Principle of maximum entropy ergodic theory Statistical thermodynamics Ensembles partition functions equations of state thermodynamic potential : U H F G Maxwell relations Models Ferromagnetism models Ising Potts Heisenberg percolation Particles with force field depletion force Lennard-Jones potential Mathematical approaches Boltzmann equation H-theorem Vlasov equation BBGKY hierarchy stochastic process mean-field theory and conformal field theory Critical phenomena Phase transition Critical exponents correlation length size scaling Entropy Boltzmann Shannon Tsallis Rényi von Neumann Applications Statistical field theory elementary particle superfluidity Condensed matter physics Complex system chaos information theory Boltzmann machine v t e Albert Einstein Physics Theory of relativity Special relativity General relativity Mass–energy equivalence (E=mc 2 ) Brownian motion Photoelectric effect Einstein coefficients Einstein solid Equivalence principle Einstein field equations Einstein radius Einstein relation (kinetic theory) Einstein ring Cosmological constant Bose–Einstein condensate Bose–Einstein statistics Bose–Einstein correlations Einstein–Cartan theory Einstein–Infeld–Hoffmann equations Einstein–de Haas effect EPR paradox Bohr–Einstein debates Teleparallelism Thought experiments Unsuccessful investigations Wave–particle duality Gravitational wave Tea leaf paradox Works Annus mirabilis papers (1905) " Investigations on the Theory of Brownian Movement " (1905) Relativity: The Special and the General Theory (1916) The Meaning of Relativity (1922) The World as I See It (1934) The Evolution of Physics (1938) " Why Socialism?

" (1949) Russell–Einstein Manifesto (1955) In popular culture Die Grundlagen der Einsteinschen Relativitäts-Theorie (1922 documentary) The Einstein Theory of Relativity (1923 documentary) Relics: Einstein's Brain (1994 documentary) Insignificance (1985 film) Young Einstein (1988 film) Picasso at the Lapin Agile (1993 play) I.Q.

(1994 film) Einstein's Gift (2003 play) Einstein and Eddington (2008 TV film) Genius (2017 series) Oppenheimer (2023 film) Prizes Albert Einstein Award Albert Einstein Medal Kalinga Prize Albert Einstein Peace Prize Albert Einstein World Award of Science Einstein Prize for Laser Science Einstein Prize (APS) Books about Einstein Albert Einstein: Creator and Rebel Einstein and Religion Einstein for Beginners Einstein: His Life and Universe Einstein in Oxford Einstein on the Run Einstein's Cosmos I Am Albert Einstein Introducing Relativity Subtle is the Lord Family Mileva Marić (first wife) Elsa Einstein (second wife; cousin) Lieserl Einstein (daughter) Hans Albert Einstein (son) Pauline Koch (mother) Hermann Einstein (father) Maja Einstein (sister) Eduard Einstein (son) Robert Einstein (cousin) Bernhard Caesar Einstein (grandson) Evelyn Einstein (granddaughter) Thomas Martin Einstein (great-grandson) Siegbert Einstein (distant cousin) Related Awards and honors Brain House Memorial Political views Religious views Things named after Einstein–Oppenheimer relationship Albert Einstein Archives Einstein's Blackboard Einstein Papers Project Einstein refrigerator Einsteinhaus Einsteinium Max Talmey Emergency Committee of Atomic Scientists Category Wikimedia Commons has media related to Bose-Einstein distribution .

Authority control databases : National Germany NewPP limit report
Parsed by mw‐web.codfw.main‐597b4b5bbd‐6xrrd
Cached time: 20250814215543
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.874 seconds
Real time usage: 1.151 seconds
Preprocessor visited node count: 3764/1000000
Revision size: 41487/2097152 bytes
Post‐expand include size: 89017/2097152 bytes
Template argument size: 4382/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 118448/5000000 bytes
Lua time usage: 0.363/10.000 seconds
Lua memory usage: 25417053/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  635.252      1 -total
 21.76%  138.226      1 Template:Reflist
 16.87%  107.162      8 Template:Cite_book
 13.31%   84.558      2 Template:Lang
 12.76%   81.059      1 Template:Short_description
 11.17%   70.939      1 Template:Statistical_mechanics
 10.93%   69.423      1 Template:Sidebar_with_collapsible_lists
  8.54%   54.223      2 Template:Pagetype
  7.87%   50.014      9 Template:NumBlk
  5.82%   36.973      1 Template:Commons_category Saved in parser cache with key enwiki:pcache:188935:|#|:idhash:canonical and timestamp 20250814215543 and revision id 1305316633. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Bose–Einstein_statistics&oldid=1305316633 " Categories : Bose–Einstein statistics Concepts in physics Quantum field theory Albert Einstein Statistical mechanics Satyendra Nath Bose Hidden categories: CS1 French-language sources (fr) CS1 German-language sources (de) Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from June 2025 Articles containing German-language text Commons category link is on Wikidata This page was last edited on 11 August 2025, at 10:10 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Bose–Einstein statistics 49 languages Add topic

