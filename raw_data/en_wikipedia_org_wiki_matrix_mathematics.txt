Title: Matrix (mathematics)

URL Source: https://en.wikipedia.org/wiki/Matrix_(mathematics)

Published Time: 2002-10-22T10:06:23Z

Markdown Content:
[![Image 1: Two tall square brackets with m-many rows each containing n-many subscripted letter 'a' variables. Each letter 'a' is given a row number and column number as its subscript.](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/MatrixLabelled.svg/250px-MatrixLabelled.svg.png)](https://en.wikipedia.org/wiki/File:MatrixLabelled.svg)

An _m_ × _n_ matrix: the _m_ rows are horizontal and the _n_ columns are vertical. Each element of a matrix is often denoted by a variable with two [subscripts](https://en.wikipedia.org/wiki/Index_notation "Index notation"). For example, _a_ 2,1 represents the element at the second row and first column of the matrix.

In [mathematics](https://en.wikipedia.org/wiki/Mathematics "Mathematics"), a **matrix** (pl.: **matrices**) is a [rectangular](https://en.wikipedia.org/wiki/Rectangle "Rectangle") array of [numbers](https://en.wikipedia.org/wiki/Number "Number") or other [mathematical objects](https://en.wikipedia.org/wiki/Mathematical_objects "Mathematical objects") with elements or entries arranged in rows and columns, usually satisfying certain properties of [addition](https://en.wikipedia.org/wiki/Matrix_addition "Matrix addition") and [multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication "Matrix multiplication").

For example, ![Image 2: {\displaystyle {\begin{bmatrix}1&9&-13\\20&5&-6\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/61f786996bcfb75972dd77712c90122bc8765269) denotes a matrix with two rows and three columns. This is often referred to as a "two-by-three matrix", a "⁠![Image 3: {\displaystyle 2\times 3}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8b74d5a424cfb56b99e1060910dbfed284314da0)⁠ matrix", or a matrix of dimension ⁠![Image 4: {\displaystyle 2\times 3}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8b74d5a424cfb56b99e1060910dbfed284314da0)⁠.

In [linear algebra](https://en.wikipedia.org/wiki/Linear_algebra "Linear algebra"), matrices are used as [linear maps](https://en.wikipedia.org/wiki/Linear_map "Linear map"). In [geometry](https://en.wikipedia.org/wiki/Geometry "Geometry"), matrices are used for [geometric transformations](https://en.wikipedia.org/wiki/Geometric_transformation "Geometric transformation") (for example [rotations](https://en.wikipedia.org/wiki/Rotation_(mathematics) "Rotation (mathematics)")) and [coordinate changes](https://en.wikipedia.org/wiki/Coordinate_change "Coordinate change"). In [numerical analysis](https://en.wikipedia.org/wiki/Numerical_analysis "Numerical analysis"), many computational problems are solved by reducing them to a matrix computation, and this often involves computing with matrices of huge dimensions. Matrices are used in most areas of mathematics and scientific fields, either directly, or through their use in geometry and numerical analysis.

_[Square matrices](https://en.wikipedia.org/wiki/Square\_matrices "Square matrices")_, matrices with the same number of rows and columns, play a major role in matrix theory. The [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") of a square matrix is a number associated with the matrix, which is fundamental for the study of a square matrix; for example, a square matrix is [invertible](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix") if and only if it has a nonzero determinant and the [eigenvalues](https://en.wikipedia.org/wiki/Eigenvalue "Eigenvalue") of a square matrix are the roots of a [polynomial](https://en.wikipedia.org/wiki/Polynomial "Polynomial") determinant.

**Matrix theory** is the [branch of mathematics](https://en.wikipedia.org/wiki/Branch_of_mathematics "Branch of mathematics") that focuses on the study of matrices. It was initially a sub-branch of [linear algebra](https://en.wikipedia.org/wiki/Linear_algebra "Linear algebra"), but soon grew to include subjects related to [graph theory](https://en.wikipedia.org/wiki/Graph_theory "Graph theory"), [algebra](https://en.wikipedia.org/wiki/Algebra "Algebra"), [combinatorics](https://en.wikipedia.org/wiki/Combinatorics "Combinatorics") and [statistics](https://en.wikipedia.org/wiki/Statistics "Statistics").

A matrix is a rectangular array of [numbers](https://en.wikipedia.org/wiki/Number "Number") (or other mathematical objects), called the "entries" of the matrix. Matrices are subject to standard [operations](https://en.wikipedia.org/wiki/Operation_(mathematics) "Operation (mathematics)") such as [addition](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Basic_operations) and [multiplication](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Matrix_multiplication).[[1]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang2002Chapter_XIII-1) Most commonly, a matrix over a [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)")![Image 5: {\displaystyle F}](https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57) is a rectangular array of [elements](https://en.wikipedia.org/wiki/Element_(mathematics) "Element (mathematics)") of ⁠![Image 6: {\displaystyle F}](https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57)⁠.[[2]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEFraleigh1976209-2)[[3]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTENering197037-3) A **real matrix** and a **complex matrix** are matrices whose entries are respectively [real numbers](https://en.wikipedia.org/wiki/Real_number "Real number") or [complex numbers](https://en.wikipedia.org/wiki/Complex_number "Complex number"). More general types of entries are discussed [below](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Matrices_with_more_general_entries). For instance, this is a real matrix: ![Image 7: {\displaystyle \mathbf {A} ={\begin{bmatrix}-1.3&0.6\\20.4&5.5\\9.7&-6.2\end{bmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/93197553f2e35e42d461b20ee549ea2fde617e1e)

The numbers (or other objects) in the matrix are called its _entries_ or its _elements_. The horizontal and vertical lines of entries in a matrix are respectively called _rows_ and _columns_.[[4]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown19911-4)

The size of a matrix is defined by the number of rows and columns it contains. There is no limit to the number of rows and columns that a matrix (in the usual sense) can have as long as they are positive integers. A matrix with ![Image 8: {\displaystyle m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc) rows and ![Image 9: {\displaystyle n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b) columns is called an ![Image 10: {\displaystyle m\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/12b23d207d23dd430b93320539abbb0bde84870d) matrix,[[4]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown19911-4) or ![Image 11: {\displaystyle {m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/989d8ed6300d470470571f438bbe51f0693fb7b2)-by-![Image 12: {\displaystyle {n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/70b6881107a598c20a60e72fe82bc41a4a1f7f4c) matrix,[[5]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGolubVan_Loan19963-5) where ![Image 13: {\displaystyle {m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/989d8ed6300d470470571f438bbe51f0693fb7b2) and ![Image 14: {\displaystyle {n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/70b6881107a598c20a60e72fe82bc41a4a1f7f4c) are called its _dimensions_.[[6]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson19855-6) For example, the matrix ![Image 15: {\displaystyle {\mathbf {A} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/724d496b798f73a7173ef082565f5111ca547bb6) above is a ![Image 16: {\displaystyle {3\times 2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f657f2e0de15cb9309ee4d1566b03ec938b03d45) matrix.

Matrices with a single row are called _[row matrices](https://en.wikipedia.org/wiki/Row\_matrix "Row matrix")_ or _row vectors_, and those with a single column are called _[column matrices](https://en.wikipedia.org/wiki/Column\_matrix "Column matrix")_ or _column vectors_. A matrix with the same number of rows and columns is called a _[square matrix](https://en.wikipedia.org/wiki/Square\_matrix "Square matrix")_.[[7]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur201189-7) A matrix with an infinite number of rows or columns (or both) is called an [_infinite matrix_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Infinite_matrices). In some contexts, such as [computer algebra programs](https://en.wikipedia.org/wiki/Computer_algebra_system "Computer algebra system"), it is useful to consider a matrix with no rows or no columns, called an [_empty matrix_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Empty_matrix).[[8]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-empty-8)

Overview of a matrix size | Name | Size | Example | Description |
| --- | --- | --- | --- |
| [Row matrix](https://en.wikipedia.org/wiki/Row_matrix "Row matrix") | ![Image 17: {\displaystyle 1\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0bce5f6a6d0d32834484048c16f3b39f9c23d076) | ![Image 18: {\displaystyle {\begin{bmatrix}3&7&2\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/47374c1d98d87b805e7c798d77865d060fc9780d) | A matrix with one row, sometimes used to represent a vector |
| [Column matrix](https://en.wikipedia.org/wiki/Column_matrix "Column matrix") | ![Image 19: {\displaystyle n\times 1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d24148f103e1cccb60addeeb0a64cb1c3d5622e0) | ![Image 20: {\displaystyle {\begin{bmatrix}4\\1\\8\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d5f6732e6903bb84f36b682d8762f9ec5f8b489d) | A matrix with one column, sometimes used to represent a vector |
| [Square matrix](https://en.wikipedia.org/wiki/Square_matrix "Square matrix") | ![Image 21: {\displaystyle n\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/59d2b4cb72e304526cf5b5887147729ea259da78) | ![Image 22: {\displaystyle {\begin{bmatrix}9&13&5\\1&11&7\\2&6&3\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/55375914df4213b621f22cb1e5a0d6eb09af29df) | A matrix with the same number of rows and columns, sometimes used to represent a [linear transformation](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Linear_transformations) from a vector space to itself, such as [reflection](https://en.wikipedia.org/wiki/Reflection_(mathematics) "Reflection (mathematics)"), [rotation](https://en.wikipedia.org/wiki/Rotation_(mathematics) "Rotation (mathematics)"), or [shearing](https://en.wikipedia.org/wiki/Shear_mapping "Shear mapping"). |

The specifics of symbolic matrix notation vary widely, with some prevailing trends. Matrices are commonly written in [square brackets](https://en.wikipedia.org/wiki/Square_bracket "Square bracket") or [parentheses](https://en.wikipedia.org/wiki/Parentheses "Parentheses"),[[9]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTERamachandra_RaoBhimasankaram2000[httpsbooksgooglecombooksidZfJdDwAAQBAJpgPA71_71]-9) so that an ![Image 23: {\displaystyle m\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/12b23d207d23dd430b93320539abbb0bde84870d) matrix ![Image 24: {\displaystyle \mathbf {A} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0795cc96c75d81520a120482662b90f024c9a1a1) is represented as ![Image 25: {\displaystyle \mathbf {A} ={\begin{bmatrix}a_{11}&a_{12}&\cdots &a_{1n}\\a_{21}&a_{22}&\cdots &a_{2n}\\\vdots &\vdots &\ddots &\vdots \\a_{m1}&a_{m2}&\cdots &a_{mn}\end{bmatrix}}={\begin{pmatrix}a_{11}&a_{12}&\cdots &a_{1n}\\a_{21}&a_{22}&\cdots &a_{2n}\\\vdots &\vdots &\ddots &\vdots \\a_{m1}&a_{m2}&\cdots &a_{mn}\end{pmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5467918c1f72eed942e20d1c7662188194246f80) This may be abbreviated by writing only a single generic term, possibly along with indices, as in ![Image 26: {\displaystyle \mathbf {A} =\left(a_{ij}\right),\quad \left[a_{ij}\right],\quad {\text{or}}\quad \left(a_{ij}\right)_{1\leq i\leq m,\;1\leq j\leq n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bfc2e9990806f2830d7a3865e6adb451a66e546c) or ![Image 27: {\displaystyle \mathbf {A} =(a_{i,j})_{1\leq i,j\leq n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e03f4cd8c02d54ca318a68dab549b3011837a0d2) in the case that ⁠![Image 28: {\displaystyle n=m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/480d6131c6cb07a90f4ec18a376a59fab884b860)⁠.

Matrices are usually symbolized using [upper-case](https://en.wikipedia.org/wiki/Upper-case "Upper-case") letters (such as ![Image 29: {\displaystyle {\mathbf {A} }}](https://wikimedia.org/api/rest_v1/media/math/render/svg/724d496b798f73a7173ef082565f5111ca547bb6) in the examples above),[[10]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHamilton1987[httpsbooksgooglecombooksidW5o4AAAAIAAJpgPA29_29]-10) while the corresponding [lower-case](https://en.wikipedia.org/wiki/Lower-case "Lower-case") letters, with two subscript indices (e.g., ⁠![Image 30: {\displaystyle a_{11}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/411c26881c752d514e61bfdd5eb8463c6e808202)⁠, or ⁠![Image 31: {\displaystyle a_{1,1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/564ac6fe1700e96d1f5acc8123e2faad1d86c8ed)⁠), represent the entries.[[11]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGentle1998[httpsbooksgooglecombooksid2J0ndF_LmqoCpgPA52_52%E2%80%9353]-11) In addition to using upper-case letters to symbolize matrices, many authors use a special [typographical style](https://en.wikipedia.org/wiki/Emphasis_(typography) "Emphasis (typography)"), commonly boldface Roman (non-italic), to further distinguish matrices from other mathematical objects. An alternative notation involves the use of a double-underline with the variable name, with or without boldface style, as in ⁠![Image 32: {\displaystyle {\underline {\underline {A}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/998c5de9803c6c1eaf3a4944fcdceed6f0af959f)⁠.[[12]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBauchauCraig2009[httpsbooksgooglecombooksidGYRX8ZYVNYQCpgPA915_915]-12)

The entry in the _i_ th row and _j_ th column of a matrix **A** is sometimes referred to as the ![Image 33: {\displaystyle {i,j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5876095735fdb75f51433429203661da7fca390f) or ![Image 34: {\displaystyle (i,j)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8ef21910f980c6fca2b15bee102a7a0d861ed712) entry of the matrix, and commonly denoted by ![Image 35: {\displaystyle a_{i,j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4bb5a346f58c6568306a02596dd318d1b7e6b2c2) or ⁠![Image 36: {\displaystyle a_{ij}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ebea6cd2813c330c798921a2894b358f7b643917)⁠.[[13]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEJohnston2021[httpsbooksgooglecombooksidy24vEAAAQBAJpgPA21_21]-13) Alternative notations for that entry are ![Image 37: {\displaystyle {\mathbf {A} [i,j]}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/eeb3630aa110e0aa90d0bc0e4c0b55f659d3d63e) and ⁠![Image 38: {\displaystyle \mathbf {A} _{i,j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/892f08569b7918083599c20a9f16343a45538bbe)⁠. For example, the ![Image 39: {\displaystyle (1,3)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8c80e593e3953231c56d0887f5b247bbe517461f) entry of the following matrix ![Image 40: {\displaystyle \mathbf {A} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0795cc96c75d81520a120482662b90f024c9a1a1) is 5 (also denoted ⁠![Image 41: {\displaystyle a_{13}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/de4f86c305ff1b04fabb1cddcedd192853d6815c)⁠, ⁠![Image 42: {\displaystyle a_{1,3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/63f8a60fca726758b8b9b777135049055acf5269)⁠, ![Image 43: {\displaystyle \mathbf {A} [1,3]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fa3b9da80148fbbfe012952941a2bdc0d8393c38) or ⁠![Image 44: {\displaystyle {\mathbf {A} }_{1,3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/232f17b33d9df827c06193db5ad8818f076eab87)⁠): ![Image 45: {\displaystyle \mathbf {A} ={\begin{bmatrix}4&-7&\color {red}{5}&0\\-2&0&11&8\\19&1&-3&12\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f9d58776afc906466b6163beaf584405eaf7a97f)

Sometimes, the entries of a matrix can be defined by a formula such as ⁠![Image 46: {\displaystyle a_{i,j}=f(i,j)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e4451079309af20865d76b996b62f06fbe41314e)⁠. For example, each of the entries of the following matrix ![Image 47: {\displaystyle \mathbf {A} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0795cc96c75d81520a120482662b90f024c9a1a1) is determined by the formula ⁠![Image 48: {\displaystyle a_{ij}=i-j}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a2d745dd14d76ec708e0c984bf2489509caecd2c)⁠. ![Image 49: {\displaystyle \mathbf {A} ={\begin{bmatrix}0&-1&-2&-3\\1&0&-1&-2\\2&1&0&-1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9f51de53bfecb43be29e3905aad271db49679f50) In this case, the matrix itself is sometimes defined by that formula, within square brackets or double parentheses. For example, the matrix above is defined as ![Image 50: {\displaystyle {\mathbf {A} }=[i-j]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9724402762df013fda41e49ca5572dc9b89cd9cc) or ⁠![Image 51: {\displaystyle \mathbf {A} =((i-j))}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3163c9900b049bad85ca32c2f713b2795af668ab)⁠. If matrix size is ⁠![Image 52: {\displaystyle m\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/12b23d207d23dd430b93320539abbb0bde84870d)⁠, the above-mentioned formula ![Image 53: {\displaystyle f(i,j)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ceb5444a99e0ebb8684c4544152ab1268160da20) is valid for any ![Image 54: {\displaystyle i=1,\dots ,m}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d38508db1c01a8fbea6da93f1866f86944e3f12d) and any ⁠![Image 55: {\displaystyle j=1,\dots ,n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6f9393eaa189f1fb2c747b687b7b8d67640d5f1e)⁠. This can be specified separately or indicated using ![Image 56: {\displaystyle m\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/12b23d207d23dd430b93320539abbb0bde84870d) as a subscript. For instance, the matrix ![Image 57: {\displaystyle \mathbf {A} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/0795cc96c75d81520a120482662b90f024c9a1a1) above is ⁠![Image 58: {\displaystyle 3\times 4}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7fda443e7a6e78fa880a6dccbf8bdf43a10d9988)⁠, and can be defined as ![Image 59: {\displaystyle {\mathbf {A} }=[i-j](i=1,2,3;j=1,\dots ,4)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8ad68413c2769db2a39b51a017fb2e45cd793d3b) or ⁠![Image 60: {\displaystyle \mathbf {A} =[i-j]_{3\times 4}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b72d465b17f0b62f3a2c9699661f23897fe18a00)⁠.

Some programming languages utilize doubly subscripted arrays (or arrays of arrays) to represent an _m_-by-_n_ matrix. Some programming languages start the numbering of array indexes at zero, in which case the entries of an _m_-by-_n_ matrix are indexed by ![Image 61: {\displaystyle 0\leq i\leq m-1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ca4b2f05ce28398ed53128680921025e92b3fc4e) and ⁠![Image 62: {\displaystyle 0\leq j\leq n-1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a80ba06f8c7cb92e65b1932f837ceb3e9a405e51)⁠.[[14]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEOualline2003Ch._5-14) This article follows the more common convention in mathematical writing where enumeration starts from 1.

The [set](https://en.wikipedia.org/wiki/Set_(mathematics) "Set (mathematics)") of all _m_-by-_n_ real matrices is often denoted ⁠![Image 63: {\displaystyle {\mathcal {M}}(m,n)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdf7a6ead3a8ee7b3ef1b76c39b8df6cfbd0882b)⁠, or ⁠![Image 64: {\displaystyle {\mathcal {M}}_{m\times n}(\mathbb {R} )}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e39b3414b3345df29961eb0e14235025c42bf749)⁠. The set of all _m_-by-_n_ matrices over another [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)"), or over a [ring](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)")_R_, is similarly denoted ⁠![Image 65: {\displaystyle {\mathcal {M}}(m,n,R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8bec7b81c155766289e9c93a2737ef9b62324f52)⁠, or ⁠![Image 66: {\displaystyle {\mathcal {M}}_{m\times n}(R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c7af4af630e3903ea1d98dee5bf0eecd8095a0b9)⁠. If _m_ = _n_, such as in the case of [square matrices](https://en.wikipedia.org/wiki/Square_matrices "Square matrices"), one does not repeat the dimension: ⁠![Image 67: {\displaystyle {\mathcal {M}}(n,R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ceab90b479045388ccec06ca5836bf863ae9de0f)⁠, or ⁠![Image 68: {\displaystyle {\mathcal {M}}_{n}(R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/898fd3711a7daf6e6998854deaf83fe985ffd896)⁠.[[15]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPopFurdui2017-15) Often, ⁠![Image 69: {\displaystyle M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd)⁠, or ⁠![Image 70: {\displaystyle \operatorname {Mat} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/42fdf1777541a3ef4e694461fa576f1aabe4375f)⁠, is used in place of ⁠![Image 71: {\displaystyle {\mathcal {M}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2cc2abebd45ec020509a0ec548b67c9a2cb7cecd)⁠.[[16]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-16)

Several basic operations can be applied to matrices. Some, such as _transposition_ and _submatrix_ do not depend on the nature of the entries. Others, such as _matrix addition_, _scalar multiplication_, _matrix multiplication_, and _row operations_ involve operations on matrix entries and therefore require that matrix entries are numbers or belong to a [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)") or a [ring](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)").[[17]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_I.2.1_(addition),_Definition_I.2.4_(scalar_multiplication),_and_Definition_I.2.33_(transpose)-17)

In this section, it is supposed that matrix entries belong to a fixed ring, which is typically a field of numbers.

[![Image 72](https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Matrix_addition_qtl2.svg/250px-Matrix_addition_qtl2.svg.png)](https://en.wikipedia.org/wiki/File:Matrix_addition_qtl2.svg)

Illustration of the addition of two matrices.

Matrix addition and subtraction require matrices of a consistent size, and are calculated entrywise. The _sum_**A** + **B** and the difference **A** − **B** of two _m_×_n_ matrices are:[[18]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWhitelaw199129-18)

![Image 73: {\displaystyle {\begin{aligned}({\mathbf {A}}+{\mathbf {B}})_{i,j}={\mathbf {A}}_{i,j}+{\mathbf {B}}_{i,j},\quad 1\leq i\leq m,\quad 1\leq j\leq n.\\({\mathbf {A}}-{\mathbf {B}})_{i,j}={\mathbf {A}}_{i,j}-{\mathbf {B}}_{i,j},\quad 1\leq i\leq m,\quad 1\leq j\leq n.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e752ed2f4adb167ce4699d752983355dbabdaa0f)

For example,

![Image 74: {\displaystyle {\begin{bmatrix}1&3&1\\1&0&0\end{bmatrix}}+{\begin{bmatrix}0&0&5\\7&5&0\end{bmatrix}}={\begin{bmatrix}1+0&3+0&1+5\\1+7&0+5&0+0\end{bmatrix}}={\begin{bmatrix}1&3&6\\8&5&0\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9e600aa691a93ceb33f0fdac290002d1391d6688)

Familiar properties of numbers extend to these operations on matrices: for example, addition is [commutative](https://en.wikipedia.org/wiki/Commutative "Commutative"), that is, the matrix sum does not depend on the order of the summands: **A** + **B** = **B** + **A**.[[19]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Theorem_I.2.6-19)

### Scalar multiplication

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=6 "Edit section: Scalar multiplication")]

The product _c_**A** of a number c (also called a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) "Scalar (mathematics)") in this context) and a matrix **A** is computed by multiplying each entry of **A** by c:[[20]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWhitelaw199130-20)![Image 75: {\displaystyle (c{\mathbf {A}})_{i,j}=c\cdot {\mathbf {A}}_{i,j}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d99dc53991b812afcf155f2e546cd41a6ae36f10) This operation is called _scalar multiplication_, but its result is not named "scalar product" to avoid confusion, since "scalar product" is often used as a synonym for "[inner product](https://en.wikipedia.org/wiki/Inner_product "Inner product")".[[21]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMaxwell1969[httpsbooksgooglecombooksidoQk9AAAAIAAJpgPA46_46]-21) For example:

![Image 76: {\displaystyle 2\cdot {\begin{bmatrix}1&8&-3\\4&-2&5\end{bmatrix}}={\begin{bmatrix}2\cdot 1&2\cdot 8&2\cdot -3\\2\cdot 4&2\cdot -2&2\cdot 5\end{bmatrix}}={\begin{bmatrix}2&16&-6\\8&-4&10\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cf7fe1075c8c575225e74096007bef9205c88964)

Matrix subtraction is consistent with composition of matrix addition with scalar multiplication by –1:[[22]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid2c011Aptsa8CpgPA6_6%E2%80%937]-22)

![Image 77: {\displaystyle \mathbf {A} -\mathbf {B} =\mathbf {A} +(-1)\cdot \mathbf {B} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1743905b472434f9b2ffec5c159062c1b77e9643)

The _transpose_ of an _m_×_n_ matrix **A** is the _n_×_m_ matrix **A**T (also denoted **A**tr or t**A**) formed by turning rows into columns and vice versa: ![Image 78: {\displaystyle \left({\mathbf {A}}^{\rm {T}}\right)_{i,j}={\mathbf {A}}_{j,i}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a593edc189c58430468491beba276358a71a8761) For example: ![Image 79: {\displaystyle {\begin{bmatrix}1&2&3\\0&-6&7\end{bmatrix}}^{\mathrm {T} }={\begin{bmatrix}1&0\\2&-6\\3&7\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/51f6dba024e104b412ed0562163ca9a11fcb9463)

The transpose is compatible with addition and scalar multiplication, as expressed by (_c_**A**)T = _c_(**A**T) and (**A** + **B**)T = **A**T + **B**T. Finally, (**A**T)T = **A**.[[23]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAndrilliHecker2022[httpsbooksgooglecombooksidWtpVEAAAQBAJpgPA38_38]The_transpose_of_a_matrix_and_its_properties-23)

### Matrix multiplication

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=8 "Edit section: Matrix multiplication")]

[![Image 80](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/MatrixMultiplication.png/330px-MatrixMultiplication.png)](https://en.wikipedia.org/wiki/File:MatrixMultiplication.png)

Schematic depiction of the matrix product **AB** of two matrices **A** and **B**

_Multiplication_ of two matrices corresponds to the composition of [linear transformations](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Linear_transformations) represented by each matrix. It is defined if and only if the number of columns of the left matrix is the same as the number of rows of the right matrix. If **A** is an _m_×_n_ matrix and **B** is an _n_×_p_ matrix, then their _matrix product_**AB** is the _m_×_p_ matrix whose entries are given by the [dot product](https://en.wikipedia.org/wiki/Dot_product "Dot product") of the corresponding row of **A** and the corresponding column of **B**:[[24]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid4nfNCgAAQBAJpgPA9_9]-24)![Image 81: {\displaystyle [\mathbf {AB} ]_{i,j}=a_{i,1}b_{1,j}+a_{i,2}b_{2,j}+\cdots +a_{i,n}b_{n,j}=\sum _{r=1}^{n}a_{i,r}b_{r,j},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c903c2c14d249005ce9ebaa47a8d6c6710c1c29e) where 1 ≤ _i_ ≤ _m_ and 1 ≤ _j_ ≤ _p_.[[25]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_I.2.20-25) For example, the underlined entry 2340 in the product is calculated as (2 × 1000) + (3 × 100) + (4 × 10) = 2340:![Image 82: {\displaystyle {\begin{aligned}{\begin{bmatrix}{\underline {2}}&{\underline {3}}&{\underline {4}}\\1&0&0\\\end{bmatrix}}{\begin{bmatrix}0&{\underline {1000}}\\1&{\underline {100}}\\0&{\underline {10}}\\\end{bmatrix}}&={\begin{bmatrix}3&{\underline {2340}}\\0&1000\\\end{bmatrix}}.\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8435ba88efca5a73e7d1b122bb19f99ef136d71e)

Matrix multiplication satisfies the rules (**AB**)**C** = **A**(**BC**) ([associativity](https://en.wikipedia.org/wiki/Associativity "Associativity")), and (**A** + **B**)**C** = **AC** + **BC** as well as **C**(**A** + **B**) = **CA** + **CB** (left and right [distributivity](https://en.wikipedia.org/wiki/Distributivity "Distributivity")), whenever the size of the matrices is such that the various products are defined.[[26]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Theorem_I.2.24-26) The product **AB** may be defined without **BA** being defined, namely if **A** and **B** are _m_×_n_ and _n_×_k_ matrices, respectively, and _m_ ≠ _k_. Even if both products are defined, they generally need not be equal, that is:[[27]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005117-27)![Image 83: {\displaystyle {\mathbf {AB}}\neq {\mathbf {BA}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/89c668f86bb3696952f5ff52998df9d0a6ba8c73)

In other words, matrix multiplication is not [commutative](https://en.wikipedia.org/wiki/Commutative_property "Commutative property"), in marked contrast to (rational, real, or complex) numbers, whose product is independent of the order of the factors.[[24]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid4nfNCgAAQBAJpgPA9_9]-24) An example of two matrices not commuting with each other is: ![Image 84: {\displaystyle {\begin{bmatrix}1&2\\3&4\\\end{bmatrix}}{\begin{bmatrix}0&1\\0&0\\\end{bmatrix}}={\begin{bmatrix}0&1\\0&3\\\end{bmatrix}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f04b29d8a273a3d2ccff8b2ac98c9e75c305c7bd) whereas ![Image 85: {\displaystyle {\begin{bmatrix}0&1\\0&0\\\end{bmatrix}}{\begin{bmatrix}1&2\\3&4\\\end{bmatrix}}={\begin{bmatrix}3&4\\0&0\\\end{bmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d3d260e7e7dda974d50647f542f9968c9267eff0)

Besides the ordinary matrix multiplication just described, other less frequently used operations on matrices that can be considered forms of multiplication also exist, such as the [Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices) "Hadamard product (matrices)") and the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product "Kronecker product").[[28]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Ch._4_and_5-28) They arise in solving matrix equations such as the [Sylvester equation](https://en.wikipedia.org/wiki/Sylvester_equation "Sylvester equation").[[29]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEVan_Loan2000-29)

There are three types of row operations:[[30]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPerrone2024[httpbooksgooglecombooksidJO8GEQAAQBAJpgPA119_119%E2%80%93120]-30)[[31]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1986[httpbooksgooglecombooksidc_NEBAAAQBAJpgPA71_71]-31)

1.   row addition, that is, adding a row to another.
2.   row multiplication, that is, multiplying all entries of a row by a non-zero constant;
3.   row switching, that is, interchanging two rows of a matrix;

These operations are used in several ways, including solving [linear equations](https://en.wikipedia.org/wiki/Linear_equation "Linear equation") and finding [matrix inverses](https://en.wikipedia.org/wiki/Matrix_inverse "Matrix inverse") with [Gauss elimination](https://en.wikipedia.org/wiki/Gauss_elimination "Gauss elimination") and Gauss–Jordan elimination, respectively.[[32]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWatkins2002[httpbooksgooglecombooksidxi5omWiQ-3kCpgPA102_102]-32)

A **submatrix** of a matrix is a matrix obtained by deleting any collection of rows or columns or both.[[33]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBronson197016-33)[[34]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKreyszig1972220-34)[[35]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEProtterMorrey1970869-35) For example, from the following 3-by-4 matrix, we can construct a 2-by-3 submatrix by removing row 3 and column 2: ![Image 86: {\displaystyle \mathbf {A} ={\begin{bmatrix}1&\color {red}{2}&3&4\\5&\color {red}{6}&7&8\\\color {red}{9}&\color {red}{10}&\color {red}{11}&\color {red}{12}\end{bmatrix}}\rightarrow {\begin{bmatrix}1&3&4\\5&7&8\end{bmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1f7347ef1fbe8802dde70d98638277d3ca81ec4e)

The [minors](https://en.wikipedia.org/wiki/Minor_(linear_algebra) "Minor (linear algebra)") and cofactors of a matrix are found by computing the [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") of certain submatrices.[[35]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEProtterMorrey1970869-35)[[36]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKreyszig1972241,_244-36)

A **principal submatrix** is a square submatrix obtained by removing certain rows and columns. The definition varies from author to author. According to some authors, a principal submatrix is a submatrix in which the set of row indices that remain is the same as the set of column indices that remain.[[37]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTESchneiderBarker2012-37)[[38]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPerlis1991-38) Other authors define a principal submatrix as one in which the first k rows and columns, for some number k, are the ones that remain;[[39]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010-39) this type of submatrix has also been called a **leading principal submatrix**.[[40]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-40)

Matrices can be used to compactly write and work with multiple linear equations, that is, systems of linear equations. For example, if **A** is an _m_×_n_ matrix, **x** designates a column vector (that is, _n_×1-matrix) of n variables _x_ 1, _x_ 2, ..., _x_ _n_, and **b** is an _m_×1-column vector, then the matrix equation ![Image 87: {\displaystyle \mathbf {Ax} =\mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/e68388b7df59f536a3bef4e70def2f2bb36f48c0) is equivalent to the system of linear equations[[41]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991I.2.21_and_22-41)![Image 88: {\displaystyle {\begin{aligned}a_{1,1}x_{1}+a_{1,2}x_{2}+&\cdots +a_{1,n}x_{n}=b_{1}\\&\ \ \vdots \\a_{m,1}x_{1}+a_{m,2}x_{2}+&\cdots +a_{m,n}x_{n}=b_{m}\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d4d36435b1869be0a1174a28d251c44929556218)

Using matrices, this can be solved more compactly than would be possible by writing out all the equations separately. If _n_ = _m_ and the equations are [independent](https://en.wikipedia.org/wiki/Independent_equation "Independent equation"), then this can be done by writing[[42]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur201195-42)![Image 89: {\displaystyle \mathbf {x} =\mathbf {A} ^{-1}\mathbf {b} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/079fdc93cc44d2d3d6bdf92dadb0ad8ade2efe09) where **A**−1 is the [inverse matrix](https://en.wikipedia.org/wiki/Inverse_matrix "Inverse matrix") of **A**. If **A** has no inverse, solutions—if any—can be found using its [generalized inverse](https://en.wikipedia.org/wiki/Generalized_inverse "Generalized inverse").[[43]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBen-IsraelGreville20031%E2%80%932-43)

Linear transformations
----------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=12 "Edit section: Linear transformations")]

[![Image 90](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Area_parallellogram_as_determinant.svg/250px-Area_parallellogram_as_determinant.svg.png)](https://en.wikipedia.org/wiki/File:Area_parallellogram_as_determinant.svg)

The vectors represented by a 2-by-2 matrix correspond to the sides of a unit square transformed into a parallelogram.

Matrices and matrix multiplication reveal their essential features when related to _linear transformations_, also known as _linear maps_. A real m-by-n matrix **A** gives rise to a linear transformation ![Image 91: {\displaystyle \mathbb {R} ^{n}\to \mathbb {R} ^{m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cccdefd5f0e00fc2fa5fde2d8cbb039cc408a035) mapping each vector **x** in ⁠![Image 92: {\displaystyle \mathbb {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c510b63578322050121fe966f2e5770bea43308d)⁠ to the (matrix) product **Ax**, which is a vector in ⁠![Image 93: {\displaystyle \mathbb {R} ^{m}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/300954c24584ecb8256b59b1d1e6ea54ae1ae889)⁠ Conversely, each linear transformation ![Image 94: {\displaystyle f:\mathbb {R} ^{n}\to \mathbb {R} ^{m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aad78382c3d23bcb4051b3148f1a23b1d0ba52e3) arises from a unique m-by-n matrix **A**: explicitly, the (_i_, _j_)-entry of **A** is the i th coordinate of _f_ (**e**_j_), where **e**_j_ = (0, ..., 0, 1, 0, ..., 0) is the [unit vector](https://en.wikipedia.org/wiki/Unit_vector "Unit vector") with 1 in the j th position and 0 elsewhere. The matrix **A** is said to represent the linear map f, and **A** is called the _transformation matrix_ of f.[[44]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGrossman1994494%E2%80%93495-44)

For example, the 2×2 matrix ![Image 95: {\displaystyle \mathbf {A} ={\begin{bmatrix}a&c\\b&d\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0996c87b9d5163ae1a5e132fd08eb0abced82042) can be viewed as the transform of the [unit square](https://en.wikipedia.org/wiki/Unit_square "Unit square") into a [parallelogram](https://en.wikipedia.org/wiki/Parallelogram "Parallelogram") with vertices at (0, 0), (_a_, _b_), (_a_ + _c_, _b_ + _d_), and (_c_, _d_). The parallelogram pictured at the right is obtained by multiplying **A** with each of the column vectors ⁠![Image 96: {\displaystyle \left[{\begin{smallmatrix}0\\0\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/04da017a7369d47021b125d02752780176594b1c)⁠, ⁠![Image 97: {\displaystyle \left[{\begin{smallmatrix}1\\0\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9d140ee54c59d3e3508c4c7c468dc9765dab265a)⁠, ⁠![Image 98: {\displaystyle \left[{\begin{smallmatrix}1\\1\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e582d8b98956816f058fb801b004e402613f77c8)⁠, and ⁠![Image 99: {\displaystyle \left[{\begin{smallmatrix}0\\1\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/63e1cb5cf2d3e89b9f079112975dac6af6a25d70)⁠ in turn. These vectors define the vertices of the unit square.[[45]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBierens2004[httpsbooksgooglecombooksidZrBaRPVRLRoCpgPA263_263]-45) The following table shows several 2×2 real matrices with the associated linear maps of ⁠![Image 100: {\displaystyle \mathbb {R} ^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e150115ab9f63023215109595b76686a1ff890fd)⁠. The blue original is mapped to the green grid and shapes. The origin (0, 0) is marked with a black point.

[Horizontal shear](https://en.wikipedia.org/wiki/Shear_mapping "Shear mapping")[[46]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEJohnston2021[httpsbooksgooglecombooksidy24vEAAAQBAJpgPA56_56]-46)

with _m_ = 1.25.[Reflection](https://en.wikipedia.org/wiki/Reflection_(mathematics) "Reflection (mathematics)")[[47]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPettofrezzo1978[httpsbooksgooglecombooksid2wzp9zQhA_ICpgPA60_60]-47) through the vertical axis[Squeeze mapping](https://en.wikipedia.org/wiki/Squeeze_mapping "Squeeze mapping")[[48]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHanKimNoz1997-48)

with _r_ = 3/2[Scaling](https://en.wikipedia.org/wiki/Scaling_(geometry) "Scaling (geometry)")[[49]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEJeffrey2010[httpsbooksgooglecombooksiduan0Dkn9HY8CpgPA264_264]-49)

by a factor of 3/2[Rotation](https://en.wikipedia.org/wiki/Rotation_matrix "Rotation matrix")[[48]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHanKimNoz1997-48)

by π/6 = 30°
![Image 101: {\displaystyle {\begin{bmatrix}1&1.25\\0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/952686ab43a12dcc73b5a2faaef995e28c54af2b)![Image 102: {\displaystyle {\begin{bmatrix}-1&0\\0&1\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c5ddc64d626699bfb8b3b1722d8156c6d71b3101)![Image 103: {\displaystyle {\begin{bmatrix}{\frac {3}{2}}&0\\0&{\frac {2}{3}}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed82dee99393f43ca58ca109a07882c8502039fa)![Image 104: {\displaystyle {\begin{bmatrix}{\frac {3}{2}}&0\\0&{\frac {3}{2}}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/dfb4cd5330d9744daf8cce4670f5d7baeb8405c1)![Image 105: {\displaystyle {\begin{bmatrix}\cos \left({\frac {\pi }{6}}\right)&-\sin \left({\frac {\pi }{6}}\right)\\\sin \left({\frac {\pi }{6}}\right)&\cos \left({\frac {\pi }{6}}\right)\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/30963a4382db630e21570eedf5fa461cbf06cfb7)
[![Image 106](https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/VerticalShear_m%3D1.25.svg/250px-VerticalShear_m%3D1.25.svg.png)](https://en.wikipedia.org/wiki/File:VerticalShear_m%3D1.25.svg)[![Image 107](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Flip_map.svg/250px-Flip_map.svg.png)](https://en.wikipedia.org/wiki/File:Flip_map.svg)[![Image 108](https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Squeeze_r%3D1.5.svg/250px-Squeeze_r%3D1.5.svg.png)](https://en.wikipedia.org/wiki/File:Squeeze_r%3D1.5.svg)[![Image 109](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Scaling_by_1.5.svg/250px-Scaling_by_1.5.svg.png)](https://en.wikipedia.org/wiki/File:Scaling_by_1.5.svg)[![Image 110](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Rotation_by_pi_over_6.svg/250px-Rotation_by_pi_over_6.svg.png)](https://en.wikipedia.org/wiki/File:Rotation_by_pi_over_6.svg)

Under the [1-to-1 correspondence](https://en.wikipedia.org/wiki/Bijection "Bijection") between matrices and linear maps, matrix multiplication corresponds to [composition](https://en.wikipedia.org/wiki/Function_composition "Function composition") of maps:[[50]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-50) if a k-by-m matrix **B** represents another linear map ⁠![Image 111: {\displaystyle g:\mathbb {R} ^{m}\to \mathbb {R} ^{k}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ccc4b5d55e98cf86ea55aa1a57e470fc6b3076fe)⁠, then the composition _g_ ∘ _f_ is represented by **BA** since[[51]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1986%C2%A7VI.1-51)![Image 112: {\displaystyle (g\circ f)({\mathbf {x}})=g(f({\mathbf {x}}))=g({\mathbf {Ax}})={\mathbf {B}}({\mathbf {Ax}})=({\mathbf {BA}}){\mathbf {x}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7449df2e95a0fe52fd087e3f8d3b32e09606c338)

The last equality follows from the above-mentioned associativity of matrix multiplication.

The [rank of a matrix](https://en.wikipedia.org/wiki/Rank_of_a_matrix "Rank of a matrix")**A** is the maximum number of [linearly independent](https://en.wikipedia.org/wiki/Linear_independence "Linear independence") row vectors of the matrix, which is the same as the maximum number of linearly independent column vectors.[[52]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_II.3.3-52) Equivalently it is the [dimension](https://en.wikipedia.org/wiki/Hamel_dimension "Hamel dimension") of the [image](https://en.wikipedia.org/wiki/Image_(mathematics) "Image (mathematics)") of the linear map represented by **A**.[[53]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGreub1975Section_III.1-53) The [rank–nullity theorem](https://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem "Rank–nullity theorem") states that the dimension of the [kernel](https://en.wikipedia.org/wiki/Kernel_(matrix) "Kernel (matrix)") of a matrix plus the rank equals the number of columns of the matrix.[[54]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Theorem_II.3.22-54)

A [square matrix](https://en.wikipedia.org/wiki/Square_matrix "Square matrix") is a matrix with the same number of rows and columns. An n-by-n matrix is known as a square matrix of order n. Any two square matrices of the same order can be added and multiplied. The entries a ii form the [main diagonal](https://en.wikipedia.org/wiki/Main_diagonal "Main diagonal") of a square matrix. They lie on the imaginary line running from the top left corner to the bottom right corner of the matrix.[[55]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA27_27]-55)

Square matrices of a given dimension form a [noncommutative ring](https://en.wikipedia.org/wiki/Noncommutative_ring "Noncommutative ring"), which is one of the most common examples of a noncommutative ring.[[56]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEReyes2025-56)

| Name | Example with _n_ = 3 |
| --- | --- |
| [Diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix "Diagonal matrix") | ![Image 113: {\displaystyle {\begin{bmatrix}a_{11}&0&0\\0&a_{22}&0\\0&0&a_{33}\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/58c1cbd586cf9fd90a642b4a7ca5e78e92418557) |
| [Lower triangular matrix](https://en.wikipedia.org/wiki/Lower_triangular_matrix "Lower triangular matrix") | ![Image 114: {\displaystyle {\begin{bmatrix}a_{11}&0&0\\a_{21}&a_{22}&0\\a_{31}&a_{32}&a_{33}\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b0cfe35165701bd0692e6063e5fca0c636b5b905) |
| [Upper triangular matrix](https://en.wikipedia.org/wiki/Upper_triangular_matrix "Upper triangular matrix") | ![Image 115: {\displaystyle {\begin{bmatrix}a_{11}&a_{12}&a_{13}\\0&a_{22}&a_{23}\\0&0&a_{33}\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a33db4eee227aa187ac0a47dfbe1079336bcae86) |

#### Diagonal and triangular matrix

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=15 "Edit section: Diagonal and triangular matrix")]

If all entries of **A** below the main diagonal are zero, **A** is called an _upper [triangular matrix](https://en.wikipedia.org/wiki/Triangular\_matrix "Triangular matrix")_. Similarly, if all entries of **A** above the main diagonal are zero, **A** is called a _lower triangular matrix_.[[57]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA68_68]-57) If all entries outside the main diagonal are zero, **A** is called a [diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix "Diagonal matrix").[[58]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur201191-58)

The _identity matrix_**I**_n_ of size n is the n-by-n matrix in which all the elements on the [main diagonal](https://en.wikipedia.org/wiki/Main_diagonal "Main diagonal") are equal to 1 and all other elements are equal to 0,[[59]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005118-59) for example, ![Image 116: {\displaystyle {\begin{aligned}\mathbf {I} _{1}&={\begin{bmatrix}1\end{bmatrix}},\\[4pt]\mathbf {I} _{2}&={\begin{bmatrix}1&0\\0&1\end{bmatrix}},\\[4pt]\vdots &\\[4pt]\mathbf {I} _{n}&={\begin{bmatrix}1&0&\cdots &0\\0&1&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &1\end{bmatrix}}\end{aligned}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e2f691509cf9deb5416f60f917b8dfc543b1c6d3) It is a square matrix of order n, and also a special kind of [diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix "Diagonal matrix"). It is called an identity matrix because multiplication with it leaves a matrix unchanged:[[59]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005118-59)![Image 117: {\displaystyle {\mathbf {AI}}_{n}={\mathbf {I}}_{m}{\mathbf {A}}={\mathbf {A}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a9f23e8b30561da7e7566d0b4b6f6e2e3ea424d6) for any m-by-n matrix **A**.

A scalar multiple of an identity matrix is called a _scalar_ matrix.[[60]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985%C2%A70.9.1_Diagonal_matrices-60)

#### Symmetric or skew-symmetric matrix

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=17 "Edit section: Symmetric or skew-symmetric matrix")]

A square matrix **A** that is equal to its transpose, that is, **A** = **A**T, is a [symmetric matrix](https://en.wikipedia.org/wiki/Symmetric_matrix "Symmetric matrix"). If instead, **A** is equal to the negative of its transpose, that is, **A** = −**A**T, then **A** is a [skew-symmetric matrix](https://en.wikipedia.org/wiki/Skew-symmetric_matrix "Skew-symmetric matrix"). In complex matrices, symmetry is often replaced by the concept of [Hermitian matrices](https://en.wikipedia.org/wiki/Hermitian_matrix "Hermitian matrix"), which satisfies **A**∗ = **A**, where the star or [asterisk](https://en.wikipedia.org/wiki/Asterisk "Asterisk") denotes the [conjugate transpose](https://en.wikipedia.org/wiki/Conjugate_transpose "Conjugate transpose") of the matrix, that is, the transpose of the [complex conjugate](https://en.wikipedia.org/wiki/Complex_conjugate "Complex conjugate") of **A**.[[61]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005138-61)

By the [spectral theorem](https://en.wikipedia.org/wiki/Spectral_theorem "Spectral theorem"), real symmetric matrices and complex Hermitian matrices have an [eigenbasis](https://en.wikipedia.org/wiki/Eigenbasis "Eigenbasis"); that is, every vector is expressible as a [linear combination](https://en.wikipedia.org/wiki/Linear_combination "Linear combination") of eigenvectors. In both cases, all eigenvalues are real.[[62]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Theorem_2.5.6-62) This theorem can be generalized to infinite-dimensional situations related to matrices with infinitely many rows and columns.[[63]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEConway1990262%E2%80%93263-63)

#### Invertible matrix and its inverse

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=18 "Edit section: Invertible matrix and its inverse")]

A square matrix **A** is called _[invertible](https://en.wikipedia.org/wiki/Invertible\_matrix "Invertible matrix")_ or _non-singular_ if there exists a matrix **B** such that[[64]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_I.2.28-64)[[65]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_I.5.13-65)![Image 118: {\displaystyle {\mathbf {AB}}={\mathbf {BA}}={\mathbf {I}}_{n},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ce3183e5c83ae58ed74e6dea8bf59174800f86f2) where **I**_n_ is the _n_×_n_[identity matrix](https://en.wikipedia.org/wiki/Identity_matrix "Identity matrix") with 1 for each entry on the [main diagonal](https://en.wikipedia.org/wiki/Main_diagonal "Main diagonal") and 0 elsewhere. If **B** exists, it is unique and is called the _[inverse matrix](https://en.wikipedia.org/wiki/Invertible\_matrix "Invertible matrix")_ of **A**, denoted **A**−1.[[66]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA62_62]-66)

There are many [algorithms](https://en.wikipedia.org/wiki/Algorithm "Algorithm") for testing whether a square matrix is invertible, and, if it is, computing its inverse. One of the oldest, which is still in common use is [Gaussian elimination](https://en.wikipedia.org/wiki/Gaussian_elimination "Gaussian elimination").[[67]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur201199%E2%80%93100-67)

| [Positive definite matrix](https://en.wikipedia.org/wiki/Positive_definite_matrix "Positive definite matrix") | [Indefinite matrix](https://en.wikipedia.org/wiki/Indefinite_matrix "Indefinite matrix") |
| --- | --- |
| ![Image 119: {\displaystyle {\begin{bmatrix}{\frac {1}{4}}&0\\0&1\\\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0f6b3f39260b6d0dee463e5765d97348abe2433c) | ![Image 120: {\displaystyle {\begin{bmatrix}{\frac {1}{4}}&0\\0&-{\frac {1}{4}}\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cdcf7cd95e30f375ac7f0bf077507688e78a758a) |
| ![Image 121: {\displaystyle Q(x,y)={\frac {1}{4}}x^{2}+y^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/da7a2535f99b29a4deb6ec7f4e3e1d3494f6e12d) | ![Image 122: {\displaystyle Q(x,y)={\frac {1}{4}}x^{2}-{\frac {1}{4}}y^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8556380d0b0d296c6ac1b3f56b5730429eb04113) |
| [![Image 123](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Ellipse_in_coordinate_system_with_semi-axes_labelled.svg/250px-Ellipse_in_coordinate_system_with_semi-axes_labelled.svg.png)](https://en.wikipedia.org/wiki/File:Ellipse_in_coordinate_system_with_semi-axes_labelled.svg) Points such that ![Image 124: {\textstyle Q(x,y)=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/73a7b404d61be48d4968c117c8cefaf259e838dd) ([Ellipse](https://en.wikipedia.org/wiki/Ellipse "Ellipse")) | [![Image 125](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Hyperbola2_SVG.svg/250px-Hyperbola2_SVG.svg.png)](https://en.wikipedia.org/wiki/File:Hyperbola2_SVG.svg) Points such that ![Image 126: {\textstyle Q(x,y)=1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/73a7b404d61be48d4968c117c8cefaf259e838dd) ([Hyperbola](https://en.wikipedia.org/wiki/Hyperbola "Hyperbola")) |

A symmetric real matrix **A** is called [_positive-definite_](https://en.wikipedia.org/wiki/Positive-definite_matrix "Positive-definite matrix") if the associated [quadratic form](https://en.wikipedia.org/wiki/Quadratic_form "Quadratic form")![Image 127: {\displaystyle f({\mathbf {x}})={\mathbf {x}}^{\rm {T}}{\mathbf {Ax}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2424901a8cf7b01fee4adbba41b4497930367b08) has a positive value for every nonzero vector **x** in ⁠![Image 128: {\displaystyle \mathbb {R} ^{n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c510b63578322050121fe966f2e5770bea43308d)⁠. If _f_(**x**) yields only negative values then **A** is [_negative-definite_](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix#Negative_definite "Definiteness of a matrix"); if f does produce both negative and positive values then **A** is [_indefinite_](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix#Indefinite "Definiteness of a matrix").[[68]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Chapter_7-68) If the quadratic form f yields only non-negative values (positive or zero), the symmetric matrix is called _positive-semidefinite_ (or if only non-positive values, then negative-semidefinite); hence the matrix is indefinite precisely when it is neither positive-semidefinite nor negative-semidefinite.[[69]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010Thm._7.3.2-69)

A symmetric matrix is positive-definite if and only if all its eigenvalues are positive, that is, the matrix is positive-semidefinite and it is invertible.[[70]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Theorem_7.2.1-70) The table at the right shows two possibilities for 2-by-2 matrices. The eigenvalues of a diagonal matrix are simply the entries along the diagonal,[[71]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005150-71) and so in these examples, the eigenvalues can be read directly from the matrices themselves. The first matrix has two eigenvalues that are both positive, while the second has one that is positive and another that is negative.

Allowing as input two different vectors instead yields the [bilinear form](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form") associated to **A**:[[72]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985169Example_4.0.6-72)![Image 129: {\displaystyle B_{\mathbf {A}}({\mathbf {x}},{\mathbf {y}})={\mathbf {x}}^{\rm {T}}{\mathbf {Ay}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5a051ec59e1d36edd416b57f306d96b54811d40e)

In the case of complex matrices, the same terminology and results apply, with _symmetric matrix_, _quadratic form_, _bilinear form_, and _transpose_**x**T replaced respectively by [Hermitian matrix](https://en.wikipedia.org/wiki/Hermitian_matrix "Hermitian matrix"), [Hermitian form](https://en.wikipedia.org/wiki/Hermitian_form "Hermitian form"), [sesquilinear form](https://en.wikipedia.org/wiki/Sesquilinear_form "Sesquilinear form"), and [conjugate transpose](https://en.wikipedia.org/wiki/Conjugate_transpose "Conjugate transpose")**x**H.[[73]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1986Appendix._Complex_numbers-73)

An _orthogonal matrix_ is a square matrix with [real](https://en.wikipedia.org/wiki/Real_number "Real number") entries whose columns and rows are [orthogonal](https://en.wikipedia.org/wiki/Orthogonal "Orthogonal")[unit vectors](https://en.wikipedia.org/wiki/Unit_vector "Unit vector") (that is, [orthonormal](https://en.wikipedia.org/wiki/Orthonormality "Orthonormality") vectors).[[74]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson198566%E2%80%9367-74) Equivalently, a matrix **A** is orthogonal if its [transpose](https://en.wikipedia.org/wiki/Transpose "Transpose") is equal to its [inverse](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix"): ![Image 130: {\displaystyle \mathbf {A} ^{\mathrm {T} }=\mathbf {A} ^{-1},\,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/77f07fbcf3f405d35734fe7d362ec752cec6582b) which entails ![Image 131: {\displaystyle \mathbf {A} ^{\mathrm {T} }\mathbf {A} =\mathbf {A} \mathbf {A} ^{\mathrm {T} }=\mathbf {I} _{n},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7e78d5149a8e1b1ad0708fa65a56aa43879587d0) where **I**_n_ is the [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix "Identity matrix") of size n.[[75]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur2011102%E2%80%93103-75)

An orthogonal matrix **A** is necessarily [invertible](https://en.wikipedia.org/wiki/Invertible_matrix "Invertible matrix") (with inverse **A**−1 = **A**T), [unitary](https://en.wikipedia.org/wiki/Unitary_matrix "Unitary matrix") (**A**−1 = **A***), and [normal](https://en.wikipedia.org/wiki/Normal_matrix "Normal matrix") (**A*****A** = **AA***). The [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") of any orthogonal matrix is either +1 or −1. A _special orthogonal matrix_ is an orthogonal matrix with [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant")+1. As a [linear transformation](https://en.wikipedia.org/wiki/Linear_transformation "Linear transformation"), every orthogonal matrix with determinant +1 is a pure [rotation](https://en.wikipedia.org/wiki/Rotation_(mathematics) "Rotation (mathematics)") without reflection, i.e., the transformation preserves the orientation of the transformed structure, while every orthogonal matrix with determinant −1 reverses the orientation, i.e., is a composition of a pure [reflection](https://en.wikipedia.org/wiki/Reflection_(mathematics) "Reflection (mathematics)") and a (possibly null) rotation. The identity matrices have determinant 1 and are pure rotations by an angle zero.[[76]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005127,_153%E2%80%93154-76)

The [complex](https://en.wikipedia.org/wiki/Complex_number "Complex number") analog of an orthogonal matrix is a [unitary matrix](https://en.wikipedia.org/wiki/Unitary_matrix "Unitary matrix").[[77]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoas2005141-77)

The [trace](https://en.wikipedia.org/wiki/Trace_of_a_matrix "Trace of a matrix"), tr(**A**) of a square matrix **A** is the sum of its diagonal entries. While matrix multiplication is not commutative as mentioned [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#_noncommutative), the trace of the product of two matrices is independent of the order of the factors:[[78]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson198540,_42-78)![Image 132: {\displaystyle \operatorname {tr} (\mathbf {AB} )=\operatorname {tr} (\mathbf {BA} ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/348b05db9499e85326f9e41f5bcb6cf7eb053350) This is immediate from the definition of matrix multiplication:[[79]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1986p._281-79)![Image 133: {\displaystyle \operatorname {tr} (\mathbf {AB} )=\sum _{i=1}^{m}\sum _{j=1}^{n}a_{ij}b_{ji}=\operatorname {tr} (\mathbf {BA} ).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0caa4f820bb74d566e181ba5cf3d09181a2e9cb8) It follows that the trace of the product of more than two matrices is independent of [cyclic permutations](https://en.wikipedia.org/wiki/Cyclic_permutation "Cyclic permutation") of the matrices; however, this does not in general apply for arbitrary permutations. For example, tr(**ABC**) ≠ tr(**BAC**), in general.[[80]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTETang2006226-80) Also, the trace of a matrix is equal to that of its transpose,[[81]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBernstein200994-81) that is, ![Image 134: {\displaystyle \operatorname {tr} ({\mathbf {A}})=\operatorname {tr} ({\mathbf {A}}^{\rm {T}}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/06c85c23ef3930b8eb98802873e47d727ad1ec49)

[![Image 135](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Determinant_example.svg/330px-Determinant_example.svg.png)](https://en.wikipedia.org/wiki/File:Determinant_example.svg)

A linear transformation on ⁠![Image 136: {\displaystyle \mathbb {R} ^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e150115ab9f63023215109595b76686a1ff890fd)⁠ given by the indicated matrix. The determinant of this matrix is −1, as the area of the green parallelogram at the right is 1, but the map reverses the [orientation](https://en.wikipedia.org/wiki/Orientation_(mathematics) "Orientation (mathematics)"), since it turns the counterclockwise orientation of the vectors to a clockwise one.

The _determinant_ of a square matrix **A** (denoted det(**A**) or |**A**|) is a number encoding certain properties of the matrix. A matrix is invertible [if and only if](https://en.wikipedia.org/wiki/If_and_only_if "If and only if") its determinant is nonzero.[[82]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985%C2%A70.5_Nonsingularity-82) Its [absolute value](https://en.wikipedia.org/wiki/Absolute_value "Absolute value") equals the area (in ⁠![Image 137: {\displaystyle \mathbb {R} ^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e150115ab9f63023215109595b76686a1ff890fd)⁠) or volume (in ⁠![Image 138: {\displaystyle \mathbb {R} ^{3}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f936ddf584f8f3dd2a0ed08917001b7a404c10b5)⁠) of the image of the unit square (or cube), while its sign corresponds to the orientation of the corresponding linear map: the determinant is positive if and only if the orientation is preserved.[[83]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMargalitRabinoff2019-83)

The determinant of 2-by-2 matrices is given by[[84]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-:3-84)![Image 139: {\displaystyle \det {\begin{bmatrix}a&b\\c&d\end{bmatrix}}=ad-bc.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8138b2141d7b9406cebd3eb82b3cf05b238ca851) The determinant of 3-by-3 matrices involves 6 terms ([rule of Sarrus](https://en.wikipedia.org/wiki/Rule_of_Sarrus "Rule of Sarrus")). The more lengthy [Leibniz formula](https://en.wikipedia.org/wiki/Leibniz_formula_for_determinants "Leibniz formula for determinants") generalizes these two formulae to all dimensions.[[85]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_III.2.1-85)

The determinant of a product of square matrices equals the product of their determinants: ![Image 140: {\displaystyle \det({\mathbf {AB}})=\det({\mathbf {A}})\cdot \det({\mathbf {B}}),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/41efa7afe8f21c3ccbd03f26ae04e75dd8970157) or using alternate notation:[[86]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Theorem_III.2.12-86)![Image 141: {\displaystyle |{\mathbf {AB}}|=|{\mathbf {A}}|\cdot |{\mathbf {B}}|.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c2c1367abab8f34a3bcea0c4eb1c3751555af3c1) Adding a multiple of any row to another row, or a multiple of any column to another column, does not change the determinant. Interchanging two rows or two columns affects the determinant by multiplying it by −1.[[87]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Corollary_III.2.16-87) Using these operations, any matrix can be transformed to a lower (or upper) triangular matrix, and for such matrices, the determinant equals the product of the entries on the main diagonal; this provides a method to calculate the determinant of any matrix. Finally, the [Laplace expansion](https://en.wikipedia.org/wiki/Laplace_expansion "Laplace expansion") expresses the determinant in terms of [minors](https://en.wikipedia.org/wiki/Minor_(linear_algebra) "Minor (linear algebra)"), that is, determinants of smaller matrices.[[88]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMirsky1990Theorem_1.4.1-88) This expansion can be used for a recursive definition of determinants (taking as starting case the determinant of a 1-by-1 matrix, which is its unique entry, or even the determinant of a 0-by-0 matrix, which is 1), that can be seen to be equivalent to the Leibniz formula. Determinants can be used to solve [linear systems](https://en.wikipedia.org/wiki/Linear_system "Linear system") using [Cramer's rule](https://en.wikipedia.org/wiki/Cramer%27s_rule "Cramer's rule"), where the division of the determinants of two related square matrices equates to the value of each of the system's variables.[[89]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Theorem_III.3.18-89)

#### Eigenvalues and eigenvectors

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=24 "Edit section: Eigenvalues and eigenvectors")]

A number ![Image 142: {\textstyle \lambda }](https://wikimedia.org/api/rest_v1/media/math/render/svg/f801b46dadd4b4d0ba4c6592b232053bd79e080b) and a nonzero vector **v** satisfying ![Image 143: {\displaystyle \mathbf {A} \mathbf {v} =\lambda \mathbf {v} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb4bca75ce898b48e51ff4f79b0a8cc3c53afdee) are called an _eigenvalue_ and an _eigenvector_ of **A**, respectively.[[90]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-90)[[91]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_III.4.1-91) The number λ is an eigenvalue of an _n_×_n_-matrix **A** if and only if (**A** − _λ_**I**_n_) is not invertible, which is [equivalent](https://en.wikipedia.org/wiki/Logical_equivalence "Logical equivalence") to[[92]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Definition_III.4.9-92)![Image 144: {\displaystyle \det(\mathbf {A} -\lambda \mathbf {I} )=0.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c2df8eef1d708ca2a7cfbc4fa8fc10088ddc2b26) The polynomial _p_**A** in an [indeterminate](https://en.wikipedia.org/wiki/Indeterminate_(variable) "Indeterminate (variable)")X given by evaluation of the determinant det(_X_**I**_n_ − **A**) is called the [characteristic polynomial](https://en.wikipedia.org/wiki/Characteristic_polynomial "Characteristic polynomial") of **A**. It is a [monic polynomial](https://en.wikipedia.org/wiki/Monic_polynomial "Monic polynomial") of [degree](https://en.wikipedia.org/wiki/Degree_of_a_polynomial "Degree of a polynomial")n. Therefore the polynomial equation _p_**A**(_λ_) = 0 has at most n different solutions, that is, eigenvalues of the matrix.[[93]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrown1991Corollary_III.4.10-93) They may be complex even if the entries of **A** are real.[[94]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAnton2010[httpsbooksgooglecombooksidypROEAAAQBAJpgPA317_317%E2%80%93319]-94) According to the [Cayley–Hamilton theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem "Cayley–Hamilton theorem"), _p_**A**(**A**) = **0**, that is, the result of substituting the matrix itself into its characteristic polynomial yields the [zero matrix](https://en.wikipedia.org/wiki/Zero_matrix "Zero matrix").[[95]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBernstein2009265-95)

Computational aspects
---------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=25 "Edit section: Computational aspects")]

Matrix calculations can be often performed with different techniques. Many problems can be solved by both direct algorithms and iterative approaches. For example, the eigenvectors of a square matrix can be obtained by finding a [sequence](https://en.wikipedia.org/wiki/Sequence_(mathematics) "Sequence (mathematics)") of vectors **x**_n_[converging](https://en.wikipedia.org/wiki/Limit_of_a_sequence "Limit of a sequence") to an eigenvector when n tends to [infinity](https://en.wikipedia.org/wiki/Infinity "Infinity").[[96]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHouseholder1975Ch._7-96)

To choose the most appropriate algorithm for each specific problem, it is important to determine both the effectiveness and precision of all the available algorithms. The domain studying these matters is called [numerical linear algebra](https://en.wikipedia.org/wiki/Numerical_linear_algebra "Numerical linear algebra").[[97]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBau_IIITrefethen1997-97) As with other numerical situations, two main aspects are the [complexity](https://en.wikipedia.org/wiki/Complexity_analysis "Complexity analysis") of algorithms and their [numerical stability](https://en.wikipedia.org/wiki/Numerical_stability "Numerical stability").

Determining the complexity of an algorithm means finding [upper bounds](https://en.wikipedia.org/wiki/Upper_bound "Upper bound") or estimates of how many elementary operations such as additions and multiplications of scalars are necessary to perform some algorithm, for example, multiplication of matrices. Calculating the matrix product of two n-by-n matrices using the definition given above needs _n_ 3 multiplications, since for any of the _n_ 2 entries of the product, n multiplications are necessary. The [Strassen algorithm](https://en.wikipedia.org/wiki/Strassen_algorithm "Strassen algorithm") outperforms this "naive" algorithm; it needs only _n_ 2.807 multiplications.[[98]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGolubVan_Loan1996Algorithm_1.3.1-98) Theoretically faster but impractical [matrix multiplication algorithms](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm "Matrix multiplication algorithm") have been developed,[[99]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEVassilevska_WilliamsXuXuZhou2024-99) as have speedups to this problem using [parallel algorithms](https://en.wikipedia.org/wiki/Parallel_algorithm "Parallel algorithm") or [distributed computation](https://en.wikipedia.org/wiki/Distributed_computation "Distributed computation") systems such as [MapReduce](https://en.wikipedia.org/wiki/MapReduce "MapReduce").[[100]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMisraBhattacharyaGhosh2022-100)

In many practical situations, additional information about the matrices involved is known. An important case concerns [sparse matrices](https://en.wikipedia.org/wiki/Sparse_matrix "Sparse matrix"), that is, matrices whose entries are mostly zero. There are specifically adapted algorithms for, say, solving linear systems **Ax** = **b** for sparse matrices **A**, such as the [conjugate gradient method](https://en.wikipedia.org/wiki/Conjugate_gradient_method "Conjugate gradient method").[[101]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGolubVan_Loan1996Chapters_9_and_10,_esp._section_10.2-101)

An algorithm is, roughly speaking, numerically stable if little deviations in the input values do not lead to big deviations in the result. For example, one can calculate the inverse of a matrix by computing its [adjugate matrix](https://en.wikipedia.org/wiki/Adjugate_matrix "Adjugate matrix"): ![Image 145: {\displaystyle {\mathbf {A}}^{-1}=\operatorname {adj} ({\mathbf {A}})/\det({\mathbf {A}}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/441d74fd6a4a420b15c24cd8b34352af0e6fa474) However, this may lead to significant rounding errors if the determinant of the matrix is very small. The [norm of a matrix](https://en.wikipedia.org/wiki/Matrix_norm "Matrix norm") can be used to capture the [conditioning](https://en.wikipedia.org/wiki/Condition_number "Condition number") of linear algebraic problems, such as computing a matrix's inverse.[[102]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGolubVan_Loan1996Chapter_2.3-102)

There are several methods to render matrices into a more easily accessible form. They are generally referred to as _matrix decomposition_ or _matrix factorization_ techniques. These techniques are of interest because they can make computations easier.

The [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition "LU decomposition") factors matrices as a product of lower (**L**) and an upper [triangular matrices](https://en.wikipedia.org/wiki/Triangular_matrix "Triangular matrix") (**U**).[[103]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPressFlanneryTeukolskyVetterling1992-103) Once this decomposition is calculated, linear systems can be solved more efficiently by a simple technique called [forward and back substitution](https://en.wikipedia.org/wiki/Forward_substitution "Forward substitution"). Likewise, inverses of triangular matrices are algorithmically easier to calculate. The _Gaussian elimination_ is a similar algorithm; it transforms any matrix to [row echelon form](https://en.wikipedia.org/wiki/Row_echelon_form "Row echelon form").[[104]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEStoerBulirsch2002Section_4.1-104) Both methods proceed by multiplying the matrix by suitable [elementary matrices](https://en.wikipedia.org/wiki/Elementary_matrix "Elementary matrix"), which correspond to [permuting rows or columns](https://en.wikipedia.org/wiki/Permutation_matrix "Permutation matrix") and adding multiples of one row to another row. [Singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition "Singular value decomposition") (SVD) expresses any matrix **A** as a product **UDV**∗, where **U** and **V** are [unitary matrices](https://en.wikipedia.org/wiki/Unitary_matrix "Unitary matrix") and **D** is a diagonal matrix.[[105]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGbur2011146%E2%80%93153-105)

[![Image 146](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Jordan_blocks.svg/250px-Jordan_blocks.svg.png)](https://en.wikipedia.org/wiki/File:Jordan_blocks.svg)

An example of a matrix in Jordan normal form. The grey blocks are called Jordan blocks.

The [eigendecomposition](https://en.wikipedia.org/wiki/Eigendecomposition "Eigendecomposition") or _diagonalization_ expresses **A** as a product **VDV**−1, where **D** is a diagonal matrix and **V** is a suitable invertible matrix.[[106]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Theorem_2.5.4-106) If **A** can be written in this form, it is called [diagonalizable](https://en.wikipedia.org/wiki/Diagonalizable_matrix "Diagonalizable matrix"). More generally, and applicable to all matrices, the Jordan decomposition transforms a matrix into [Jordan normal form](https://en.wikipedia.org/wiki/Jordan_normal_form "Jordan normal form"), that is to say matrices whose only nonzero entries are the eigenvalues _λ_ 1 to λ n of **A**, placed on the main diagonal and possibly entries equal to one directly above the main diagonal, as shown at the right.[[107]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson1985Ch._3.1,_3.2-107) Given the eigendecomposition, the n th power of **A** (that is, n-fold iterated matrix multiplication) can be calculated via ![Image 147: {\displaystyle {\mathbf {A}}^{n}=({\mathbf {VDV}}^{-1})^{n}={\mathbf {VDV}}^{-1}{\mathbf {VDV}}^{-1}\ldots {\mathbf {VDV}}^{-1}={\mathbf {VD}}^{n}{\mathbf {V}}^{-1}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/15d88bd4917acd685a3648d0769cce69493d5ef4) and the power of a diagonal matrix can be calculated by taking the corresponding powers of the diagonal entries, which is much easier than doing the exponentiation for **A** instead. This can be used to compute the [matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential "Matrix exponential")_e_**A**, a need frequently arising in solving [linear differential equations](https://en.wikipedia.org/wiki/Linear_differential_equation "Linear differential equation"), [matrix logarithms](https://en.wikipedia.org/wiki/Matrix_logarithm "Matrix logarithm") and [square roots of matrices](https://en.wikipedia.org/wiki/Square_root_of_a_matrix "Square root of a matrix").[[108]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEArnold1992Sections_14.5,_7,_8-108) To avoid numerically [ill-conditioned](https://en.wikipedia.org/wiki/Condition_number "Condition number") situations, further algorithms such as the [Schur decomposition](https://en.wikipedia.org/wiki/Schur_decomposition "Schur decomposition") can be employed.[[109]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBronson1989Ch._15-109)

Abstract algebraic aspects and generalizations
----------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=27 "Edit section: Abstract algebraic aspects and generalizations")]

Matrices can be generalized in different ways. Abstract algebra uses matrices with entries in more general [fields](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)") or even [rings](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)"), while linear algebra codifies properties of matrices in the notion of linear maps. It is possible to consider matrices with infinitely many columns and rows. Another extension is [tensors](https://en.wikipedia.org/wiki/Tensor "Tensor"), which can be seen as higher-dimensional arrays of numbers, as opposed to vectors, which can often be realized as sequences of numbers, while matrices are rectangular or two-dimensional arrays of numbers.[[110]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECoburn1955Ch._V-110) Matrices, subject to certain requirements tend to form [groups](https://en.wikipedia.org/wiki/Group_(mathematics) "Group (mathematics)") known as matrix groups.[[111]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTETapp2016-111) Similarly under certain conditions matrices form [rings](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)") known as [matrix rings](https://en.wikipedia.org/wiki/Matrix_ring "Matrix ring").[[112]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELam1999461%E2%80%93470Chapter_7,_%C2%A717_Matrix_Rings,_%C2%A717A_Characterization_and_Examples-112) Though the product of matrices is not in general commutative, certain matrices form [fields](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)") sometimes called matrix fields.[[113]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHachenbergerJungnickel2020[httpsbooksgooglecombooksidiSAAEAAAQBAJpgPA302_302]Definition_7.2.1-113) (However the term "matrix field" is ambiguous, also referring to certain forms of physical [fields](https://en.wikipedia.org/wiki/Field_(physics) "Field (physics)") that continuously map points of some space to matrices.[[114]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEYdri2016-114)) In general, matrices over any ring and their [multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication "Matrix multiplication") can be represented as the arrows and composition of arrows in a [category](https://en.wikipedia.org/wiki/Category_(mathematics) "Category (mathematics)"), the [category of matrices](https://en.wikipedia.org/wiki/Category_of_matrices "Category of matrices") over that ring. The objects of this category are natural numbers, representing the dimensions of the matrices.[[115]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTERiehl2016[httpsbooksgooglecombooksid6B9MDgAAQBAJpgPA4_4-6]-115)

### Matrices with entries in a field or ring

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=28 "Edit section: Matrices with entries in a field or ring")]

This article focuses on matrices whose entries are real or complex numbers. However, matrices can be considered with much more general types of entries than real or complex numbers. As a first step of generalization, any [field](https://en.wikipedia.org/wiki/Field_(mathematics) "Field (mathematics)"), that is, a [set](https://en.wikipedia.org/wiki/Set_(mathematics) "Set (mathematics)") where [addition](https://en.wikipedia.org/wiki/Addition "Addition"), [subtraction](https://en.wikipedia.org/wiki/Subtraction "Subtraction"), [multiplication](https://en.wikipedia.org/wiki/Multiplication "Multiplication"), and [division](https://en.wikipedia.org/wiki/Division_(mathematics) "Division (mathematics)") operations are defined and well-behaved, may be used instead of ⁠![Image 148: {\displaystyle \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/786849c765da7a84dbc3cce43e96aad58a5868dc)⁠ or ⁠![Image 149: {\displaystyle \mathbb {C} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/f9add4085095b9b6d28d045fd9c92c2c09f549a7)⁠, for example [rational numbers](https://en.wikipedia.org/wiki/Rational_number "Rational number") or [finite fields](https://en.wikipedia.org/wiki/Finite_field "Finite field"). For example, [coding theory](https://en.wikipedia.org/wiki/Coding_theory "Coding theory") makes use of matrices over finite fields.[[116]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTERoth2006[httpsbooksgooglecombooksidfk7u8awR0hICpgPA27_27]-116) Wherever [eigenvalues](https://en.wikipedia.org/wiki/Eigenvalue "Eigenvalue") are considered, as these are roots of a polynomial, they may exist only in a larger field than that of the entries of the matrix. For instance, they may be complex in the case of a matrix with real entries. The possibility to reinterpret the entries of a matrix as elements of a larger field (for example, to view a real matrix as a complex matrix whose entries happen to be all real) then allows considering each square matrix to possess a full set of eigenvalues.[[117]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEChahal2018[httpsbooksgooglecombooksidZIqADwAAQBAJpgPA115_115%E2%80%93116]-117) Alternatively one can consider only matrices with entries in an [algebraically closed field](https://en.wikipedia.org/wiki/Algebraically_closed_field "Algebraically closed field"), such as ⁠![Image 150: {\displaystyle \mathbb {C} ,}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c6ff6a3dc2982018ff20f1d2c927afc74a217be6)⁠ from the outset.[[118]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMeckesMeckes2018[httpsbooksgooglecombooksidwK1XDwAAQBAJpgPA360_360%E2%80%93361]-118)

Matrices whose entries are [polynomials](https://en.wikipedia.org/wiki/Polynomial "Polynomial"),[[119]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEEdwards2004[httpsbooksgooglecombooksidylFR4h5BIDECpgPA80_80]-119) and more generally, matrices with entries in a [ring](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)")R are widely used in mathematics.[[1]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang2002Chapter_XIII-1) Rings are a more general notion than fields in that a division operation need not exist. The very same addition and multiplication operations of matrices extend to this setting, too. The set M(_n_, _R_) (also denoted M _n_(R)[[15]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPopFurdui2017-15)) of all square n-by-n matrices over R is a ring called [matrix ring](https://en.wikipedia.org/wiki/Matrix_ring "Matrix ring"), isomorphic to the [endomorphism ring](https://en.wikipedia.org/wiki/Endomorphism_ring "Endomorphism ring") of the left R-[module](https://en.wikipedia.org/wiki/Module_(mathematics) "Module (mathematics)")R n.[[120]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang2002643XVII.1-120) If the ring R is [commutative](https://en.wikipedia.org/wiki/Commutative_ring "Commutative ring"), that is, its multiplication is commutative, then the ring M(_n_, _R_) is also an [associative algebra](https://en.wikipedia.org/wiki/Associative_algebra "Associative algebra") over _R_. The [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant") of square matrices over a commutative ring R can still be defined using the [Leibniz formula](https://en.wikipedia.org/wiki/Leibniz_formula_(determinant) "Leibniz formula (determinant)"); such a matrix is invertible if and only if its determinant is [invertible](https://en.wikipedia.org/wiki/Invertible "Invertible") in R, generalizing the situation over a field F, where every nonzero element is invertible.[[121]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang2002Proposition_XIII.4.16-121) Matrices over [superrings](https://en.wikipedia.org/wiki/Superring "Superring") are called [supermatrices](https://en.wikipedia.org/wiki/Supermatrix "Supermatrix").[[122]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEReichl2004Section_L.2-122)

Matrices do not always have all their entries in the same ring– or even in any ring at all. One special but common case is [block matrices](https://en.wikipedia.org/wiki/Block_matrix "Block matrix"), which may be considered as matrices whose entries themselves are matrices. The entries need not be square matrices, and thus need not be members of any [ring](https://en.wikipedia.org/wiki/Ring_(mathematics) "Ring (mathematics)"); but in order to multiply them, their sizes must fulfill certain conditions: each pair of submatrices that are multiplied in forming the overall product must have compatible sizes.[[123]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEJeffrey2010[httpsbooksgooglecombooksiduan0Dkn9HY8CpgPA54_54ff]3.7_Partitioning_of_matrices-123)

### Relationship to linear maps

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=29 "Edit section: Relationship to linear maps")]

Linear maps ![Image 151: {\displaystyle \mathbb {R} ^{n}\to \mathbb {R} ^{m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/cccdefd5f0e00fc2fa5fde2d8cbb039cc408a035) are equivalent to m-by-n matrices, as described [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#linear_maps). More generally, any linear map _f_ : _V_ → _W_ between finite-[dimensional](https://en.wikipedia.org/wiki/Hamel_dimension "Hamel dimension")[vector spaces](https://en.wikipedia.org/wiki/Vector_space "Vector space") can be described by a matrix **A** = (_a ij_), after choosing [bases](https://en.wikipedia.org/wiki/Basis_(linear_algebra) "Basis (linear algebra)")**v**1, ..., **v**_n_ of V, and **w**1, ..., **w**_m_ of W (so n is the dimension of V and m is the dimension of W), which is such that ![Image 152: {\displaystyle f(\mathbf {v} _{j})=\sum _{i=1}^{m}a_{i,j}\mathbf {w} _{i}\qquad {\mbox{for}}\ j=1,\ldots ,n.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7b8cc99fbe2677739b89586fcc5ff568c8bae2c8) In other words, column j of **A** expresses the image of **v**_j_ in terms of the basis vectors **w**_i_ of W; thus this relation uniquely determines the entries of the matrix **A**. The matrix depends on the choice of the bases: different choices of bases give rise to different, but [equivalent matrices](https://en.wikipedia.org/wiki/Matrix_equivalence "Matrix equivalence").[[124]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGreub1975Section_III.3-124) Many of the above concrete notions can be reinterpreted in this light, for example, the transpose matrix **A**T describes the [transpose of the linear map](https://en.wikipedia.org/wiki/Transpose_of_a_linear_map "Transpose of a linear map") given by **A**, concerning the [dual bases](https://en.wikipedia.org/wiki/Dual_space "Dual space").[[125]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGreub1975Section_III.3.13-125)

These properties can be restated more naturally: the [category of matrices](https://en.wikipedia.org/wiki/Category_of_matrices "Category of matrices") with entries in a field ![Image 153: {\displaystyle k}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40) with multiplication as composition is [equivalent](https://en.wikipedia.org/wiki/Equivalence_of_categories "Equivalence of categories") to the category of finite-dimensional [vector spaces](https://en.wikipedia.org/wiki/Vector_space "Vector space") and linear maps over this field.[[126]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPerrone202499%E2%80%93100-126)

More generally, the set of _m_×_n_ matrices can be used to represent the R-linear maps between the free modules R m and R n for an arbitrary ring R with unity. When _n_ = _m_ composition of these maps is possible, and this gives rise to the [matrix ring](https://en.wikipedia.org/wiki/Matrix_ring "Matrix ring") of _n_×_n_ matrices representing the [endomorphism ring](https://en.wikipedia.org/wiki/Endomorphism_ring "Endomorphism ring") of R n.[[127]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHungerford1980328%E2%80%93335VII.1:_Matrices_and_maps-127)

A [group](https://en.wikipedia.org/wiki/Group_(mathematics) "Group (mathematics)") is a mathematical structure consisting of a set of objects together with a [binary operation](https://en.wikipedia.org/wiki/Binary_operation "Binary operation"), that is, an operation combining any two objects to a third, subject to certain requirements.[[128]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHornJohnson198569-128) A group in which the objects are matrices and the group operation is matrix multiplication is called a _matrix group_.[[129]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-129)[[130]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBaker2003Def._1.30-130) All invertible matrices of a given size form a matrix group, called a [general linear group](https://en.wikipedia.org/wiki/General_linear_group "General linear group"). Since every element of a matrix group must be invertible, the general linear groups are the most general matrix groups, in the sense that every matrix group is a subgroup of a general linear group.[[131]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECameron2014-131)

Any property of matrices that is preserved under matrix products and inverses can be used to define further matrix groups. For example, matrices with a given size and with a determinant of 1 form a [subgroup](https://en.wikipedia.org/wiki/Subgroup "Subgroup") of (that is, a smaller group contained in) their general linear group, called a [special linear group](https://en.wikipedia.org/wiki/Special_linear_group "Special linear group").[[132]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBaker2003Theorem_1.2-132)[Orthogonal matrices](https://en.wikipedia.org/wiki/Orthogonal_matrix "Orthogonal matrix"), determined by the condition ![Image 154: {\displaystyle {\mathbf {M}}^{\rm {T}}{\mathbf {M}}={\mathbf {I}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b577e4937fe3414e4fba9fc3830728eb75accb22) form the [orthogonal group](https://en.wikipedia.org/wiki/Orthogonal_group "Orthogonal group").[[133]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEArtin1991Chapter_4.5-133) Every orthogonal matrix has [determinant](https://en.wikipedia.org/wiki/Determinant "Determinant")1 or −1. Orthogonal matrices with determinant 1 form a subgroup called the _special orthogonal group_.[[134]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTESerre2007[httpsbooksgooglecombooksidvY_xBwAAQBAJpgPA20_20]-134)

Every [finite group](https://en.wikipedia.org/wiki/Finite_group "Finite group") is [isomorphic](https://en.wikipedia.org/wiki/Isomorphic "Isomorphic") to a matrix group, as one can see by considering the [regular representation](https://en.wikipedia.org/wiki/Regular_representation "Regular representation") of the [symmetric group](https://en.wikipedia.org/wiki/Symmetric_group "Symmetric group").[[135]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTERowen2008198Example_19.2-135) General groups can be studied using matrix groups, which are comparatively well understood, using [representation theory](https://en.wikipedia.org/wiki/Representation_theory "Representation theory").[[136]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-136)

It is also possible to consider matrices with infinitely many rows and columns.[[137]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-137) The basic operations introduced above are defined the same way in this case. Matrix multiplication, however, and all operations stemming therefrom are only meaningful when restricted to certain matrices, since the [sum featuring in the above definition](https://en.wikipedia.org/wiki/Matrix_(mathematics)#matrix_product) of the matrix product will contain an infinity of summands.[[138]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBoos2000[httpsbooksgooglecombooksidkZ9cy6XyidECpgPA34_34%E2%80%9339]2.2_Dealing_with_infinite_matrices-138) An easy way to circumvent this issue is to restrict to _finitary matrices_ all of whose rows (or columns) contain only finitely many nonzero terms.[[139]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGrillet2007[httpsbooksgooglecombooksidLJtyhu8-xYwCpgPA334_334]-139) As in the finite case (see [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#linear_maps)), where matrices describe linear maps, infinite matrices can be used to describe [operators on Hilbert spaces](https://en.wikipedia.org/wiki/Hilbert_space#Operators_on_Hilbert_spaces "Hilbert space"), where convergence and [continuity](https://en.wikipedia.org/wiki/Continuous_function "Continuous function") questions arise. However, the explicit point of view of matrices tends to obfuscate the matter,[[140]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-140) and the abstract and more powerful tools of [functional analysis](https://en.wikipedia.org/wiki/Functional_analysis "Functional analysis") are used instead, by relating matrices to linear maps (as in the finite case [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#linear_maps)), but imposing additional convergence and continuity constraints.

An _empty matrix_ is a matrix in which the number of rows or columns (or both) is zero.[[141]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-141)[[8]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-empty-8) Empty matrices can be a useful [base case](https://en.wikipedia.org/wiki/Base_case_(recursion) "Base case (recursion)") for certain [recursive](https://en.wikipedia.org/wiki/Recursion "Recursion") constructions,[[142]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEColemanVan_Loan1988[httpsbooksgooglecombooksidzUh9I2mSKxgCpgPA213_213]-142) and can help to deal with maps involving the [zero vector space](https://en.wikipedia.org/wiki/Zero_vector_space "Zero vector space").[[143]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHazewinkelGubareni2017[httpbooksgooglecombooksid5w6lDgAAQBAJpgPA151_151]-143) For example, if **A** is a 3-by-0 matrix and **B** is a 0-by-3 matrix, then **AB** is the 3-by-3 [zero matrix](https://en.wikipedia.org/wiki/Zero_matrix "Zero matrix") corresponding to the null map from a 3-dimensional space V to itself, while **BA** is a 0-by-0 matrix. There is no common notation for empty matrices, but most [computer algebra systems](https://en.wikipedia.org/wiki/Computer_algebra_system "Computer algebra system") allow creating and computing with them.[[144]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-144) The determinant of the 0-by-0 matrix is conventionally defined to be 1, consistent with the [empty product](https://en.wikipedia.org/wiki/Empty_product "Empty product") occurring in the Leibniz formula for the determinant.[[145]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWest2020[httpsbooksgooglecombooksid0-3vDwAAQBAJpgPA750_750]-145) This value is also needed for consistency with the ![Image 155: {\displaystyle 2\times 2}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f8a0e3400ffb97d67c00267ed50cddfe824cbe80) case of the [Desnanot–Jacobi identity](https://en.wikipedia.org/wiki/Desnanot%E2%80%93Jacobi_identity "Desnanot–Jacobi identity") relating determinants to the determinants of smaller matrices.[[146]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBrualdiCarmonavan_den_DriesscheKirkland2018[httpsbooksgooglecombooksidLMRTDwAAQBAJpgPA19_19]-146)

### Matrices with entries in a semiring

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=33 "Edit section: Matrices with entries in a semiring")]

A [semiring](https://en.wikipedia.org/wiki/Semiring "Semiring") is similar to a ring, but elements need not have [additive inverses](https://en.wikipedia.org/wiki/Additive_inverse "Additive inverse"), therefore one cannot do subtraction freely there. The definition of addition and multiplication of matrices with entries in a ring applies to matrices with entries in a semiring without modification. Matrices of fixed size with entries in a semiring form a [commutative monoid](https://en.wikipedia.org/wiki/Commutative_monoid "Commutative monoid")![Image 156: {\displaystyle \operatorname {Mat} (m,n;R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ac711c4052d893e23d11c15600663ed800018f82) under addition.[[147]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEFaridKhanWang20132087-147) Square matrices of fixed size with entries in a semiring form a semiring ![Image 157: {\displaystyle \operatorname {Mat} (n;R)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/91e9f24a35d629b7bc279a9565e553b1893523d3) under addition and multiplication.[[147]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEFaridKhanWang20132087-147)

The determinant of an ![Image 158: {\displaystyle n\times n}](https://wikimedia.org/api/rest_v1/media/math/render/svg/59d2b4cb72e304526cf5b5887147729ea259da78) square matrix ![Image 159: {\displaystyle M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd) with entries in a [commutative semiring](https://en.wikipedia.org/wiki/Commutative_semiring "Commutative semiring")![Image 160: {\displaystyle R}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4b0bfb3769bf24d80e15374dc37b0441e2616e33) cannot be defined in general because the definition would involve additive inverses of semiring elements. What plays its role instead is the pair of positive and negative determinants

![Image 161: {\displaystyle \det \nolimits _{+}M=\sum _{\sigma \in \operatorname {Alt} (n)}M_{1\sigma (1)}\cdots M_{n\sigma (n)}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b5ff7312b30d952b7622993d46603a55d907c173)![Image 162: {\displaystyle \det \nolimits _{-}M=\sum _{\sigma \in \operatorname {Sym} (n)\setminus \operatorname {Alt} (n)}M_{1\sigma (1)}\cdots M_{n\sigma (n)}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/82671c586ff27ce767fcccc7c6b10244ebae52a4)
where the sums are taken over [even permutations](https://en.wikipedia.org/wiki/Even_permutation "Even permutation") and odd permutations, respectively.[[148]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEReutenauerStraubing1984351-148)[[149]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGhosh1996222-149)

### Matrices with entries in a category

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=34 "Edit section: Matrices with entries in a category")]

Matrices and their multiplication can be defined with entries objects of a [category](https://en.wikipedia.org/wiki/Category_(mathematics) "Category (mathematics)") equipped with a "[tensor product](https://en.wikipedia.org/wiki/Monoidal_category "Monoidal category")" similar to multiplication in a ring, having [coproducts](https://en.wikipedia.org/wiki/Coproduct "Coproduct") similar to addition in a ring, in that the former is [distributive](https://en.wikipedia.org/wiki/Distributive_property "Distributive property") over the latter.[[150]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECarboniKasangianWalters1987137-150) However, the multiplication thus defined may be only associative in a sense weaker than usual. These are part of a bigger structure called the _bicategory of matrices_. The complete description of the above summary for interested readers follows.

Let ![Image 163: {\displaystyle ({\mathcal {C}},\otimes ,I)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d86684cbfac7c83f9727235ed8024115c2f655b8) be a [monoidal category](https://en.wikipedia.org/wiki/Monoidal_category "Monoidal category") satisfying the following two conditions:

Then, the [bicategory](https://en.wikipedia.org/wiki/Bicategory "Bicategory") of ![Image 164: {\displaystyle {\mathcal {C}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e7b3edab7022ca9e2976651bc59c489513ee9019)-matrices ![Image 165: {\displaystyle \operatorname {Mat} ({\mathcal {C}})}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aa1cb29b35c2ed3568f9a642b2bba84bc9fa7110) is as follows:[[150]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECarboniKasangianWalters1987137-150)

In general, the bicategory of matrices need not be a strict [2-category](https://en.wikipedia.org/wiki/2-category "2-category"). For example, the composition of 1-morphisms may not be associative in the usual strict sense, but only up to [coherent](https://en.wikipedia.org/wiki/Coherency_(homotopy_theory) "Coherency (homotopy theory)") isomorphism.

There are numerous applications of matrices, both in mathematics and other sciences. Some of them merely take advantage of the compact representation of a set of numbers in a matrix. For example, [Text mining](https://en.wikipedia.org/wiki/Text_mining "Text mining") and automated [thesaurus](https://en.wikipedia.org/wiki/Thesaurus "Thesaurus") compilation makes use of [document-term matrices](https://en.wikipedia.org/wiki/Document-term_matrix "Document-term matrix") such as [tf-idf](https://en.wikipedia.org/wiki/Tf-idf "Tf-idf") to track frequencies of certain words in several documents.[[151]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEManningSch%C3%BCtze1999Section_15.3.4-151)

Complex numbers can be represented by particular real 2-by-2 matrices via ![Image 166: {\displaystyle a+ib\leftrightarrow {\begin{bmatrix}a&-b\\b&a\end{bmatrix}},}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a953f9863f7860c1a4d31a6db5ab251b96050670) under which addition and multiplication of complex numbers and matrices correspond to each other. For example, 2-by-2 rotation matrices represent the multiplication with some complex number of [absolute value](https://en.wikipedia.org/wiki/Absolute_value "Absolute value") 1, as [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#rotation_matrix). A similar interpretation is possible for [quaternions](https://en.wikipedia.org/wiki/Quaternion "Quaternion")[[152]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWard1997Ch._2.8-152) and [Clifford algebras](https://en.wikipedia.org/wiki/Clifford_algebra "Clifford algebra") in general.[[153]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEAb%C5%82amowicz2000[httpsbooksgooglecombooksidyvCC94xzJG8CpgPA436_436]-153)

In [game theory](https://en.wikipedia.org/wiki/Game_theory "Game theory") and [economics](https://en.wikipedia.org/wiki/Economics "Economics"), the [payoff matrix](https://en.wikipedia.org/wiki/Payoff_matrix "Payoff matrix") encodes the payoff for two players, depending on which out of a given (finite) set of strategies the players choose.[[154]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEFudenbergTirole1983Section_1.1.1-154) The expected outcome of the game, when both players play [mixed strategies](https://en.wikipedia.org/wiki/Mixed_strategy "Mixed strategy"), is obtained by multiplying this matrix on both sides by vectors representing the strategies.[[155]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMcHugh2025[httpsbooksgooglecombooksidU9slEQAAQBAJpgPA390_390]11.2.3_The_expected_payoff_as_a_vector%E2%80%93matrix%E2%80%93vector_product-155) The [minimax theorem](https://en.wikipedia.org/wiki/Minimax_theorem "Minimax theorem") central to game theory is closely related to the [duality theory of linear programs](https://en.wikipedia.org/wiki/Dual_linear_program "Dual linear program"), which are often formulated in terms of matrix-vector products.[[156]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMatou%C5%A1ekG%C3%A4rtner2007[httpsbooksgooglecombooksid6MO_RS4z0w8CpgPA136_136%E2%80%93137]-156)

Early [encryption](https://en.wikipedia.org/wiki/Encryption "Encryption") techniques such as the [Hill cipher](https://en.wikipedia.org/wiki/Hill_cipher "Hill cipher") also used matrices. However, due to the linear nature of matrices, these codes are comparatively easy to break.[[157]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEStinson2005Ch._1.1.5_and_1.2.4-157)[Computer graphics](https://en.wikipedia.org/wiki/Computer_graphics "Computer graphics") uses matrices to represent objects; to calculate transformations of objects using affine [rotation matrices](https://en.wikipedia.org/wiki/Rotation_matrix "Rotation matrix") to accomplish tasks such as projecting a three-dimensional object onto a two-dimensional screen, corresponding to a theoretical camera observation; and to apply image convolutions such as sharpening, blurring, edge detection, and more.[[158]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEISRD_Group2005Ch._7-158) Matrices over a [polynomial ring](https://en.wikipedia.org/wiki/Polynomial_ring "Polynomial ring") are important in the study of [control theory](https://en.wikipedia.org/wiki/Control_theory "Control theory").[[159]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBhayaKaszkurewicz2006[httpsbooksgooglecombooksid3X7S_965jywCpgPA230_230]-159)

[Chemistry](https://en.wikipedia.org/wiki/Chemistry "Chemistry") makes use of matrices in various ways, particularly since the use of [quantum theory](https://en.wikipedia.org/wiki/Quantum_mechanics "Quantum mechanics") to discuss [molecular bonding](https://en.wikipedia.org/wiki/Chemical_bond "Chemical bond") and [spectroscopy](https://en.wikipedia.org/wiki/Spectroscopy "Spectroscopy"). Examples are the [overlap matrix](https://en.wikipedia.org/wiki/Overlap_matrix "Overlap matrix") and the [Fock matrix](https://en.wikipedia.org/wiki/Fock_matrix "Fock matrix") used in solving the [Roothaan equations](https://en.wikipedia.org/wiki/Roothaan_equations "Roothaan equations") to obtain the [molecular orbitals](https://en.wikipedia.org/wiki/Molecular_orbital "Molecular orbital") of the [Hartree–Fock method](https://en.wikipedia.org/wiki/Hartree%E2%80%93Fock_method "Hartree–Fock method").[[160]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEJensen1999[httpsarchiveorgdetailsintroductiontoco0000jenspage65mode2upqmatrix_65%E2%80%9369]-160)

[![Image 167](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Labelled_undirected_graph.svg/150px-Labelled_undirected_graph.svg.png)](https://en.wikipedia.org/wiki/File:Labelled_undirected_graph.svg)

An undirected graph with adjacency matrix: ![Image 168: {\displaystyle {\begin{bmatrix}1&1&0\\1&0&1\\0&1&0\end{bmatrix}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f51425c53fc279038a1da01e1cece5958d13149b)

The [adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix "Adjacency matrix") of a [finite graph](https://en.wikipedia.org/wiki/Finite_graph "Finite graph") is a basic notion of [graph theory](https://en.wikipedia.org/wiki/Graph_theory "Graph theory").[[161]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGodsilRoyle2004Ch._8.1-161) It records which vertices of the graph are connected by an edge. Matrices containing just two different values (1 and 0 meaning for example "yes" and "no", respectively) are called [logical matrices](https://en.wikipedia.org/wiki/Logical_matrix "Logical matrix"). The [distance (or cost) matrix](https://en.wikipedia.org/wiki/Distance_matrix "Distance matrix") contains information about the distances of the edges.[[162]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPunnenGutin2002-162) These concepts can be applied to [websites](https://en.wikipedia.org/wiki/Website "Website") connected by [hyperlinks](https://en.wikipedia.org/wiki/Hyperlink "Hyperlink"),[[163]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEZhangYuHou2006[httpbooksgooglecombooksid0xhra9vKCnUCpgPA7_7]-163) or cities connected by roads etc., in which case (unless the connection network is extremely dense) the matrices tend to be [sparse](https://en.wikipedia.org/wiki/Sparse_matrix "Sparse matrix"), that is, contain few nonzero entries. Therefore, specifically tailored matrix algorithms can be used in [network theory](https://en.wikipedia.org/wiki/Network_theory "Network theory").[[164]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEScottT%C5%AFma2023-164)

### Analysis and geometry

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=37 "Edit section: Analysis and geometry")]

The [Hessian matrix](https://en.wikipedia.org/wiki/Hessian_matrix "Hessian matrix") of a [differentiable function](https://en.wikipedia.org/wiki/Differentiable_function "Differentiable function")![Image 169: {\displaystyle f:\mathbb {R} ^{n}\to \mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/306c097f43c91dce633d12cde024948d39e73752) consists of the [second derivatives](https://en.wikipedia.org/wiki/Second_derivative "Second derivative") of ƒ concerning the several coordinate directions, that is,[[165]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1987Ch._XVI.6-165)![Image 170: {\displaystyle H(f)=\left[{\frac {\partial ^{2}f}{\partial x_{i}\,\partial x_{j}}}\right].}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9cf91a060a82dd7a47c305e9a4c2865378fcf35f)

[![Image 171](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Saddle_Point_SVG.svg/250px-Saddle_Point_SVG.svg.png)](https://en.wikipedia.org/wiki/File:Saddle_Point_SVG.svg)

At the [saddle point](https://en.wikipedia.org/wiki/Saddle_point "Saddle point")(_x_ = 0, _y_ = 0) (red) of the function _f_ (_x_,−_y_) = _x_ 2 − _y_ 2, the Hessian matrix ![Image 172: {\displaystyle {\begin{bmatrix}2&0\\0&-2\end{bmatrix}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fd987cfcc4338b2c3319323e7a73182e09215d09) is [indefinite](https://en.wikipedia.org/wiki/Indefinite_matrix "Indefinite matrix").

It encodes information about the local growth behavior of the function: given a [critical point](https://en.wikipedia.org/wiki/Critical_point_(mathematics) "Critical point (mathematics)")**x** = (_x_ 1, ..., _x n_), that is, a point where the first [partial derivatives](https://en.wikipedia.org/wiki/Partial_derivative "Partial derivative")![Image 173: {\displaystyle \partial f/\partial x_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2c4abc6fa2414772b9c4e03b6c6e5d0516eaf4f3) of f vanish, the function has a [local minimum](https://en.wikipedia.org/wiki/Local_minimum "Local minimum") if the Hessian matrix is [positive definite](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix "Definiteness of a matrix"). [Quadratic programming](https://en.wikipedia.org/wiki/Quadratic_programming "Quadratic programming") can be used to find global minima or maxima of quadratic functions closely related to the ones attached to matrices (see [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#quadratic_forms)).[[166]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTENocedalWright2006Ch._16-166)

Another matrix frequently used in geometrical situations is the [Jacobi matrix](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant "Jacobian matrix and determinant") of a differentiable map ⁠![Image 174: {\displaystyle f:\mathbb {R} ^{n}\to \mathbb {R} ^{m}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/aad78382c3d23bcb4051b3148f1a23b1d0ba52e3)⁠. If _f_ 1, ..., _f m_ denote the components of f, then the Jacobi matrix is defined as[[167]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELang1987Ch._XVI.1-167)![Image 175: {\displaystyle J(f)=\left[{\frac {\partial f_{i}}{\partial x_{j}}}\right]_{1\leq i\leq m,1\leq j\leq n}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdbd42114b895c82930ea1e229b566f71fd6b07d) If _n_>_m_, and if the rank of the Jacobi matrix attains its maximal value m, f is locally invertible at that point, by the [implicit function theorem](https://en.wikipedia.org/wiki/Implicit_function_theorem "Implicit function theorem").[[168]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-168)

[Partial differential equations](https://en.wikipedia.org/wiki/Partial_differential_equation "Partial differential equation") can be classified by considering the matrix of coefficients of the highest-order differential operators of the equation. For [elliptic partial differential equations](https://en.wikipedia.org/wiki/Elliptic_partial_differential_equation "Elliptic partial differential equation") this matrix is positive definite, which has a decisive influence on the set of possible solutions of the equation in question.[[169]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGilbargTrudinger2001-169)

The [finite element method](https://en.wikipedia.org/wiki/Finite_element_method "Finite element method") is an important numerical method to solve partial differential equations, widely applied in simulating complex physical systems. It attempts to approximate the solution to some equation by piecewise linear functions, where the pieces are chosen concerning a sufficiently fine grid, which in turn can be recast as a matrix equation.[[170]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-170)

### Probability theory and statistics

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=38 "Edit section: Probability theory and statistics")]

[![Image 176](https://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Markov_chain_SVG.svg/330px-Markov_chain_SVG.svg.png)](https://en.wikipedia.org/wiki/File:Markov_chain_SVG.svg)

Two different Markov chains. The chart depicts the number of particles (of a total of 1000) in state "2". Both limiting values can be determined from the transition matrices, which are given by ![Image 177: {\displaystyle \left[{\begin{smallmatrix}0.7&0\\0.3&1\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed9fb2da165c906a24f1d1c3d672b29e70dcfe17) (red) and ![Image 178: {\displaystyle \left[{\begin{smallmatrix}0.7&0.2\\0.3&0.8\end{smallmatrix}}\right]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5ac0656499afbf0abed73c2f804c408089444f57) (black).

[Stochastic matrices](https://en.wikipedia.org/wiki/Stochastic_matrix "Stochastic matrix") are square matrices whose rows are [probability vectors](https://en.wikipedia.org/wiki/Probability_vector "Probability vector"), that is, whose entries are non-negative and sum up to one. Stochastic matrices are used to define [Markov chains](https://en.wikipedia.org/wiki/Markov_chain "Markov chain") with finitely many states.[[171]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTELatoucheRamaswami1999-171) A row of the stochastic matrix gives the probability distribution for the next position of some particle currently in the state that corresponds to the row. Properties of the Markov chain—like [absorbing states](https://en.wikipedia.org/wiki/Absorbing_state "Absorbing state"), that is, states that any particle attains eventually—can be read off the eigenvectors of the transition matrices.[[172]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMehataSrinivasan1978Ch._2.8-172)

Statistics also makes use of matrices in many different forms.[[173]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-173)[Descriptive statistics](https://en.wikipedia.org/wiki/Descriptive_statistics "Descriptive statistics") is concerned with describing data sets, which can often be represented as [data matrices](https://en.wikipedia.org/wiki/Data_matrix_(multivariate_statistics) "Data matrix (multivariate statistics)"), which may then be subjected to [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction "Dimensionality reduction") techniques. The [covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix "Covariance matrix") encodes the mutual [variance](https://en.wikipedia.org/wiki/Variance "Variance") of several [random variables](https://en.wikipedia.org/wiki/Random_variable "Random variable").[[174]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKrzanowski198860Ch._2.2-174) Another technique using matrices are [linear least squares](https://en.wikipedia.org/wiki/Linear_least_squares "Linear least squares"), a method that approximates a finite set of pairs (_x_ 1, _y_ 1), (_x_ 2, _y_ 2), ..., (_x_ _N_, _y_ _N_), by a linear function ![Image 179: {\displaystyle y_{i}\approx ax_{i}+b,\quad i=1,\ldots ,N}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6e4950af44677bf96255e8d2e3fd53b6d5d065a8) which can be formulated in terms of matrices, related to the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition "Singular value decomposition") of matrices.[[175]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKrzanowski1988Ch._4.1-175)

[Random matrices](https://en.wikipedia.org/wiki/Random_matrix "Random matrix") are matrices whose entries are random numbers, subject to suitable [probability distributions](https://en.wikipedia.org/wiki/Probability_distribution "Probability distribution"), such as [matrix normal distribution](https://en.wikipedia.org/wiki/Matrix_normal_distribution "Matrix normal distribution"). Beyond probability theory, they are applied in domains ranging from [number theory](https://en.wikipedia.org/wiki/Number_theory "Number theory") to [physics](https://en.wikipedia.org/wiki/Physics "Physics").[[176]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-176)[[177]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-177)

### Quantum mechanics and particle physics

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=39 "Edit section: Quantum mechanics and particle physics")]

The first model of [quantum mechanics](https://en.wikipedia.org/wiki/Quantum_mechanics "Quantum mechanics") ([Heisenberg](https://en.wikipedia.org/wiki/Werner_Heisenberg "Werner Heisenberg"), 1925) used infinite-dimensional matrices to define the operators that took over the role of variables like position, momentum and energy from classical physics.[[178]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTESchiff1968Ch._6-178) (This is sometimes referred to as [matrix mechanics](https://en.wikipedia.org/wiki/Matrix_mechanics "Matrix mechanics").[[179]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPeres199320-179)) Matrices, both finite and infinite-dimensional, have since been employed for many purposes in quantum mechanics. One particular example is the [density matrix](https://en.wikipedia.org/wiki/Density_matrix "Density matrix"), a tool used in calculating the [probabilities](https://en.wikipedia.org/wiki/Probabilities "Probabilities") of the outcomes of [measurements](https://en.wikipedia.org/wiki/Measurement_in_quantum_mechanics "Measurement in quantum mechanics") performed on [physical systems](https://en.wikipedia.org/wiki/Physical_system "Physical system").[[180]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBohm2001sections_I.8,_II.4,_and_II.8-180)[[181]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPeres199373-181)

Linear transformations and the associated [symmetries](https://en.wikipedia.org/wiki/Symmetry "Symmetry") play a [key role in modern physics](https://en.wikipedia.org/wiki/Symmetry_in_physics "Symmetry in physics"). For example, [elementary particles](https://en.wikipedia.org/wiki/Elementary_particle "Elementary particle") in [quantum field theory](https://en.wikipedia.org/wiki/Quantum_field_theory "Quantum field theory") are classified as representations of the [Lorentz group](https://en.wikipedia.org/wiki/Lorentz_group "Lorentz group") of special relativity and, more specifically, by their behavior under the [spin group](https://en.wikipedia.org/wiki/Spin_group "Spin group"). Concrete representations involving the [Pauli matrices](https://en.wikipedia.org/wiki/Pauli_matrices "Pauli matrices") and more general [gamma matrices](https://en.wikipedia.org/wiki/Gamma_matrices "Gamma matrices") are an integral part of the physical description of [fermions](https://en.wikipedia.org/wiki/Fermion "Fermion"), which behave as [spinors](https://en.wikipedia.org/wiki/Spinor "Spinor").[[182]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEItzyksonZuber1980Ch._2-182) For the three lightest [quarks](https://en.wikipedia.org/wiki/Quark "Quark"), there is a group-theoretical representation involving the [special unitary group](https://en.wikipedia.org/wiki/Special_unitary_group "Special unitary group") SU(3); for their calculations, physicists use a convenient matrix representation known as the [Gell-Mann matrices](https://en.wikipedia.org/wiki/Gell-Mann_matrices "Gell-Mann matrices"), which are also used for the SU(3) [gauge group](https://en.wikipedia.org/wiki/Gauge_group "Gauge group") that forms the basis of the modern description of strong nuclear interactions, [quantum chromodynamics](https://en.wikipedia.org/wiki/Quantum_chromodynamics "Quantum chromodynamics"). The [Cabibbo–Kobayashi–Maskawa matrix](https://en.wikipedia.org/wiki/Cabibbo%E2%80%93Kobayashi%E2%80%93Maskawa_matrix "Cabibbo–Kobayashi–Maskawa matrix"), in turn, expresses the fact that the basic quark states that are important for [weak interactions](https://en.wikipedia.org/wiki/Weak_interaction "Weak interaction") are not the same as, but linearly related to the basic quark states that define particles with specific and distinct [masses](https://en.wikipedia.org/wiki/Mass "Mass").[[183]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEBurgessMoore2007section_1.6.3._(SU(3)),_section_2.4.3.2._(Kobayashi%E2%80%93Maskawa_matrix)-183)

Another matrix serves as a key tool for describing the scattering experiments that form the cornerstone of experimental particle physics: Collision reactions such as occur in [particle accelerators](https://en.wikipedia.org/wiki/Particle_accelerator "Particle accelerator"), where non-interacting particles head towards each other and collide in a small interaction zone, with a new set of non-interacting particles as the result, can be described as the scalar product of outgoing particle states and a linear combination of ingoing particle states. The linear combination is given by a matrix known as the [S-matrix](https://en.wikipedia.org/wiki/S-matrix "S-matrix"), which encodes all information about the possible interactions between particles.[[184]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWeinberg1995Ch._3-184)

A general application of matrices in physics is the description of linearly coupled harmonic systems. The [equations of motion](https://en.wikipedia.org/wiki/Equations_of_motion "Equations of motion") of such systems can be described in matrix form, with a mass matrix multiplying a generalized velocity to give the kinetic term, and a [force](https://en.wikipedia.org/wiki/Force "Force") matrix multiplying a displacement vector to characterize the interactions. The best way to obtain solutions is to determine the system's [eigenvectors](https://en.wikipedia.org/wiki/Eigenvector "Eigenvector"), its [normal modes](https://en.wikipedia.org/wiki/Normal_mode "Normal mode"), by diagonalizing the matrix equation. Techniques like this are crucial when it comes to the internal dynamics of [molecules](https://en.wikipedia.org/wiki/Molecules "Molecules"): the internal vibrations of systems consisting of mutually bound component atoms.[[185]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEWherrett1987part_II-185) They are also needed for describing mechanical vibrations, and oscillations in electrical circuits.[[186]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTERileyHobsonBence19977.17-186)

[Geometrical optics](https://en.wikipedia.org/wiki/Geometrical_optics "Geometrical optics") provides further matrix applications. In this approximative theory, the [wave nature](https://en.wikipedia.org/wiki/Light_wave "Light wave") of light is neglected. The result is a model in which [light rays](https://en.wikipedia.org/wiki/Ray_(optics) "Ray (optics)") are indeed [geometrical rays](https://en.wikipedia.org/wiki/Ray_(geometry) "Ray (geometry)"). If the deflection of light rays by optical elements is small, the action of a [lens](https://en.wikipedia.org/wiki/Lens_(optics) "Lens (optics)") or reflective element on a given light ray can be expressed as multiplication of a two-component vector with a two-by-two matrix called [ray transfer matrix analysis](https://en.wikipedia.org/wiki/Ray_transfer_matrix_analysis "Ray transfer matrix analysis"): the vector's components are the light ray's slope and its distance from the optical axis, while the matrix encodes the properties of the optical element. There are two kinds of matrices, viz. a _refraction matrix_ describing the refraction at a lens surface, and a _translation matrix_, describing the translation of the plane of reference to the next refracting surface, where another refraction matrix applies. The optical system, consisting of a combination of lenses and reflective elements, is simply described by the matrix resulting from the product of the components' matrices.[[187]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEGuenther1990Ch._5-187)

The [Jones calculus](https://en.wikipedia.org/wiki/Jones_calculus "Jones calculus") models the [polarization](https://en.wikipedia.org/wiki/Polarization_(physics) "Polarization (physics)") of a light source as a ![Image 180: {\displaystyle 2\times 2}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f8a0e3400ffb97d67c00267ed50cddfe824cbe80) vector, and the effects of [optical filters](https://en.wikipedia.org/wiki/Optical_filter "Optical filter") on this polarization vector as a matrix.[[48]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHanKimNoz1997-48)

Electronic circuits that are composed of linear components (such as resistors, inductors and capacitors) obey [Kirchhoff's circuit laws](https://en.wikipedia.org/wiki/Kirchhoff%27s_circuit_laws "Kirchhoff's circuit laws"), which leads to a system of linear equations, which can be described with a matrix equation that relates the source currents and voltages to the resultant currents and voltages at each point in the circuit, and where the matrix entries are determined by the circuit.[[188]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTESuresh_Kumar2009747%E2%80%93749-188)

Matrices have a long history of application in solving [linear equations](https://en.wikipedia.org/wiki/Linear_equation "Linear equation") but they were known as arrays until the 1800s. The [Chinese text](https://en.wikipedia.org/wiki/Chinese_mathematics "Chinese mathematics")_[The Nine Chapters on the Mathematical Art](https://en.wikipedia.org/wiki/The\_Nine\_Chapters\_on\_the\_Mathematical\_Art "The Nine Chapters on the Mathematical Art")_ written in the 10th–2nd century BCE is the first example of the use of array methods to solve [simultaneous equations](https://en.wikipedia.org/wiki/System_of_linear_equations "System of linear equations"),[[189]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-189) including the concept of [determinants](https://en.wikipedia.org/wiki/Determinant "Determinant"). In 1545 Italian mathematician [Gerolamo Cardano](https://en.wikipedia.org/wiki/Gerolamo_Cardano "Gerolamo Cardano") introduced the method to Europe when he published _Ars Magna_.[[190]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564%E2%80%93565-190) The [Japanese mathematician](https://en.wikipedia.org/wiki/Japanese_mathematics "Japanese mathematics")[Seki](https://en.wikipedia.org/wiki/Seki_Kowa "Seki Kowa") used the same array methods to solve simultaneous equations in 1683.[[191]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-191) The Dutch mathematician[Jan de Witt](https://en.wikipedia.org/wiki/Jan_de_Witt "Jan de Witt") represented transformations using arrays in his 1659 book _Elements of Curves_ (1659).[[192]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564-192) Between 1700 and 1710 [Gottfried Wilhelm Leibniz](https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz "Gottfried Wilhelm Leibniz") publicized the use of arrays for recording information or solutions and experimented with over 50 different systems of arrays.[[190]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564%E2%80%93565-190)[Cramer](https://en.wikipedia.org/wiki/Gabriel_Cramer "Gabriel Cramer") presented [his rule](https://en.wikipedia.org/wiki/Cramer%27s_rule "Cramer's rule") in 1750.[[193]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECramer1750-193)[[194]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKosinski2001-194)

This use of the term _matrix_ in mathematics (an English word for "womb" in the 19th century, from Latin, as well as a jargon word [in printing](https://en.wikipedia.org/wiki/Matrix_(printing) "Matrix (printing)"), [in biology](https://en.wikipedia.org/wiki/Matrix_(biology) "Matrix (biology)") and [in geology](https://en.wikipedia.org/wiki/Matrix_(geology) "Matrix (geology)")[[195]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-195)) was coined by [James Joseph Sylvester](https://en.wikipedia.org/wiki/James_Joseph_Sylvester "James Joseph Sylvester") in 1850,[[196]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-196) who understood a matrix as an object giving rise to several determinants today called [minors](https://en.wikipedia.org/wiki/Minor_(linear_algebra) "Minor (linear algebra)"), that is to say, determinants of smaller matrices that derive from the original one by removing columns and rows. In an 1851 paper, Sylvester explains:[[197]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTESylvester1904247[httpsbooksgooglecombooksid5GQPlxWrDiECpgPA247_Paper_37]-197)

> I have in previous papers defined a "Matrix" as a rectangular array of terms, out of which different systems of determinants may be engendered from the womb of a common parent.

[Arthur Cayley](https://en.wikipedia.org/wiki/Arthur_Cayley "Arthur Cayley") published a treatise on geometric transformations using matrices that were not rotated versions of the coefficients being investigated as had previously been done. Instead, he defined operations such as addition, subtraction, multiplication, and division as transformations of those matrices and showed the associative and distributive properties held. Cayley investigated and demonstrated the non-commutative property of matrix multiplication as well as the commutative property of matrix addition.[[190]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564%E2%80%93565-190) Early matrix theory had limited the use of arrays almost exclusively to determinants and Cayley's abstract matrix operations were revolutionary. He was instrumental in proposing a matrix concept independent of equation systems. In 1858, Cayley published his _A memoir on the theory of matrices_[[198]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTECayley1858-198)[[199]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDieudonn%C3%A91978Vol._1,_Ch._III,_p._96-199) in which he proposed and demonstrated the [Cayley–Hamilton theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem "Cayley–Hamilton theorem").[[190]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564%E2%80%93565-190)

The English mathematician [Cuthbert Edmund Cullis](https://en.wikipedia.org/wiki/Cuthbert_Edmund_Cullis "Cuthbert Edmund Cullis") was the first to use modern bracket notation for matrices in 1913 and he simultaneously demonstrated the first significant use of the notation **A** = [_a_ _i_,_j_] to represent a matrix where _a_ _i_,_j_ refers to the i th row and the j th column.[[190]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEDossey2002564%E2%80%93565-190)

The modern study of determinants sprang from several sources.[[200]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKnobloch1994-200)[Number-theoretical](https://en.wikipedia.org/wiki/Number_theory "Number theory") problems led [Gauss](https://en.wikipedia.org/wiki/Gauss "Gauss") to relate coefficients of [quadratic forms](https://en.wikipedia.org/wiki/Quadratic_form "Quadratic form"), that is, expressions such as _x_ 2 + _xy_ − 2 _y_ 2, and [linear maps](https://en.wikipedia.org/wiki/Linear_map "Linear map") in three dimensions to matrices. [Eisenstein](https://en.wikipedia.org/wiki/Gotthold_Eisenstein "Gotthold Eisenstein") further developed these notions, including the remark that, in modern parlance, [matrix products](https://en.wikipedia.org/wiki/Matrix_product "Matrix product") are [non-commutative](https://en.wikipedia.org/wiki/Non-commutative "Non-commutative"). [Cauchy](https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy "Augustin-Louis Cauchy") was the first to prove general statements about determinants, using as the definition of the determinant of a matrix **A** = [_a_ _i_,_j_] the following: replace the powers _a_ _j_ _k_ by _a_ _j_,_k_ in the [polynomial](https://en.wikipedia.org/wiki/Polynomial "Polynomial")![Image 181: {\displaystyle a_{1}a_{2}\cdots a_{n}\prod _{i<j}(a_{j}-a_{i}),}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0c20ada406da038ab435b0d905aac157e50be6d8) where ![Image 182: {\displaystyle \textstyle \prod }](https://wikimedia.org/api/rest_v1/media/math/render/svg/423a3226e80f549c55e3873aecbf57af9296e0fd) denotes the [product](https://en.wikipedia.org/wiki/Multiplication "Multiplication") of the indicated terms. He also showed, in 1829, that the [eigenvalues](https://en.wikipedia.org/wiki/Eigenvalue "Eigenvalue") of symmetric matrices are real.[[201]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHawkins1975-201)[Jacobi](https://en.wikipedia.org/wiki/Carl_Gustav_Jacob_Jacobi "Carl Gustav Jacob Jacobi") studied "functional determinants"—later called [Jacobi determinants](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant "Jacobian matrix and determinant") by Sylvester—which can be used to describe geometric transformations at a local (or [infinitesimal](https://en.wikipedia.org/wiki/Infinitesimal "Infinitesimal")) level, see [above](https://en.wikipedia.org/wiki/Matrix_(mathematics)#Jacobi_matrix). [Kronecker](https://en.wikipedia.org/wiki/Leopold_Kronecker "Leopold Kronecker")'s _Vorlesungen über die Theorie der Determinanten_[[202]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-202) and [Weierstrass](https://en.wikipedia.org/wiki/Karl_Weierstrass "Karl Weierstrass")'s _Zur Determinantentheorie_,[[203]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-203) both published in 1903, first treated determinants [axiomatically](https://en.wikipedia.org/wiki/Axiom "Axiom"), as opposed to previous more concrete approaches such as the mentioned formula of Cauchy. At that point, determinants were firmly established.[[204]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEMiller1930-204)[[200]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEKnobloch1994-200)

Many theorems were first established for small matrices only, for example, the [Cayley–Hamilton theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem "Cayley–Hamilton theorem") was proved for 2×2 matrices by Cayley in the aforementioned memoir, and by [Hamilton](https://en.wikipedia.org/wiki/William_Rowan_Hamilton "William Rowan Hamilton") for 4×4 matrices. [Frobenius](https://en.wikipedia.org/wiki/Georg_Frobenius "Georg Frobenius"), working on [bilinear forms](https://en.wikipedia.org/wiki/Bilinear_form "Bilinear form"), generalized the theorem to all dimensions (1898). Also at the end of the 19th century, the [Gauss–Jordan elimination](https://en.wikipedia.org/wiki/Gauss%E2%80%93Jordan_elimination "Gauss–Jordan elimination") (generalizing a special case now known as [Gauss elimination](https://en.wikipedia.org/wiki/Gauss_elimination "Gauss elimination")) was established by [Wilhelm Jordan](https://en.wikipedia.org/wiki/Wilhelm_Jordan_(geodesist) "Wilhelm Jordan (geodesist)"). In the early 20th century, matrices attained a central role in linear algebra,[[205]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEB%C3%B4cher2004-205) partially due to their use in the classification of the [hypercomplex number](https://en.wikipedia.org/wiki/Hypercomplex_number "Hypercomplex number") systems of the previous century.[[206]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEHawkins1972-206)

The inception of [matrix mechanics](https://en.wikipedia.org/wiki/Matrix_mechanics "Matrix mechanics") by [Heisenberg](https://en.wikipedia.org/wiki/Werner_Heisenberg "Werner Heisenberg"), [Born](https://en.wikipedia.org/wiki/Max_Born "Max Born") and [Jordan](https://en.wikipedia.org/wiki/Pascual_Jordan "Pascual Jordan") led to studying matrices with infinitely many rows and columns.[[207]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEvan_der_Waerden200728%E2%80%9340-207) Later, [von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann "John von Neumann") carried out the [mathematical formulation of quantum mechanics](https://en.wikipedia.org/wiki/Mathematical_formulation_of_quantum_mechanics "Mathematical formulation of quantum mechanics"), by further developing [functional analytic](https://en.wikipedia.org/wiki/Functional_analysis "Functional analysis") notions such as [linear operators](https://en.wikipedia.org/wiki/Linear_operator "Linear operator") on [Hilbert spaces](https://en.wikipedia.org/wiki/Hilbert_space "Hilbert space"), which, very roughly speaking, correspond to [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space "Euclidean space"), but with an infinity of [independent directions](https://en.wikipedia.org/wiki/Hamel_dimension "Hamel dimension").[[208]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTEPeres199379,_106%E2%80%93107-208)

### Other historical usages of the word "matrix" in mathematics

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=44 "Edit section: Other historical usages of the word \"matrix\" in mathematics")]

The word has been used in unusual ways by at least two authors of historical importance.

[Bertrand Russell](https://en.wikipedia.org/wiki/Bertrand_Russell "Bertrand Russell") and [Alfred North Whitehead](https://en.wikipedia.org/wiki/Alfred_North_Whitehead "Alfred North Whitehead") in their _[Principia Mathematica](https://en.wikipedia.org/wiki/Principia\_Mathematica "Principia Mathematica")_ (1910–1913) use the word "matrix" in the context of their [axiom of reducibility](https://en.wikipedia.org/wiki/Axiom_of_reducibility "Axiom of reducibility"). They proposed this axiom as a means to reduce any function to one of lower type, successively, so that at the "bottom" (0 order) the function is identical to its [extension](https://en.wikipedia.org/wiki/Extension_(predicate_logic) "Extension (predicate logic)"):[[209]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-209)

> Let us give the name of _matrix_ to any function, of however many variables, that does not involve any [apparent variables](https://en.wikipedia.org/wiki/Apparent_variable "Apparent variable"). Then, any possible function other than a matrix derives from a matrix using generalization, that is, by considering the proposition that the function in question is true with all possible values or with some value of one of the arguments, the other argument or arguments remaining undetermined.

For example, a function Φ(_x_, _y_) of two variables x and y can be reduced to a _collection_ of functions of a single variable, such as y, by "considering" the function for all possible values of "individuals" a i substituted in place of a variable x. And then the resulting collection of functions of the single variable y, that is, ∀_a_ _i_: Φ(_a_ _i_, _y_), can be reduced to a "matrix" of values by "considering" the function for all possible values of "individuals" _b_ _i_ substituted in place of variable y: ![Image 183: {\displaystyle \forall b_{j}\forall a_{i}\colon \phi (a_{i},b_{j}).}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2d5055ceb96bb3a9df75d5050763e3335479cb2a)

[Alfred Tarski](https://en.wikipedia.org/wiki/Alfred_Tarski "Alfred Tarski") in his 1941 _Introduction to Logic_ used the word "matrix" synonymously with the notion of [truth table](https://en.wikipedia.org/wiki/Truth_table "Truth table") as used in mathematical logic.[[210]](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_note-FOOTNOTETarski1941[httpsbooksgooglecombooksid5MeNCgAAQBAJpgPA40_40]-210)

*   [List of named matrices](https://en.wikipedia.org/wiki/List_of_named_matrices "List of named matrices")
*   [Gram–Schmidt process](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process "Gram–Schmidt process")– Orthonormalization of a set of vectors
*   [Irregular matrix](https://en.wikipedia.org/wiki/Irregular_matrix "Irregular matrix")
*   [Matrix calculus](https://en.wikipedia.org/wiki/Matrix_calculus "Matrix calculus")– Specialized notation for multivariable calculus
*   [Matrix function](https://en.wikipedia.org/wiki/Matrix_function "Matrix function")– Function that maps matrices to matrices

1.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang2002Chapter_XIII_1-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang2002Chapter_XIII_1-1)[Lang (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang2002), Chapter XIII.
2.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEFraleigh1976209_2-0)**[Fraleigh (1976)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFFraleigh1976), p.209.
3.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTENering197037_3-0)**[Nering (1970)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFNering1970), p.37.
4.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown19911_4-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown19911_4-1)[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), p.1.
5.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGolubVan_Loan19963_5-0)**[Golub & Van Loan (1996)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGolubVan_Loan1996), p.3.
6.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson19855_6-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), p.5.
7.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur201189_7-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), p.89.
8.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-empty_8-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-empty_8-1)"A matrix having at least one dimension equal to zero is called an empty matrix", [MATLAB Data Structures](https://system.nada.kth.se/unix/software/matlab/Release_14.1/techdoc/matlab_prog/ch_dat29.html)[Archived](https://web.archive.org/web/20091228102653/http://www.system.nada.kth.se/unix/software/matlab/Release_14.1/techdoc/matlab_prog/ch_dat29.html) 2009-12-28 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine")
9.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTERamachandra_RaoBhimasankaram2000[httpsbooksgooglecombooksidZfJdDwAAQBAJpgPA71_71]_9-0)**[Ramachandra Rao & Bhimasankaram (2000)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFRamachandra_RaoBhimasankaram2000), p.[71](https://books.google.com/books?id=ZfJdDwAAQBAJ&pg=PA71).
10.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHamilton1987[httpsbooksgooglecombooksidW5o4AAAAIAAJpgPA29_29]_10-0)**[Hamilton (1987)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHamilton1987), p.[29](https://books.google.com/books?id=W5o4AAAAIAAJ&pg=PA29).
11.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGentle1998[httpsbooksgooglecombooksid2J0ndF_LmqoCpgPA52_52%E2%80%9353]_11-0)**[Gentle (1998)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGentle1998), pp.[52–53](https://books.google.com/books?id=2J0ndF_LmqoC&pg=PA52).
12.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBauchauCraig2009[httpsbooksgooglecombooksidGYRX8ZYVNYQCpgPA915_915]_12-0)**[Bauchau & Craig (2009)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBauchauCraig2009), p.[915](https://books.google.com/books?id=GYRX8ZYVNYQC&pg=PA915).
13.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEJohnston2021[httpsbooksgooglecombooksidy24vEAAAQBAJpgPA21_21]_13-0)**[Johnston (2021)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFJohnston2021), p.[21](https://books.google.com/books?id=y24vEAAAQBAJ&pg=PA21).
14.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEOualline2003Ch._5_14-0)**[Oualline (2003)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFOualline2003), Ch. 5.
15.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPopFurdui2017_15-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPopFurdui2017_15-1)[Pop & Furdui (2017)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPopFurdui2017).
16.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-16)**For example, for ⁠![Image 184: {\displaystyle M}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd)⁠, see [Mello (2017)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMello2017), [p. 48](https://books.google.com/books?id=RC4tDwAAQBAJ&pg=PA48); for ⁠![Image 185: {\displaystyle \operatorname {Mat} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/42fdf1777541a3ef4e694461fa576f1aabe4375f)⁠, see [Axler (1997)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAxler1997), [p. 50](https://books.google.com/books?id=ovIYVIlithQC&pg=PA50).
17.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_I.2.1_(addition),_Definition_I.2.4_(scalar_multiplication),_and_Definition_I.2.33_(transpose)_17-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition I.2.1 (addition), Definition I.2.4 (scalar multiplication), and Definition I.2.33 (transpose).
18.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWhitelaw199129_18-0)**[Whitelaw (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWhitelaw1991), p.29.
19.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Theorem_I.2.6_19-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Theorem I.2.6.
20.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWhitelaw199130_20-0)**[Whitelaw (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWhitelaw1991), p.30.
21.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMaxwell1969[httpsbooksgooglecombooksidoQk9AAAAIAAJpgPA46_46]_21-0)**[Maxwell (1969)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMaxwell1969), p.[46](https://books.google.com/books?id=oQk9AAAAIAAJ&pg=PA46).
22.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid2c011Aptsa8CpgPA6_6%E2%80%937]_22-0)**[Lancaster & Tismenetsky (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLancasterTismenetsky1985), pp.[6–7](https://books.google.com/books?id=2c011Aptsa8C&pg=PA6).
23.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAndrilliHecker2022[httpsbooksgooglecombooksidWtpVEAAAQBAJpgPA38_38]The_transpose_of_a_matrix_and_its_properties_23-0)**[Andrilli & Hecker (2022)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAndrilliHecker2022), p.[38](https://books.google.com/books?id=WtpVEAAAQBAJ&pg=PA38), The transpose of a matrix and its properties.
24.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid4nfNCgAAQBAJpgPA9_9]_24-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELancasterTismenetsky1985[httpsbooksgooglecombooksid4nfNCgAAQBAJpgPA9_9]_24-1)[Lancaster & Tismenetsky (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLancasterTismenetsky1985), p.[9](https://books.google.com/books?id=4nfNCgAAQBAJ&pg=PA9).
25.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_I.2.20_25-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition I.2.20.
26.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Theorem_I.2.24_26-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Theorem I.2.24.
27.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005117_27-0)**[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), p.117.
28.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Ch._4_and_5_28-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Ch. 4 and 5.
29.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEVan_Loan2000_29-0)**[Van Loan (2000)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFVan_Loan2000).
30.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPerrone2024[httpbooksgooglecombooksidJO8GEQAAQBAJpgPA119_119%E2%80%93120]_30-0)**[Perrone (2024)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPerrone2024), p.[119–120](http://books.google.com/books?id=JO8GEQAAQBAJ&pg=PA119).
31.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1986[httpbooksgooglecombooksidc_NEBAAAQBAJpgPA71_71]_31-0)**[Lang (1986)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1986), p.[71](http://books.google.com/books?id=c_NEBAAAQBAJ&pg=PA71).
32.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWatkins2002[httpbooksgooglecombooksidxi5omWiQ-3kCpgPA102_102]_32-0)**[Watkins (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWatkins2002), p.[102](http://books.google.com/books?id=xi5omWiQ-3kC&pg=PA102).
33.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBronson197016_33-0)**[Bronson (1970)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBronson1970), p.16.
34.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKreyszig1972220_34-0)**[Kreyszig (1972)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKreyszig1972), p.220.
35.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEProtterMorrey1970869_35-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEProtterMorrey1970869_35-1)[Protter & Morrey (1970)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFProtterMorrey1970), p.869.
36.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKreyszig1972241,_244_36-0)**[Kreyszig (1972)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKreyszig1972), pp.241, 244.
37.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTESchneiderBarker2012_37-0)**[Schneider & Barker (2012)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFSchneiderBarker2012).
38.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPerlis1991_38-0)**[Perlis (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPerlis1991).
39.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010_39-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010).
40.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-40)**Horn, Roger A.; Johnson, Charles R. (2012), [_Matrix Analysis_](https://books.google.com/books?id=5I5AYeeh0JUC&pg=PA17) (2nd ed.), Cambridge University Press, p.17, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-83940-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-83940-2 "Special:BookSources/978-0-521-83940-2").
41.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991I.2.21_and_22_41-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), I.2.21 and 22.
42.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur201195_42-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), p.95.
43.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBen-IsraelGreville20031%E2%80%932_43-0)**[Ben-Israel & Greville (2003)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBen-IsraelGreville2003), pp.1–2.
44.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGrossman1994494%E2%80%93495_44-0)**[Grossman (1994)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGrossman1994), pp.494–495.
45.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBierens2004[httpsbooksgooglecombooksidZrBaRPVRLRoCpgPA263_263]_45-0)**[Bierens (2004)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBierens2004), p.[263](https://books.google.com/books?id=ZrBaRPVRLRoC&pg=PA263).
46.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEJohnston2021[httpsbooksgooglecombooksidy24vEAAAQBAJpgPA56_56]_46-0)**[Johnston (2021)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFJohnston2021), p.[56](https://books.google.com/books?id=y24vEAAAQBAJ&pg=PA56).
47.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPettofrezzo1978[httpsbooksgooglecombooksid2wzp9zQhA_ICpgPA60_60]_47-0)**[Pettofrezzo (1978)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPettofrezzo1978), p.[60](https://books.google.com/books?id=2wzp9zQhA_IC&pg=PA60).
48.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHanKimNoz1997_48-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHanKimNoz1997_48-1)[_**c**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHanKimNoz1997_48-2)[Han, Kim & Noz (1997)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHanKimNoz1997).
49.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEJeffrey2010[httpsbooksgooglecombooksiduan0Dkn9HY8CpgPA264_264]_49-0)**[Jeffrey (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFJeffrey2010), p.[264](https://books.google.com/books?id=uan0Dkn9HY8C&pg=PA264).
50.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-50)**[Greub (1975](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGreub1975), p.90). Note however that Greub follows a transposed convention of representing a transformation by multiplying a row vector by a matrix, rather than multiplying a matrix by a column vector, leading to the reversed order for the two matrices in the product that represents a composition.
51.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1986%C2%A7VI.1_51-0)**[Lang (1986)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1986), §VI.1.
52.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_II.3.3_52-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition II.3.3.
53.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGreub1975Section_III.1_53-0)**[Greub (1975)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGreub1975), Section III.1.
54.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Theorem_II.3.22_54-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Theorem II.3.22.
55.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA27_27]_55-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010), p.[27](https://books.google.com/books?id=YmcQJoFyZ5gC&pg=PA27).
56.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEReyes2025_56-0)**[Reyes (2025)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFReyes2025).
57.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA68_68]_57-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010), p.[68](https://books.google.com/books?id=YmcQJoFyZ5gC&pg=PA68).
58.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur201191_58-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), p.91.
59.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005118_59-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005118_59-1)[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), p.118.
60.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985%C2%A70.9.1_Diagonal_matrices_60-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), §0.9.1 Diagonal matrices.
61.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005138_61-0)**[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), p.138.
62.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Theorem_2.5.6_62-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Theorem 2.5.6.
63.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEConway1990262%E2%80%93263_63-0)**[Conway (1990)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFConway1990), pp.262–263.
64.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_I.2.28_64-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition I.2.28.
65.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_I.5.13_65-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition I.5.13.
66.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010[httpsbooksgooglecombooksidYmcQJoFyZ5gCpgPA62_62]_66-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010), p.[62](https://books.google.com/books?id=YmcQJoFyZ5gC&pg=PA62).
67.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur201199%E2%80%93100_67-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), pp.99–100.
68.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Chapter_7_68-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Chapter 7.
69.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010Thm._7.3.2_69-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010), Thm. 7.3.2.
70.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Theorem_7.2.1_70-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Theorem 7.2.1.
71.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005150_71-0)**[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), p.150.
72.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985169Example_4.0.6_72-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), p.169, Example 4.0.6.
73.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1986Appendix._Complex_numbers_73-0)**[Lang (1986)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1986), Appendix. Complex numbers.
74.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson198566%E2%80%9367_74-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), pp.66–67.
75.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur2011102%E2%80%93103_75-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), pp.102–103.
76.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005127,_153%E2%80%93154_76-0)**[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), pp.127, 153–154.
77.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoas2005141_77-0)**[Boas (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoas2005), p.141.
78.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson198540,_42_78-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), pp.40, 42.
79.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1986p._281_79-0)**[Lang (1986)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1986), p. 281.
80.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTETang2006226_80-0)**[Tang (2006)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFTang2006), p.226.
81.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBernstein200994_81-0)**[Bernstein (2009)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBernstein2009), p.94.
82.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985%C2%A70.5_Nonsingularity_82-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), §0.5 Nonsingularity.
83.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMargalitRabinoff2019_83-0)**[Margalit & Rabinoff (2019)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMargalitRabinoff2019).
84.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-:3_84-0)**["Matrix | mathematics"](https://britannica.com/science/matrix-mathematics), _Encyclopedia Britannica_, retrieved 2020-08-19
85.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_III.2.1_85-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition III.2.1.
86.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Theorem_III.2.12_86-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Theorem III.2.12.
87.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Corollary_III.2.16_87-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Corollary III.2.16.
88.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMirsky1990Theorem_1.4.1_88-0)**[Mirsky (1990)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMirsky1990), Theorem 1.4.1.
89.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Theorem_III.3.18_89-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Theorem III.3.18.
90.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-90)**_Eigen_ means "own" in [German](https://en.wikipedia.org/wiki/German_language "German language") and in [Dutch](https://en.wikipedia.org/wiki/Dutch_language "Dutch language"). See [Wiktionary](https://en.wiktionary.org/wiki/eigen).
91.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_III.4.1_91-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition III.4.1.
92.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Definition_III.4.9_92-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Definition III.4.9.
93.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrown1991Corollary_III.4.10_93-0)**[Brown (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrown1991), Corollary III.4.10.
94.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAnton2010[httpsbooksgooglecombooksidypROEAAAQBAJpgPA317_317%E2%80%93319]_94-0)**[Anton (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAnton2010), pp.[317–319](https://books.google.com/books?id=ypROEAAAQBAJ&pg=PA317).
95.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBernstein2009265_95-0)**[Bernstein (2009)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBernstein2009), p.265.
96.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHouseholder1975Ch._7_96-0)**[Householder (1975)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHouseholder1975), Ch. 7.
97.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBau_IIITrefethen1997_97-0)**[Bau III & Trefethen (1997)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBau_IIITrefethen1997).
98.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGolubVan_Loan1996Algorithm_1.3.1_98-0)**[Golub & Van Loan (1996)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGolubVan_Loan1996), Algorithm 1.3.1.
99.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEVassilevska_WilliamsXuXuZhou2024_99-0)**[Vassilevska Williams et al. (2024)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFVassilevska_WilliamsXuXuZhou2024).
100.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMisraBhattacharyaGhosh2022_100-0)**[Misra, Bhattacharya & Ghosh (2022)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMisraBhattacharyaGhosh2022).
101.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGolubVan_Loan1996Chapters_9_and_10,_esp._section_10.2_101-0)**[Golub & Van Loan (1996)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGolubVan_Loan1996), Chapters 9 and 10, esp. section 10.2.
102.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGolubVan_Loan1996Chapter_2.3_102-0)**[Golub & Van Loan (1996)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGolubVan_Loan1996), Chapter 2.3.
103.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPressFlanneryTeukolskyVetterling1992_103-0)**[Press et al. (1992)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPressFlanneryTeukolskyVetterling1992).
104.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEStoerBulirsch2002Section_4.1_104-0)**[Stoer & Bulirsch (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFStoerBulirsch2002), Section 4.1.
105.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGbur2011146%E2%80%93153_105-0)**[Gbur (2011)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGbur2011), pp.146–153.
106.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Theorem_2.5.4_106-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Theorem 2.5.4.
107.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson1985Ch._3.1,_3.2_107-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), Ch. 3.1, 3.2.
108.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEArnold1992Sections_14.5,_7,_8_108-0)**[Arnold (1992)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFArnold1992), Sections 14.5, 7, 8.
109.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBronson1989Ch._15_109-0)**[Bronson (1989)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBronson1989), Ch. 15.
110.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECoburn1955Ch._V_110-0)**[Coburn (1955)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFCoburn1955), Ch. V.
111.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTETapp2016_111-0)**[Tapp (2016)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFTapp2016).
112.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELam1999461%E2%80%93470Chapter_7,_%C2%A717_Matrix_Rings,_%C2%A717A_Characterization_and_Examples_112-0)**[Lam (1999)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLam1999), pp.461–470, Chapter 7, §17 Matrix Rings, §17A Characterization and Examples.
113.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHachenbergerJungnickel2020[httpsbooksgooglecombooksidiSAAEAAAQBAJpgPA302_302]Definition_7.2.1_113-0)**[Hachenberger & Jungnickel (2020)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHachenbergerJungnickel2020), p.[302](https://books.google.com/books?id=iSAAEAAAQBAJ&pg=PA302), Definition 7.2.1.
114.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEYdri2016_114-0)**[Ydri (2016)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFYdri2016).
115.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTERiehl2016[httpsbooksgooglecombooksid6B9MDgAAQBAJpgPA4_4-6]_115-0)**[Riehl (2016)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFRiehl2016), pp.[4-6](https://books.google.com/books?id=6B9MDgAAQBAJ&pg=PA4).
116.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTERoth2006[httpsbooksgooglecombooksidfk7u8awR0hICpgPA27_27]_116-0)**[Roth (2006)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFRoth2006), p.[27](https://books.google.com/books?id=fk7u8awR0hIC&pg=PA27).
117.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEChahal2018[httpsbooksgooglecombooksidZIqADwAAQBAJpgPA115_115%E2%80%93116]_117-0)**[Chahal (2018)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFChahal2018), pp.[115–116](https://books.google.com/books?id=ZIqADwAAQBAJ&pg=PA115).
118.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMeckesMeckes2018[httpsbooksgooglecombooksidwK1XDwAAQBAJpgPA360_360%E2%80%93361]_118-0)**[Meckes & Meckes (2018)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMeckesMeckes2018), pp.[360–361](https://books.google.com/books?id=wK1XDwAAQBAJ&pg=PA360).
119.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEEdwards2004[httpsbooksgooglecombooksidylFR4h5BIDECpgPA80_80]_119-0)**[Edwards (2004)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFEdwards2004), p.[80](https://books.google.com/books?id=ylFR4h5BIDEC&pg=PA80).
120.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang2002643XVII.1_120-0)**[Lang (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang2002), p.643, XVII.1.
121.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang2002Proposition_XIII.4.16_121-0)**[Lang (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang2002), Proposition XIII.4.16.
122.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEReichl2004Section_L.2_122-0)**[Reichl (2004)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFReichl2004), Section L.2.
123.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEJeffrey2010[httpsbooksgooglecombooksiduan0Dkn9HY8CpgPA54_54ff]3.7_Partitioning_of_matrices_123-0)**[Jeffrey (2010)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFJeffrey2010), pp.[54ff](https://books.google.com/books?id=uan0Dkn9HY8C&pg=PA54), 3.7 Partitioning of matrices.
124.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGreub1975Section_III.3_124-0)**[Greub (1975)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGreub1975), Section III.3.
125.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGreub1975Section_III.3.13_125-0)**[Greub (1975)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGreub1975), Section III.3.13.
126.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPerrone202499%E2%80%93100_126-0)**[Perrone (2024)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPerrone2024), pp.99–100.
127.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHungerford1980328%E2%80%93335VII.1:_Matrices_and_maps_127-0)**[Hungerford (1980)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHungerford1980), pp.328–335, VII.1: Matrices and maps.
128.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHornJohnson198569_128-0)**[Horn & Johnson (1985)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHornJohnson1985), p.69.
129.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-129)**Additionally, the group must be [closed](https://en.wikipedia.org/wiki/Closed_subset "Closed subset") in the general linear group.
130.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBaker2003Def._1.30_130-0)**[Baker (2003)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBaker2003), Def. 1.30.
131.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECameron2014_131-0)**[Cameron (2014)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFCameron2014).
132.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBaker2003Theorem_1.2_132-0)**[Baker (2003)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBaker2003), Theorem 1.2.
133.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEArtin1991Chapter_4.5_133-0)**[Artin (1991)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFArtin1991), Chapter 4.5.
134.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTESerre2007[httpsbooksgooglecombooksidvY_xBwAAQBAJpgPA20_20]_134-0)**[Serre (2007)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFSerre2007), p.[20](https://books.google.com/books?id=vY_xBwAAQBAJ&pg=PA20).
135.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTERowen2008198Example_19.2_135-0)**[Rowen (2008)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFRowen2008), p.198, Example 19.2.
136.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-136)**See any reference in representation theory or [group representation](https://en.wikipedia.org/wiki/Group_representation "Group representation").
137.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-137)**See the item "Matrix" in Itô[1987](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFIt%C3%B41987).
138.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBoos2000[httpsbooksgooglecombooksidkZ9cy6XyidECpgPA34_34%E2%80%9339]2.2_Dealing_with_infinite_matrices_138-0)**[Boos (2000)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBoos2000), pp.[34–39](https://books.google.com/books?id=kZ9cy6XyidEC&pg=PA34), 2.2 Dealing with infinite matrices.
139.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGrillet2007[httpsbooksgooglecombooksidLJtyhu8-xYwCpgPA334_334]_139-0)**[Grillet (2007)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGrillet2007), p.[334](https://books.google.com/books?id=LJtyhu8-xYwC&pg=PA334).
140.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-140)** "Not much of matrix theory carries over to infinite-dimensional spaces, and what does is not so useful, but it sometimes helps." Halmos[1982](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHalmos1982), p. 23, Chapter 5.
141.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-141)**"Empty Matrix: A matrix is empty if either its row or column dimension is zero", [Glossary](https://omatrix.com/manual/glossary.htm)[Archived](https://web.archive.org/web/20090429015728/http://www.omatrix.com/manual/glossary.htm) 2009-04-29 at the [Wayback Machine](https://en.wikipedia.org/wiki/Wayback_Machine "Wayback Machine"), O-Matrix v6 User Guide
142.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEColemanVan_Loan1988[httpsbooksgooglecombooksidzUh9I2mSKxgCpgPA213_213]_142-0)**[Coleman & Van Loan (1988)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFColemanVan_Loan1988), p.[213](https://books.google.com/books?id=zUh9I2mSKxgC&pg=PA213).
143.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHazewinkelGubareni2017[httpbooksgooglecombooksid5w6lDgAAQBAJpgPA151_151]_143-0)**[Hazewinkel & Gubareni (2017)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHazewinkelGubareni2017), p.[151](http://books.google.com/books?id=5w6lDgAAQBAJ&pg=PA151).
144.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-144)**The notation of empty matrix is used differently from some sources like [Bernstein (2009)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBernstein2009), p.[90](http://books.google.com/books?id=-c0NxJg4vHMC&pg=PA90) use ![Image 186: {\displaystyle 0_{0\times n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/ccdb17508b331d9a14f1419c55afa0b868958d69), resembling the [zero matrix](https://en.wikipedia.org/wiki/Zero_matrix "Zero matrix"); [Hazewinkel & Gubareni (2017)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHazewinkelGubareni2017), p.[151](http://books.google.com/books?id=5w6lDgAAQBAJ&pg=PA151) use ![Image 187: {\displaystyle {\mathfrak {I}}_{0\times n}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fcff97e4090aece992d80f8b049451bcb930083b).
145.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWest2020[httpsbooksgooglecombooksid0-3vDwAAQBAJpgPA750_750]_145-0)**[West (2020)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWest2020), p.[750](https://books.google.com/books?id=0-3vDwAAQBAJ&pg=PA750).
146.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBrualdiCarmonavan_den_DriesscheKirkland2018[httpsbooksgooglecombooksidLMRTDwAAQBAJpgPA19_19]_146-0)**[Brualdi et al. (2018)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBrualdiCarmonavan_den_DriesscheKirkland2018), p.[19](https://books.google.com/books?id=LMRTDwAAQBAJ&pg=PA19).
147.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEFaridKhanWang20132087_147-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEFaridKhanWang20132087_147-1)[Farid, Khan & Wang (2013)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFFaridKhanWang2013), 2087.
148.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEReutenauerStraubing1984351_148-0)**[Reutenauer & Straubing (1984)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFReutenauerStraubing1984), 351.
149.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGhosh1996222_149-0)**[Ghosh (1996)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGhosh1996), 222.
150.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECarboniKasangianWalters1987137_150-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECarboniKasangianWalters1987137_150-1)[Carboni, Kasangian & Walters (1987)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFCarboniKasangianWalters1987), 137.
151.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEManningSch%C3%BCtze1999Section_15.3.4_151-0)**[Manning & Schütze (1999)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFManningSch%C3%BCtze1999), Section 15.3.4.
152.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWard1997Ch._2.8_152-0)**[Ward (1997)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWard1997), Ch. 2.8.
153.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEAb%C5%82amowicz2000[httpsbooksgooglecombooksidyvCC94xzJG8CpgPA436_436]_153-0)**[Abłamowicz (2000)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFAb%C5%82amowicz2000), p.[436](https://books.google.com/books?id=yvCC94xzJG8C&pg=PA436).
154.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEFudenbergTirole1983Section_1.1.1_154-0)**[Fudenberg & Tirole (1983)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFFudenbergTirole1983), Section 1.1.1.
155.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMcHugh2025[httpsbooksgooglecombooksidU9slEQAAQBAJpgPA390_390]11.2.3_The_expected_payoff_as_a_vector%E2%80%93matrix%E2%80%93vector_product_155-0)**[McHugh (2025)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMcHugh2025), p.[390](https://books.google.com/books?id=U9slEQAAQBAJ&pg=PA390), 11.2.3 The expected payoff as a vector–matrix–vector product.
156.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMatou%C5%A1ekG%C3%A4rtner2007[httpsbooksgooglecombooksid6MO_RS4z0w8CpgPA136_136%E2%80%93137]_156-0)**[Matoušek & Gärtner (2007)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMatou%C5%A1ekG%C3%A4rtner2007), pp.[136–137](https://books.google.com/books?id=6MO_RS4z0w8C&pg=PA136).
157.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEStinson2005Ch._1.1.5_and_1.2.4_157-0)**[Stinson (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFStinson2005), Ch. 1.1.5 and 1.2.4.
158.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEISRD_Group2005Ch._7_158-0)**[ISRD Group (2005)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFISRD_Group2005), Ch. 7.
159.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBhayaKaszkurewicz2006[httpsbooksgooglecombooksid3X7S_965jywCpgPA230_230]_159-0)**[Bhaya & Kaszkurewicz (2006)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBhayaKaszkurewicz2006), p.[230](https://books.google.com/books?id=3X7S_965jywC&pg=PA230).
160.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEJensen1999[httpsarchiveorgdetailsintroductiontoco0000jenspage65mode2upqmatrix_65%E2%80%9369]_160-0)**[Jensen (1999)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFJensen1999), p.[65–69](https://archive.org/details/introductiontoco0000jens/page/65/mode/2up?q=matrix).
161.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGodsilRoyle2004Ch._8.1_161-0)**[Godsil & Royle (2004)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGodsilRoyle2004), Ch. 8.1.
162.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPunnenGutin2002_162-0)**[Punnen & Gutin (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPunnenGutin2002).
163.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEZhangYuHou2006[httpbooksgooglecombooksid0xhra9vKCnUCpgPA7_7]_163-0)**[Zhang, Yu & Hou (2006)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFZhangYuHou2006), p.[7](http://books.google.com/books?id=0xhra9vKCnUC&pg=PA7).
164.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEScottT%C5%AFma2023_164-0)**[Scott & Tůma (2023)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFScottT%C5%AFma2023).
165.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1987Ch._XVI.6_165-0)**[Lang (1987)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1987), Ch. XVI.6.
166.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTENocedalWright2006Ch._16_166-0)**[Nocedal & Wright (2006)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFNocedalWright2006), Ch. 16.
167.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELang1987Ch._XVI.1_167-0)**[Lang (1987)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1987), Ch. XVI.1.
168.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-168)**Lang[1987](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1987), Ch. XVI.5. For a more advanced, and more general statement see Lang[1969](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLang1969), Ch. VI.2.
169.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGilbargTrudinger2001_169-0)**[Gilbarg & Trudinger (2001)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGilbargTrudinger2001).
170.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-170)**Šolin[2005](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREF%C5%A0olin2005), Ch. 2.5. See also [stiffness method](https://en.wikipedia.org/wiki/Stiffness_method "Stiffness method").
171.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTELatoucheRamaswami1999_171-0)**[Latouche & Ramaswami (1999)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFLatoucheRamaswami1999).
172.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMehataSrinivasan1978Ch._2.8_172-0)**[Mehata & Srinivasan (1978)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMehataSrinivasan1978), Ch. 2.8.
173.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-173)**[Healy, Michael](https://en.wikipedia.org/wiki/Michael_Healy_(statistician) "Michael Healy (statistician)") (1986), _Matrices for Statistics_, [Oxford University Press](https://en.wikipedia.org/wiki/Oxford_University_Press "Oxford University Press"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-19-850702-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-19-850702-4 "Special:BookSources/978-0-19-850702-4")
174.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKrzanowski198860Ch._2.2_174-0)**[Krzanowski (1988)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKrzanowski1988), p.60, Ch. 2.2.
175.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKrzanowski1988Ch._4.1_175-0)**[Krzanowski (1988)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKrzanowski1988), Ch. 4.1.
176.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-176)**[Conrey](https://en.wikipedia.org/wiki/Brian_Conrey "Brian Conrey")[2007](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFConrey2007)
177.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-177)**Zabrodin, Brézin & Kazakov et al.[2006](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFZabrodinBr%C3%A9zinKazakovSerban2006)
178.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTESchiff1968Ch._6_178-0)**[Schiff (1968)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFSchiff1968), Ch. 6.
179.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPeres199320_179-0)**[Peres (1993)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPeres1993), p.20.
180.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBohm2001sections_I.8,_II.4,_and_II.8_180-0)**[Bohm (2001)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBohm2001), sections I.8, II.4, and II.8.
181.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPeres199373_181-0)**[Peres (1993)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPeres1993), p.73.
182.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEItzyksonZuber1980Ch._2_182-0)**[Itzykson & Zuber (1980)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFItzyksonZuber1980), Ch. 2.
183.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEBurgessMoore2007section_1.6.3._(SU(3)),_section_2.4.3.2._(Kobayashi%E2%80%93Maskawa_matrix)_183-0)**[Burgess & Moore (2007)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBurgessMoore2007), section 1.6.3. (SU(3)), section 2.4.3.2. (Kobayashi–Maskawa matrix).
184.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWeinberg1995Ch._3_184-0)**[Weinberg (1995)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWeinberg1995), Ch. 3.
185.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEWherrett1987part_II_185-0)**[Wherrett (1987)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWherrett1987), part II.
186.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTERileyHobsonBence19977.17_186-0)**[Riley, Hobson & Bence (1997)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFRileyHobsonBence1997), 7.17.
187.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEGuenther1990Ch._5_187-0)**[Guenther (1990)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFGuenther1990), Ch. 5.
188.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTESuresh_Kumar2009747%E2%80%93749_188-0)**[Suresh Kumar (2009)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFSuresh_Kumar2009), pp.747–749.
189.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-189)**Shen, Crossley & Lun[1999](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFShenCrossleyLun1999) cited by Bretscher[2005](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFBretscher2005), p. 1
190.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564%E2%80%93565_190-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564%E2%80%93565_190-1)[_**c**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564%E2%80%93565_190-2)[_**d**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564%E2%80%93565_190-3)[_**e**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564%E2%80%93565_190-4)[Dossey (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFDossey2002), pp.564–565.
191.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-191)**[Needham, Joseph](https://en.wikipedia.org/wiki/Joseph_Needham "Joseph Needham"); [Wang Ling](https://en.wikipedia.org/wiki/Wang_Ling_(historian) "Wang Ling (historian)") (1959), [_Science and Civilisation in China_](https://books.google.com/books?id=jfQ9E0u4pLAC&pg=PA117), vol.III, Cambridge: Cambridge University Press, p.117, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-05801-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-05801-8 "Special:BookSources/978-0-521-05801-8")`{{cite book}}`: CS1 maint: ignored ISBN errors ([link](https://en.wikipedia.org/wiki/Category:CS1_maint:_ignored_ISBN_errors "Category:CS1 maint: ignored ISBN errors"))
192.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDossey2002564_192-0)**[Dossey (2002)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFDossey2002), p.564.
193.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECramer1750_193-0)**[Cramer (1750)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFCramer1750).
194.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKosinski2001_194-0)**[Kosinski (2001)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKosinski2001).
195.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-195)**[Murray, James](https://en.wikipedia.org/wiki/James_Murray_(lexicographer) "James Murray (lexicographer)"); [Bradley, Henry](https://en.wikipedia.org/wiki/Henry_Bradley "Henry Bradley"), eds. (1908), ["Matrix"](https://archive.org/details/oed6barch/page/238/mode/1up), _[A New English Dictionary on Historical Principles](https://en.wikipedia.org/wiki/A\_New\_English\_Dictionary\_on\_Historical\_Principles "A New English Dictionary on Historical Principles")_, vol.6, pt. 2 (M–N), Oxford: Clarendon Press, p.238
196.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-196)**The earliest published example is J. J. Sylvester (1850) "Additions to the articles in the September number of this journal, 'On a new class of theorems,' and on Pascal's theorem," _The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science_, **37**: 363-370. [From page 369](https://books.google.com/books?id=CBhDAQAAIAAJ&pg=PA369): "For this purpose, we must commence, not with a square, but with an oblong arrangement of terms consisting, suppose, of m lines and n columns. This does not in itself represent a determinant, but is, as it were, a Matrix out of which we may form various systems of determinants ... "
197.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTESylvester1904247[httpsbooksgooglecombooksid5GQPlxWrDiECpgPA247_Paper_37]_197-0)**[Sylvester (1904)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFSylvester1904), p.247, [Paper 37](https://books.google.com/books?id=5GQPlxWrDiEC&pg=PA247).
198.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTECayley1858_198-0)**[Cayley (1858)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFCayley1858).
199.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEDieudonn%C3%A91978Vol._1,_Ch._III,_p._96_199-0)**[Dieudonné (1978)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFDieudonn%C3%A91978), Vol. 1, Ch. III, p. 96.
200.   ^ [_**a**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKnobloch1994_200-0)[_**b**_](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEKnobloch1994_200-1)[Knobloch (1994)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKnobloch1994).
201.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHawkins1975_201-0)**[Hawkins (1975)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHawkins1975).
202.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-202)**Kronecker[1897](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFKronecker1897)
203.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-203)**Weierstrass[1915](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFWeierstrass1915), pp. 271–286
204.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEMiller1930_204-0)**[& Miller (1930)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFMiller1930).
205.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEB%C3%B4cher2004_205-0)**[Bôcher (2004)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFB%C3%B4cher2004).
206.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEHawkins1972_206-0)**[Hawkins (1972)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFHawkins1972).
207.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEvan_der_Waerden200728%E2%80%9340_207-0)**[van der Waerden (2007)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFvan_der_Waerden2007), pp.28–40.
208.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTEPeres199379,_106%E2%80%93107_208-0)**[Peres (1993)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFPeres1993), pp.79, 106–107.
209.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-209)**Whitehead, Alfred North; and Russell, Bertrand (1913) _Principia Mathematica to *56_, Cambridge at the University Press, Cambridge UK (republished 1962) cf page 162ff.
210.   **[^](https://en.wikipedia.org/wiki/Matrix_(mathematics)#cite_ref-FOOTNOTETarski1941[httpsbooksgooglecombooksid5MeNCgAAQBAJpgPA40_40]_210-0)**[Tarski (1941)](https://en.wikipedia.org/wiki/Matrix_(mathematics)#CITEREFTarski1941), p.[40](https://books.google.com/books?id=5MeNCgAAQBAJ&pg=PA40).

### Mathematical references

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=48 "Edit section: Mathematical references")]

*   Andrilli, Stephen; Hecker, David (2022), _Elementary Linear Algebra_ (6th ed.), Academic Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780323984263](https://en.wikipedia.org/wiki/Special:BookSources/9780323984263 "Special:BookSources/9780323984263")
*   Anton, Howard (2010), [_Elementary Linear Algebra_](https://books.google.com/books?id=YmcQJoFyZ5gC&pg=PA414) (10th ed.), John Wiley & Sons, p.414, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-470-45821-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-470-45821-1 "Special:BookSources/978-0-470-45821-1")
*   [Arnold, Vladimir I.](https://en.wikipedia.org/wiki/Vladimir_Arnold "Vladimir Arnold") (1992), _Ordinary differential equations_, translated by Cooke, Roger, Berlin, DE; New York, NY: [Springer-Verlag](https://en.wikipedia.org/wiki/Springer-Verlag "Springer-Verlag"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-54813-3](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-54813-3 "Special:BookSources/978-3-540-54813-3")
*   [Artin, Michael](https://en.wikipedia.org/wiki/Michael_Artin "Michael Artin") (1991), _Algebra_, [Prentice Hall](https://en.wikipedia.org/wiki/Prentice_Hall "Prentice Hall"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-89871-510-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-89871-510-1 "Special:BookSources/978-0-89871-510-1")
*   Axler, Sheldon (1997), _Linear Algebra Done Right_, Undergraduate Texts in Mathematics (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387982595](https://en.wikipedia.org/wiki/Special:BookSources/9780387982595 "Special:BookSources/9780387982595")
*   Baker, Andrew J. (2003), [_Matrix Groups: An Introduction to Lie Group Theory_](https://archive.org/details/matrixgroupsintr0000bake), Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-85233-470-3](https://en.wikipedia.org/wiki/Special:BookSources/978-1-85233-470-3 "Special:BookSources/978-1-85233-470-3")
*   Bau III, David; [Trefethen, Lloyd N.](https://en.wikipedia.org/wiki/Lloyd_N._Trefethen "Lloyd N. Trefethen") (1997), _Numerical linear algebra_, Philadelphia, PA: Society for Industrial and Applied Mathematics, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-89871-361-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-89871-361-9 "Special:BookSources/978-0-89871-361-9")
*   [Ben-Israel, Adi](https://en.wikipedia.org/wiki/Adi_Ben-Israel "Adi Ben-Israel"); [Greville, Thomas Nall Eden](https://en.wikipedia.org/wiki/Thomas_N._E._Greville "Thomas N. E. Greville") (2003), _Generalized Inverses: Theory and Applications_ (2nd ed.), New York, NY: Springer, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/b97366](https://doi.org/10.1007%2Fb97366), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-00293-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-00293-4 "Special:BookSources/978-0-387-00293-4")
*   Bernstein, Dennis S. (2009), _Matrix mathematics: theory, facts, and formulas_ (2nd ed.), Princeton, N.J: Princeton University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4008-3334-4](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4008-3334-4 "Special:BookSources/978-1-4008-3334-4")
*   Bhaya, Amit; Kaszkurewicz, Eugenius (2006), _Control Perspectives on Numerical Algorithms and Matrix Problems_, Advances in Design and Control, vol.10, SIAM, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780898716023](https://en.wikipedia.org/wiki/Special:BookSources/9780898716023 "Special:BookSources/9780898716023")
*   Bierens, Herman J. (2004), _Introduction to the Mathematical and Statistical Foundations of Econometrics_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780521542241](https://en.wikipedia.org/wiki/Special:BookSources/9780521542241 "Special:BookSources/9780521542241")
*   Boos, Johann (2000), _Classical and Modern Methods in Summability_, Oxford mathematical monographs, Oxford University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780198501657](https://en.wikipedia.org/wiki/Special:BookSources/9780198501657 "Special:BookSources/9780198501657")
*   Bretscher, Otto (2005), _Linear Algebra with Applications_ (3rd ed.), Prentice Hall
*   Bronson, Richard (1970), _Matrix Methods: An Introduction_, New York: [Academic Press](https://en.wikipedia.org/wiki/Academic_Press "Academic Press"), [LCCN](https://en.wikipedia.org/wiki/LCCN_(identifier) "LCCN (identifier)")[70097490](https://lccn.loc.gov/70097490)
*   Bronson, Richard (1989), _Schaum's outline of theory and problems of matrix operations_, New York: [McGraw–Hill](https://en.wikipedia.org/wiki/McGraw%E2%80%93Hill "McGraw–Hill"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-007978-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-007978-6 "Special:BookSources/978-0-07-007978-6")
*   Brown, William C. (1991), [_Matrices and vector spaces_](https://archive.org/details/matricesvectorsp0000brow), New York, NY: [Marcel Dekker](https://en.wikipedia.org/wiki/Marcel_Dekker "Marcel Dekker"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8247-8419-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8247-8419-5 "Special:BookSources/978-0-8247-8419-5")
*   [Brualdi, Richard A.](https://en.wikipedia.org/wiki/Richard_A._Brualdi "Richard A. Brualdi"); Carmona, Ángeles; [van den Driessche, P.](https://en.wikipedia.org/wiki/Pauline_van_den_Driessche "Pauline van den Driessche"); Kirkland, Stephen; Stevanović, Dragan (2018), Encinas, Andrés M.; Mitjana, Margarida (eds.), _Combinatorial Matrix Theory_, Advanced Courses in Mathematics. CRM Barcelona, Birkhäuser/Springer, Cham, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-3-319-70953-6](https://doi.org/10.1007%2F978-3-319-70953-6), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-319-70952-9](https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-70952-9 "Special:BookSources/978-3-319-70952-9"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[3791450](https://mathscinet.ams.org/mathscinet-getitem?mr=3791450)
*   Cameron, Peter J. (2014), ["Matrix groups"](https://webspace.maths.qmul.ac.uk/p.j.cameron/preprints/mgo.pdf)(PDF), in Hogben, Leslie (ed.), _Handbook of Linear Algebra_, Discrete Mathematics and its Applications (Boca Raton) (2nd ed.), CRC Press, Boca Raton, FL, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4665-0728-9](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4665-0728-9 "Special:BookSources/978-1-4665-0728-9"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[3013937](https://mathscinet.ams.org/mathscinet-getitem?mr=3013937)
*   Carboni, Aurelio; Kasangian, Stefano; Walters, Robert (1987), "An axiomatics for bicategories of modules", _Journal of Pure and Applied Algebra_, **45** (2): 127–141, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0022-4049(87)90065-X](https://doi.org/10.1016%2F0022-4049%2887%2990065-X), [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0022-4049](https://search.worldcat.org/issn/0022-4049), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0889588](https://mathscinet.ams.org/mathscinet-getitem?mr=0889588), [Zbl](https://en.wikipedia.org/wiki/Zbl_(identifier) "Zbl (identifier)")[0615.18006](https://zbmath.org/?format=complete&q=an:0615.18006)
*   Chahal, J. S. (2018), _Fundamentals of Linear Algebra_, CRC Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780429758119](https://en.wikipedia.org/wiki/Special:BookSources/9780429758119 "Special:BookSources/9780429758119")
*   Coburn, Nathaniel (1955), _Vector and tensor analysis_, New York, NY: Macmillan, [OCLC](https://en.wikipedia.org/wiki/OCLC_(identifier) "OCLC (identifier)")[1029828](https://search.worldcat.org/oclc/1029828)
*   Coleman, Thomas F.; Van Loan, Charles (1988), _Handbook for Matrix Computations_, Frontiers in Applied Mathematics, vol.4, SIAM, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780898712278](https://en.wikipedia.org/wiki/Special:BookSources/9780898712278 "Special:BookSources/9780898712278")
*   Conrey, J. Brian (2007), _Ranks of elliptic curves and random matrix theory_, [Cambridge University Press](https://en.wikipedia.org/wiki/Cambridge_University_Press "Cambridge University Press"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-69964-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-69964-8 "Special:BookSources/978-0-521-69964-8")
*   Dossey, John A. (2002), _Discrete Mathematics_ (4th ed.), Addison Wesley, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780321079121](https://en.wikipedia.org/wiki/Special:BookSources/9780321079121 "Special:BookSources/9780321079121")
*   [Conway, John B.](https://en.wikipedia.org/wiki/John_B._Conway "John B. Conway") (1990), _A Course in Functional Analysis_, Graduate Texts in Mathematics, vol.96 (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-387-97245-5](https://en.wikipedia.org/wiki/Special:BookSources/0-387-97245-5 "Special:BookSources/0-387-97245-5")
*   [Edwards, Harold M.](https://en.wikipedia.org/wiki/Harold_Edwards_(mathematician) "Harold Edwards (mathematician)") (2004), _Linear Algebra_, Springer Science & Business Media, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780817643706](https://en.wikipedia.org/wiki/Special:BookSources/9780817643706 "Special:BookSources/9780817643706")
*   Farid, F. O.; Khan, Israr Ali; Wang, Qing-Wen (2013), "On matrices over an arbitrary semiring and their generalized inverses", _Linear Algebra and its Applications_, **439** (7): 2085–2105, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.laa.2013.06.002](https://doi.org/10.1016%2Fj.laa.2013.06.002), [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0024-3795](https://search.worldcat.org/issn/0024-3795), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[3090456](https://mathscinet.ams.org/mathscinet-getitem?mr=3090456), [Zbl](https://en.wikipedia.org/wiki/Zbl_(identifier) "Zbl (identifier)")[1283.15016](https://zbmath.org/?format=complete&q=an:1283.15016)
*   Fraleigh, John B. (1976), _A First Course In Abstract Algebra_ (2nd ed.), Reading: [Addison-Wesley](https://en.wikipedia.org/wiki/Addison-Wesley "Addison-Wesley"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-201-01984-1](https://en.wikipedia.org/wiki/Special:BookSources/0-201-01984-1 "Special:BookSources/0-201-01984-1")
*   Fudenberg, Drew; [Tirole, Jean](https://en.wikipedia.org/wiki/Jean_Tirole "Jean Tirole") (1983), _Game Theory_, [MIT Press](https://en.wikipedia.org/wiki/MIT_Press "MIT Press")
*   Gentle, James E. (1998), _Numerical Linear Algebra for Applications in Statistics_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387985428](https://en.wikipedia.org/wiki/Special:BookSources/9780387985428 "Special:BookSources/9780387985428")
*   Ghosh, Shamik (1996), "Matrices over semirings", _Information Sciences_, **90** (1–4): 221–230, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0020-0255(95)00283-9](https://doi.org/10.1016%2F0020-0255%2895%2900283-9), [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0020-0255](https://search.worldcat.org/issn/0020-0255), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1388422](https://mathscinet.ams.org/mathscinet-getitem?mr=1388422), [Zbl](https://en.wikipedia.org/wiki/Zbl_(identifier) "Zbl (identifier)")[0884.15010](https://zbmath.org/?format=complete&q=an:0884.15010)
*   Gilbarg, David; [Trudinger, Neil S.](https://en.wikipedia.org/wiki/Neil_Trudinger "Neil Trudinger") (2001), _Elliptic partial differential equations of second order_ (2nd ed.), Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-41160-4](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-41160-4 "Special:BookSources/978-3-540-41160-4")
*   [Godsil, Chris](https://en.wikipedia.org/wiki/Chris_Godsil "Chris Godsil"); [Royle, Gordon](https://en.wikipedia.org/wiki/Gordon_Royle "Gordon Royle") (2004), _Algebraic Graph Theory_, Graduate Texts in Mathematics, vol.207, Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-95220-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-95220-8 "Special:BookSources/978-0-387-95220-8")
*   [Golub, Gene H.](https://en.wikipedia.org/wiki/Gene_H._Golub "Gene H. Golub"); [Van Loan, Charles F.](https://en.wikipedia.org/wiki/Charles_F._Van_Loan "Charles F. Van Loan") (1996), _Matrix Computations_ (3rd ed.), Johns Hopkins, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8018-5414-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8018-5414-9 "Special:BookSources/978-0-8018-5414-9")
*   Greub, Werner Hildbert (1975), _Linear algebra_, Graduate Texts in Mathematics, Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-90110-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-90110-7 "Special:BookSources/978-0-387-90110-7")
*   Grillet, Pierre Antoine (2007), _Abstract Algebra_, [Graduate Texts in Mathematics](https://en.wikipedia.org/wiki/Graduate_Texts_in_Mathematics "Graduate Texts in Mathematics"), vol.242 (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387715681](https://en.wikipedia.org/wiki/Special:BookSources/9780387715681 "Special:BookSources/9780387715681")
*   Hachenberger, Dirk; Jungnickel, Dieter (2020), _Topics in Galois Fields_, Algorithms and Computation in Mathematics, vol.29, Cham: Springer, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-3-030-60806-4](https://doi.org/10.1007%2F978-3-030-60806-4), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-030-60804-0](https://en.wikipedia.org/wiki/Special:BookSources/978-3-030-60804-0 "Special:BookSources/978-3-030-60804-0"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[4233161](https://mathscinet.ams.org/mathscinet-getitem?mr=4233161)
*   [Halmos, Paul Richard](https://en.wikipedia.org/wiki/Paul_Halmos "Paul Halmos") (1982), _A Hilbert space problem book_, Graduate Texts in Mathematics, vol.19 (2nd ed.), Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-90685-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-90685-0 "Special:BookSources/978-0-387-90685-0"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0675952](https://mathscinet.ams.org/mathscinet-getitem?mr=0675952)
*   Grossman, Stanley I. (1994), _Elementary Linear Algebra_ (5th ed.), Saunders College Pub., [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780030973543](https://en.wikipedia.org/wiki/Special:BookSources/9780030973543 "Special:BookSources/9780030973543")
*   Hamilton, A. G. (1987), _A First Course in Linear Algebra: With Concurrent Examples_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780521310413](https://en.wikipedia.org/wiki/Special:BookSources/9780521310413 "Special:BookSources/9780521310413")
*   Hazewinkel, Michiel; Gubareni, Nadiya M. (2017), _Algebras, Rings and Modules, Volume 2: Non-commutative Algebras and Rings_ (2nd ed.), CRC Press}
*   [Horn, Roger A.](https://en.wikipedia.org/wiki/Roger_Horn "Roger Horn"); [Johnson, Charles R.](https://en.wikipedia.org/wiki/Charles_Royal_Johnson "Charles Royal Johnson") (1985), _Matrix Analysis_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-38632-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-38632-6 "Special:BookSources/978-0-521-38632-6")
*   Householder, Alston S. (1975), _The theory of matrices in numerical analysis_, New York, NY: [Dover Publications](https://en.wikipedia.org/wiki/Dover_Publications "Dover Publications"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0378371](https://mathscinet.ams.org/mathscinet-getitem?mr=0378371)
*   Hungerford, Thomas W. (1980), _Algebra_, Graduate Texts in Mathematics, vol.73, Springer-Verlag, New York-Berlin, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-387-90518-9](https://en.wikipedia.org/wiki/Special:BookSources/0-387-90518-9 "Special:BookSources/0-387-90518-9"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0600654](https://mathscinet.ams.org/mathscinet-getitem?mr=0600654)
*   ISRD Group (2005), _Computer Graphics_, Tata McGraw–Hill, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-059376-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-059376-3 "Special:BookSources/978-0-07-059376-3")
*   Itô, Kiyosi, ed. (1987), _Encyclopedic dictionary of mathematics. Vol. I-IV_ (2nd ed.), MIT Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-262-09026-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-262-09026-1 "Special:BookSources/978-0-262-09026-1"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0901762](https://mathscinet.ams.org/mathscinet-getitem?mr=0901762)
*   Jeffrey, Alan (2010), _Matrix Operations for Engineers and Scientists: An Essential Guide in Linear Algebra_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9789048192748](https://en.wikipedia.org/wiki/Special:BookSources/9789048192748 "Special:BookSources/9789048192748")
*   Johnston, Nathaniel (2021), _Introduction to Linear and Matrix Algebra_, Springer Nature, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9783030528119](https://en.wikipedia.org/wiki/Special:BookSources/9783030528119 "Special:BookSources/9783030528119")
*   Kreyszig, Erwin (1972), [_Advanced Engineering Mathematics_](https://archive.org/details/advancedengineer00krey) (3rd ed.), New York: [Wiley](https://en.wikipedia.org/wiki/John_Wiley_%26_Sons "John Wiley & Sons"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-471-50728-8](https://en.wikipedia.org/wiki/Special:BookSources/0-471-50728-8 "Special:BookSources/0-471-50728-8").
*   Krzanowski, Wojtek J. (1988), _Principles of multivariate analysis_, Oxford Statistical Science Series, vol.3, The Clarendon Press Oxford University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-19-852211-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-19-852211-9 "Special:BookSources/978-0-19-852211-9"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0969370](https://mathscinet.ams.org/mathscinet-getitem?mr=0969370)
*   Lam, T. Y. (1999), _Lectures on Modules and Rings_, Graduate Texts in Mathematics, vol.189, Springer-Verlag, New York, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-1-4612-0525-8](https://doi.org/10.1007%2F978-1-4612-0525-8), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-387-98428-3](https://en.wikipedia.org/wiki/Special:BookSources/0-387-98428-3 "Special:BookSources/0-387-98428-3"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1653294](https://mathscinet.ams.org/mathscinet-getitem?mr=1653294)
*   Lancaster, Peter; Tismenetsky, Miron (1985), _The Theory of Matrices: With Applications_ (2nd ed.), Elsevier, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780080519081](https://en.wikipedia.org/wiki/Special:BookSources/9780080519081 "Special:BookSources/9780080519081")
*   [Lang, Serge](https://en.wikipedia.org/wiki/Serge_Lang "Serge Lang") (1969), _Analysis II_, [Addison-Wesley](https://en.wikipedia.org/wiki/Addison-Wesley "Addison-Wesley")
*   [Lang, Serge](https://en.wikipedia.org/wiki/Serge_Lang "Serge Lang") (1986), _Introduction to Linear Algebra_ (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781461210702](https://en.wikipedia.org/wiki/Special:BookSources/9781461210702 "Special:BookSources/9781461210702")
*   Lang, Serge (1987), [_Calculus of several variables_](https://archive.org/details/calculusofsevera0000lang) (3rd ed.), Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-96405-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-96405-8 "Special:BookSources/978-0-387-96405-8")
*   [Lang, Serge](https://en.wikipedia.org/wiki/Serge_Lang "Serge Lang") (2002), _[Algebra](https://en.wikipedia.org/wiki/Algebra\_(Lang) "Algebra (Lang)")_, [Graduate Texts in Mathematics](https://en.wikipedia.org/wiki/Graduate_Texts_in_Mathematics "Graduate Texts in Mathematics"), vol.211 (Revised third ed.), New York: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-95385-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-95385-4 "Special:BookSources/978-0-387-95385-4"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1878556](https://mathscinet.ams.org/mathscinet-getitem?mr=1878556)
*   Latouche, Guy; Ramaswami, Vaidyanathan (1999), _Introduction to matrix analytic methods in stochastic modeling_ (1st ed.), Philadelphia, PA: Society for Industrial and Applied Mathematics, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-89871-425-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-89871-425-8 "Special:BookSources/978-0-89871-425-8")
*   Manning, Christopher D.; Schütze, Hinrich (1999), _Foundations of statistical natural language processing_, MIT Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-262-13360-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-262-13360-9 "Special:BookSources/978-0-262-13360-9")
*   Margalit, Dan; Rabinoff, Joseph (2019), ["Determinants and Volumes"](https://textbooks.math.gatech.edu/ila/determinants-volumes.html), _Interactive Linear Algebra_, Georgia Institute of Technology, retrieved 2025-05-10
*   [Matoušek, Jiří](https://en.wikipedia.org/wiki/Ji%C5%99%C3%AD_Matou%C5%A1ek_(mathematician) "Jiří Matoušek (mathematician)"); Gärtner, Bernd (2007), _Understanding and Using Linear Programming_, Springer Science & Business Media, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9783540307174](https://en.wikipedia.org/wiki/Special:BookSources/9783540307174 "Special:BookSources/9783540307174")
*   Maxwell, E. A. (1969), _Algebraic Structure and Matrices, Being Part II of Advanced Algebra_, Cambridge University Press
*   McHugh, Andrew (2025), _Finite Mathematics: An Introduction with Applications in Business, Social Sciences, and Music_, Academic Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780443290954](https://en.wikipedia.org/wiki/Special:BookSources/9780443290954 "Special:BookSources/9780443290954")
*   [Meckes, Elizabeth S.](https://en.wikipedia.org/wiki/Elizabeth_Meckes "Elizabeth Meckes"); Meckes, Mark W. (2018), _Linear Algebra_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781316836026](https://en.wikipedia.org/wiki/Special:BookSources/9781316836026 "Special:BookSources/9781316836026")
*   Mehata, K. M.; Srinivasan, S. K. (1978), _Stochastic processes_, New York, NY: McGraw–Hill, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-096612-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-096612-3 "Special:BookSources/978-0-07-096612-3")
*   Mello, David C. (2017), _Invitation to Linear Algebra_, Textbooks in Mathematics, CRC Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781498779586](https://en.wikipedia.org/wiki/Special:BookSources/9781498779586 "Special:BookSources/9781498779586")
*   [Mirsky, Leonid](https://en.wikipedia.org/wiki/Leon_Mirsky "Leon Mirsky") (1990), [_An Introduction to Linear Algebra_](https://books.google.com/books?id=ULMmheb26ZcC&q=linear+algebra+determinant&pg=PA1), Courier Dover Publications, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-66434-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-66434-7 "Special:BookSources/978-0-486-66434-7")
*   Misra, Chandan; Bhattacharya, Sourangshu; Ghosh, Soumya K. (June 2022), "Stark: Fast and scalable Strassen's matrix multiplication using Apache Spark", _IEEE Transactions on Big Data_, **8** (3): 699–710, [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[1811.07325](https://arxiv.org/abs/1811.07325), [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1109/tbdata.2020.2977326](https://doi.org/10.1109%2Ftbdata.2020.2977326)
*   Nering, Evar D. (1970), _Linear Algebra and Matrix Theory_ (2nd ed.), New York: [Wiley](https://en.wikipedia.org/wiki/John_Wiley_%26_Sons "John Wiley & Sons"), [LCCN](https://en.wikipedia.org/wiki/LCCN_(identifier) "LCCN (identifier)")[76-91646](https://lccn.loc.gov/76-91646)
*   Nocedal, Jorge; Wright, Stephen J. (2006), _Numerical Optimization_ (2nd ed.), Berlin, DE; New York, NY: Springer-Verlag, p.449, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-30303-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-30303-1 "Special:BookSources/978-0-387-30303-1")
*   Oualline, Steve (2003), _Practical C++ programming_, [O'Reilly](https://en.wikipedia.org/wiki/O%27Reilly_Media "O'Reilly Media"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-596-00419-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-596-00419-4 "Special:BookSources/978-0-596-00419-4")
*   Perrone, Paolo (2024), [_Starting Category Theory_](https://www.worldscientific.com/worldscibooks/10.1142/13670), World Scientific, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1142/9789811286018_0005](https://doi.org/10.1142%2F9789811286018_0005), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-981-12-8600-1](https://en.wikipedia.org/wiki/Special:BookSources/978-981-12-8600-1 "Special:BookSources/978-981-12-8600-1")
*   Pettofrezzo, Anthony J. (1978), _Matrices and Transformations_, Dover Books on Mathematics, Courier Corporation, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780486636344](https://en.wikipedia.org/wiki/Special:BookSources/9780486636344 "Special:BookSources/9780486636344")
*   Perlis, Sam (1991), [_Theory of Matrices_](https://books.google.com/books?id=5_sxtcnvLhoC&pg=PA103), Dover books on advanced mathematics, Courier Dover Corporation, p.103, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-66810-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-66810-9 "Special:BookSources/978-0-486-66810-9")
*   Pop; Furdui (2017), _Square Matrices of Order 2_, Springer International Publishing, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-319-54938-5](https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-54938-5 "Special:BookSources/978-3-319-54938-5")
*   Press, William H.; Flannery, Brian P.; [Teukolsky, Saul A.](https://en.wikipedia.org/wiki/Saul_Teukolsky "Saul Teukolsky"); Vetterling, William T. (1992), ["LU Decomposition and Its Applications"](https://web.archive.org/web/20090906113144/http://www.mpi-hd.mpg.de/astrophysik/HEA/internal/Numerical_Recipes/f2-3.pdf)(PDF), _Numerical Recipes in FORTRAN: The Art of Scientific Computing_ (2nd ed.), Cambridge University Press, pp.34–42, archived from the original on 2009-09-06
*   Protter, Murray H.; Morrey, Charles B. Jr. (1970), _College Calculus with Analytic Geometry_ (2nd ed.), Reading: [Addison-Wesley](https://en.wikipedia.org/wiki/Addison-Wesley "Addison-Wesley"), [LCCN](https://en.wikipedia.org/wiki/LCCN_(identifier) "LCCN (identifier)")[76087042](https://lccn.loc.gov/76087042)
*   Punnen, Abraham P.; Gutin, Gregory (2002), _The traveling salesman problem and its variations_, Boston, MA: Kluwer Academic Publishers, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4020-0664-7](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4020-0664-7 "Special:BookSources/978-1-4020-0664-7")
*   Ramachandra Rao, A.; Bhimasankaram, P. (2000), _Linear Algebra_, Texts and Readings in Mathematics, vol.19 (2nd ed.), Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9789386279019](https://en.wikipedia.org/wiki/Special:BookSources/9789386279019 "Special:BookSources/9789386279019")
*   Reutenauer, Christophe; Straubing, Howard (1984), "Inversion of matrices over a commutative semiring", _Journal of Algebra_, **88** (2): 350–360, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0021-8693(84)90070-X](https://doi.org/10.1016%2F0021-8693%2884%2990070-X), [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0021-8693](https://search.worldcat.org/issn/0021-8693), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0747520](https://mathscinet.ams.org/mathscinet-getitem?mr=0747520), [Zbl](https://en.wikipedia.org/wiki/Zbl_(identifier) "Zbl (identifier)")[0563.15011](https://zbmath.org/?format=complete&q=an:0563.15011)
*   Reyes, Manuel (2025), "A tour of noncommutative spectral theories", _Notices of the American Mathematical Society_, **72** (2): 145–153, [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[2409.08421](https://arxiv.org/abs/2409.08421), [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1090/noti3100](https://doi.org/10.1090%2Fnoti3100), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[4854325](https://mathscinet.ams.org/mathscinet-getitem?mr=4854325)
*   [Riehl, Emily](https://en.wikipedia.org/wiki/Emily_Riehl "Emily Riehl") (2016), [_Category Theory in Context_](https://books.google.com/books?id=6B9MDgAAQBAJ), Dover, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780486809038](https://en.wikipedia.org/wiki/Special:BookSources/9780486809038 "Special:BookSources/9780486809038")
*   Roth, Ron (2006), _Introduction to Coding Theory_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780521845045](https://en.wikipedia.org/wiki/Special:BookSources/9780521845045 "Special:BookSources/9780521845045")
*   Rowen, Louis Halle (2008), _Graduate Algebra: noncommutative view_, Providence, RI: [American Mathematical Society](https://en.wikipedia.org/wiki/American_Mathematical_Society "American Mathematical Society"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8218-4153-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8218-4153-2 "Special:BookSources/978-0-8218-4153-2")
*   Schneider, Hans; Barker, George Phillip (2012), [_Matrices and Linear Algebra_](https://books.google.com/books?id=9vjBAgAAQBAJ&pg=PA251), Dover Books on Mathematics, Courier Dover Corporation, p.251, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-13930-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-13930-2 "Special:BookSources/978-0-486-13930-2")
*   Scott, J.; Tůma, M. (2023), "Sparse Matrices and Their Graphs", _Algorithms for Sparse Linear Systems_, Nečas Center Series, Cham: Birkhäuser, pp.19–30, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-3-031-25820-6_2](https://doi.org/10.1007%2F978-3-031-25820-6_2), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-031-25819-0](https://en.wikipedia.org/wiki/Special:BookSources/978-3-031-25819-0 "Special:BookSources/978-3-031-25819-0")
*   Serre, Denis (2007), _Matrices: Theory and Applications_, [Graduate Texts in Mathematics](https://en.wikipedia.org/wiki/Graduate_Texts_in_Mathematics "Graduate Texts in Mathematics"), vol.216, Springer Science & Business Media, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-1-4419-7683-3](https://doi.org/10.1007%2F978-1-4419-7683-3), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780387227580](https://en.wikipedia.org/wiki/Special:BookSources/9780387227580 "Special:BookSources/9780387227580")
*   Šolin, Pavel (2005), _Partial Differential Equations and the Finite Element Method_, [Wiley-Interscience](https://en.wikipedia.org/wiki/Wiley-Interscience "Wiley-Interscience"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-471-76409-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-76409-0 "Special:BookSources/978-0-471-76409-0")
*   Stinson, Douglas R. (2005), _Cryptography_, Discrete Mathematics and its Applications, Chapman & Hall/CRC, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-58488-508-5](https://en.wikipedia.org/wiki/Special:BookSources/978-1-58488-508-5 "Special:BookSources/978-1-58488-508-5")
*   Stoer, Josef; Bulirsch, Roland (2002), _Introduction to Numerical Analysis_ (3rd ed.), Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-95452-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-95452-3 "Special:BookSources/978-0-387-95452-3")
*   Suresh Kumar, K. S. (2009), _Electric Circuits and Networks_, Dorling Kindersley, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-81-317-1390-7](https://en.wikipedia.org/wiki/Special:BookSources/978-81-317-1390-7 "Special:BookSources/978-81-317-1390-7")
*   Tang, K. T. (2006), _Mathematical Methods for Engineers and Scientists 1: Complex Analysis, Determinants and Matrices_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-30273-5](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-30273-5 "Special:BookSources/978-3-540-30273-5")
*   Tapp, Kristopher (2016), _Matrix Groups for Undergraduates_, Student Mathematical Library, vol.79 (2nd ed.), Providence, Rhode Island: American Mathematical Society, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1090/stml/079](https://doi.org/10.1090%2Fstml%2F079), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4704-2722-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4704-2722-1 "Special:BookSources/978-1-4704-2722-1"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[3468869](https://mathscinet.ams.org/mathscinet-getitem?mr=3468869)
*   [Van Loan, Charles F.](https://en.wikipedia.org/wiki/Charles_F._Van_Loan "Charles F. Van Loan") (2000), "The ubiquitous Kronecker product", _[Journal of Computational and Applied Mathematics](https://en.wikipedia.org/wiki/Journal\_of\_Computational\_and\_Applied\_Mathematics "Journal of Computational and Applied Mathematics")_, **123** (1–2): 85–100, [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2000JCoAM.123...85L](https://ui.adsabs.harvard.edu/abs/2000JCoAM.123...85L), [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/S0377-0427(00)00393-9](https://doi.org/10.1016%2FS0377-0427%2800%2900393-9), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1798520](https://mathscinet.ams.org/mathscinet-getitem?mr=1798520)
*   Vassilevska Williams, Virginia; Xu, Yinzhan; Xu, Zixuan; Zhou, Renfei (2024), "New bounds for matrix multiplication: from alpha to omega", _Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pp.3792–3835, [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[2307.07970](https://arxiv.org/abs/2307.07970), [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1137/1.9781611977912.134](https://doi.org/10.1137%2F1.9781611977912.134), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-61197-791-2](https://en.wikipedia.org/wiki/Special:BookSources/978-1-61197-791-2 "Special:BookSources/978-1-61197-791-2")
*   Ward, J. P. (1997), [_Quaternions and Cayley numbers_](https://archive.org/details/quaternionscayle0000ward), Mathematics and its Applications, vol.403, Dordrecht, NL: Kluwer Academic Publishers Group, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-94-011-5768-1](https://doi.org/10.1007%2F978-94-011-5768-1), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-7923-4513-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-7923-4513-8 "Special:BookSources/978-0-7923-4513-8"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1458894](https://mathscinet.ams.org/mathscinet-getitem?mr=1458894)
*   Watkins, David S. (2002), [_Fundamentals of Matrix Computations_](https://books.google.com/books?id=xi5omWiQ-3kC), [John Wiley & Sons](https://en.wikipedia.org/wiki/John_Wiley_%26_Sons "John Wiley & Sons"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-471-46167-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-46167-8 "Special:BookSources/978-0-471-46167-8")
*   [West, Douglas B.](https://en.wikipedia.org/wiki/Douglas_West_(mathematician) "Douglas West (mathematician)") (2020), _Combinatorial Mathematics_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781108889520](https://en.wikipedia.org/wiki/Special:BookSources/9781108889520 "Special:BookSources/9781108889520")
*   Whitelaw, T. A. (1991), [_Introduction to Linear Algebra_](https://books.google.com/books?id=6M_kDzA7-qIC) (2nd ed.), CRC Press, p.29, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780751401592](https://en.wikipedia.org/wiki/Special:BookSources/9780751401592 "Special:BookSources/9780751401592")
*   Zhang, Yanchun; Yu, Jeffrey Xu; Hou, Jingyu (2006), _Web Communities: Analysis and Construction_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-27737-8](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-27737-8 "Special:BookSources/978-3-540-27737-8")

*   Abłamowicz, Rafał (2000), _Clifford Algebras and their Applications in Mathematical Physics, Volume 1: Algebra and Physics_, Progress in Mathematical Physics, vol.18, Birkhäuser / Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9780817641825](https://en.wikipedia.org/wiki/Special:BookSources/9780817641825 "Special:BookSources/9780817641825")
*   Bauchau, O. A.; Craig, J. I. (2009), _Structural Analysis: With Applications to Aerospace Structures_, Solid Mechanics and Its Applications, vol.163, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9789048125166](https://en.wikipedia.org/wiki/Special:BookSources/9789048125166 "Special:BookSources/9789048125166")
*   [Boas, Mary L.](https://en.wikipedia.org/wiki/Mary_L._Boas "Mary L. Boas") (2005), [_Mathematical Methods in the Physical Sciences_](https://en.wikipedia.org/wiki/Mathematical_Methods_in_the_Physical_Sciences "Mathematical Methods in the Physical Sciences") (3rd ed.), John Wiley & Sons, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-471-19826-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-19826-0 "Special:BookSources/978-0-471-19826-0")
*   Bohm, Arno (2001), _Quantum Mechanics: Foundations and Applications_, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-387-95330-2](https://en.wikipedia.org/wiki/Special:BookSources/0-387-95330-2 "Special:BookSources/0-387-95330-2")
*   Burgess, Cliff; Moore, Guy (2007), _The Standard Model. A Primer_, Cambridge University Press, [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2007smp..book.....B](https://ui.adsabs.harvard.edu/abs/2007smp..book.....B), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-86036-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-86036-9 "Special:BookSources/978-0-521-86036-9")
*   [Gbur, Greg](https://en.wikipedia.org/wiki/Greg_Gbur "Greg Gbur") (2011), _Mathematical Methods in Optical Physics and Engineering_, Cambridge University Press, [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2011mmop.book.....G](https://ui.adsabs.harvard.edu/abs/2011mmop.book.....G), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-521-51610-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-51610-5 "Special:BookSources/978-0-521-51610-5")
*   Guenther, Robert D. (1990), _Modern Optics_, John Wiley, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-471-60538-7](https://en.wikipedia.org/wiki/Special:BookSources/0-471-60538-7 "Special:BookSources/0-471-60538-7")
*   Han, D.; Kim, Y. S.; Noz, Marilyn E. (September 1997), ["Jones-matrix formalism as a representation of the Lorentz group"](https://scholar.archive.org/work/g6cqiliqqrcjxalo44oayibjw4), _Journal of the Optical Society of America A_, **14** (9), Optica Publishing Group: 2290, [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[physics/9703032](https://arxiv.org/abs/physics/9703032), [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[1997JOSAA..14.2290H](https://ui.adsabs.harvard.edu/abs/1997JOSAA..14.2290H), [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1364/josaa.14.002290](https://doi.org/10.1364%2Fjosaa.14.002290)
*   [Itzykson, Claude](https://en.wikipedia.org/wiki/Claude_Itzykson "Claude Itzykson"); [Zuber, Jean-Bernard](https://en.wikipedia.org/wiki/Jean-Bernard_Zuber "Jean-Bernard Zuber") (1980), [_Quantum Field Theory_](https://archive.org/details/quantumfieldtheo0000itzy), McGraw–Hill, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-07-032071-3](https://en.wikipedia.org/wiki/Special:BookSources/0-07-032071-3 "Special:BookSources/0-07-032071-3")
*   Jensen, Frank (1999), [_Introduction to Computational Chemistry_](https://archive.org/details/introductiontoco0000jens), John Wiley & Sons, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-471-98085-4](https://en.wikipedia.org/wiki/Special:BookSources/0-471-98085-4 "Special:BookSources/0-471-98085-4")
*   [Peres, Asher](https://en.wikipedia.org/wiki/Asher_Peres "Asher Peres") (1993), [_Quantum Theory: Concepts and Methods_](https://en.wikipedia.org/wiki/Quantum_Theory:_Concepts_and_Methods "Quantum Theory: Concepts and Methods"), Kluwer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-7923-3632-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-7923-3632-7 "Special:BookSources/978-0-7923-3632-7")
*   [Reichl, Linda E.](https://en.wikipedia.org/wiki/Linda_Reichl "Linda Reichl") (2004), _The transition to chaos: conservative classical systems and quantum manifestations_, Berlin, DE; New York, NY: Springer-Verlag, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-98788-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-98788-0 "Special:BookSources/978-0-387-98788-0")
*   [Riley, Kenneth F.](https://en.wikipedia.org/wiki/Ken_Riley_(physicist) "Ken Riley (physicist)"); Hobson, Michael P.; Bence, Stephen J. (1997), _Mathematical methods for physics and engineering_, Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-521-55506-X](https://en.wikipedia.org/wiki/Special:BookSources/0-521-55506-X "Special:BookSources/0-521-55506-X")
*   [Schiff, Leonard I.](https://en.wikipedia.org/wiki/Leonard_I._Schiff "Leonard I. Schiff") (1968), _Quantum Mechanics_ (3rd ed.), McGraw–Hill
*   [Weinberg, Steven](https://en.wikipedia.org/wiki/Steven_Weinberg "Steven Weinberg") (1995), [_The Quantum Theory of Fields. Volume I: Foundations_](https://archive.org/details/quantumtheoryoff00stev), Cambridge University Press, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-521-55001-7](https://en.wikipedia.org/wiki/Special:BookSources/0-521-55001-7 "Special:BookSources/0-521-55001-7")
*   Wherrett, Brian S. (1987), _Group Theory for Atoms, Molecules and Solids_, Prentice–Hall International, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-13-365461-3](https://en.wikipedia.org/wiki/Special:BookSources/0-13-365461-3 "Special:BookSources/0-13-365461-3")
*   Ydri, Badis (2016), _Lectures on Matrix Field Theory_, Lecture Notes in Physics, vol.929, Springer, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9783319460031](https://en.wikipedia.org/wiki/Special:BookSources/9783319460031 "Special:BookSources/9783319460031")
*   Zabrodin, Anton; [Brézin, Édouard](https://en.wikipedia.org/wiki/%C3%89douard_Br%C3%A9zin "Édouard Brézin"); Kazakov, Vladimir; Serban, Didina; [Wiegmann, Paul](https://en.wikipedia.org/wiki/Paul_Wiegmann "Paul Wiegmann") (2006), _Applications of Random Matrices in Physics (NATO Science Series II: Mathematics, Physics and Chemistry)_, Berlin, DE; New York, NY: [Springer-Verlag](https://en.wikipedia.org/wiki/Springer-Verlag "Springer-Verlag"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4020-4530-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4020-4530-1 "Special:BookSources/978-1-4020-4530-1")

### Historical references

[[edit](https://en.wikipedia.org/w/index.php?title=Matrix_(mathematics)&action=edit&section=50 "Edit section: Historical references")]

*   [Bôcher, Maxime](https://en.wikipedia.org/wiki/Maxime_B%C3%B4cher "Maxime Bôcher") (2004), _Introduction to Higher Algebra_, New York, NY: [Dover Publications](https://en.wikipedia.org/wiki/Dover_Publications "Dover Publications"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-49570-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-49570-5 "Special:BookSources/978-0-486-49570-5"), reprint of the 1907 original edition
*   [Cayley, Arthur](https://en.wikipedia.org/wiki/Arthur_Cayley "Arthur Cayley") (December 1858), "A memoir on the theory of matrices", _[Philosophical Transactions of the Royal Society of London](https://en.wikipedia.org/wiki/Philosophical\_Transactions\_of\_the\_Royal\_Society\_of\_London "Philosophical Transactions of the Royal Society of London")_, **148**: 17–37, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1098/rstl.1858.0002](https://doi.org/10.1098%2Frstl.1858.0002), [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[108649](https://www.jstor.org/stable/108649); reprinted in _The collected mathematical papers of Arthur Cayley_, vol. II, Cambridge University Press, 1889, [pp. 475–496](https://archive.org/details/collectedmathema02cayluoft/page/474).
*   [Cayley, Arthur](https://en.wikipedia.org/wiki/Arthur_Cayley "Arthur Cayley") (1889), [_The collected mathematical papers of Arthur Cayley_](https://quod.lib.umich.edu/cgi/t/text/pageviewer-idx?c=umhistmath;cc=umhistmath;rgn=full%20text;idno=ABS3153.0001.001;didno=ABS3153.0001.001;view=image;seq=00000140), vol.I (1841–1853), [Cambridge University Press](https://en.wikipedia.org/wiki/Cambridge_University_Press "Cambridge University Press"), pp.123–126
*   [Cramer, Gabriel](https://en.wikipedia.org/wiki/Gabriel_Cramer "Gabriel Cramer") (1750), [_Introduction à l'Analyse des lignes Courbes algébriques_](https://www.europeana.eu/resolve/record/03486/E71FE3799CEC1F8E2B76962513829D2E36B63015) (in French), Geneva: Europeana, pp.656–659, retrieved 2012-05-18
*   [Dieudonné, Jean](https://en.wikipedia.org/wiki/Jean_Dieudonn%C3%A9 "Jean Dieudonné"), ed. (1978), _Abrégé d'histoire des mathématiques 1700-1900_, Paris, FR: Hermann
*   [Hawkins, Thomas](https://en.wikipedia.org/wiki/Thomas_W._Hawkins_Jr. "Thomas W. Hawkins Jr.") (1972), "Hypercomplex numbers, Lie groups, and the creation of group representation theory", _[Archive for History of Exact Sciences](https://en.wikipedia.org/wiki/Archive\_for\_History\_of\_Exact\_Sciences "Archive for History of Exact Sciences")_, **8** (4): 243–287, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/bf00328434](https://doi.org/10.1007%2Fbf00328434)
*   [Hawkins, Thomas](https://en.wikipedia.org/wiki/Thomas_W._Hawkins_Jr. "Thomas W. Hawkins Jr.") (1975), "Cauchy and the spectral theory of matrices", _[Historia Mathematica](https://en.wikipedia.org/wiki/Historia\_Mathematica "Historia Mathematica")_, **2**: 1–29, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/0315-0860(75)90032-4](https://doi.org/10.1016%2F0315-0860%2875%2990032-4), [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[0315-0860](https://search.worldcat.org/issn/0315-0860), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0469635](https://mathscinet.ams.org/mathscinet-getitem?mr=0469635)
*   [Knobloch, Eberhard](https://en.wikipedia.org/wiki/Eberhard_Knobloch "Eberhard Knobloch") (1994), "From Gauß to Weierstraß: determinant theory and its historical evaluations", in Sasaki, Chikara; Sugiura, Mitsuo; Dauben, Joseph W. (eds.), _The Intersection of History and Mathematics_, Science Networks: Historical Studies, vol.15, Birkhäuser, pp.51–66, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1007/978-3-0348-7521-9_5](https://doi.org/10.1007%2F978-3-0348-7521-9_5), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[3-7643-5029-6](https://en.wikipedia.org/wiki/Special:BookSources/3-7643-5029-6 "Special:BookSources/3-7643-5029-6"), [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[1308079](https://mathscinet.ams.org/mathscinet-getitem?mr=1308079)
*   Kosinski, A. A. (2001), "Cramer's Rule is due to Cramer", _[Mathematics Magazine](https://en.wikipedia.org/wiki/Mathematics\_Magazine "Mathematics Magazine")_, **74** (4): 310–312, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.2307/2691101](https://doi.org/10.2307%2F2691101), [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[2691101](https://www.jstor.org/stable/2691101)
*   [Kronecker, Leopold](https://en.wikipedia.org/wiki/Leopold_Kronecker "Leopold Kronecker") (1897), [Hensel, Kurt](https://en.wikipedia.org/wiki/Kurt_Hensel "Kurt Hensel") (ed.), [_Leopold Kronecker's Werke_](https://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=AAS8260.0002.001), Teubner
*   [Miller, G. A.](https://en.wikipedia.org/wiki/George_Abram_Miller "George Abram Miller") (May 1930), "On the history of determinants", _[The American Mathematical Monthly](https://en.wikipedia.org/wiki/The\_American\_Mathematical\_Monthly "The American Mathematical Monthly")_, **37** (5): 216–219, [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1080/00029890.1930.11987058](https://doi.org/10.1080%2F00029890.1930.11987058), [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[2299112](https://www.jstor.org/stable/2299112)
*   Shen, Kangshen; [Crossley, John N.](https://en.wikipedia.org/wiki/John_Newsome_Crossley "John Newsome Crossley"); Lun, Anthony Wah-Cheung (1999), _Nine Chapters of the Mathematical Art, Companion and Commentary_ (2nd ed.), [Oxford University Press](https://en.wikipedia.org/wiki/Oxford_University_Press "Oxford University Press"), [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-19-853936-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-19-853936-0 "Special:BookSources/978-0-19-853936-0")
*   [Sylvester, J. J.](https://en.wikipedia.org/wiki/James_Joseph_Sylvester "James Joseph Sylvester") (1904), [Baker, H. F.](https://en.wikipedia.org/wiki/Henry_F._Baker "Henry F. Baker") (ed.), [_The Collected Mathematical Papers of James Joseph Sylvester, Volume I (1837–1853)_](https://archive.org/details/collectedmathem01sylvrich), Cambridge, England: Cambridge University Press
*   [van der Waerden, B. L.](https://en.wikipedia.org/wiki/Bartel_Leendert_van_der_Waerden "Bartel Leendert van der Waerden"), ed. (2007) [1968], _Sources of Quantum Mechanics_, Dover, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-45892-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-45892-2 "Special:BookSources/978-0-486-45892-2")
*   [Tarski, Alfred](https://en.wikipedia.org/wiki/Alfred_Tarski "Alfred Tarski") (1941), _Introduction to Logic and the Methodology of Deductive Sciences_, Oxford University Press, [MR](https://en.wikipedia.org/wiki/MR_(identifier) "MR (identifier)")[0003375](https://mathscinet.ams.org/mathscinet-getitem?mr=0003375); reprint of 1946 corrected printing, Dover Publications, 1995, [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[0-486-28462-X](https://en.wikipedia.org/wiki/Special:BookSources/0-486-28462-X "Special:BookSources/0-486-28462-X")
*   [Weierstrass, Karl](https://en.wikipedia.org/wiki/Karl_Weierstrass "Karl Weierstrass") (1915), [_Collected Works_](https://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=AAN8481.0003.001), vol.3

*   ["Matrix"](https://www.encyclopediaofmath.org/index.php?title=Matrix), _[Encyclopedia of Mathematics](https://en.wikipedia.org/wiki/Encyclopedia\_of\_Mathematics "Encyclopedia of Mathematics")_, [EMS Press](https://en.wikipedia.org/wiki/European_Mathematical_Society "European Mathematical Society"), 2001 [1994]
*   Petersen, Kaare Brandt; Petersen, Michael Syskind (November 15, 2012), [_The Matrix Cookbook_](https://math.uwaterloo.ca/~hwolkowi//matrixcookbook.pdf)(PDF), University of Waterloo, retrieved 24 March 2014
*   Brookes, Mike (2005), [_The Matrix Reference Manual_](https://web.archive.org/web/20081216124433/http://www.ee.ic.ac.uk/hp/staff/dmb/matrix/intro.html), London: [Imperial College](https://en.wikipedia.org/wiki/Imperial_College "Imperial College"), archived from [the original](https://ee.ic.ac.uk/hp/staff/dmb/matrix/intro.html) on 16 December 2008, retrieved 10 Dec 2008

*   O'Connor, J. J.; Robertson, E. F. (February 1996), ["Matrices and determinants"](https://mathshistory.st-andrews.ac.uk/HistTopics/Matrices_and_determinants/), _[MacTutor History of Mathematics Archive](https://en.wikipedia.org/wiki/MacTutor\_History\_of\_Mathematics\_Archive "MacTutor History of Mathematics Archive")_, [University of St Andrews](https://en.wikipedia.org/wiki/University_of_St_Andrews "University of St Andrews")
*   [Matrices and Linear Algebra on the Earliest Uses Pages](https://economics.soton.ac.uk/staff/aldrich/matrices.htm)
*   [Earliest Uses of Symbols for Matrices and Vectors](https://jeff560.tripod.com/matrices.html)
