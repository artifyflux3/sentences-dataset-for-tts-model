Title: Control theory

URL Source: https://en.wikipedia.org/wiki/Control_theory

Published Time: 2001-11-07T20:08:09Z

Markdown Content:
**Control theory** is a field of [control engineering](https://en.wikipedia.org/wiki/Control_engineering "Control engineering") and [applied mathematics](https://en.wikipedia.org/wiki/Applied_mathematics "Applied mathematics") that deals with the [control](https://en.wikipedia.org/wiki/Control_system "Control system") of [dynamical systems](https://en.wikipedia.org/wiki/Dynamical_system "Dynamical system"). The objective is to develop a model or algorithm governing the application of system inputs to drive the system to a desired state, while minimizing any _delay_, _overshoot_, or _steady-state error_ and ensuring a level of control [stability](https://en.wikipedia.org/wiki/Stability_theory "Stability theory"); often with the aim to achieve a degree of [optimality](https://en.wikipedia.org/wiki/Optimal_control "Optimal control").

To do this, a **controller** with the requisite corrective behavior is required. This controller monitors the controlled [process variable](https://en.wikipedia.org/wiki/Process_variable "Process variable") (PV), and compares it with the reference or [set point](https://en.wikipedia.org/wiki/Setpoint_(control_system) "Setpoint (control system)") (SP). The difference between actual and desired value of the process variable, called the _error_ signal, or SP-PV error, is applied as feedback to generate a control action to bring the controlled process variable to the same value as the set point. Other aspects which are also studied are [controllability](https://en.wikipedia.org/wiki/Controllability "Controllability") and [observability](https://en.wikipedia.org/wiki/Observability "Observability"). Control theory is used in [control system engineering](https://en.wikipedia.org/wiki/Control_system_engineering "Control system engineering") to design automation that have revolutionized manufacturing, aircraft, communications and other industries, and created new fields such as [robotics](https://en.wikipedia.org/wiki/Robotics "Robotics").

Extensive use is usually made of a diagrammatic style known as the [block diagram](https://en.wikipedia.org/wiki/Block_diagram "Block diagram"). In it the [transfer function](https://en.wikipedia.org/wiki/Transfer_function "Transfer function"), also known as the system function or network function, is a mathematical model of the relation between the input and output based on the [differential equations](https://en.wikipedia.org/wiki/Differential_equation "Differential equation") describing the system.

Control theory dates from the 19th century, when the theoretical basis for the operation of governors was first described by [James Clerk Maxwell](https://en.wikipedia.org/wiki/James_Clerk_Maxwell "James Clerk Maxwell").[[1]](https://en.wikipedia.org/wiki/Control_theory#cite_note-1) Control theory was further advanced by [Edward Routh](https://en.wikipedia.org/wiki/Edward_Routh "Edward Routh") in 1874, [Charles Sturm](https://en.wikipedia.org/wiki/Jacques_Charles_Fran%C3%A7ois_Sturm "Jacques Charles François Sturm") and in 1895, [Adolf Hurwitz](https://en.wikipedia.org/wiki/Adolf_Hurwitz "Adolf Hurwitz"), who all contributed to the establishment of control stability criteria; and from 1922 onwards, the development of [PID control](https://en.wikipedia.org/wiki/PID_control "PID control") theory by [Nicolas Minorsky](https://en.wikipedia.org/wiki/Nicolas_Minorsky "Nicolas Minorsky").[[2]](https://en.wikipedia.org/wiki/Control_theory#cite_note-2) Although the most direct application of [mathematical](https://en.wikipedia.org/wiki/Mathematical "Mathematical") control theory is its use in [control systems engineering](https://en.wikipedia.org/wiki/Control_systems_engineering "Control systems engineering") (dealing with [process control](https://en.wikipedia.org/wiki/Process_control "Process control") systems for [robotics](https://en.wikipedia.org/wiki/Robotics "Robotics") and industry), control theory is routinely applied to problems both the natural and [behavioral sciences](https://en.wikipedia.org/wiki/Behavioral_science "Behavioral science"). As the general theory of feedback systems, control theory is useful wherever feedback occurs, making it important to fields like [economics](https://en.wikipedia.org/wiki/Economics "Economics"), [operations research](https://en.wikipedia.org/wiki/Operations_research "Operations research"), and the [life sciences](https://en.wikipedia.org/wiki/Life_science "Life science").[[3]](https://en.wikipedia.org/wiki/Control_theory#cite_note-3)

[![Image 1](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Boulton_and_Watt_centrifugal_governor-MJ.jpg/250px-Boulton_and_Watt_centrifugal_governor-MJ.jpg)](https://en.wikipedia.org/wiki/File:Boulton_and_Watt_centrifugal_governor-MJ.jpg)

[Centrifugal governor](https://en.wikipedia.org/wiki/Centrifugal_governor "Centrifugal governor") in a [Boulton & Watt engine](https://en.wikipedia.org/wiki/Boulton_%26_Watt_engine "Boulton & Watt engine") of 1788

Although control systems of various types date back to antiquity, a more formal analysis of the field began with a dynamics analysis of the [centrifugal governor](https://en.wikipedia.org/wiki/Centrifugal_governor "Centrifugal governor"), conducted by the physicist [James Clerk Maxwell](https://en.wikipedia.org/wiki/James_Clerk_Maxwell "James Clerk Maxwell") in 1868, entitled _On Governors_.[[4]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Maxwell1867-4) A centrifugal governor was already used to regulate the velocity of windmills.[[5]](https://en.wikipedia.org/wiki/Control_theory#cite_note-5) Maxwell described and analyzed the phenomenon of [self-oscillation](https://en.wikipedia.org/wiki/Self-oscillation "Self-oscillation"), in which lags in the system may lead to overcompensation and unstable behavior. This generated a flurry of interest in the topic, during which Maxwell's classmate, [Edward John Routh](https://en.wikipedia.org/wiki/Edward_John_Routh "Edward John Routh"), abstracted Maxwell's results for the general class of linear systems.[[6]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Routh1975-6) Independently, [Adolf Hurwitz](https://en.wikipedia.org/wiki/Adolf_Hurwitz "Adolf Hurwitz") analyzed system stability using differential equations in 1877, resulting in what is now known as the [Routh–Hurwitz theorem](https://en.wikipedia.org/wiki/Routh%E2%80%93Hurwitz_theorem "Routh–Hurwitz theorem").[[7]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Routh1877-7)[[8]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Hurwitz1964-8)

A notable application of dynamic control was in the area of crewed flight. The [Wright brothers](https://en.wikipedia.org/wiki/Wright_brothers "Wright brothers") made their first successful test flights on December 17, 1903, and were distinguished by their ability to control their flights for substantial periods (more so than the ability to produce lift from an airfoil, which was known). Continuous, reliable control of the airplane was necessary for flights lasting longer than a few seconds.

By [World War II](https://en.wikipedia.org/wiki/World_War_II "World War II"), control theory was becoming an important area of research. [Irmgard Flügge-Lotz](https://en.wikipedia.org/wiki/Irmgard_Fl%C3%BCgge-Lotz "Irmgard Flügge-Lotz") developed the theory of discontinuous automatic control systems, and applied the [bang-bang principle](https://en.wikipedia.org/wiki/Bang%E2%80%93bang_control "Bang–bang control") to the development of [automatic flight control equipment](https://en.wikipedia.org/wiki/Autopilot "Autopilot") for aircraft.[[9]](https://en.wikipedia.org/wiki/Control_theory#cite_note-9)[[10]](https://en.wikipedia.org/wiki/Control_theory#cite_note-10) Other areas of application for discontinuous controls included [fire-control systems](https://en.wikipedia.org/wiki/Fire-control_system "Fire-control system"), [guidance systems](https://en.wikipedia.org/wiki/Guidance_system "Guidance system") and [electronics](https://en.wikipedia.org/wiki/Electronics "Electronics").

Sometimes, mechanical methods are used to improve the stability of systems. For example, [ship stabilizers](https://en.wikipedia.org/wiki/Stabilizer_(ship) "Stabilizer (ship)") are fins mounted beneath the waterline and emerging laterally. In contemporary vessels, they may be gyroscopically controlled active fins, which have the capacity to change their angle of attack to counteract roll caused by wind or waves acting on the ship.

The [Space Race](https://en.wikipedia.org/wiki/Space_Race "Space Race") also depended on accurate spacecraft control, and control theory has also seen an increasing use in fields such as economics and artificial intelligence. Here, one might say that the goal is to find an [internal model](https://en.wikipedia.org/wiki/Internal_model_(motor_control) "Internal model (motor control)") that obeys the [good regulator theorem](https://en.wikipedia.org/wiki/Good_regulator "Good regulator"). So, for example, in economics, the more accurately a (stock or commodities) trading model represents the actions of the market, the more easily it can control that market (and extract "useful work" (profits) from it). In AI, an example might be a chatbot modelling the discourse state of humans: the more accurately it can model the human state (e.g. on a telephone voice-support hotline), the better it can manipulate the human (e.g. into performing the corrective actions to resolve the problem that caused the phone call to the help-line). These last two examples take the narrow historical interpretation of control theory as a set of differential equations modeling and regulating kinetic motion, and broaden it into a vast generalization of a [regulator](https://en.wikipedia.org/wiki/Controller_(control_theory) "Controller (control theory)") interacting with a [plant](https://en.wikipedia.org/wiki/Plant_(control_theory) "Plant (control theory)").

Open-loop and closed-loop (feedback) control
--------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=2 "Edit section: Open-loop and closed-loop (feedback) control")]

Fundamentally, there are two types of control loop: _[open-loop control](https://en.wikipedia.org/wiki/Open-loop\_control "Open-loop control")_ (feedforward), and _[closed-loop control](https://en.wikipedia.org/wiki/Closed-loop\_control "Closed-loop control")_ (feedback).

*   In open-loop control, the control action from the controller is independent of the "process output" (or "controlled process variable"). A good example of this is a central heating boiler controlled only by a timer, so that heat is applied for a constant time, regardless of the temperature of the building. The control action is the switching on/off of the boiler, but the controlled variable should be the building temperature, but is not because this is open-loop control of the boiler, which does not give closed-loop control of the temperature.
*   In closed loop control, the control action from the controller is dependent on the process output. In the case of the boiler analogy, this would include a thermostat to monitor the building temperature, and thereby feed back a signal to ensure the controller maintains the building at the temperature set on the thermostat. A closed loop controller therefore has a feedback loop which ensures the controller exerts a control action to give a process output the same as the "reference input" or "set point". For this reason, closed loop controllers are also called feedback controllers.[[11]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Control_loop_auto-11)

The definition of a closed loop control system according to the [British Standards Institution](https://en.wikipedia.org/wiki/British_Standards_Institution "British Standards Institution") is "a control system possessing monitoring feedback, the deviation signal formed as a result of this feedback being used to control the action of a final control element in such a way as to tend to reduce the deviation to zero."[[12]](https://en.wikipedia.org/wiki/Control_theory#cite_note-12)

Likewise; "A _Feedback Control System_ is a system which tends to maintain a prescribed relationship of one system variable to another by comparing functions of these variables and using the difference as a means of control."[[13]](https://en.wikipedia.org/wiki/Control_theory#cite_note-13)

Classical control theory
------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=3 "Edit section: Classical control theory")]

[![Image 2](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Industrial_control_loop.jpg/330px-Industrial_control_loop.jpg)](https://en.wikipedia.org/wiki/File:Industrial_control_loop.jpg)

Example of a single industrial control loop; showing continuously modulated control of process flow.

[![Image 3](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Closed_Control_Loop.svg/330px-Closed_Control_Loop.svg.png)](https://en.wikipedia.org/wiki/File:Closed_Control_Loop.svg)

Illustration of a Closed Loop Control consisting of [Set Point](https://en.wikipedia.org/wiki/Setpoint_(control_system) "Setpoint (control system)")![Image 4: {\displaystyle w(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/327b8c0fa7ba996b29c530b495c276a7ebdea2ec), [Measured Output](https://en.wikipedia.org/wiki/Feedback "Feedback")![Image 5: {\displaystyle y_{m}(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/da222222725987d9ca1193b5f59a943fd735baaa), Measured Error ![Image 6: {\displaystyle e(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/98cb518a61ada87bcd636f531d4d9fd2e67876c3), Controller Output ![Image 7: {\displaystyle u(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b375df3b65d282f8715835dc91ccb22f46993959), System Input ![Image 8: {\displaystyle u_{s}(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9dddc5532f74744d87111978baf2d61f1795cd9d), Disturbance ![Image 9: {\displaystyle d(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e115e742b9743138b3f4c1fd7cf9c7263dcdbe43), and System Output ![Image 10: {\displaystyle y(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/397de1edef5bf2ee15c020f325d7d781a3aa7f50)

A [closed-loop controller](https://en.wikipedia.org/wiki/Closed-loop_controller "Closed-loop controller") or feedback controller is a [control loop](https://en.wikipedia.org/wiki/Control_loop "Control loop") which incorporates [feedback](https://en.wikipedia.org/wiki/Feedback "Feedback"), in contrast to an _[open-loop controller](https://en.wikipedia.org/wiki/Open-loop\_controller "Open-loop controller")_ or _non-feedback controller_. A closed-loop controller uses feedback to control [states](https://en.wikipedia.org/wiki/State_(controls) "State (controls)") or [outputs](https://en.wikipedia.org/wiki/Negative_feedback#Overview "Negative feedback") of a [dynamical system](https://en.wikipedia.org/wiki/Dynamical_system "Dynamical system"). Its name comes from the information path in the system: process inputs (e.g., [voltage](https://en.wikipedia.org/wiki/Voltage "Voltage") applied to an [electric motor](https://en.wikipedia.org/wiki/Electric_motor "Electric motor")) have an effect on the process outputs (e.g., speed or torque of the motor), which is measured with [sensors](https://en.wikipedia.org/wiki/Sensor "Sensor") and processed by the controller; the result (the control signal) is "fed back" as input to the process, closing the loop.[[14]](https://en.wikipedia.org/wiki/Control_theory#cite_note-14)

In the case of linear [feedback](https://en.wikipedia.org/wiki/Feedback "Feedback") systems, a [control loop](https://en.wikipedia.org/wiki/Control_loop "Control loop") including [sensors](https://en.wikipedia.org/wiki/Sensor "Sensor"), control algorithms, and actuators is arranged in an attempt to regulate a variable at a [setpoint](https://en.wikipedia.org/wiki/Setpoint_(control_system) "Setpoint (control system)") (SP). An everyday example is the [cruise control](https://en.wikipedia.org/wiki/Cruise_control "Cruise control") on a road vehicle; where external influences such as hills would cause speed changes, and the driver has the ability to alter the desired set speed. The [PID algorithm](https://en.wikipedia.org/wiki/PID_algorithm "PID algorithm") in the controller restores the actual speed to the desired speed in an optimum way, with minimal delay or [overshoot](https://en.wikipedia.org/wiki/Overshoot_(signal) "Overshoot (signal)"), by controlling the power output of the vehicle's engine. Control systems that include some sensing of the results they are trying to achieve are making use of feedback and can adapt to varying circumstances to some extent. [Open-loop control systems](https://en.wikipedia.org/wiki/Open-loop_controller "Open-loop controller") do not make use of feedback, and run only in pre-arranged ways.

Closed-loop controllers have the following advantages over open-loop controllers:

*   disturbance rejection (such as hills in the cruise control example above)
*   guaranteed performance even with [model](https://en.wikipedia.org/wiki/Mathematical_model "Mathematical model") uncertainties, when the model structure does not match perfectly the real process and the model parameters are not exact
*   [unstable](https://en.wikipedia.org/wiki/Instability "Instability") processes can be stabilized
*   reduced sensitivity to parameter variations
*   improved reference tracking performance
*   improved rectification of random fluctuations[[15]](https://en.wikipedia.org/wiki/Control_theory#cite_note-15)

In some systems, closed-loop and open-loop control are used simultaneously. In such systems, the open-loop control is termed _[feedforward](https://en.wikipedia.org/wiki/Feed\_forward\_(control) "Feed forward (control)")_ and serves to further improve reference tracking performance.

A common closed-loop controller architecture is the [PID controller](https://en.wikipedia.org/wiki/PID_controller "PID controller").

[![Image 11](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Ideal_feedback_model.svg/250px-Ideal_feedback_model.svg.png)](https://en.wikipedia.org/wiki/File:Ideal_feedback_model.svg)

 A basic feedback loop

Linear and nonlinear control theory
-----------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=4 "Edit section: Linear and nonlinear control theory")]

The field of control theory can be divided into two branches:

*   _[Linear control theory](https://en.wikipedia.org/wiki/Linear\_control\_theory "Linear control theory")_ – This applies to systems made of devices which obey the [superposition principle](https://en.wikipedia.org/wiki/Superposition_principle "Superposition principle"), which means roughly that the output is proportional to the input. They are governed by [linear differential equations](https://en.wikipedia.org/wiki/Linear_differential_equation "Linear differential equation"). A major subclass is systems which in addition have parameters which do not change with time, called _[linear time invariant](https://en.wikipedia.org/wiki/Linear\_time\_invariant "Linear time invariant")_ (LTI) systems. These systems are amenable to powerful [frequency domain](https://en.wikipedia.org/wiki/Frequency_domain "Frequency domain") mathematical techniques of great generality, such as the [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform"), [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform "Fourier transform"), [Z transform](https://en.wikipedia.org/wiki/Z_transform "Z transform"), [Bode plot](https://en.wikipedia.org/wiki/Bode_plot "Bode plot"), [root locus](https://en.wikipedia.org/wiki/Root_locus "Root locus"), and [Nyquist stability criterion](https://en.wikipedia.org/wiki/Nyquist_stability_criterion "Nyquist stability criterion"). These lead to a description of the system using terms like [bandwidth](https://en.wikipedia.org/wiki/Bandwidth_(signal_processing) "Bandwidth (signal processing)"), [frequency response](https://en.wikipedia.org/wiki/Frequency_response "Frequency response"), [eigenvalues](https://en.wikipedia.org/wiki/Eigenvalue "Eigenvalue"), [gain](https://en.wikipedia.org/wiki/Gain_(electronics) "Gain (electronics)"), [resonant frequencies](https://en.wikipedia.org/wiki/Resonant_frequency "Resonant frequency"), [zeros and poles](https://en.wikipedia.org/wiki/Zeros_and_poles "Zeros and poles"), which give solutions for system response and design techniques for most systems of interest.
*   _[Nonlinear control theory](https://en.wikipedia.org/wiki/Nonlinear\_control\_theory "Nonlinear control theory")_ – This covers a wider class of systems that do not obey the superposition principle, and applies to more real-world systems because all real control systems are nonlinear. These systems are often governed by [nonlinear differential equations](https://en.wikipedia.org/wiki/Nonlinear_differential_equation "Nonlinear differential equation"). The few mathematical techniques which have been developed to handle them are more difficult and much less general, often applying only to narrow categories of systems. These include [limit cycle](https://en.wikipedia.org/wiki/Limit_cycle "Limit cycle") theory, [Poincaré maps](https://en.wikipedia.org/wiki/Poincar%C3%A9_map "Poincaré map"), [Lyapunov stability theorem](https://en.wikipedia.org/wiki/Lyapunov_function "Lyapunov function"), and [describing functions](https://en.wikipedia.org/wiki/Describing_function "Describing function"). Nonlinear systems are often analyzed using [numerical methods](https://en.wikipedia.org/wiki/Numerical_method "Numerical method") on computers, for example by [simulating](https://en.wikipedia.org/wiki/Simulation "Simulation") their operation using a [simulation language](https://en.wikipedia.org/wiki/Simulation_language "Simulation language"). If only solutions near a stable point are of interest, nonlinear systems can often be [linearized](https://en.wikipedia.org/wiki/Linearization "Linearization") by approximating them by a linear system using [perturbation theory](https://en.wikipedia.org/wiki/Perturbation_theory "Perturbation theory"), and linear techniques can be used.[[16]](https://en.wikipedia.org/wiki/Control_theory#cite_note-16)

Analysis techniques – frequency domain and time domain
------------------------------------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=5 "Edit section: Analysis techniques – frequency domain and time domain")]

Mathematical techniques for analyzing and designing control systems fall into two different categories:

*   _[Frequency domain](https://en.wikipedia.org/wiki/Frequency\_domain "Frequency domain")_ – In this type the values of the [state variables](https://en.wikipedia.org/wiki/State_variable "State variable"), the mathematical [variables](https://en.wikipedia.org/wiki/Variable_(mathematics) "Variable (mathematics)") representing the system's input, output and feedback are represented as functions of [frequency](https://en.wikipedia.org/wiki/Frequency "Frequency"). The input signal and the system's [transfer function](https://en.wikipedia.org/wiki/Transfer_function "Transfer function") are converted from time functions to functions of frequency by a [transform](https://en.wikipedia.org/wiki/Transform_(mathematics) "Transform (mathematics)") such as the [Fourier transform](https://en.wikipedia.org/wiki/Fourier_transform "Fourier transform"), [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform"), or [Z transform](https://en.wikipedia.org/wiki/Z_transform "Z transform"). The advantage of this technique is that it results in a simplification of the mathematics; the _[differential equations](https://en.wikipedia.org/wiki/Differential\_equation "Differential equation")_ that represent the system are replaced by _[algebraic equations](https://en.wikipedia.org/wiki/Algebraic\_equation "Algebraic equation")_ in the frequency domain which is much simpler to solve. However, frequency domain techniques can only be used with linear systems, as mentioned above.
*   _[Time-domain state space representation](https://en.wikipedia.org/wiki/Time-domain\_state\_space\_representation "Time-domain state space representation")_ – In this type the values of the [state variables](https://en.wikipedia.org/wiki/State_variable "State variable") are represented as functions of time. With this model, the system being analyzed is represented by one or more [differential equations](https://en.wikipedia.org/wiki/Differential_equation "Differential equation"). Since frequency domain techniques are limited to [linear](https://en.wikipedia.org/wiki/Linear_function "Linear function") systems, time domain is widely used to analyze real-world nonlinear systems. Although these are more difficult to solve, modern computer simulation techniques such as [simulation languages](https://en.wikipedia.org/wiki/Simulation_language "Simulation language") have made their analysis routine.

In contrast to the frequency-domain analysis of the classical control theory, modern control theory utilizes the time-domain [state space](https://en.wikipedia.org/wiki/State_space_(controls) "State space (controls)") representation,[_[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation\_needed "Wikipedia:Citation needed")_] a mathematical model of a physical system as a set of input, output and state variables related by first-order differential equations. To abstract from the number of inputs, outputs, and states, the variables are expressed as vectors and the differential and algebraic equations are written in matrix form (the latter only being possible when the dynamical system is linear). The state space representation (also known as the "time-domain approach") provides a convenient and compact way to model and analyze systems with multiple inputs and outputs. With inputs and outputs, we would otherwise have to write down Laplace transforms to encode all the information about a system. Unlike the frequency domain approach, the use of the state-space representation is not limited to systems with linear components and zero initial conditions. "State space" refers to the space whose axes are the state variables. The state of the system can be represented as a point within that space.[[17]](https://en.wikipedia.org/wiki/Control_theory#cite_note-17)[[18]](https://en.wikipedia.org/wiki/Control_theory#cite_note-18)

Control systems can be divided into different categories depending on the number of inputs and outputs.

*   [Single-input single-output](https://en.wikipedia.org/wiki/Single-input_single-output_system "Single-input single-output system") (SISO) – This is the simplest and most common type, in which one output is controlled by one control signal. Examples are the cruise control example above, or an [audio system](https://en.wikipedia.org/wiki/Audio_system "Audio system"), in which the control input is the input audio signal and the output is the sound waves from the speaker.
*   [Multiple-input multiple-output](https://en.wikipedia.org/wiki/Multiple-input_multiple-output_system "Multiple-input multiple-output system") (MIMO) – These are found in more complicated systems. For example, modern large [telescopes](https://en.wikipedia.org/wiki/Telescope "Telescope") such as the [Keck](https://en.wikipedia.org/wiki/Keck_telescopes "Keck telescopes") and [MMT](https://en.wikipedia.org/wiki/MMT_Observatory "MMT Observatory") have mirrors composed of many separate segments each controlled by an [actuator](https://en.wikipedia.org/wiki/Actuator "Actuator"). The shape of the entire mirror is constantly adjusted by a MIMO [active optics](https://en.wikipedia.org/wiki/Active_optics "Active optics") control system using input from multiple sensors at the focal plane, to compensate for changes in the mirror shape due to thermal expansion, contraction, stresses as it is rotated and distortion of the [wavefront](https://en.wikipedia.org/wiki/Wavefront "Wavefront") due to turbulence in the atmosphere. Complicated systems such as [nuclear reactors](https://en.wikipedia.org/wiki/Nuclear_reactor "Nuclear reactor") and human [cells](https://en.wikipedia.org/wiki/Cell_(biology) "Cell (biology)") are simulated by a computer as large MIMO control systems.

### Classical SISO system design

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=7 "Edit section: Classical SISO system design")]

The scope of classical control theory is limited to single-input and single-output (SISO) system design, except when analyzing for disturbance rejection using a second input. The system analysis is carried out in the time domain using [differential equations](https://en.wikipedia.org/wiki/Differential_equations "Differential equations"), in the complex-s domain with the [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform"), or in the frequency domain by transforming from the complex-s domain. Many systems may be assumed to have a second order and single variable system response in the time domain. A controller designed using classical theory often requires on-site tuning due to incorrect design approximations. Yet, due to the easier physical implementation of classical controller designs as compared to systems designed using modern control theory, these controllers are preferred in most industrial applications. The most common controllers designed using classical control theory are [PID controllers](https://en.wikipedia.org/wiki/PID_controller "PID controller"). A less common implementation may include either or both a Lead or Lag filter. The ultimate end goal is to meet requirements typically provided in the time-domain called the step response, or at times in the frequency domain called the open-loop response. The step response characteristics applied in a specification are typically percent overshoot, settling time, etc. The open-loop response characteristics applied in a specification are typically Gain and Phase margin and bandwidth. These characteristics may be evaluated through simulation including a dynamic model of the system under control coupled with the compensation model.

### Modern MIMO system design

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=8 "Edit section: Modern MIMO system design")]

Modern control theory is carried out in the [state space](https://en.wikipedia.org/wiki/State_space_(controls) "State space (controls)"), and can deal with multiple-input and multiple-output (MIMO) systems. This overcomes the limitations of classical control theory in more sophisticated design problems, such as fighter aircraft control, with the limitation that no frequency domain analysis is possible. In modern design, a system is represented to the greatest advantage as a set of decoupled first order [differential equations](https://en.wikipedia.org/wiki/Differential_equation "Differential equation") defined using [state variables](https://en.wikipedia.org/wiki/State_variables "State variables"). [Nonlinear](https://en.wikipedia.org/wiki/Nonlinear_control "Nonlinear control"), [multivariable](https://en.wikipedia.org/w/index.php?title=Multivariable_control&action=edit&redlink=1 "Multivariable control (page does not exist)"), [adaptive](https://en.wikipedia.org/wiki/Adaptive_control "Adaptive control") and [robust control](https://en.wikipedia.org/wiki/Robust_control "Robust control") theories come under this division. Being fairly new, modern control theory has many areas yet to be explored. Scholars like [Rudolf E. Kálmán](https://en.wikipedia.org/wiki/Rudolf_E._K%C3%A1lm%C3%A1n "Rudolf E. Kálmán") and [Aleksandr Lyapunov](https://en.wikipedia.org/wiki/Aleksandr_Lyapunov "Aleksandr Lyapunov") are well known among the people who have shaped modern control theory.

Topics in control theory
------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=9 "Edit section: Topics in control theory")]

The _stability_ of a general [dynamical system](https://en.wikipedia.org/wiki/Dynamical_system "Dynamical system") with no input can be described with [Lyapunov stability](https://en.wikipedia.org/wiki/Lyapunov_stability "Lyapunov stability") criteria.

*   A [linear system](https://en.wikipedia.org/wiki/Linear_system "Linear system") is called [bounded-input bounded-output (BIBO) stable](https://en.wikipedia.org/wiki/BIBO_stability "BIBO stability") if its output will stay [bounded](https://en.wikipedia.org/wiki/Bounded_function "Bounded function") for any bounded input.
*   Stability for [nonlinear systems](https://en.wikipedia.org/wiki/Nonlinear_system "Nonlinear system") that take an input is [input-to-state stability](https://en.wikipedia.org/wiki/Input-to-state_stability "Input-to-state stability") (ISS), which combines Lyapunov stability and a notion similar to BIBO stability.

For simplicity, the following descriptions focus on continuous-time and discrete-time **linear systems**.

Mathematically, this means that for a causal linear system to be stable all of the [poles](https://en.wikipedia.org/wiki/Pole_(complex_analysis) "Pole (complex analysis)") of its [transfer function](https://en.wikipedia.org/wiki/Transfer_function "Transfer function") must have negative-real values, i.e. the real part of each pole must be less than zero. Practically speaking, stability requires that the transfer function complex poles reside

*   in the open left half of the [complex plane](https://en.wikipedia.org/wiki/Complex_plane "Complex plane") for continuous time, when the [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform") is used to obtain the transfer function.
*   inside the [unit circle](https://en.wikipedia.org/wiki/Unit_circle "Unit circle") for discrete time, when the [Z-transform](https://en.wikipedia.org/wiki/Z-transform "Z-transform") is used.

The difference between the two cases is simply due to the traditional method of plotting continuous time versus discrete time transfer functions. The continuous Laplace transform is in [Cartesian coordinates](https://en.wikipedia.org/wiki/Cartesian_coordinates "Cartesian coordinates") where the ![Image 12: {\displaystyle x}](https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4) axis is the real axis and the discrete Z-transform is in [circular coordinates](https://en.wikipedia.org/wiki/Circular_coordinates "Circular coordinates") where the ![Image 13: {\displaystyle \rho }](https://wikimedia.org/api/rest_v1/media/math/render/svg/1f7d439671d1289b6a816e6af7a304be40608d64) axis is the real axis.

When the appropriate conditions above are satisfied a system is said to be [asymptotically stable](https://en.wikipedia.org/wiki/Asymptotic_stability "Asymptotic stability"); the variables of an asymptotically stable control system always decrease from their initial value and do not show permanent oscillations. Permanent oscillations occur when a pole has a real part exactly equal to zero (in the continuous time case) or a [modulus](https://en.wikipedia.org/wiki/Absolute_value#Complex_numbers "Absolute value") equal to one (in the discrete time case). If a simply stable system response neither decays nor grows over time, and has no oscillations, it is [marginally stable](https://en.wikipedia.org/wiki/Marginal_stability "Marginal stability"); in this case the system transfer function has non-repeated poles at the complex plane origin (i.e. their real and complex component is zero in the continuous time case). Oscillations are present when poles with real part equal to zero have an imaginary part not equal to zero.

If a system in question has an [impulse response](https://en.wikipedia.org/wiki/Impulse_response "Impulse response") of

![Image 14: {\displaystyle \ x[n]=0.5^{n}u[n]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c3fe9bf89c5cffaf461081935fd41745dc768063)
then the Z-transform (see [this example](https://en.wikipedia.org/wiki/Z-transform#Example_2_(causal_ROC) "Z-transform")), is given by

![Image 15: {\displaystyle \ X(z)={\frac {1}{1-0.5z^{-1}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/4f65c87b92a3611ffc58d3df40792ff4e5e69b65)
which has a pole in ![Image 16: {\displaystyle z=0.5}](https://wikimedia.org/api/rest_v1/media/math/render/svg/d9267ea9749ae11b3cde9c735c21f2507de379f3) (zero [imaginary part](https://en.wikipedia.org/wiki/Imaginary_number "Imaginary number")). This system is BIBO (asymptotically) stable since the pole is _inside_ the unit circle.

However, if the impulse response was

![Image 17: {\displaystyle \ x[n]=1.5^{n}u[n]}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b769b726a2a55b9fc5e5c8d800187d7715cf84cd)
then the Z-transform is

![Image 18: {\displaystyle \ X(z)={\frac {1}{1-1.5z^{-1}}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/81dd2f0c11aecabe8b5bf08505c7d52974f4ec35)
which has a pole at ![Image 19: {\displaystyle z=1.5}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5f374dfe3fe7ce1355695d53ea69482094aa8935) and is not BIBO stable since the pole has a modulus strictly greater than one.

Numerous tools exist for the analysis of the poles of a system. These include graphical systems like the [root locus](https://en.wikipedia.org/wiki/Root_locus "Root locus"), [Bode plots](https://en.wikipedia.org/wiki/Bode_plot "Bode plot") or the [Nyquist plots](https://en.wikipedia.org/wiki/Nyquist_plot "Nyquist plot").

Mechanical changes can make equipment (and control systems) more stable. Sailors add ballast to improve the stability of ships. Cruise ships use [antiroll fins](https://en.wikipedia.org/wiki/Ship_stability#Stabilizer_fins "Ship stability") that extend transversely from the side of the ship for perhaps 30 feet (10 m) and are continuously rotated about their axes to develop forces that oppose the roll.

### Controllability and observability

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=11 "Edit section: Controllability and observability")]

[Controllability](https://en.wikipedia.org/wiki/Controllability "Controllability") and [observability](https://en.wikipedia.org/wiki/Observability "Observability") are main issues in the analysis of a system before deciding the best control strategy to be applied, or whether it is even possible to control or stabilize the system. Controllability is related to the possibility of forcing the system into a particular state by using an appropriate control signal. If a state is not controllable, then no signal will ever be able to control the state. If a state is not controllable, but its dynamics are stable, then the state is termed _stabilizable_. Observability instead is related to the possibility of _observing_, through output measurements, the state of a system. If a state is not observable, the controller will never be able to determine the behavior of an unobservable state and hence cannot use it to stabilize the system. However, similar to the stabilizability condition above, if a state cannot be observed it might still be detectable.

From a geometrical point of view, looking at the states of each variable of the system to be controlled, every "bad" state of these variables must be controllable and observable to ensure a good behavior in the closed-loop system. That is, if one of the [eigenvalues](https://en.wikipedia.org/wiki/Eigenvalues "Eigenvalues") of the system is not both controllable and observable, this part of the dynamics will remain untouched in the closed-loop system. If such an eigenvalue is not stable, the dynamics of this eigenvalue will be present in the closed-loop system which therefore will be unstable. Unobservable poles are not present in the transfer function realization of a state-space representation, which is why sometimes the latter is preferred in dynamical systems analysis.

Solutions to problems of an uncontrollable or unobservable system include adding actuators and sensors.

### Control specification

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=12 "Edit section: Control specification")]

Several different control strategies have been devised in the past years. These vary from extremely general ones (PID controller), to others devoted to very particular classes of systems (especially [robotics](https://en.wikipedia.org/wiki/Robotics "Robotics") or aircraft cruise control).

A control problem can have several specifications. Stability, of course, is always present. The controller must ensure that the closed-loop system is stable, regardless of the open-loop stability. A poor choice of controller can even worsen the stability of the open-loop system, which must normally be avoided. Sometimes it would be desired to obtain particular dynamics in the closed loop: i.e. that the poles have ![Image 20: {\displaystyle Re[\lambda ]<-{\overline {\lambda }}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/acd3c480f7bd6fa14fd42e56521994a3b4ad8e2d), where ![Image 21: {\displaystyle {\overline {\lambda }}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/de9d2ee37eb0cd550de8d8f34b9d13700f79384e) is a fixed value strictly greater than zero, instead of simply asking that ![Image 22: {\displaystyle Re[\lambda ]<0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/57bd3912e4d0e7aafac442e28a10f4748da7b90d).

Another typical specification is the rejection of a step disturbance; including an [integrator](https://en.wikipedia.org/wiki/Integrator "Integrator") in the open-loop chain (i.e. directly before the system under control) easily achieves this. Other classes of disturbances need different types of sub-systems to be included.

Other "classical" control theory specifications regard the time-response of the closed-loop system. These include the [rise time](https://en.wikipedia.org/wiki/Rise_time "Rise time") (the time needed by the control system to reach the desired value after a perturbation), peak [overshoot](https://en.wikipedia.org/wiki/Overshoot_(signal) "Overshoot (signal)") (the highest value reached by the response before reaching the desired value) and others ([settling time](https://en.wikipedia.org/wiki/Settling_time "Settling time"), quarter-decay). Frequency domain specifications are usually related to [robustness](https://en.wikipedia.org/wiki/Robust_control "Robust control") (see after).

Modern performance assessments use some variation of integrated tracking error (IAE, ISA, CQI).

### Model identification and robustness

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=13 "Edit section: Model identification and robustness")]

A control system must always have some robustness property. A [robust controller](https://en.wikipedia.org/wiki/Robust_control "Robust control") is such that its properties do not change much if applied to a system slightly different from the mathematical one used for its synthesis. This requirement is important, as no real physical system truly behaves like the series of differential equations used to represent it mathematically. Typically a simpler mathematical model is chosen in order to simplify calculations, otherwise, the true [system dynamics](https://en.wikipedia.org/wiki/System_dynamics "System dynamics") can be so complicated that a complete model is impossible.

System identification
The process of determining the equations that govern the model's dynamics is called [system identification](https://en.wikipedia.org/wiki/System_identification "System identification"). This can be done off-line: for example, executing a series of measures from which to calculate an approximated mathematical model, typically its [transfer function](https://en.wikipedia.org/wiki/Transfer_function "Transfer function") or matrix. Such identification from the output, however, cannot take account of unobservable dynamics. Sometimes the model is built directly starting from known physical equations, for example, in the case of a [mass-spring-damper](https://en.wikipedia.org/wiki/Mass-spring-damper_model "Mass-spring-damper model") system we know that ![Image 23: {\displaystyle m{\ddot {x}}(t)=-Kx(t)-\mathrm {B} {\dot {x}}(t)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/1eb22dba60937019ecc7cd8dd87f67d6977c2209). Even assuming that a "complete" model is used in designing the controller, all the parameters included in these equations (called "nominal parameters") are never known with absolute precision; the control system will have to behave correctly even when connected to a physical system with true parameter values away from nominal.

Some advanced control techniques include an "on-line" identification process (see later). The parameters of the model are calculated ("identified") while the controller itself is running. In this way, if a drastic variation of the parameters ensues, for example, if the robot's arm releases a weight, the controller will adjust itself consequently in order to ensure the correct performance.

Analysis
Analysis of the robustness of a SISO (single input single output) control system can be performed in the frequency domain, considering the system's transfer function and using [Nyquist](https://en.wikipedia.org/wiki/Nyquist_diagram "Nyquist diagram") and [Bode diagrams](https://en.wikipedia.org/wiki/Bode_diagram "Bode diagram"). Topics include [gain and phase margin](https://en.wikipedia.org/wiki/Bode_plot#Gain_margin_and_phase_margin "Bode plot") and amplitude margin. For MIMO (multi-input multi output) and, in general, more complicated control systems, one must consider the theoretical results devised for each control technique (see next section). I.e., if particular robustness qualities are needed, the engineer must shift their attention to a control technique by including these qualities in its properties.

Constraints
A particular robustness issue is the requirement for a control system to perform properly in the presence of input and state constraints. In the physical world every signal is limited. It could happen that a controller will send control signals that cannot be followed by the physical system, for example, trying to rotate a valve at excessive speed. This can produce undesired behavior of the closed-loop system, or even damage or break actuators or other subsystems. Specific control techniques are available to solve the problem: [model predictive control](https://en.wikipedia.org/wiki/Model_predictive_control "Model predictive control") (see later), and [anti-wind up systems](https://en.wikipedia.org/wiki/Anti-wind_up_system_(control) "Anti-wind up system (control)"). The latter consists of an additional control block that ensures that the control signal never exceeds a given threshold.

System classifications
----------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=14 "Edit section: System classifications")]

### Linear systems control

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=15 "Edit section: Linear systems control")]

For MIMO systems, pole placement can be performed mathematically using a [state space representation](https://en.wikipedia.org/wiki/State_space_(controls) "State space (controls)") of the open-loop system and calculating a feedback matrix assigning poles in the desired positions. In complicated systems this can require computer-assisted calculation capabilities, and cannot always ensure robustness. Furthermore, all system states are not in general measured and so observers must be included and incorporated in pole placement design.

### Nonlinear systems control

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=16 "Edit section: Nonlinear systems control")]

Processes in industries like [robotics](https://en.wikipedia.org/wiki/Robotics "Robotics") and the [aerospace industry](https://en.wikipedia.org/wiki/Aerospace_industry "Aerospace industry") typically have strong nonlinear dynamics. In control theory it is sometimes possible to linearize such classes of systems and apply linear techniques, but in many cases it can be necessary to devise from scratch theories permitting control of nonlinear systems. These, e.g., [feedback linearization](https://en.wikipedia.org/wiki/Feedback_linearization "Feedback linearization"), [backstepping](https://en.wikipedia.org/wiki/Backstepping "Backstepping"), [sliding mode control](https://en.wikipedia.org/wiki/Sliding_mode_control "Sliding mode control"), trajectory linearization control normally take advantage of results based on [Lyapunov's theory](https://en.wikipedia.org/wiki/Lyapunov%27s_theory "Lyapunov's theory"). [Differential geometry](https://en.wikipedia.org/wiki/Differential_geometry "Differential geometry") has been widely used as a tool for generalizing well-known linear control concepts to the nonlinear case, as well as showing the subtleties that make it a more challenging problem. Control theory has also been used to decipher the neural mechanism that directs cognitive states.[[19]](https://en.wikipedia.org/wiki/Control_theory#cite_note-Shi_Gu_et_al-19)

### Decentralized systems control

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=17 "Edit section: Decentralized systems control")]

When the system is controlled by multiple controllers, the problem is one of decentralized control. Decentralization is helpful in many ways, for instance, it helps control systems to operate over a larger geographical area. The agents in decentralized control systems can interact using communication channels and coordinate their actions.

### Deterministic and stochastic systems control

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=18 "Edit section: Deterministic and stochastic systems control")]

A stochastic control problem is one in which the evolution of the state variables is subjected to random shocks from outside the system. A deterministic control problem is not subject to external random shocks.

Main control strategies
-----------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=19 "Edit section: Main control strategies")]

Every control system must guarantee first the stability of the closed-loop behavior. For [linear systems](https://en.wikipedia.org/wiki/Linear_system "Linear system"), this can be obtained by directly placing the poles. Nonlinear control systems use specific theories (normally based on [Aleksandr Lyapunov](https://en.wikipedia.org/wiki/Aleksandr_Lyapunov "Aleksandr Lyapunov")'s Theory) to ensure stability without regard to the inner dynamics of the system. The possibility to fulfill different specifications varies from the model considered and the control strategy chosen.

List of the main control techniques
*   [Optimal control](https://en.wikipedia.org/wiki/Optimal_control "Optimal control") is a particular control technique in which the control signal optimizes a certain "cost index": for example, in the case of a satellite, the jet thrusts needed to bring it to desired trajectory that consume the least amount of fuel. Two optimal control design methods have been widely used in industrial applications, as it has been shown they can guarantee closed-loop stability. These are [Model Predictive Control](https://en.wikipedia.org/wiki/Model_Predictive_Control "Model Predictive Control") (MPC) and [linear-quadratic-Gaussian control](https://en.wikipedia.org/wiki/Linear-quadratic-Gaussian_control "Linear-quadratic-Gaussian control") (LQG). The first can more explicitly take into account constraints on the signals in the system, which is an important feature in many industrial processes. However, the "optimal control" structure in MPC is only a means to achieve such a result, as it does not optimize a true performance index of the closed-loop control system. Together with PID controllers, MPC systems are the most widely used control technique in [process control](https://en.wikipedia.org/wiki/Process_control "Process control").
*   [Robust control](https://en.wikipedia.org/wiki/Robust_control "Robust control") deals explicitly with uncertainty in its approach to controller design. Controllers designed using _robust control_ methods tend to be able to cope with small differences between the true system and the nominal model used for design.[[20]](https://en.wikipedia.org/wiki/Control_theory#cite_note-20) The early methods of [Bode](https://en.wikipedia.org/wiki/Hendrik_Wade_Bode "Hendrik Wade Bode") and others were fairly robust; the state-space methods invented in the 1960s and 1970s were sometimes found to lack robustness. Examples of modern robust control techniques include [H-infinity loop-shaping](https://en.wikipedia.org/wiki/H-infinity_loop-shaping "H-infinity loop-shaping") developed by Duncan McFarlane and [Keith Glover](https://en.wikipedia.org/wiki/Keith_Glover "Keith Glover"), [Sliding mode control](https://en.wikipedia.org/wiki/Sliding_mode_control "Sliding mode control") (SMC) developed by [Vadim Utkin](https://en.wikipedia.org/wiki/Vadim_Utkin "Vadim Utkin"), and safe protocols designed for control of large heterogeneous populations of electric loads in Smart Power Grid applications.[[21]](https://en.wikipedia.org/wiki/Control_theory#cite_note-TCL1-21) Robust methods aim to achieve robust performance and/or [stability](https://en.wikipedia.org/wiki/Stability_theory "Stability theory") in the presence of small modeling errors.
*   [Stochastic control](https://en.wikipedia.org/wiki/Stochastic_control "Stochastic control") deals with control design with uncertainty in the model. In typical stochastic control problems, it is assumed that there exist random noise and disturbances in the model and the controller, and the control design must take into account these random deviations.
*   [Adaptive control](https://en.wikipedia.org/wiki/Adaptive_control "Adaptive control") uses on-line identification of the process parameters, or modification of controller gains, thereby obtaining strong robustness properties. Adaptive controls were applied for the first time in the [aerospace industry](https://en.wikipedia.org/wiki/Aerospace_industry "Aerospace industry") in the 1950s, and have found particular success in that field.
*   A [hierarchical control system](https://en.wikipedia.org/wiki/Hierarchical_control_system "Hierarchical control system") is a type of [control system](https://en.wikipedia.org/wiki/Control_system "Control system") in which a set of devices and governing software is arranged in a [hierarchical](https://en.wikipedia.org/wiki/Hierarchical "Hierarchical")[tree](https://en.wikipedia.org/wiki/Tree_(data_structure) "Tree (data structure)"). When the links in the tree are implemented by a [computer network](https://en.wikipedia.org/wiki/Computer_network "Computer network"), then that hierarchical control system is also a form of [networked control system](https://en.wikipedia.org/wiki/Networked_control_system "Networked control system").
*   [Intelligent control](https://en.wikipedia.org/wiki/Intelligent_control "Intelligent control") uses various AI computing approaches like [artificial neural networks](https://en.wikipedia.org/wiki/Artificial_neural_networks "Artificial neural networks"), [Bayesian probability](https://en.wikipedia.org/wiki/Bayesian_probability "Bayesian probability"), [fuzzy logic](https://en.wikipedia.org/wiki/Fuzzy_logic "Fuzzy logic"),[[22]](https://en.wikipedia.org/wiki/Control_theory#cite_note-22)[machine learning](https://en.wikipedia.org/wiki/Machine_learning "Machine learning"), [evolutionary computation](https://en.wikipedia.org/wiki/Evolutionary_computation "Evolutionary computation") and [genetic algorithms](https://en.wikipedia.org/wiki/Genetic_algorithms "Genetic algorithms") or a combination of these methods, such as [neuro-fuzzy](https://en.wikipedia.org/wiki/Neuro-fuzzy "Neuro-fuzzy") algorithms, to control a [dynamic system](https://en.wikipedia.org/wiki/Dynamic_system "Dynamic system").
*   [Self-organized criticality control](https://en.wikipedia.org/wiki/Self-organized_criticality_control "Self-organized criticality control") may be defined as attempts to interfere in the processes by which the [self-organized](https://en.wikipedia.org/wiki/Self-organized "Self-organized") system dissipates energy.

People in systems and control
-----------------------------

[[edit](https://en.wikipedia.org/w/index.php?title=Control_theory&action=edit&section=20 "Edit section: People in systems and control")]

Many active and historical figures made significant contribution to control theory including

*   [Pierre-Simon Laplace](https://en.wikipedia.org/wiki/Pierre-Simon_Laplace "Pierre-Simon Laplace") invented the [Z-transform](https://en.wikipedia.org/wiki/Z-transform "Z-transform") in his work on [probability theory](https://en.wikipedia.org/wiki/Probability_theory "Probability theory"), now used to solve discrete-time control theory problems. The Z-transform is a discrete-time equivalent of the [Laplace transform](https://en.wikipedia.org/wiki/Laplace_transform "Laplace transform") which is named after him.
*   [Irmgard Flugge-Lotz](https://en.wikipedia.org/wiki/Irmgard_Flugge-Lotz "Irmgard Flugge-Lotz") developed the theory of [discontinuous automatic control](https://en.wikipedia.org/wiki/Bang-bang_control "Bang-bang control") and applied it to [automatic aircraft control systems](https://en.wikipedia.org/wiki/Autopilot "Autopilot").
*   [Alexander Lyapunov](https://en.wikipedia.org/wiki/Alexander_Lyapunov "Alexander Lyapunov") in the 1890s marks the beginning of [stability theory](https://en.wikipedia.org/wiki/Stability_theory "Stability theory").
*   [Harold S. Black](https://en.wikipedia.org/wiki/Harold_Stephen_Black "Harold Stephen Black") invented the concept of [negative feedback amplifiers](https://en.wikipedia.org/wiki/Negative_feedback_amplifier "Negative feedback amplifier") in 1927. He managed to develop stable negative feedback amplifiers in the 1930s.
*   [Harry Nyquist](https://en.wikipedia.org/wiki/Harry_Nyquist "Harry Nyquist") developed the [Nyquist stability criterion](https://en.wikipedia.org/wiki/Nyquist_stability_criterion "Nyquist stability criterion") for feedback systems in the 1930s.
*   [Richard Bellman](https://en.wikipedia.org/wiki/Richard_Bellman "Richard Bellman") developed [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming "Dynamic programming") in the 1940s.[[23]](https://en.wikipedia.org/wiki/Control_theory#cite_note-23)
*   [Warren E. Dixon](https://en.wikipedia.org/wiki/Warren_E._Dixon "Warren E. Dixon"), control theorist and a professor
*   [Kyriakos G. Vamvoudakis](https://en.wikipedia.org/w/index.php?title=Kyriakos_G._Vamvoudakis&action=edit&redlink=1 "Kyriakos G. Vamvoudakis (page does not exist)"), developed synchronous reinforcement learning algorithms to solve optimal control and game theoretic problems
*   [Andrey Kolmogorov](https://en.wikipedia.org/wiki/Andrey_Kolmogorov "Andrey Kolmogorov") co-developed the [Wiener–Kolmogorov filter](https://en.wikipedia.org/wiki/Wiener_filter "Wiener filter") in 1941.
*   [Norbert Wiener](https://en.wikipedia.org/wiki/Norbert_Wiener "Norbert Wiener") co-developed the Wiener–Kolmogorov filter and coined the term [cybernetics](https://en.wikipedia.org/wiki/Cybernetics "Cybernetics") in the 1940s.
*   [John R. Ragazzini](https://en.wikipedia.org/wiki/John_R._Ragazzini "John R. Ragazzini") introduced [digital control](https://en.wikipedia.org/wiki/Digital_control "Digital control") and the use of [Z-transform](https://en.wikipedia.org/wiki/Z-transform "Z-transform") in control theory (invented by Laplace) in the 1950s.
*   [Lev Pontryagin](https://en.wikipedia.org/wiki/Lev_Pontryagin "Lev Pontryagin") introduced the [maximum principle](https://en.wikipedia.org/wiki/Pontryagin%27s_minimum_principle "Pontryagin's minimum principle") and the [bang-bang principle](https://en.wikipedia.org/wiki/Bang-bang_control "Bang-bang control").
*   [Pierre-Louis Lions](https://en.wikipedia.org/wiki/Pierre-Louis_Lions "Pierre-Louis Lions") developed [viscosity solutions](https://en.wikipedia.org/wiki/Viscosity_solutions "Viscosity solutions") into stochastic control and [optimal control](https://en.wikipedia.org/wiki/Optimal_control "Optimal control") methods.
*   [Rudolf E. Kálmán](https://en.wikipedia.org/wiki/Rudolf_E._K%C3%A1lm%C3%A1n "Rudolf E. Kálmán") pioneered the [state-space](https://en.wikipedia.org/wiki/State-space "State-space") approach to systems and control. Introduced the notions of [controllability](https://en.wikipedia.org/wiki/Controllability "Controllability") and [observability](https://en.wikipedia.org/wiki/Observability "Observability"). Developed the [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter "Kalman filter") for linear estimation.
*   [Ali H. Nayfeh](https://en.wikipedia.org/wiki/Ali_H._Nayfeh "Ali H. Nayfeh") who was one of the main contributors to nonlinear control theory and published many books on perturbation methods
*   [Jan C. Willems](https://en.wikipedia.org/wiki/Jan_Camiel_Willems "Jan Camiel Willems") Introduced the concept of dissipativity, as a generalization of [Lyapunov function](https://en.wikipedia.org/wiki/Lyapunov_function "Lyapunov function") to input/state/output systems. The construction of the storage function, as the analogue of a Lyapunov function is called, led to the study of the [linear matrix inequality](https://en.wikipedia.org/wiki/Linear_matrix_inequality "Linear matrix inequality") (LMI) in control theory. He pioneered the behavioral approach to mathematical systems theory.

Examples of control systems

*   [Automation](https://en.wikipedia.org/wiki/Automation "Automation")– Use of various control systems for operating equipment
*   [Deadbeat controller](https://en.wikipedia.org/wiki/Deadbeat_controller "Deadbeat controller")
*   [Distributed parameter systems](https://en.wikipedia.org/wiki/Distributed_parameter_systems "Distributed parameter systems")– System with an infinite-dimensional state-space
*   [Fractional-order control](https://en.wikipedia.org/wiki/Fractional-order_control "Fractional-order control")– Field of mathematical control theory
*   [H-infinity loop-shaping](https://en.wikipedia.org/wiki/H-infinity_loop-shaping "H-infinity loop-shaping")
*   [Hierarchical control system](https://en.wikipedia.org/wiki/Hierarchical_control_system "Hierarchical control system")
*   [Model predictive control](https://en.wikipedia.org/wiki/Model_predictive_control "Model predictive control")– Advanced method of process control
*   [Optimal control](https://en.wikipedia.org/wiki/Optimal_control "Optimal control")– Mathematical way of attaining a desired output from a dynamic system
*   [Process control](https://en.wikipedia.org/wiki/Process_control "Process control")– Discipline that uses industrial control to achieve a production level of consistency
*   [Robust control](https://en.wikipedia.org/wiki/Robust_control "Robust control")– Approach to controller design that explicitly deals with uncertainty
*   [Servomechanism](https://en.wikipedia.org/wiki/Servomechanism "Servomechanism")– Control system for the motion of a mechanical system
*   [State space (controls)](https://en.wikipedia.org/wiki/State_space_(controls) "State space (controls)")– Mathematical model of a system in control engineering
*   [Vector control](https://en.wikipedia.org/wiki/Vector_control_(motor) "Vector control (motor)")– Method to control electric motors

Topics in control theory

*   [Coefficient diagram method](https://en.wikipedia.org/wiki/Coefficient_diagram_method "Coefficient diagram method")
*   [Control reconfiguration](https://en.wikipedia.org/wiki/Control_reconfiguration "Control reconfiguration")– Approach in control theory to achieve fault-tolerant control for dynamic systems
*   [Feedback](https://en.wikipedia.org/wiki/Feedback "Feedback")– Process where information about current status is used to influence future status
*   [H infinity](https://en.wikipedia.org/wiki/H_infinity "H infinity")
*   [Hankel singular value](https://en.wikipedia.org/wiki/Hankel_singular_value "Hankel singular value")
*   [Krener's theorem](https://en.wikipedia.org/wiki/Krener%27s_theorem "Krener's theorem")
*   [Lead-lag compensator](https://en.wikipedia.org/wiki/Lead-lag_compensator "Lead-lag compensator")– Control system component
*   [Minor loop feedback](https://en.wikipedia.org/wiki/Minor_loop_feedback "Minor loop feedback")– Classical method used to design feedback control systems
*   [Multi-loop feedback](https://en.wikipedia.org/wiki/Minor_loop_feedback "Minor loop feedback")– Classical method used to design feedback control systems
*   [Positive systems](https://en.wikipedia.org/wiki/Positive_systems "Positive systems")
*   [Radial basis function](https://en.wikipedia.org/wiki/Radial_basis_function "Radial basis function")– Type of mathematical function
*   [Root locus](https://en.wikipedia.org/wiki/Root_locus "Root locus")– Stability criterion in control theory
*   [Signal-flow graph](https://en.wikipedia.org/wiki/Signal-flow_graph "Signal-flow graph")– Flow graph invented by Claude Shannons
*   [Stable polynomial](https://en.wikipedia.org/wiki/Stable_polynomial "Stable polynomial")– Characteristic polynomial whose associated linear system is stable
*   [State space representation](https://en.wikipedia.org/wiki/State_space_representation "State space representation")– Mathematical model of a system in control engineering
*   [Steady state](https://en.wikipedia.org/wiki/Steady_state "Steady state")– State in which variables of a system are unchanging in time
*   [Transient response](https://en.wikipedia.org/wiki/Transient_response "Transient response")– Response of a system to a change from an equilibrium state
*   [Transient state](https://en.wikipedia.org/wiki/Transient_state "Transient state")– State of a system after conditions are changed, before it settles into steady state
*   [Underactuation](https://en.wikipedia.org/wiki/Underactuation "Underactuation")
*   [Youla–Kucera parametrization](https://en.wikipedia.org/wiki/Youla%E2%80%93Kucera_parametrization "Youla–Kucera parametrization")– Formulaic parametrization
*   [Markov chain approximation method](https://en.wikipedia.org/wiki/Markov_chain_approximation_method "Markov chain approximation method")

Other related topics

*   [Adaptive system](https://en.wikipedia.org/wiki/Adaptive_system "Adaptive system")– System that can adapt to the environment
*   [Automation and remote control](https://en.wikipedia.org/wiki/Automation_and_remote_control "Automation and remote control")
*   [Bond graph](https://en.wikipedia.org/wiki/Bond_graph "Bond graph")– Graphical representation of a dynamic system
*   [Control engineering](https://en.wikipedia.org/wiki/Control_engineering "Control engineering")– Engineering discipline that deals with control systems
*   [Control–feedback–abort loop](https://en.wikipedia.org/wiki/Control%E2%80%93feedback%E2%80%93abort_loop "Control–feedback–abort loop")
*   [Controller (control theory)](https://en.wikipedia.org/wiki/Controller_(control_theory) "Controller (control theory)")– Branch of engineering and mathematics
*   [Cybernetics](https://en.wikipedia.org/wiki/Cybernetics "Cybernetics")– Transdisciplinary field concerned with regulatory and purposive systems
*   [Intelligent control](https://en.wikipedia.org/wiki/Intelligent_control "Intelligent control")– Artificial intelligence control techniques
*   [Mathematical system theory](https://en.wikipedia.org/wiki/Mathematical_system_theory "Mathematical system theory")– Area of mathematics used to describe the behavior of complex dynamical systems
*   [Negative feedback amplifier](https://en.wikipedia.org/wiki/Negative_feedback_amplifier "Negative feedback amplifier")– Type of electronic amplifier
*   [Outline of management](https://en.wikipedia.org/wiki/Outline_of_management "Outline of management")– Overview of concepts related to management
*   [People in systems and control](https://en.wikipedia.org/wiki/People_in_systems_and_control "People in systems and control")
*   [Perceptual control theory](https://en.wikipedia.org/wiki/Perceptual_control_theory "Perceptual control theory")– Psychological theory
*   [Systems theory](https://en.wikipedia.org/wiki/Systems_theory "Systems theory")– Interdisciplinary study of systems

1.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-1)**[Maxwell, J. C.](https://en.wikipedia.org/wiki/James_Clerk_Maxwell "James Clerk Maxwell") (1868). ["On Governors"](https://upload.wikimedia.org/wikipedia/commons/b/b1/On_Governors.pdf)(PDF). _Proceedings of the Royal Society_. **100**. [Archived](https://web.archive.org/web/20081219051207/http://upload.wikimedia.org/wikipedia/commons/b/b1/On_Governors.pdf)(PDF) from the original on December 19, 2008.
2.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-2)**[Minorsky, Nicolas](https://en.wikipedia.org/wiki/Nicolas_Minorsky "Nicolas Minorsky") (1922). "Directional stability of automatically steered bodies". _Journal of the American Society of Naval Engineers_. **34** (2): 280–309. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1111/j.1559-3584.1922.tb04958.x](https://doi.org/10.1111%2Fj.1559-3584.1922.tb04958.x).
3.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-3)**GND. ["Katalog der Deutschen Nationalbibliothek (Authority control)"](https://d-nb.info/gnd/4032317-1). _portal.dnb.de_. Retrieved December 21, 2024.
4.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Maxwell1867_4-0)**Maxwell, J.C. (1868). "On Governors". _Proceedings of the Royal Society of London_. **16**: 270–283. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1098/rspl.1867.0055](https://doi.org/10.1098%2Frspl.1867.0055). [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[112510](https://www.jstor.org/stable/112510).
5.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-5)**Fernandez-Cara, E.; Zuazua, E. ["Control Theory: History, Mathematical Achievements and Perspectives"](https://citeseerx.ist.psu.edu/doc/10.1.1.302.5633). Boletin de la Sociedad Espanola de Matematica Aplicada. [CiteSeerX](https://en.wikipedia.org/wiki/CiteSeerX_(identifier) "CiteSeerX (identifier)")[10.1.1.302.5633](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.302.5633). [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier) "ISSN (identifier)")[1575-9822](https://search.worldcat.org/issn/1575-9822).
6.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Routh1975_6-0)**Routh, E.J.; Fuller, A.T. (1975). _Stability of motion_. Taylor & Francis.
7.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Routh1877_7-0)**Routh, E.J. (1877). [_A Treatise on the Stability of a Given State of Motion, Particularly Steady Motion: Particularly Steady Motion_](https://archive.org/details/atreatiseonstab00routgoog). Macmillan and co.
8.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Hurwitz1964_8-0)**Hurwitz, A. (1964). "On The Conditions Under Which An Equation Has Only Roots With Negative Real Parts". _Selected Papers on Mathematical Trends in Control Theory_.
9.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-9)**Flugge-Lotz, Irmgard; Titus, Harold A. (October 1962). ["Optimum and Quasi-Optimum Control of Third and Fourth-Order Systems"](https://web.archive.org/web/20190427142417/http://www.dtic.mil/dtic/tr/fulltext/u2/621137.pdf)(PDF). _Stanford University Technical Report_ (134): 8–12. Archived from [the original](http://www.dtic.mil/dtic/tr/fulltext/u2/621137.pdf)(PDF) on April 27, 2019.
10.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-10)**Hallion, Richard P. (1980). Sicherman, Barbara; Green, Carol Hurd; Kantrov, Ilene; Walker, Harriette (eds.). [_Notable American Women: The Modern Period: A Biographical Dictionary_](https://archive.org/details/notableamericanw00sich). Cambridge, Mass.: Belknap Press of Harvard University Press. pp.[241–242](https://archive.org/details/notableamericanw00sich/page/241). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[9781849722704](https://en.wikipedia.org/wiki/Special:BookSources/9781849722704 "Special:BookSources/9781849722704").
11.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Control_loop_auto_11-0)**"Feedback and control systems" - JJ Di Steffano, AR Stubberud, IJ Williams. Schaums outline series, McGraw-Hill 1967
12.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-12)**[Mayr, Otto](https://en.wikipedia.org/wiki/Otto_Mayr "Otto Mayr") (1970). _The Origins of Feedback Control_. Clinton, MA US: The Colonial Press, Inc.
13.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-13)**[Mayr, Otto](https://en.wikipedia.org/wiki/Otto_Mayr "Otto Mayr") (1969). _The Origins of Feedback Control_. Clinton, MA US: The Colonial Press, Inc.
14.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-14)**Bechhoefer, John (August 31, 2005). ["Feedback for physicists: A tutorial essay on control"](https://link.aps.org/doi/10.1103/RevModPhys.77.783). _Reviews of Modern Physics_. **77** (3): 783–836. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1103/RevModPhys.77.783](https://doi.org/10.1103%2FRevModPhys.77.783).
15.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-15)**Cao, F. J.; Feito, M. (April 10, 2009). ["Thermodynamics of feedback controlled systems"](https://link.aps.org/doi/10.1103/PhysRevE.79.041118). _Physical Review E_. **79** (4): 041118. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[0805.4824](https://arxiv.org/abs/0805.4824). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1103/PhysRevE.79.041118](https://doi.org/10.1103%2FPhysRevE.79.041118).
16.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-16)**["trim point"](http://www.mathworks.com/help/toolbox/simulink/slref/trim.html).
17.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-17)**Donald M Wiberg (1971). _State space & linear systems_. Schaum's outline series. McGraw Hill. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-070096-3](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-070096-3 "Special:BookSources/978-0-07-070096-3").
18.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-18)**Terrell, William (1999). ["Some fundamental control theory I: Controllability, observability, and duality —AND— Some fundamental control Theory II: Feedback linearization of single input nonlinear systems"](http://www.maa.org/programs/maa-awards/writing-awards/some-fundamental-control-theory-i-controllability-observability-and-duality-and-some-fundamental). _American Mathematical Monthly_. **106** (9): 705–719 and 812–828. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.2307/2589614](https://doi.org/10.2307%2F2589614). [JSTOR](https://en.wikipedia.org/wiki/JSTOR_(identifier) "JSTOR (identifier)")[2589614](https://www.jstor.org/stable/2589614).
19.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-Shi_Gu_et_al_19-0)**Gu Shi; et al. (2015). ["Controllability of structural brain networks (Article Number 8414)"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4600713). _Nature Communications_. **6** (6): 8414. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[1406.5197](https://arxiv.org/abs/1406.5197). [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2015NatCo...6.8414G](https://ui.adsabs.harvard.edu/abs/2015NatCo...6.8414G). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1038/ncomms9414](https://doi.org/10.1038%2Fncomms9414). [PMC](https://en.wikipedia.org/wiki/PMC_(identifier) "PMC (identifier)")[4600713](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4600713). [PMID](https://en.wikipedia.org/wiki/PMID_(identifier) "PMID (identifier)")[26423222](https://pubmed.ncbi.nlm.nih.gov/26423222). Here we use tools from control and network theories to offer a mechanistic explanation for how the brain moves between cognitive states drawn from the network organization of white matter microstructure
20.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-20)**Melby, Paul; et., al. (2002). "Robustness of Adaptation in Controlled Self-Adjusting Chaotic Systems". _Fluctuation and Noise Letters_. **02** (4): L285 –L292. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1142/S0219477502000919](https://doi.org/10.1142%2FS0219477502000919).
21.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-TCL1_21-0)**N. A. Sinitsyn. S. Kundu, S. Backhaus (2013). "Safe Protocols for Generating Power Pulses with Heterogeneous Populations of Thermostatically Controlled Loads". _[Energy Conversion and Management](https://en.wikipedia.org/wiki/Energy\_Conversion\_and\_Management "Energy Conversion and Management")_. **67**: 297–308. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[1211.0248](https://arxiv.org/abs/1211.0248). [Bibcode](https://en.wikipedia.org/wiki/Bibcode_(identifier) "Bibcode (identifier)"):[2013ECM....67..297S](https://ui.adsabs.harvard.edu/abs/2013ECM....67..297S). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.enconman.2012.11.021](https://doi.org/10.1016%2Fj.enconman.2012.11.021). [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier) "S2CID (identifier)")[32067734](https://api.semanticscholar.org/CorpusID:32067734).
22.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-22)**Liu, Jie; Wilson Wang; Farid Golnaraghi; Eric Kubica (2010). "A novel fuzzy framework for nonlinear system control". _Fuzzy Sets and Systems_. **161** (21): 2746–2759. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1016/j.fss.2010.04.009](https://doi.org/10.1016%2Fj.fss.2010.04.009).
23.   **[^](https://en.wikipedia.org/wiki/Control_theory#cite_ref-23)**[Richard Bellman](https://en.wikipedia.org/wiki/Richard_Bellman "Richard Bellman") (1964). "Control Theory". _[Scientific American](https://en.wikipedia.org/wiki/Scientific\_American "Scientific American")_. Vol.211, no.3. pp.186–200. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"):[10.1038/scientificamerican0964-186](https://doi.org/10.1038%2Fscientificamerican0964-186).

*   Levine, William S., ed. (1996). _The Control Handbook_. New York: CRC Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-8493-8570-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8493-8570-4 "Special:BookSources/978-0-8493-8570-4").
*   Karl J. Åström; Richard M. Murray (2008). [_Feedback Systems: An Introduction for Scientists and Engineers_](http://www.cds.caltech.edu/~murray/books/AM08/pdf/am08-complete_28Sep12.pdf)(PDF). Princeton University Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-691-13576-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-691-13576-2 "Special:BookSources/978-0-691-13576-2").
*   Christopher Kilian (2005). _Modern Control Technology_. Thompson Delmar Learning. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-4018-5806-3](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4018-5806-3 "Special:BookSources/978-1-4018-5806-3").
*   Vannevar Bush (1929). _Operational Circuit Analysis_. John Wiley and Sons, Inc.
*   Robert F. Stengel (1994). _Optimal Control and Estimation_. Dover Publications. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-486-68200-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-68200-6 "Special:BookSources/978-0-486-68200-6").
*   Franklin; et al. (2002). _Feedback Control of Dynamic Systems_ (4 ed.). New Jersey: Prentice Hall. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-032393-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-032393-4 "Special:BookSources/978-0-13-032393-4").
*   Joseph L. Hellerstein; [Dawn M. Tilbury](https://en.wikipedia.org/wiki/Dawn_Tilbury "Dawn Tilbury"); Sujay Parekh (2004). _Feedback Control of Computing Systems_. John Wiley and Sons. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-471-26637-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-26637-2 "Special:BookSources/978-0-471-26637-2").
*   [Diederich Hinrichsen](https://en.wikipedia.org/wiki/Diederich_Hinrichsen "Diederich Hinrichsen") and Anthony J. Pritchard (2005). _Mathematical Systems Theory I – Modelling, State Space Analysis, Stability and Robustness_. Springer. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-3-540-44125-0](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-44125-0 "Special:BookSources/978-3-540-44125-0").
*   [Sontag, Eduardo](https://en.wikipedia.org/wiki/Eduardo_D._Sontag "Eduardo D. Sontag") (1998). [_Mathematical Control Theory: Deterministic Finite Dimensional Systems. Second Edition_](http://www.sontaglab.org/FTPDIR/sontag_mathematical_control_theory_springer98.pdf)(PDF). Springer. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-387-98489-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-98489-6 "Special:BookSources/978-0-387-98489-6").
*   Goodwin, Graham (2001). _Control System Design_. Prentice Hall. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-13-958653-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-958653-8 "Special:BookSources/978-0-13-958653-8").
*   Christophe Basso (2012). [_Designing Control Loops for Linear and Switching Power Supplies: A Tutorial Guide_](http://cbasso.pagesperso-orange.fr/Spice.htm). Artech House. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1608075577](https://en.wikipedia.org/wiki/Special:BookSources/978-1608075577 "Special:BookSources/978-1608075577").
*   Boris J. Lurie; Paul J. Enright (2019). _Classical Feedback Control with Nonlinear Multi-loop Systems_ (3 ed.). CRC Press. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-1-1385-4114-6](https://en.wikipedia.org/wiki/Special:BookSources/978-1-1385-4114-6 "Special:BookSources/978-1-1385-4114-6").

For Chemical Engineering
*   Luyben, William (1989). _Process Modeling, Simulation, and Control for Chemical Engineers_. McGraw Hill. [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)")[978-0-07-039159-8](https://en.wikipedia.org/wiki/Special:BookSources/978-0-07-039159-8 "Special:BookSources/978-0-07-039159-8").

*   [Control Tutorials for Matlab](https://ctms.engin.umich.edu/CTMS/index.php?aux=Home), a set of worked-through control examples solved by several different methods.
*   [Control Tuning and Best Practices](https://controlguru.com/)
*   [Advanced control structures, free on-line simulators explaining the control theory](https://www.pidlab.com/)
