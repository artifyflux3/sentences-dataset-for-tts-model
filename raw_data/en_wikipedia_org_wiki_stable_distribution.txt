Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definition Toggle Definition subsection 1.1 Parametrizations 1.2 The distribution 2 One-sided stable distribution and stable count distribution 3 Properties 4 The Generalized Central Limit Theorem 5 Special cases 6 Series representation 7 Parameter estimation 8 Simulation of stable variates 9 Applications 10 Other analytic cases 11 See also 12 Software implementations 13 References Toggle the table of contents Stable distribution 10 languages Català Deutsch Español Français Nederlands 日本語 Русский Shqip Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Distribution of variables which satisfies a stability property under linear combinations Not to be confused with Stationary distribution .

Stable Probability density function Symmetric α α {\displaystyle \alpha } -stable distributions with unit scale factor Skewed centered stable distributions with unit scale factor Cumulative distribution function CDFs for symmetric α α {\displaystyle \alpha } -stable distributions CDFs for skewed centered stable distributions Parameters α α ∈ ∈ ( 0 , 2 ] {\displaystyle \alpha \in (0,2]} — stability parameter β β {\displaystyle \beta } ∈ [−1, 1] — skewness parameter (note that skewness is undefined) c ∈ (0, ∞) — scale parameter μ ∈ (−∞, ∞) — location parameter Support x ∈ [ μ , +∞) if α α < 1 {\displaystyle \alpha <1} and β β = 1 {\displaystyle \beta =1} x ∈ (-∞, μ ] if α α < 1 {\displaystyle \alpha <1} and β β = − − 1 {\displaystyle \beta =-1} x ∈ R otherwise PDF not analytically expressible, except for some parameter values CDF not analytically expressible, except for certain parameter values Mean μ when α α > 1 {\displaystyle \alpha >1} , otherwise undefined Median μ when β β = 0 {\displaystyle \beta =0} , otherwise not analytically expressible Mode μ when β β = 0 {\displaystyle \beta =0} , otherwise not analytically expressible Variance 2 c 2 when α α = 2 {\displaystyle \alpha =2} , otherwise infinite Skewness 0 when α α = 2 {\displaystyle \alpha =2} , otherwise undefined Excess kurtosis 0 when α α = 2 {\displaystyle \alpha =2} , otherwise undefined Entropy not analytically expressible, except for certain parameter values MGF exp ( t μ μ + c 2 t 2 ) {\displaystyle \exp \!{\big (}t\mu +c^{2}t^{2}{\big )}} when α α = 2 {\displaystyle \alpha =2} , exp ( t μ μ − − c α α t α α sec ⁡ ⁡ ( π π α α / 2 ) ) {\displaystyle \exp \!{\big (}t\mu -c^{\alpha }t^{\alpha }\sec(\pi \alpha /2){\big )}} when α α ≠ ≠ 1 , β β = − − 1 , t > 0 {\displaystyle \alpha \neq 1,\beta =-1,t>0} , exp ( t μ μ − − c 2 π π − − 1 t ln ⁡ ⁡ t ) {\displaystyle \exp \!{\big (}t\mu -c2\pi ^{-1}t\ln t{\big )}} when α α = 1 , β β = − − 1 , t > 0 {\displaystyle \alpha =1,\beta =-1,t>0} , otherwise undefined CF exp [ i t μ μ − − | c t | α α ( 1 − − i β β sgn ⁡ ⁡ ( t ) Φ Φ ) ] , {\displaystyle \exp \!{\Big [}\;it\mu -|c\,t|^{\alpha }\,(1-i\beta \operatorname {sgn}(t)\Phi )\;{\Big ]},} where Φ Φ = { tan ⁡ ⁡ π π α α 2 if α α ≠ ≠ 1 − − 2 π π log ⁡ ⁡ | t | if α α = 1 {\displaystyle \Phi ={\begin{cases}\tan {\tfrac {\pi \alpha }{2}}&{\text{if }}\alpha \neq 1\\-{\tfrac {2}{\pi }}\log |t|&{\text{if }}\alpha =1\end{cases}}} In probability theory , a distribution is said to be stable if a linear combination of two independent random variables with this distribution has the same distribution, up to location and scale parameters. A random variable is said to be stable if its distribution is stable. The stable distribution family is also sometimes referred to as the Lévy alpha-stable distribution , after Paul Lévy , the first mathematician to have studied it.

[ 1 ] [ 2 ] Of the four parameters defining the family, most attention has been focused on the stability parameter, α α {\displaystyle \alpha } (see panel). Stable distributions have 0 < α α ≤ ≤ 2 {\displaystyle 0<\alpha \leq 2} , with the upper bound corresponding to the normal distribution , and α α = 1 {\displaystyle \alpha =1} to the Cauchy distribution . The distributions have undefined variance for α α < 2 {\displaystyle \alpha <2} , and undefined mean for α α ≤ ≤ 1 {\displaystyle \alpha \leq 1} .

The importance of stable probability distributions is that they are " attractors " for properly normed sums of independent and identically distributed ( iid ) random variables. The normal distribution defines a family of stable distributions. By the classical central limit theorem , the properly normed sum of a set of random variables, each with finite variance, will tend toward a normal distribution as the number of variables increases. Without the finite variance assumption, the limit may be a stable distribution that is not normal.

Mandelbrot referred to such distributions as "stable Paretian distributions", [ 3 ] [ 4 ] [ 5 ] after Vilfredo Pareto . In particular, he referred to those maximally skewed in the positive direction with 1 < α α < 2 {\displaystyle 1<\alpha <2} as "Pareto–Lévy distributions", [ 1 ] which he regarded as better descriptions of stock and commodity prices than normal distributions.

[ 6 ] Definition [ edit ] A non- degenerate distribution is a stable distribution if it satisfies the following property: Let X 1 and X 2 be independent realizations of a random variable X . Then X is said to be stable if for any constants a > 0 and b > 0 the random variable aX 1 + bX 2 has the same distribution as cX + d for some constants c > 0 and d . The distribution is said to be strictly stable if this holds with d = 0 .

[ 7 ] Since the normal distribution , the Cauchy distribution , and the Lévy distribution all have the above property, it follows that they are special cases of stable distributions.

Such distributions form a four-parameter family of continuous probability distributions parametrized by location and scale parameters μ and c , respectively, and two shape parameters β β {\displaystyle \beta } and α α {\displaystyle \alpha } , roughly corresponding to measures of asymmetry and concentration, respectively (see the figures).

The characteristic function φ φ {\displaystyle \varphi } of a probability distribution with density function f {\displaystyle f} is the Fourier transform of f .

{\displaystyle f.} The density function is then the inverse Fourier transform of the characteristic function: [ 8 ] φ φ ( t ) = ∫ ∫ − − ∞ ∞ ∞ ∞ f ( x ) e i x t d x .

{\displaystyle \varphi (t)=\int _{-\infty }^{\infty }f(x)e^{ixt}\,dx.} Although the probability density function for a general stable distribution cannot be written analytically, the general characteristic function can be expressed analytically. A random variable X is called stable if its characteristic function can be written as [ 7 ] [ 9 ] φ φ ( t ; α α , β β , c , μ μ ) = exp ⁡ ⁡ ( i t μ μ − − | c t | α α ( 1 − − i β β sgn ⁡ ⁡ ( t ) Φ Φ ) ) {\displaystyle \varphi (t;\alpha ,\beta ,c,\mu )=\exp \left(it\mu -|ct|^{\alpha }\left(1-i\beta \operatorname {sgn}(t)\Phi \right)\right)} where sgn( t ) is just the sign of t and Φ Φ = { tan ⁡ ⁡ ( π π α α 2 ) α α ≠ ≠ 1 − − 2 π π log ⁡ ⁡ | t | α α = 1 {\displaystyle \Phi ={\begin{cases}\tan \left({\frac {\pi \alpha }{2}}\right)&\alpha \neq 1\\-{\frac {2}{\pi }}\log |t|&\alpha =1\end{cases}}} μ ∈ R is a shift parameter, β β ∈ ∈ [ − − 1 , 1 ] {\displaystyle \beta \in [-1,1]} , called the skewness parameter , is a measure of asymmetry. Notice that in this context the usual skewness is not well defined, as for α α < 2 {\displaystyle \alpha <2} the distribution does not admit 2nd or higher moments , and the usual skewness definition is the 3rd central moment .

The reason this gives a stable distribution is that the characteristic function for the sum of two independent random variables equals the product of the two corresponding characteristic functions. Adding two random variables from a stable distribution gives something with the same values of α α {\displaystyle \alpha } and β β {\displaystyle \beta } , but possibly different values of μ and c .

Not every function is the characteristic function of a legitimate probability distribution (that is, one whose cumulative distribution function is real and goes from 0 to 1 without decreasing), but the characteristic functions given above will be legitimate so long as the parameters are in their ranges. The value of the characteristic function at some value t is the complex conjugate of its value at − t as it should be so that the probability distribution function will be real.

In the simplest case β β = 0 {\displaystyle \beta =0} , the characteristic function is just a stretched exponential function ; the  distribution is symmetric about μ and is referred to as a (Lévy) symmetric alpha-stable distribution , often abbreviated SαS .

When α α < 1 {\displaystyle \alpha <1} and β β = 1 {\displaystyle \beta =1} , the distribution is supported on [ μ , ∞).

The parameter c > 0 is a scale factor which is a measure of the width of the distribution while α α {\displaystyle \alpha } is the exponent or index of the distribution and specifies the asymptotic behavior of the distribution.

Parametrizations [ edit ] The parametrization of stable distributions is not unique. Nolan [ 10 ] tabulates 11 parametrizations seen in the literature and gives conversion formulas. The two most commonly used parametrizations are the one above (Nolan's "1") and the one immediately below (Nolan's "0").

The parametrization above is easiest to use for theoretical work, but its probability density is not continuous in the parameters at α α = 1 {\displaystyle \alpha =1} .

[ 11 ] A continuous parametrization, better for numerical work,  is [ 7 ] φ φ ( t ; α α , β β , γ γ , δ δ ) = exp ⁡ ⁡ ( i t δ δ − − | γ γ t | α α ( 1 − − i β β sgn ⁡ ⁡ ( t ) Φ Φ ) ) {\displaystyle \varphi (t;\alpha ,\beta ,\gamma ,\delta )=\exp \left(it\delta -|\gamma t|^{\alpha }\left(1-i\beta \operatorname {sgn}(t)\Phi \right)\right)} where: Φ Φ = { ( 1 − − | γ γ t | 1 − − α α ) tan ⁡ ⁡ ( π π α α 2 ) α α ≠ ≠ 1 − − 2 π π log ⁡ ⁡ | γ γ t | α α = 1 {\displaystyle \Phi ={\begin{cases}\left(1-|\gamma t|^{1-\alpha }\right)\tan \left({\tfrac {\pi \alpha }{2}}\right)&\alpha \neq 1\\[1ex]-{\frac {2}{\pi }}\log |\gamma t|&\alpha =1\end{cases}}} The ranges of α α {\displaystyle \alpha } and β β {\displaystyle \beta } are the same as before, γ (like c ) should be positive, and δ (like μ ) should be real.

In either parametrization one can make a linear transformation of the random variable to get a random variable whose density is f ( y ; α α , β β , 1 , 0 ) {\displaystyle f(y;\alpha ,\beta ,1,0)} .

In the first parametrization, this is done by defining the new variable: y = { x − − μ μ γ γ α α ≠ ≠ 1 x − − μ μ γ γ − − β β 2 π π ln ⁡ ⁡ γ γ α α = 1 {\displaystyle y={\begin{cases}{\frac {x-\mu }{\gamma }}&\alpha \neq 1\\[1ex]{\frac {x-\mu }{\gamma }}-\beta {\frac {2}{\pi }}\ln \gamma &\alpha =1\end{cases}}} For the second parametrization, simply use y = x − − δ δ γ γ {\displaystyle y={\frac {x-\delta }{\gamma }}} independent of α α {\displaystyle \alpha } . In the first parametrization, if the mean exists (that is, α α > 1 {\displaystyle \alpha >1} ) then it is equal to μ , whereas in the second parametrization when the mean exists it is equal to δ δ − − β β γ γ tan ⁡ ⁡ ( π π α α 2 ) .

{\displaystyle \delta -\beta \gamma \tan \left({\tfrac {\pi \alpha }{2}}\right).} The distribution [ edit ] A stable distribution is therefore specified by the above four parameters. It can be shown that any non-degenerate stable distribution has a smooth (infinitely differentiable) density function.

[ 7 ] If f ( x ; α α , β β , c , μ μ ) {\displaystyle f(x;\alpha ,\beta ,c,\mu )} denotes the density of X and Y is the sum of independent copies of X : Y = ∑ ∑ i = 1 N k i ( X i − − μ μ ) {\displaystyle Y=\sum _{i=1}^{N}k_{i}(X_{i}-\mu )} then Y has the density 1 s f ( y / s ; α α , β β , c , 0 ) {\displaystyle {\tfrac {1}{s}}f(y/s;\alpha ,\beta ,c,0)} with s = ( ∑ ∑ i = 1 N | k i | α α ) 1 α α {\displaystyle s=\left(\sum _{i=1}^{N}|k_{i}|^{\alpha }\right)^{\frac {1}{\alpha }}} The asymptotic behavior is described, for α α < 2 {\displaystyle \alpha <2} , by: [ 7 ] f ( x ) ∼ ∼ 1 | x | 1 + α α ( c α α ( 1 + sgn ⁡ ⁡ ( x ) β β ) sin ⁡ ⁡ ( π π α α 2 ) Γ Γ ( α α + 1 ) π π ) {\displaystyle f(x)\sim {\frac {1}{|x|^{1+\alpha }}}\left(c^{\alpha }(1+\operatorname {sgn}(x)\beta )\sin \left({\frac {\pi \alpha }{2}}\right){\frac {\Gamma (\alpha +1)}{\pi }}\right)} where Γ is the Gamma function (except that when α α ≥ ≥ 1 {\displaystyle \alpha \geq 1} and β β = ± ± 1 {\displaystyle \beta =\pm 1} , the tail does not vanish to the left or right, resp., of μ , although the above expression is 0). This " heavy tail " behavior causes the variance of stable distributions to be infinite for all α α < 2 {\displaystyle \alpha <2} . This property is illustrated in the log–log plots below.

When α α = 2 {\displaystyle \alpha =2} , the distribution is Gaussian (see below), with tails asymptotic to exp(− x 2 /4 c 2 )/(2 c √ π ).

One-sided stable distribution and stable count distribution [ edit ] When α α < 1 {\displaystyle \alpha <1} and β β = 1 {\displaystyle \beta =1} , the distribution is supported on [ μ , ∞). This family is called one-sided stable distribution .

[ 12 ] Its standard distribution ( μ = 0) is defined as L α α ( x ) = f ( x ; α α , 1 , cos ⁡ ⁡ ( α α π π 2 ) 1 / α α , 0 ) , {\displaystyle L_{\alpha }(x)=f\left(x;\alpha ,1,\cos \left({\frac {\alpha \pi }{2}}\right)^{1/\alpha },0\right),} where α α < 1.

{\displaystyle \alpha <1.} Let q = exp ⁡ ⁡ ( − − i α α π π / 2 ) {\displaystyle q=\exp(-i\alpha \pi /2)} ,  its characteristic function is φ φ ( t ; α α ) = exp ⁡ ⁡ ( − − q | t | α α ) {\displaystyle \varphi (t;\alpha )=\exp \left(-q|t|^{\alpha }\right)} . Thus the integral form of its PDF is (note: Im ⁡ ⁡ ( q ) < 0 {\displaystyle \operatorname {Im} (q)<0} ) L α α ( x ) = 1 π π ℜ ℜ [ ∫ ∫ − − ∞ ∞ ∞ ∞ e i t x e − − q | t | α α d t ] = 2 π π ∫ ∫ 0 ∞ ∞ e − − Re ⁡ ⁡ ( q ) t α α sin ⁡ ⁡ ( t x ) sin ⁡ ⁡ ( − − Im ⁡ ⁡ ( q ) t α α ) d t , or = 2 π π ∫ ∫ 0 ∞ ∞ e − − Re ( q ) t α α cos ⁡ ⁡ ( t x ) cos ⁡ ⁡ ( Im ⁡ ⁡ ( q ) t α α ) d t .

{\displaystyle {\begin{aligned}L_{\alpha }(x)&={\frac {1}{\pi }}\Re \left[\int _{-\infty }^{\infty }e^{itx}e^{-q|t|^{\alpha }}\,dt\right]\\[1ex]&={\frac {2}{\pi }}\int _{0}^{\infty }e^{-\operatorname {Re} (q)\,t^{\alpha }}\sin(tx)\sin(-\operatorname {Im} (q)\,t^{\alpha })\,dt,{\text{ or }}\\[1ex]&={\frac {2}{\pi }}\int _{0}^{\infty }e^{-{\text{Re}}(q)\,t^{\alpha }}\cos(tx)\cos(\operatorname {Im} (q)\,t^{\alpha })\,dt.\end{aligned}}} The double-sine integral is more effective for very small x {\displaystyle x} .

Consider the Lévy sum Y = ∑ ∑ i = 1 N X i {\textstyle Y=\sum _{i=1}^{N}X_{i}} where X i ∼ ∼ L α α ( x ) {\textstyle X_{i}\sim L_{\alpha }(x)} , then Y has the density 1 ν ν L α α ( x ν ν ) {\textstyle {\frac {1}{\nu }}L_{\alpha }\left({\frac {x}{\nu }}\right)} where ν ν = N 1 / α α {\textstyle \nu =N^{1/\alpha }} . Set x = 1 {\textstyle x=1} to arrive at the stable count distribution .

[ 13 ] Its standard distribution is defined as N α α ( ν ν ) = α α Γ Γ ( 1 α α ) 1 ν ν L α α ( 1 ν ν ) , where ν ν > 0 and α α < 1.

{\displaystyle {\mathfrak {N}}_{\alpha }(\nu )={\frac {\alpha }{\Gamma \left({\frac {1}{\alpha }}\right)}}{\frac {1}{\nu }}L_{\alpha }\left({\frac {1}{\nu }}\right),{\text{ where }}\nu >0{\text{ and }}\alpha <1.} The stable count distribution is the conjugate prior of the one-sided stable distribution. Its location-scale family is defined as N α α ( ν ν ; ν ν 0 , θ θ ) = α α Γ Γ ( 1 α α ) 1 ν ν − − ν ν 0 L α α ( θ θ ν ν − − ν ν 0 ) , where ν ν > ν ν 0 , θ θ > 0 , and α α < 1.

{\displaystyle {\mathfrak {N}}_{\alpha }(\nu ;\nu _{0},\theta )={\frac {\alpha }{\Gamma ({\frac {1}{\alpha }})}}{\frac {1}{\nu -\nu _{0}}}L_{\alpha }\left({\frac {\theta }{\nu -\nu _{0}}}\right),{\text{ where }}\nu >\nu _{0},\;\theta >0,{\text{ and }}\alpha <1.} It is also a one-sided distribution supported on [ ν ν 0 , ∞ ∞ ) {\displaystyle [\nu _{0},\infty )} . The location parameter ν ν 0 {\displaystyle \nu _{0}} is the cut-off location, while θ θ {\displaystyle \theta } defines its scale.

When α α = 1 2 {\textstyle \alpha ={\frac {1}{2}}} , L 1 2 ( x ) {\textstyle L_{\frac {1}{2}}(x)} is the Lévy distribution which is an inverse gamma distribution. Thus N 1 2 ( ν ν ; ν ν 0 , θ θ ) {\displaystyle {\mathfrak {N}}_{\frac {1}{2}}(\nu ;\nu _{0},\theta )} is a shifted gamma distribution of shape 3/2 and scale 4 θ θ {\displaystyle 4\theta } , N 1 2 ( ν ν ; ν ν 0 , θ θ ) = 1 4 π π θ θ 3 / 2 ( ν ν − − ν ν 0 ) 1 / 2 e − − ν ν − − ν ν 0 4 θ θ , where ν ν > ν ν 0 , θ θ > 0.

{\displaystyle {\mathfrak {N}}_{\frac {1}{2}}(\nu ;\nu _{0},\theta )={\frac {1}{4{\sqrt {\pi }}\theta ^{3/2}}}(\nu -\nu _{0})^{1/2}e^{-{\frac {\nu -\nu _{0}}{4\theta }}},{\text{ where }}\nu >\nu _{0},\qquad \theta >0.} Its mean is ν ν 0 + 6 θ θ {\displaystyle \nu _{0}+6\theta } and its standard deviation is 24 θ θ {\displaystyle {\sqrt {24}}\theta } . It is hypothesized that VIX is distributed like N 1 2 ( ν ν ; ν ν 0 , θ θ ) {\textstyle {\mathfrak {N}}_{\frac {1}{2}}(\nu ;\nu _{0},\theta )} with ν ν 0 = 10.4 {\displaystyle \nu _{0}=10.4} and θ θ = 1.6 {\displaystyle \theta =1.6} (See Section 7 of [ 13 ] ). Thus the stable count distribution is the first-order marginal distribution of a volatility process. In this context, ν ν 0 {\displaystyle \nu _{0}} is called the "floor volatility".

Another approach to derive the stable count distribution is to use the Laplace transform of the one-sided stable distribution, (Section 2.4 of [ 13 ] ) ∫ ∫ 0 ∞ ∞ e − − z x L α α ( x ) d x = e − − z α α , where > α α < 1.

{\displaystyle \int _{0}^{\infty }e^{-zx}L_{\alpha }(x)dx=e^{-z^{\alpha }},{\text{ where }}>\alpha <1.} Let x = 1 / ν ν {\displaystyle x=1/\nu } , and one can decompose the integral on the left hand side as a product distribution of a standard Laplace distribution and a standard stable count distribution, ∫ ∫ 0 ∞ ∞ 1 ν ν ( 1 2 e − − | z | ν ν ) ( α α Γ Γ ( 1 α α ) 1 ν ν L α α ( 1 ν ν ) ) d ν ν = 1 2 α α Γ Γ ( 1 α α ) e − − | z | α α , where α α < 1.

{\displaystyle \int _{0}^{\infty }{\frac {1}{\nu }}\left({\frac {1}{2}}e^{-{\frac {|z|}{\nu }}}\right)\left({\frac {\alpha }{\Gamma ({\frac {1}{\alpha }})}}{\frac {1}{\nu }}L_{\alpha }\left({\frac {1}{\nu }}\right)\right)\,d\nu ={\frac {1}{2}}{\frac {\alpha }{\Gamma ({\frac {1}{\alpha }})}}e^{-|z|^{\alpha }},{\text{ where }}\alpha <1.} This is called the "lambda decomposition" (See Section 4 of [ 13 ] ) since the right hand side was named as "symmetric lambda distribution" in Lihn's former works. However, it has several more popular names such as " exponential power distribution ", or the "generalized error/normal distribution", often referred to when α α > 1 {\displaystyle \alpha >1} .

The n-th moment of N α α ( ν ν ) {\displaystyle {\mathfrak {N}}_{\alpha }(\nu )} is the − − ( n + 1 ) {\displaystyle -(n+1)} -th moment of L α α ( x ) {\displaystyle L_{\alpha }(x)} , and all positive moments are finite.

Properties [ edit ] Stable distributions are infinitely divisible .

Stable distributions are leptokurtotic and heavy-tailed distributions , with the exception of the normal distribution ( α α = 2 {\displaystyle \alpha =2} ).

Stable distributions are closed under convolution .

Stable distributions are closed under convolution for a fixed value of α α {\displaystyle \alpha } . Since convolution is equivalent to multiplication of the Fourier-transformed function, it follows that the product of two stable characteristic functions with the same α α {\displaystyle \alpha } will yield another such characteristic function. The product of two stable characteristic functions is given by: exp ⁡ ⁡ [ i t ( μ μ 1 + μ μ 2 ) − − | c 1 t | α α − − | c 2 t | α α + i ( β β 1 | c 1 t | α α + β β 2 | c 2 t | α α ) sgn ⁡ ⁡ ( t ) Φ Φ ] {\displaystyle \exp \left[it\left(\mu _{1}+\mu _{2}\right)-|c_{1}t|^{\alpha }-|c_{2}t|^{\alpha }+i\left(\beta _{1}|c_{1}t|^{\alpha }+\beta _{2}|c_{2}t|^{\alpha }\right)\operatorname {sgn}(t)\Phi \right]} Since Φ is not a function of the μ , c or β β {\displaystyle \beta } variables it follows that these parameters for the convolved function are given by: μ μ = μ μ 1 + μ μ 2 c = ( c 1 α α + c 2 α α ) 1 α α β β = β β 1 c 1 α α + β β 2 c 2 α α c 1 α α + c 2 α α {\displaystyle {\begin{aligned}\mu &=\mu _{1}+\mu _{2}\\c&=\left(c_{1}^{\alpha }+c_{2}^{\alpha }\right)^{\frac {1}{\alpha }}\\[6pt]\beta &={\frac {\beta _{1}c_{1}^{\alpha }+\beta _{2}c_{2}^{\alpha }}{c_{1}^{\alpha }+c_{2}^{\alpha }}}\end{aligned}}} In each case, it can be shown that the resulting parameters lie within the required intervals for a stable distribution.

The Generalized Central Limit Theorem [ edit ] The Generalized Central Limit Theorem (GCLT) was an effort of multiple mathematicians ( Berstein , Lindeberg , Lévy , Feller , Kolmogorov , and others) over the period from 1920 to 1937.

[ 14 ] The first published complete proof (in French) of the GCLT was in 1937 by Paul Lévy .

[ 15 ] An English language version of the complete proof of the GCLT is available in the translation of Gnedenko and Kolmogorov 's 1954 book.

[ 16 ] The statement of the GCLT is as follows: [ 10 ] Generalized Central Limit Theorem — A non-degenerate random variable Z is α-stable for some 0 < α ≤ 2 if and only if there is an independent, identically distributed sequence of random variables X 1 , X 2 , X 3 , ...

and constants a n > 0, b n ∈ ℝ with a n ( X 1 + ... + X n ) − b n → Z.

Here → means the sequence of random variable sums converges in distribution; i.e., the corresponding distributions satisfy F n ( y ) → F ( y ) at all continuity points of F.

In other words, if sums of independent, identically distributed random variables converge in distribution to some Z , then Z must be a stable distribution.

Special cases [ edit ] Log-log plot of symmetric centered stable distribution PDFs showing the power law behavior for large x . The power law behavior is evidenced by the straight-line appearance of the PDF for large x , with the slope equal to − − ( α α + 1 ) {\displaystyle -(\alpha +1)} . (The only exception is for α α = 2 {\displaystyle \alpha =2} , in black, which is a normal distribution.) Log-log plot of skewed centered stable distribution PDFs showing the power law behavior for large x . Again the slope of the linear portions is equal to − − ( α α + 1 ) {\displaystyle -(\alpha +1)} There is no general analytic solution for the form of f ( x ). There are, however, three special cases which can be expressed in terms of elementary functions as can be seen by inspection of the characteristic function : [ 7 ] [ 9 ] [ 17 ] For α α = 2 {\displaystyle \alpha =2} the distribution reduces to a Gaussian distribution with variance σ 2 = 2 c 2 and mean μ ; the skewness parameter β β {\displaystyle \beta } has no effect.

For α α = 1 {\displaystyle \alpha =1} and β β = 0 {\displaystyle \beta =0} the distribution reduces to a Cauchy distribution with scale parameter c and shift parameter μ .

For α α = 1 / 2 {\displaystyle \alpha =1/2} and β β = 1 {\displaystyle \beta =1} the distribution reduces to a Lévy distribution with scale parameter c and shift parameter μ .

Note that the above three distributions are also connected, in the following way: A standard Cauchy random variable can be viewed as a mixture of Gaussian random variables (all with mean zero), with the variance being drawn from a standard Lévy distribution. And in fact this is a special case of a more general theorem (See p. 59 of [ 18 ] ) which allows any symmetric alpha-stable distribution to be viewed in this way (with the alpha parameter of the mixture distribution equal to twice the alpha parameter of the mixing distribution—and the beta parameter of the mixing distribution always equal to one).

A general closed form expression for stable PDFs with rational values of α α {\displaystyle \alpha } is available in terms of Meijer G-functions .

[ 19 ] Fox H-Functions can also be used to express the stable probability density functions. For simple rational numbers, the closed form expression is often in terms of less complicated special functions . Several closed form expressions having rather simple expressions in terms of special functions are available. In the table below, PDFs expressible by elementary functions are indicated by an E and those that are expressible by special functions are indicated by an s .

[ 18 ] α α {\displaystyle \alpha } 1/3 1/2 2/3 1 4/3 3/2 2 β β {\displaystyle \beta } 0 s s s E s s E 1 s E s L s Some of the special cases are known by particular names: For α α = 1 {\displaystyle \alpha =1} and β β = 1 {\displaystyle \beta =1} , the distribution is a Landau distribution ( L ) which has a specific usage in physics under this name.

For α α = 3 / 2 {\displaystyle \alpha =3/2} and β β = 0 {\displaystyle \beta =0} the distribution reduces to a Holtsmark distribution with scale parameter c and shift parameter μ .

Also, in the limit as c approaches zero or as α approaches zero the distribution will approach a Dirac delta function δ ( x − μ ) .

Series representation [ edit ] The stable distribution can be restated as the real part of a simpler integral: [ 20 ] f ( x ; α α , β β , c , μ μ ) = 1 π π ℜ ℜ [ ∫ ∫ 0 ∞ ∞ e i t ( x − − μ μ ) e − − ( c t ) α α ( 1 − − i β β Φ Φ ) d t ] .

{\displaystyle f(x;\alpha ,\beta ,c,\mu )={\frac {1}{\pi }}\Re \left[\int _{0}^{\infty }e^{it(x-\mu )}e^{-(ct)^{\alpha }(1-i\beta \Phi )}\,dt\right].} Expressing the second exponential as a Taylor series , this leads to: f ( x ; α α , β β , c , μ μ ) = 1 π π ℜ ℜ [ ∫ ∫ 0 ∞ ∞ e i t ( x − − μ μ ) ∑ ∑ n = 0 ∞ ∞ ( − − q t α α ) n n !

d t ] {\displaystyle f(x;\alpha ,\beta ,c,\mu )={\frac {1}{\pi }}\Re \left[\int _{0}^{\infty }e^{it(x-\mu )}\sum _{n=0}^{\infty }{\frac {(-qt^{\alpha })^{n}}{n!}}\,dt\right]} where q = c α α ( 1 − − i β β Φ Φ ) {\displaystyle q=c^{\alpha }(1-i\beta \Phi )} . Reversing the order of integration and summation, and carrying out the integration yields: f ( x ; α α , β β , c , μ μ ) = 1 π π ℜ ℜ [ ∑ ∑ n = 1 ∞ ∞ ( − − q ) n n !

( i x − − μ μ ) α α n + 1 Γ Γ ( α α n + 1 ) ] {\displaystyle f(x;\alpha ,\beta ,c,\mu )={\frac {1}{\pi }}\Re \left[\sum _{n=1}^{\infty }{\frac {(-q)^{n}}{n!}}\left({\frac {i}{x-\mu }}\right)^{\alpha n+1}\Gamma (\alpha n+1)\right]} which will be valid for x ≠ μ and will converge for appropriate values of the parameters. (Note that the n = 0 term which yields a delta function in x − μ has therefore been dropped.) Expressing the first exponential as a series will yield another series in positive powers of x − μ which is generally less useful.

For one-sided stable distribution, the above series expansion needs to be modified, since q = exp ⁡ ⁡ ( − − i α α π π / 2 ) {\displaystyle q=\exp(-i\alpha \pi /2)} and q i α α = 1 {\displaystyle qi^{\alpha }=1} . There is no real part to sum. Instead, the integral of the characteristic function should be carried out on the negative axis, which yields: [ 21 ] [ 12 ] L α α ( x ) = 1 π π ℜ ℜ [ ∑ ∑ n = 1 ∞ ∞ ( − − q ) n n !

( − − i x ) α α n + 1 Γ Γ ( α α n + 1 ) ] = 1 π π ∑ ∑ n = 1 ∞ ∞ − − sin ⁡ ⁡ ( n ( α α + 1 ) π π ) n !

( 1 x ) α α n + 1 Γ Γ ( α α n + 1 ) {\displaystyle {\begin{aligned}L_{\alpha }(x)&={\frac {1}{\pi }}\Re \left[\sum _{n=1}^{\infty }{\frac {(-q)^{n}}{n!}}\left({\frac {-i}{x}}\right)^{\alpha n+1}\Gamma (\alpha n+1)\right]\\[1ex]&={\frac {1}{\pi }}\sum _{n=1}^{\infty }{\frac {-\sin(n(\alpha +1)\pi )}{n!}}\left({\frac {1}{x}}\right)^{\alpha n+1}\Gamma (\alpha n+1)\end{aligned}}} Parameter estimation [ edit ] In addition to the existing tests for normality and subsequent parameter estimation , a general method which relies on the quantiles was developed by McCulloch and works for both symmetric and skew stable distributions and stability parameter 0.5 < α α ≤ ≤ 2 {\displaystyle 0.5<\alpha \leq 2} .

[ 22 ] Simulation of stable variates [ edit ] There are no analytic expressions for the inverse F − − 1 ( x ) {\displaystyle F^{-1}(x)} nor the CDF F ( x ) {\displaystyle F(x)} itself, so the inversion method cannot be used to generate stable-distributed variates.

[ 11 ] [ 13 ] Other standard approaches like the rejection method would require tedious computations. An elegant and efficient solution was proposed by Chambers, Mallows and Stuck (CMS), [ 23 ] who noticed that a certain integral formula [ 24 ] yielded the following algorithm: [ 25 ] generate a random variable U {\displaystyle U} uniformly distributed on ( − − π π 2 , π π 2 ) {\displaystyle \left(-{\tfrac {\pi }{2}},{\tfrac {\pi }{2}}\right)} and an independent exponential random variable W {\displaystyle W} with mean 1; for α α ≠ ≠ 1 {\displaystyle \alpha \neq 1} compute: X = ( 1 + ζ ζ 2 ) 1 2 α α sin ⁡ ⁡ ( α α ( U + ξ ξ ) ) ( cos ⁡ ⁡ ( U ) ) 1 α α ( cos ⁡ ⁡ ( U − − α α ( U + ξ ξ ) ) W ) 1 − − α α α α , {\displaystyle X=\left(1+\zeta ^{2}\right)^{\frac {1}{2\alpha }}{\frac {\sin(\alpha (U+\xi ))}{(\cos(U))^{\frac {1}{\alpha }}}}\left({\frac {\cos(U-\alpha (U+\xi ))}{W}}\right)^{\frac {1-\alpha }{\alpha }},} for α α = 1 {\displaystyle \alpha =1} compute: X = 1 ξ ξ { ( π π 2 + β β U ) tan ⁡ ⁡ U − − β β log ⁡ ⁡ ( π π 2 W cos ⁡ ⁡ U π π 2 + β β U ) } , {\displaystyle X={\frac {1}{\xi }}\left\{\left({\frac {\pi }{2}}+\beta U\right)\tan U-\beta \log \left({\frac {{\frac {\pi }{2}}W\cos U}{{\frac {\pi }{2}}+\beta U}}\right)\right\},} where ζ ζ = − − β β tan ⁡ ⁡ π π α α 2 , ξ ξ = { 1 α α arctan ⁡ ⁡ ( − − ζ ζ ) α α ≠ ≠ 1 π π 2 α α = 1 {\displaystyle \zeta =-\beta \tan {\frac {\pi \alpha }{2}},\qquad \xi ={\begin{cases}{\frac {1}{\alpha }}\arctan(-\zeta )&\alpha \neq 1\\{\frac {\pi }{2}}&\alpha =1\end{cases}}} This algorithm yields a random variable X ∼ ∼ S α α ( β β , 1 , 0 ) {\displaystyle X\sim S_{\alpha }(\beta ,1,0)} . For a detailed proof see.

[ 26 ] To simulate a stable random variable for all admissible values of the parameters α α {\displaystyle \alpha } , c {\displaystyle c} , β β {\displaystyle \beta } and μ μ {\displaystyle \mu } use the following property: If X ∼ ∼ S α α ( β β , 1 , 0 ) {\displaystyle X\sim S_{\alpha }(\beta ,1,0)} then Y = { c X + μ μ α α ≠ ≠ 1 c X + 2 π π β β c log ⁡ ⁡ c + μ μ α α = 1 {\displaystyle Y={\begin{cases}cX+\mu &\alpha \neq 1\\cX+{\frac {2}{\pi }}\beta c\log c+\mu &\alpha =1\end{cases}}} is S α α ( β β , c , μ μ ) {\displaystyle S_{\alpha }(\beta ,c,\mu )} . For α α = 2 {\displaystyle \alpha =2} (and β β = 0 {\displaystyle \beta =0} ) the CMS method reduces to the well known Box-Muller transform for generating Gaussian random variables.

[ 27 ] While other approaches have been proposed in the literature, including application of Bergström [ 28 ] and LePage [ 29 ] series expansions, the CMS method is regarded as the fastest and the most accurate.

Applications [ edit ] Stable distributions owe their importance in both theory and practice to the generalization of the central limit theorem to random variables without second (and possibly first) order moments and the accompanying self-similarity of the stable family. It was the seeming departure from normality along with the demand for a self-similar model for financial data (i.e. the shape of the distribution for yearly asset price changes should resemble that of the constituent daily or monthly price changes) that led Benoît Mandelbrot to propose that cotton prices follow an alpha-stable distribution with α α {\displaystyle \alpha } equal to 1.7.

[ 6 ] Lévy distributions are frequently found in analysis of critical behavior and financial data.

[ 9 ] [ 30 ] They are also found in spectroscopy as a general expression for a quasistatically pressure broadened spectral line .

[ 20 ] The Lévy distribution of solar flare waiting time events (time between flare events) was demonstrated for CGRO BATSE hard x-ray solar flares in December 2001. Analysis of the Lévy statistical signature revealed that two different memory signatures were evident; one related to the solar cycle and the second whose origin appears to be associated with a localized or combination of localized solar active region effects.

[ 31 ] Other analytic cases [ edit ] A number of cases of analytically expressible stable distributions are known. Let the stable distribution be expressed by f ( x ; α α , β β , c , μ μ ) {\displaystyle f(x;\alpha ,\beta ,c,\mu )} , then: The Cauchy Distribution is given by f ( x ; 1 , 0 , 1 , 0 ) .

{\displaystyle f(x;1,0,1,0).} The Lévy distribution is given by f ( x ; 1 2 , 1 , 1 , 0 ) .

{\displaystyle f(x;{\tfrac {1}{2}},1,1,0).} The Normal distribution is given by f ( x ; 2 , 0 , 1 , 0 ) .

{\displaystyle f(x;2,0,1,0).} Let S μ μ , ν ν ( z ) {\displaystyle S_{\mu ,\nu }(z)} be a Lommel function , then: [ 32 ] f ( x ; 1 3 , 0 , 1 , 0 ) = ℜ ℜ ( 2 e − − i π π 4 3 3 π π 1 x 3 S 0 , 1 3 ( 2 e i π π 4 3 3 1 x ) ) {\displaystyle f{\left(x;{\tfrac {1}{3}},0,1,0\right)}=\Re \left({\frac {2e^{-{\frac {i\pi }{4}}}}{3{\sqrt {3}}\pi }}{\frac {1}{\sqrt {x^{3}}}}S_{0,{\frac {1}{3}}}{\left({\frac {2e^{\frac {i\pi }{4}}}{3{\sqrt {3}}}}{\frac {1}{\sqrt {x}}}\right)}\right)} Let S ( x ) {\displaystyle S(x)} and C ( x ) {\displaystyle C(x)} denote the Fresnel integrals , then: [ 33 ] f ( x ; 1 2 , 0 , 1 , 0 ) = ( 1 2 π π | x | 3 ) 1 / 2 ( sin ⁡ ⁡ ( 1 4 | x | ) [ 1 2 − − S ( 1 2 π π | x | ) ] + cos ⁡ ⁡ ( 1 4 | x | ) [ 1 2 − − C ( 1 2 π π | x | ) ] ) {\displaystyle f{\left(x;{\tfrac {1}{2}},0,1,0\right)}=\left({\tfrac {1}{2\pi \left|x\right|^{3}}}\right)^{1/2}\left(\sin \left({\tfrac {1}{4|x|}}\right)\left[{\tfrac {1}{2}}-S{\left({\tfrac {1}{\sqrt {2\pi |x|}}}\right)}\right]+\cos \left({\tfrac {1}{4|x|}}\right)\left[{\tfrac {1}{2}}-C{\left({\tfrac {1}{\sqrt {2\pi |x|}}}\right)}\right]\right)} Let K v ( x ) {\displaystyle K_{v}(x)} be the modified Bessel function of the second kind, then: [ 33 ] f ( x ; 1 3 , 1 , 1 , 0 ) = 2 5 2 3 7 4 π π 1 x 3 K 1 3 ( 2 5 2 3 9 4 1 x ) {\displaystyle f{\left(x;{\tfrac {1}{3}},1,1,0\right)}={\frac {2^{\frac {5}{2}}}{3^{\frac {7}{4}}\pi }}{\frac {1}{\sqrt {x^{3}}}}K_{\frac {1}{3}}{\left({\frac {2^{\frac {5}{2}}}{3^{\frac {9}{4}}}}{\frac {1}{\sqrt {x}}}\right)}} Let m F n {\displaystyle {}_{m}F_{n}} denote the hypergeometric functions , then: [ 32 ] f ( x ; 4 3 , 0 , 1 , 0 ) = 3 5 4 2 5 2 π π 1 2 Γ Γ ( 7 12 ) Γ Γ ( 11 12 ) Γ Γ ( 6 12 ) Γ Γ ( 8 12 ) 2 F 2 ( 7 12 , 11 12 ; 6 12 , 8 12 ; 3 3 x 4 4 4 ) − − 3 11 4 x 3 2 13 2 π π 1 2 Γ Γ ( 13 12 ) Γ Γ ( 17 12 ) Γ Γ ( 18 12 ) Γ Γ ( 15 12 ) 2 F 2 ( 13 12 , 17 12 ; 18 12 , 15 12 ; 3 3 x 4 4 4 ) {\displaystyle {\begin{aligned}f{\left(x;{\tfrac {4}{3}},0,1,0\right)}&={\frac {3^{\frac {5}{4}}}{2^{\frac {5}{2}}\pi ^{\frac {1}{2}}}}{\frac {\Gamma {\left({\tfrac {7}{12}}\right)}\,\Gamma {\left({\tfrac {11}{12}}\right)}}{\Gamma {\left({\tfrac {6}{12}}\right)}\,\Gamma {\left({\tfrac {8}{12}}\right)}}}\;{}_{2}F_{2}{\left({\tfrac {7}{12}},{\tfrac {11}{12}};{\tfrac {6}{12}},{\tfrac {8}{12}};{\tfrac {3^{3}x^{4}}{4^{4}}}\right)}\\[2pt]&\quad -{\frac {3^{\frac {11}{4}}x^{3}}{2^{\frac {13}{2}}\pi ^{\frac {1}{2}}}}{\frac {\Gamma {\left({\tfrac {13}{12}}\right)}\,\Gamma {\left({\tfrac {17}{12}}\right)}}{\Gamma {\left({\tfrac {18}{12}}\right)}\,\Gamma {\left({\tfrac {15}{12}}\right)}}}\;{}_{2}F_{2}{\left({\tfrac {13}{12}},{\tfrac {17}{12}};{\tfrac {18}{12}},{\tfrac {15}{12}};{\tfrac {3^{3}x^{4}}{4^{4}}}\right)}\end{aligned}}} f ( x ; 3 2 , 0 , 1 , 0 ) = Γ Γ ( 5 3 ) π π 2 F 3 ( 5 12 , 11 12 ; 1 3 , 1 2 , 5 6 ; − − 2 2 x 6 3 6 ) − − x 2 3 π π 3 F 4 ( 3 4 , 1 , 5 4 ; 2 3 , 5 6 , 7 6 , 4 3 ; − − 2 2 x 6 3 6 ) + 7 x 4 Γ Γ ( 4 3 ) 3 4 π π 2 2 F 3 ( 13 12 , 19 12 ; 7 6 , 3 2 , 5 3 ; − − 2 2 x 6 3 6 ) {\displaystyle {\begin{aligned}f{\left(x;{\tfrac {3}{2}},0,1,0\right)}&={\frac {\Gamma {\left({\tfrac {5}{3}}\right)}}{\pi }}{}_{2}F_{3}{\left({\tfrac {5}{12}},{\tfrac {11}{12}};{\tfrac {1}{3}},{\tfrac {1}{2}},{\tfrac {5}{6}};-{\tfrac {2^{2}x^{6}}{3^{6}}}\right)}\\[2pt]&\quad -{\frac {x^{2}}{3\pi }}\,{}_{3}F_{4}{\left({\tfrac {3}{4}},1,{\tfrac {5}{4}};{\tfrac {2}{3}},{\tfrac {5}{6}},{\tfrac {7}{6}},{\tfrac {4}{3}};-{\tfrac {2^{2}x^{6}}{3^{6}}}\right)}\\[2pt]&\quad +{\frac {7x^{4}\Gamma {\left({\tfrac {4}{3}}\right)}}{3^{4}\pi ^{2}}}{}_{2}F_{3}{\left({\tfrac {13}{12}},{\tfrac {19}{12}};{\tfrac {7}{6}},{\tfrac {3}{2}},{\tfrac {5}{3}};-{\tfrac {2^{2}x^{6}}{3^{6}}}\right)}\end{aligned}}} with the latter being the Holtsmark distribution .

Let W k , μ μ ( z ) {\displaystyle W_{k,\mu }(z)} be a Whittaker function , then: [ 34 ] [ 35 ] [ 36 ] f ( x ; 2 3 , 0 , 1 , 0 ) = 3 6 π π | x | exp ⁡ ⁡ ( 2 27 x − − 2 ) W − − 1 2 , 1 6 ( 4 27 x − − 2 ) f ( x ; 2 3 , 1 , 1 , 0 ) = 3 π π | x | exp ⁡ ⁡ ( − − 16 27 x − − 2 ) W 1 2 , 1 6 ( 32 27 x − − 2 ) f ( x ; 3 2 , 1 , 1 , 0 ) = { 3 π π | x | exp ⁡ ⁡ ( 1 27 x 3 ) W 1 2 , 1 6 ( − − 2 27 x 3 ) x < 0 3 6 π π | x | exp ⁡ ⁡ ( 1 27 x 3 ) W − − 1 2 , 1 6 ( 2 27 x 3 ) x ≥ ≥ 0 {\displaystyle {\begin{aligned}f\left(x;{\tfrac {2}{3}},0,1,0\right)&={\frac {\sqrt {3}}{6{\sqrt {\pi }}|x|}}\exp \left({\tfrac {2}{27}}x^{-2}\right)W_{-{\frac {1}{2}},{\frac {1}{6}}}\left({\tfrac {4}{27}}x^{-2}\right)\\[8pt]f\left(x;{\tfrac {2}{3}},1,1,0\right)&={\frac {\sqrt {3}}{{\sqrt {\pi }}|x|}}\exp \left(-{\tfrac {16}{27}}x^{-2}\right)W_{{\frac {1}{2}},{\frac {1}{6}}}\left({\tfrac {32}{27}}x^{-2}\right)\\[8pt]f\left(x;{\tfrac {3}{2}},1,1,0\right)&={\begin{cases}{\frac {\sqrt {3}}{{\sqrt {\pi }}|x|}}\exp \left({\frac {1}{27}}x^{3}\right)W_{{\frac {1}{2}},{\frac {1}{6}}}\left(-{\frac {2}{27}}x^{3}\right)&x<0\\{}\\{\frac {\sqrt {3}}{6{\sqrt {\pi }}|x|}}\exp \left({\frac {1}{27}}x^{3}\right)W_{-{\frac {1}{2}},{\frac {1}{6}}}\left({\frac {2}{27}}x^{3}\right)&x\geq 0\end{cases}}\end{aligned}}} See also [ edit ] Lévy flight Lévy process Other "power law" distributions Pareto distribution Zeta distribution Zipf distribution Zipf–Mandelbrot distribution Financial models with long-tailed distributions and volatility clustering Multivariate stable distribution Discrete-stable distribution Software implementations [ edit ] The STABLE program for Windows is available from John Nolan's stable webpage: http://www.robustanalysis.com/public/stable.html . It calculates the density (pdf), cumulative distribution function (cdf) and quantiles for a general stable distribution, and performs maximum likelihood estimation of stable parameters and some exploratory data analysis techniques for assessing the fit of a data set.

The GNU Scientific Library which is written in C has a package randist , which includes among the Gaussian and Cauchy distributions also an implementation of the Levy alpha-stable distribution, both with and without a skew parameter.

libstable is a C implementation for the Stable distribution pdf, cdf, random number, quantile and fitting functions (along with a benchmark replication package and an R package).

R Package 'stabledist' by Diethelm Wuertz, Martin Maechler and Rmetrics core team members.  Computes stable density, probability, quantiles, and random numbers.

Python implementation is located in scipy.stats.levy_stable in the SciPy package.

Julia provides package StableDistributions.jl which has methods of generation, fitting, probability density, cumulative distribution function, characteristic and moment generating functions, quantile and related functions, convolution and affine transformations of stable distributions. It uses modernised algorithms improved by John P. Nolan.

[ 10 ] References [ edit ] ^ a b Mandelbrot, B. (1960). "The Pareto–Lévy Law and the Distribution of Income".

International Economic Review .

1 (2): 79– 106.

doi : 10.2307/2525289 .

JSTOR 2525289 .

^ Lévy, Paul (1925).

Calcul des probabilités . Paris: Gauthier-Villars.

OCLC 1417531 .

^ Mandelbrot, B. (1961). "Stable Paretian Random Functions and the Multiplicative Variation of Income".

Econometrica .

29 (4): 517– 543.

doi : 10.2307/1911802 .

JSTOR 1911802 .

^ Mandelbrot, B. (1963). "The Variation of Certain Speculative Prices".

The Journal of Business .

36 (4): 394– 419.

doi : 10.1086/294632 .

JSTOR 2350970 .

^ Fama, Eugene F. (1963). "Mandelbrot and the Stable Paretian Hypothesis".

The Journal of Business .

36 (4): 420– 429.

doi : 10.1086/294633 .

JSTOR 2350971 .

^ a b Mandelbrot, B. (1963). "New methods in statistical economics".

The Journal of Political Economy .

71 (5): 421– 440.

doi : 10.1086/258792 .

S2CID 53004476 .

^ a b c d e f Nolan, John P.

"Stable Distributions – Models for Heavy Tailed Data" (PDF) . Archived from the original (PDF) on 2011-07-17 . Retrieved 2009-02-21 .

^ Siegrist, Kyle.

"Stable Distributions" .

www.randomservices.org . Retrieved 2018-10-18 .

^ a b c Voit, Johannes (2005). Balian, R; Beiglböck, W; Grosse, H; Thirring, W (eds.).

The Statistical Mechanics of Financial Markets – Springer . Texts and Monographs in Physics. Springer.

doi : 10.1007/b137351 .

ISBN 978-3-540-26285-5 .

^ a b c Nolan, John P. (2020).

Univariate stable distributions, Models for Heavy Tailed Data . Springer Series in Operations Research and Financial Engineering. Switzerland: Springer.

doi : 10.1007/978-3-030-52915-4 .

ISBN 978-3-030-52914-7 .

S2CID 226648987 .

^ a b Nolan, John P. (1997). "Numerical calculation of stable densities and distribution functions".

Communications in Statistics. Stochastic Models .

13 (4): 759– 774.

doi : 10.1080/15326349708807450 .

ISSN 0882-0287 .

^ a b Penson, K. A.; Górska, K. (2010-11-17). "Exact and Explicit Probability Densities for One-Sided Lévy Stable Distributions".

Physical Review Letters .

105 (21): 210604.

arXiv : 1007.0193 .

Bibcode : 2010PhRvL.105u0604P .

doi : 10.1103/PhysRevLett.105.210604 .

PMID 21231282 .

S2CID 27497684 .

^ a b c d e Lihn, Stephen (2017).

"A Theory of Asset Return and Volatility Under Stable Law and Stable Lambda Distribution" .

SSRN .

^ Le Cam, L. (February 1986).

"The Central Limit Theorem around 1935" .

Statistical Science .

1 (1): 78– 91.

JSTOR 2245503 .

^ Lévy, Paul (1937).

Theorie de l'addition des variables aleatoires [Combination theory of unpredictable variables] . Paris: Gauthier-Villars.

^ Gnedenko, Boris Vladimirovich; Kologorov, Andreĭ Nikolaevich; Doob, Joseph L.; Hsu, Pao-Lu (1968).

Limit distributions for sums of independent random variables . Reading, MA: Addison-wesley.

^ Samorodnitsky, G.; Taqqu, M.S. (1994).

Stable Non-Gaussian Random Processes: Stochastic Models with Infinite Variance . CRC Press.

ISBN 9780412051715 .

^ a b Lee, Wai Ha (2010).

Continuous and discrete properties of stochastic processes . PhD thesis, University of Nottingham.

^ Zolotarev, V. (1995). "On Representation of Densities of Stable Laws by Special Functions".

Theory of Probability and Its Applications .

39 (2): 354– 362.

doi : 10.1137/1139025 .

ISSN 0040-585X .

^ a b Peach, G. (1981). "Theory of the pressure broadening and shift of spectral lines".

Advances in Physics .

30 (3): 367– 474.

Bibcode : 1981AdPhy..30..367P .

doi : 10.1080/00018738100101467 .

ISSN 0001-8732 .

^ Pollard, Howard (1946).

"Representation of e^{-x^\lambda} As a Laplace Integral" .

Bull. Amer. Math. Soc .

52 : 908.

doi : 10.1090/S0002-9904-1946-08672-3 .

^ McCulloch, J Huston (1986).

"Simple consistent estimators of stable distribution parameters" (PDF) .

Communications in Statistics. Simulation and Computation .

15 (4): 1109– 1136.

doi : 10.1080/03610918608812563 .

^ Chambers, J. M.; Mallows, C. L.; Stuck, B. W. (1976). "A Method for Simulating Stable Random Variables".

Journal of the American Statistical Association .

71 (354): 340– 344.

doi : 10.1080/01621459.1976.10480344 .

ISSN 0162-1459 .

^ Zolotarev, V. M. (1986).

One-Dimensional Stable Distributions . American Mathematical Society.

ISBN 978-0-8218-4519-6 .

^ Misiorek, Adam; Weron, Rafał (2012). Gentle, James E.; Härdle, Wolfgang Karl; Mori, Yuichi (eds.).

Heavy-Tailed Distributions in VaR Calculations (PDF) . Springer Handbooks of Computational Statistics. Springer Berlin Heidelberg. pp.

1025– 1059.

doi : 10.1007/978-3-642-21551-3_34 .

ISBN 978-3-642-21550-6 .

^ Weron, Rafał (1996). "On the Chambers-Mallows-Stuck method for simulating skewed stable random variables".

Statistics & Probability Letters .

28 (2): 165– 171.

CiteSeerX 10.1.1.46.3280 .

doi : 10.1016/0167-7152(95)00113-1 .

S2CID 9500064 .

^ Janicki, Aleksander; Weron, Aleksander (1994).

Simulation and Chaotic Behavior of Alpha-stable Stochastic Processes . CRC Press.

ISBN 9780824788827 .

^ Mantegna, Rosario Nunzio (1994). "Fast, accurate algorithm for numerical simulation of Lévy stable stochastic processes".

Physical Review E .

49 (5): 4677– 4683.

Bibcode : 1994PhRvE..49.4677M .

doi : 10.1103/PhysRevE.49.4677 .

PMID 9961762 .

^ Janicki, Aleksander; Kokoszka, Piotr (1992). "Computer investigation of the Rate of Convergence of Lepage Type Series to α-Stable Random Variables".

Statistics .

23 (4): 365– 373.

doi : 10.1080/02331889208802383 .

ISSN 0233-1888 .

^ Rachev, Svetlozar T.; Mittnik, Stefan (2000).

Stable Paretian Models in Finance . Wiley.

ISBN 978-0-471-95314-2 .

^ Leddon, D., A statistical Study of Hard X-Ray Solar Flares ^ a b Garoni, T. M.; Frankel, N. E. (2002). "Lévy flights: Exact results and asymptotics beyond all orders".

Journal of Mathematical Physics .

43 (5): 2670– 2689.

Bibcode : 2002JMP....43.2670G .

doi : 10.1063/1.1467095 .

^ a b Hopcraft, K. I.; Jakeman, E.; Tanner, R. M. J. (1999). "Lévy random walks with fluctuating step number and multiscale behavior".

Physical Review E .

60 (5): 5327– 5343.

Bibcode : 1999PhRvE..60.5327H .

doi : 10.1103/physreve.60.5327 .

PMID 11970402 .

^ Uchaikin, V. V.; Zolotarev, V. M. (1999). "Chance And Stability – Stable Distributions And Their Applications".

VSP .

^ Zlotarev, V. M. (1961). "Expression of the density of a stable distribution with exponent alpha greater than one by means of a frequency with exponent 1/alpha".

Selected Translations in Mathematical Statistics and Probability (Translated from the Russian Article: Dokl. Akad. Nauk SSSR. 98, 735–738 (1954)) .

1 : 163– 167.

^ Zaliapin, I. V.; Kagan, Y. Y.; Schoenberg, F. P. (2005).

"Approximating the Distribution of Pareto Sums" .

Pure and Applied Geophysics .

162 (6): 1187– 1228.

Bibcode : 2005PApGe.162.1187Z .

doi : 10.1007/s00024-004-2666-3 .

S2CID 18754585 .

v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons Retrieved from " https://en.wikipedia.org/w/index.php?title=Stable_distribution&oldid=1305995651 " Categories : Continuous distributions Probability distributions with non-finite variance Power laws Stable distributions Stability (probability) Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 15 August 2025, at 08:56 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Stable distribution 10 languages Add topic

