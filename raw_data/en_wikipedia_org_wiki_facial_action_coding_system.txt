Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Background 2 Method 3 Uses Toggle Uses subsection 3.1 Baby F.A.C.S.

3.2 Use in medicine 3.3 Interspecial applications 3.4 Computer-generated imagery 4 Codes for action units Toggle Codes for action units subsection 4.1 Intensity scoring 4.2 Other letter modifiers 4.3 List of A.U.s and A.D.s (with underlying facial muscles) 4.3.1 Main codes 4.3.2 Head movement codes 4.3.3 Eye movement codes 4.3.4 Visibility codes 4.3.5 Gross behavior codes 5 See also 6 References 7 External links Toggle the table of contents Facial Action Coding System 7 languages Català Deutsch Español Français Italiano Português Русский Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia System of classifying human facial movements Muscles of head and neck The Facial Action Coding System ( F.A.C.S.

) is a system to taxonomize human facial movements by their appearance on the face,  based on a system originally developed by a Swedish anatomist named Carl-Herman Hjortsjö .

[ 1 ] It was later adopted by Paul Ekman and Wallace V. Friesen , and published in 1978.

[ 2 ] Ekman, Friesen, and Joseph C. Hager published a significant update to F.A.C.S. in 2002.

[ 3 ] Movements of individual facial muscles are encoded by the F.A.C.S. from slight different instant changes in facial appearance. It has proven useful to psychologists and to animators .

Background [ edit ] Blind athlete expressing joy in athletic competition. The fact that blind people use the same expressions as sighted people shows that expressions are innate.

In 2009, a study was conducted to study spontaneous facial expressions in sighted and blind judo athletes. They discovered that many facial expressions are innate and not visually learned.

[ 4 ] Method [ edit ] Using the F.A.C.S.

[ 5 ] human coders can manually code nearly any anatomically possible facial expression, deconstructing it into the specific "action units" (A.U.) and their temporal segments that produced the expression. As A.U.s are independent of any interpretation, they can be used for any higher-order decision-making process including recognition of basic emotions ,  or pre-programmed commands for an ambient intelligent environment. The F.A.C.S. manual is over five hundred pages in length and provides the A.U.s, as well as Ekman's interpretation of their meanings.

The F.A.C.S. defines A.U.s  as contractions or relaxations of one or more muscles. It also defines a number of "action descriptors", which differ from A.U.s in that the authors of the F.A.C.S. have not specified the muscular basis for the action and have not distinguished specific behaviors as precisely as they have for the A.U.s.

For example, the F.A.C.S. can be used to distinguish two types of smiles as follows: [ 6 ] the insincere and voluntary Pan-Am smile : contraction of zygomatic major alone the sincere and involuntary Duchenne smile : contraction of zygomatic major and inferior part of orbicularis oculi .

The F.A.C.S. is designed to be self-instructional. People can learn the technique from a number of sources including manuals and workshops, [ 7 ] and obtain certification through testing.

[ 8 ] Although the labeling of expressions currently requires trained experts, researchers have had some success in using computers to automatically identify the F.A.C.S. codes.

[ 9 ] One obstacle to automatic FACS code recognition is a shortage of manually coded ground truth data.

[ 10 ] Uses [ edit ] Baby F.A.C.S.

[ edit ] Baby F.A.C.S. (Facial Action Coding System for Infants and Young Children) [ 11 ] is a behavioral coding system that adapts the adult F.A.C.S. to code facial expressions in infants aged 0–2 years. It corresponds to specific underlying facial muscles, tailored to infant facial anatomy and expression patterns.

It was created by Dr. Harriet Oster and colleagues to address the limitations of applying adult F.A.C.S. directly to infants, whose facial musculature, proportions and developmental capabilities differ significantly.

Use in medicine [ edit ] The use of the F.A.C.S. has been proposed for use in the analysis of depression , [ 12 ] and the measurement of pain in patients unable to express themselves verbally.

[ 13 ] Interspecial applications [ edit ] The original F.A.C.S. has been modified to analyze facial movements in several non-human primates, namely chimpanzees , [ 14 ] rhesus macaques, [ 15 ] gibbons and siamangs, [ 16 ] and orangutans.

[ 17 ] More recently, it was developed also for domesticated species, including dogs, [ 18 ] horses [ 19 ] and cats.

[ 20 ] Similarly to the human F.A.C.S., the non-human F.A.C.S. has manuals available online for each species with the respective certification tests.

[ 21 ] Thus the F.A.C.S. can be used to compare facial repertoires across species due to its anatomical basis. A study conducted by Vick and others (2006) suggests that the F.A.C.S. can be modified by taking differences in underlying morphology into account. Such considerations enable a comparison of the homologous facial movements present in humans and chimpanzees, to show that the facial expressions of both species result from extremely notable appearance changes. The development of F.A.C.S. tools for different species allows the objective and anatomical study of facial expressions in communicative and emotional contexts. Furthermore, an interspecial analysis of facial expressions can help to answer interesting questions, such as which emotions are uniquely human.

[ 22 ] The Emotional Facial Action Coding System (E.M.F.A.C.S.) [ 23 ] and the  Facial Action Coding System Affect Interpretation Dictionary (F.A.C.S.A.I.D.) [ 24 ] consider only emotion-related facial actions. Examples of these are: Emotion Action units Happiness 6+12 Sadness 1+4+15 Surprise 1+2+5B+26 Fear 1+2+4+5+7+20+26 Anger 4+5+7+23 Disgust 9+15+17 Contempt R12A+R14A Computer-generated imagery [ edit ] F.A.C.S. coding is also used extensively in computer animation , in particular for computer facial animation , with facial expressions being expressed as vector graphics of A.Us.

[ 25 ] F.A.C.S. vectors are used as weights for blend shapes corresponding to each A.U., with the resulting face mesh then being used to render the finished face.

[ 26 ] [ 27 ] Deep-learning techniques can be used to determine the F.A.C.S. vectors from face images obtained during motion capture acting , facial motion capture or other performances.

[ 28 ] Codes for action units [ edit ] See also: List of muscles in the human body § The muscles of the head For clarification, the F.A.C.S. is an index of facial expressions, but does not actually provide any biomechanical information about the degree of muscle activation. Though muscle activation is not part of the F.A.C.S., the main muscles involved in the facial expression have been added here.

Action units (A.U.s) are the fundamental actions of individual muscles or groups of muscles.

Action descriptors (A.D.s) are unitary movements that may involve the actions of several muscle groups (e.g., a forward‐thrusting movement of the jaw). The muscular basis for these actions has not been specified and specific behaviors have not been distinguished as precisely as for the A.U.s.

For the most accurate annotation, the F.A.C.S. suggests agreement from at least two independent certified F.A.C.S. encoders.

Intensity scoring [ edit ] Intensities of the F.A.C.S. are annotated by appending letters A–E (for minimal-maximal intensity) to the action unit number (e.g. A.U. 1A is the weakest trace of A.U. 1 and A.U. 1E is the maximum intensity possible for the individual person).

A Trace B Slight C Marked or pronounced D Severe or extreme E Maximum Other letter modifiers [ edit ] There are other modifiers present in F.A.C.S. codes for emotional expressions, such as "R" which represents an action that occurs on the right side of the face and "L" for actions which occur on the left. An action which is unilateral (occurs on only one side of the face) but has no specific side is indicated with a "U" and an action which is bilateral but has a stronger side is indicated with an "A" for "asymmetric".

List of A.U.s and A.D.s (with underlying facial muscles) [ edit ] Main codes [ edit ] A.U. number F.A.C.S. name Muscular basis 0 Neutral face 1 Inner brow raiser frontalis ( pars medialis ) 2 Outer brow raiser frontalis ( pars lateralis ) 4 Brow lowerer depressor glabellae , depressor supercilii , corrugator supercilii 5 Upper lid raiser levator palpebrae superioris , superior tarsal muscle 6 Cheek raiser orbicularis oculi ( pars orbitalis ) 7 Lid tightener orbicularis oculi ( pars palpebralis ) 8 Lips toward each other orbicularis oris 9 Nose wrinkler levator labii superioris alaeque nasi 10 Upper lip raiser levator labii superioris , caput infraorbitalis 11 Nasolabial deepener zygomaticus minor 12 Lip corner puller zygomaticus major 13 Sharp lip puller levator anguli oris (also known as caninus ) 14 Dimpler buccinator 15 Lip corner depressor depressor anguli oris (also known as triangularis ) 16 Lower lip depressor depressor labii inferioris 17 Chin raiser mentalis 18 Lip pucker incisivii labii superioris and incisivii labii inferioris 19 Tongue show 20 Lip stretcher risorius with platysma 21 Neck tightener platysma] 22 Lip funneler orbicularis oris 23 Lip tightener orbicularis oris 24 Lip pressor orbicularis oris 25 Lips part depressor labii inferioris , or relaxation of mentalis or orbicularis oris 26 Jaw drop masseter ; relaxed temporalis and internal pterygoid 27 Mouth stretch pterygoids , digastric 28 Lip suck orbicularis oris Head movement codes [ edit ] A.U. number F.A.C.S. name Action 51 Head turn left 52 Head turn right 53 Head up 54 Head down 55 Head tilt left M55 Head tilt left The onset of the symmetrical 14 is immediately preceded or accompanied by a head tilt to the left.

56 Head tilt right M56 Head tilt right The onset of the symmetrical 14 is immediately preceded or accompanied by a head tilt to the right.

57 Head forward M57 Head thrust forward The onset of 17+24 is immediately preceded, accompanied, or followed by a head thrust forward.

58 Head back M59 Head shake up and down The onset of 17+24 is immediately preceded, accompanied, or followed by an up-down head shake (nod).

M60 Head shake side to side The onset of 17+24 is immediately preceded, accompanied, or followed by a side to side head shake.

M83 Head upward and to the side The onset of the symmetrical 14 is immediately preceded or accompanied by a movement of the head, upward and turned or tilted to either the left or right.

Eye movement codes [ edit ] A.U. number F.A.C.S. name Action 61 Eyes turn left M61 Eyes left The onset of the symmetrical 14 is immediately preceded or accompanied by eye movement to the left.

62 Eyes turn right M62 Eyes right The onset of the symmetrical 14 is immediately preceded or accompanied by eye movement to the right.

63 Eyes up 64 Eyes down 65 Walleye 66 Cross-eye M68 Upward rolling of eyes The onset of the symmetrical 14 is immediately preceded or accompanied by an upward rolling of the eyes.

69 Eyes positioned to look at other person The 4, 5, or 7, alone or in combination, occurs while the eye position is fixed on the other person in the conversation.

M69 Head or eyes look at other person The onset of the symmetrical 14 or A.U.s 4, 5, and 7, alone or in combination, is immediately preceded or accompanied by a movement of the eyes or of the head and eyes to look at the other person in the conversation.

Visibility codes [ edit ] A.U. number F.A.C.S. name 70 Brows and forehead not visible 71 Eyes not visible 72 Lower face not visible 73 Entire face not visible 74 Unscorable Gross behavior codes [ edit ] These codes are reserved for recording information about gross behaviors that may be relevant to the facial actions that are scored.

A.U. number F.A.C.S. name Muscular basis 29 Jaw thrust 30 Jaw sideways 31 Jaw clencher masseter 32 [Lip] bite 33 [Cheek] blow 34 [Cheek] puff 35 [Cheek] suck 36 [Tongue] bulge 37 Lip wipe 38 Nostril dilator nasalis (pars alaris) 39 Nostril compressor nasalis ( pars transversa ) and depressor septi nasi 40 Sniff 41 Lid droop levator palpebrae superioris (relaxation) 42 Slit orbicularis oculi muscle 43 Eyes closed relaxation of levator palpebrae superioris 44 Squint corrugator supercilii and orbicularis oculi muscle 45 Blink relaxation of levator palpebrae superioris ; contraction of orbicularis oculi ( pars palpebralis ) 46 Wink orbicularis oculi 50 Speech 80 Swallow 81 Chewing 82 Shoulder shrug 84 Head shake back and forth 85 Head nod up and down 91 Flash 92 Partial flash 97* Shiver/tremble 98* Fast up-down look See also [ edit ] Computer facial animation Computer processing of body language Emotion classification Facial electromyography Facial feedback hypothesis Facial muscles Microexpression References [ edit ] ^ Hjortsjö CH (1969).

Man's face and mimic language .

free download: Carl-Herman Hjortsjö, Man's face and mimic language" Archived 2022-08-06 at the Wayback Machine ^ Ekman P, Friesen W (1978).

Facial Action Coding System: A Technique for the Measurement of Facial Movement . Palo Alto: Consulting Psychologists Press.

^ Ekman P, Friesen WV, Hager JC (2002).

Facial Action Coding System: The Manual on CD ROM . Salt Lake City: A Human Face.

^ Matsumoto, D., & Willingham, B. (2009). "Spontaneous facial expressions of emotion of blind individuals".

Journal of Personality and Social Psychology , 96(1), 1-10 ^ Freitas-Magalhães (2012). "Microexpression and macroexpression". In Ramachandran VS (ed.).

Encyclopedia of Human Behavior . Vol. 2. Oxford: Elsevier/Academic Press. pp.

173– 183.

ISBN 978-0-12-375000-6 .

^ Del Giudice M, Colle L (May 2007). "Differences between children and adults in the recognition of enjoyment smiles".

Developmental Psychology .

43 (3): 796– 803.

doi : 10.1037/0012-1649.43.3.796 .

PMID 17484588 .

^ Rosenberg EL.

"Example and web site of one teaching professional" . Archived from the original on 2009-02-06 . Retrieved 2009-02-04 .

^ "Facial Action Coding System" .

Paul Ekman Group . Retrieved 2019-10-23 .

^ Facial Action Coding System.

Retrieved July 21, 2007.

^ Song, Juan; Liu, Zhilei (10 Mar 2023). "Self-supervised Facial Action Unit Detection with Region and Relation Learning".

arXiv : 2303.05708 [ cs.CV ].

^ Oster, Harriet (2006).

Baby FACS: Facial Action Coding System for Infants and Young Children . New York: Unpublished monograph and coding manual. New York University.

^ Reed LI, Sayette MA, Cohn JF (November 2007). "Impact of depression on response to comedy: a dynamic facial coding analysis".

Journal of Abnormal Psychology .

116 (4): 804– 9.

CiteSeerX 10.1.1.307.6950 .

doi : 10.1037/0021-843X.116.4.804 .

PMID 18020726 .

^ Lints-Martindale AC, Hadjistavropoulos T, Barber B, Gibson SJ (2007).

"A psychophysical investigation of the facial action coding system as an index of pain variability among older adults with and without Alzheimer's disease" .

Pain Medicine .

8 (8): 678– 89.

doi : 10.1111/j.1526-4637.2007.00358.x .

PMID 18028046 .

^ Parr LA, Waller BM, Vick SJ, Bard KA (February 2007).

"Classifying chimpanzee facial expressions using muscle action" .

Emotion .

7 (1): 172– 81.

doi : 10.1037/1528-3542.7.1.172 .

PMC 2826116 .

PMID 17352572 .

^ Parr LA, Waller BM, Burrows AM, Gothard KM, Vick SJ (December 2010).

"Brief communication: MaqFACS: A muscle-based facial movement coding system for the rhesus macaque" .

American Journal of Physical Anthropology .

143 (4): 625– 30.

doi : 10.1002/ajpa.21401 .

PMC 2988871 .

PMID 20872742 .

^ Waller BM, Lembeck M, Kuchenbuch P, Burrows AM, Liebal K (2012). "GibbonFACS: A Muscle-Based Facial Movement Coding System for Hylobatids".

International Journal of Primatology .

33 (4): 809– 821.

doi : 10.1007/s10764-012-9611-6 .

S2CID 18321096 .

^ Caeiro CC, Waller BM, Zimmermann E, Burrows AM, Davila-Ross M (2012).

"OrangFACS: A Muscle-Based Facial Movement Coding System for Orangutans ( Pongo spp.)" (PDF) .

International Journal of Primatology .

34 : 115– 129.

doi : 10.1007/s10764-012-9652-x .

S2CID 17612028 .

^ Waller BM, Peirce K, Caeiro CC, Scheider L, Burrows AM, McCune S, Kaminski J (2013).

"Paedomorphic facial expressions give dogs a selective advantage" .

PLOS ONE .

8 (12): e82686.

Bibcode : 2013PLoSO...882686W .

doi : 10.1371/journal.pone.0082686 .

PMC 3873274 .

PMID 24386109 .

^ Wathan J, Burrows AM, Waller BM, McComb K (2015-08-05).

"EquiFACS: The Equine Facial Action Coding System" .

PLOS ONE .

10 (8): e0131738.

Bibcode : 2015PLoSO..1031738W .

doi : 10.1371/journal.pone.0131738 .

PMC 4526551 .

PMID 26244573 .

^ Caeiro CC, Burrows AM, Waller BM (2017-04-01).

"Development and application of CatFACS: Are human cat adopters influenced by cat facial expressions?" (PDF) .

Applied Animal Behaviour Science .

189 : 66– 78.

doi : 10.1016/j.applanim.2017.01.005 .

ISSN 0168-1591 . Archived from the original (PDF) on 2018-07-21 . Retrieved 2019-11-07 .

^ "Home" .

animalfacs.com . Retrieved 2019-10-23 .

^ Vick SJ, Waller BM, Parr LA, Smith Pasqualini MC, Bard KA (March 2007).

"A Cross-species Comparison of Facial Morphology and Movement in Humans and Chimpanzees Using the Facial Action Coding System (FACS)" .

Journal of Nonverbal Behavior .

31 (1): 1– 20.

doi : 10.1007/s10919-006-0017-z .

PMC 3008553 .

PMID 21188285 .

^ Friesen W, Ekman P (1983), EMFACS-7: Emotional Facial Action Coding System. Unpublished manuscript , vol. 2, University of California at San Francisco, p. 1 ^ "Facial Action Coding System Affect Interpretation Dictionary (FACSAID)" . Archived from the original on 2011-05-20 . Retrieved 2011-02-23 .

^ Walsh, Joseph (2016-12-16).

"Rogue One: the CGI resurrection of Peter Cushing is thrilling – but is it right?" .

The Guardian .

ISSN 0261-3077 . Retrieved 2023-10-23 .

^ Gilbert, Michaël; Demarchi, Samuel; Urdapilleta, Isabel (October 2021).

"FACSHuman, a software program for creating experimental material by modeling 3D facial expressions" .

Behavior Research Methods .

53 (5): 2252– 2272.

doi : 10.3758/s13428-021-01559-9 .

ISSN 1554-3528 .

PMID 33825127 .

^ "Discover how to create FACS facial blendshapes in Maya | CG Channel" . Retrieved 2023-10-23 .

^ Gudi, Amogh; Tasli, H. Emrah; Den Uyl, Tim M.; Maroulis, Andreas (2015). "Deep learning based FACS Action Unit occurrence and intensity estimation".

2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG) . pp.

1– 5.

doi : 10.1109/FG.2015.7284873 .

ISBN 978-1-4799-6026-2 .

S2CID 6283665 . Retrieved 2023-10-23 .

External links [ edit ] Paul Ekman's articles relating to F.A.C.S.

Paul Ekman's Facial Action Coding System (F.A.C.S.) More information on the different animal F.A.C.S. projects New Yorker article discussing F.A.C.S.

Details from 1978 edition of F.A.C.S.

Site at WPI download of Carl-Herman Hjortsjö, Man's face and mimic language" Archived 2022-08-06 at the Wayback Machine (the original Swedish title of the book is: "Människans ansikte och mimiska språket". The correct translation would be: "Man's face and facial language") v t e Nonverbal communication Modalities Physical Blushing Body language / Kinesics Body-to-body communication Facial expression Facial Action Coding System Microexpression Subtle expression Gesture List Speech-independent gestures Haptic communication Imitation Interpersonal synchrony Laughter Oculesics Eye contact Pupil dilation Olfaction Posture Proxemics Speech Affect Emotional prosody Paralanguage Intonation Loudness Prosody Rhythm Stress Tone Voice quality Social context Chronemics Conventions Display rules Habitus High-context and low-context cultures Interpersonal relationship Social norm Other Emoticon / Smiley One-bit message Missed call Silent service code Unconscious Microexpression Non-verbal leakage Multi-faceted Affect display Deception Emotion recognition First impression Intimacy Broader concepts Cognitive academic language proficiency Communication Emotional intelligence Nunchi People skills Semiotics Social behavior Social competence Social cue Social skills Unsaid Further information Disorders Aprosodia Asperger syndrome Autism Fragile X Pervasive developmental disorder not otherwise specified Childhood disintegrative disorder Rett syndrome Dyssemia Nonverbal learning disorder Social (pragmatic) communication disorder Neuroanatomy Limbic system / Limbic lobe Mirror neuron Applications Cold reading Lie detection Freudian slip Poker tell Targeted advertising Technology Computer processing of body language Emotion recognition in conversation Gesture recognition List of facial expression databases Sentiment analysis Key people Ray Birdwhistell Charles Darwin Paul Ekman Related Animal communication Behavioral communication Aggressive Assertive Passive Passive-aggressive Impression management Meta-communication Monastic sign lexicons Verbal communication Manual-tactile verbal Sign language Tactile signing Tadoma Art and literature Mime Mimoplastic art Subtext Retrieved from " https://en.wikipedia.org/w/index.php?title=Facial_Action_Coding_System&oldid=1301677492 " Categories : Facial expressions Encodings Anatomical simulation Animal communication 1978 introductions Hidden categories: Webarchive template wayback links Articles with short description Short description is different from Wikidata This page was last edited on 21 July 2025, at 04:15 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Facial Action Coding System 7 languages Add topic

