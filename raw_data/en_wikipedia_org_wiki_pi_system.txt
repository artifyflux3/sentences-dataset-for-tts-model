Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Definitions 2 Examples 3 Relationship to 𝜆-systems Toggle Relationship to 𝜆-systems subsection 3.1 The π -𝜆 theorem 3.1.1 Example 4 π -Systems in probability Toggle π -Systems in probability subsection 4.1 Equality in distribution 4.2 Independent random variables 4.2.1 Example 5 See also 6 Notes 7 Citations 8 References Toggle the table of contents Pi-system 6 languages Deutsch Español Français Italiano Polski Português Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Family of sets closed under intersection This article is about π -system in mathematics. For π -systems in chemistry, see conjugated system .

In mathematics , a π -system (or pi-system ) on a set Ω Ω {\displaystyle \Omega } is a collection P {\displaystyle P} of certain subsets of Ω Ω , {\displaystyle \Omega ,} such that P {\displaystyle P} is non-empty .

If A , B ∈ ∈ P {\displaystyle A,B\in P} then A ∩ ∩ B ∈ ∈ P .

{\displaystyle A\cap B\in P.} That is, P {\displaystyle P} is a non-empty family of subsets of Ω Ω {\displaystyle \Omega } that is closed under non-empty finite intersections .

[ nb 1 ] The importance of π -systems arises from the fact that if two probability measures agree on a π -system, then they agree on the 𝜎-algebra generated by that π -system. Moreover, if other properties, such as equality of integrals, hold for the π -system, then they hold for the generated 𝜎-algebra as well. This is the case whenever the collection of subsets for which the property holds is a 𝜆-system .

π -systems are also useful for checking independence of random variables.

This is desirable because in practice, π -systems are often simpler to work with than 𝜎-algebras. For example, it may be awkward to work with 𝜎-algebras generated by infinitely many sets σ σ ( E 1 , E 2 , … … ) .

{\displaystyle \sigma (E_{1},E_{2},\ldots ).} So instead we may examine the union of all 𝜎-algebras generated by finitely many sets ⋃ ⋃ n σ σ ( E 1 , … … , E n ) .

{\textstyle \bigcup _{n}\sigma (E_{1},\ldots ,E_{n}).} This forms a π -system that generates the desired 𝜎-algebra. Another example is the collection of all intervals of the real line , along with the empty set, which is a π -system that generates the very important Borel 𝜎-algebra of subsets of the real line.

Definitions [ edit ] A π -system is a non-empty collection of sets P {\displaystyle P} that is closed under non-empty finite intersections, which is equivalent to P {\displaystyle P} containing the intersection of any two of its elements. 
If every set in this π -system is a subset of Ω Ω {\displaystyle \Omega } then it is called a π -system on Ω Ω .

{\displaystyle \Omega .} For any non-empty family Σ Σ {\displaystyle \Sigma } of subsets of Ω Ω , {\displaystyle \Omega ,} there exists a π -system I Σ Σ , {\displaystyle {\mathcal {I}}_{\Sigma },} called the π -system generated by Σ Σ {\displaystyle {\boldsymbol {\varSigma }}} , that is the unique smallest π -system of Ω Ω {\displaystyle \Omega } containing every element of Σ Σ .

{\displaystyle \Sigma .} It is equal to the intersection of all π -systems containing Σ Σ , {\displaystyle \Sigma ,} and can be explicitly described as the set of all possible non-empty finite intersections of elements of Σ Σ : {\displaystyle \Sigma :} { E 1 ∩ ∩ ⋯ ⋯ ∩ ∩ E n : 1 ≤ ≤ n ∈ ∈ N and E 1 , … … , E n ∈ ∈ Σ Σ } .

{\displaystyle \left\{E_{1}\cap \cdots \cap E_{n}~:~1\leq n\in \mathbb {N} {\text{ and }}E_{1},\ldots ,E_{n}\in \Sigma \right\}.} A non-empty family of sets has the finite intersection property if and only if the π -system it generates does not contain the empty set as an element.

Examples [ edit ] For any real numbers a {\displaystyle a} and b , {\displaystyle b,} the intervals ( − − ∞ ∞ , a ] {\displaystyle (-\infty ,a]} form a π -system, and the intervals ( a , b ] {\displaystyle (a,b]} form a π -system if the empty set is also included.

The topology (collection of open subsets ) of any topological space is a π -system.

Every filter is a π -system. Every π -system that doesn't contain the empty set is a prefilter (also known as a filter base).

For any measurable function f : Ω Ω → → R , {\displaystyle f:\Omega \to \mathbb {R} ,} the set I f = { f − − 1 ( ( − − ∞ ∞ , x ] ) : x ∈ ∈ R } {\displaystyle {\mathcal {I}}_{f}=\left\{f^{-1}((-\infty ,x]):x\in \mathbb {R} \right\}} defines a π -system, and is called the π -system generated by f .

{\displaystyle f.} (Alternatively, { f − − 1 ( ( a , b ] ) : a , b ∈ ∈ R , a < b } ∪ ∪ { ∅ ∅ } {\displaystyle \left\{f^{-1}((a,b]):a,b\in \mathbb {R} ,a<b\right\}\cup \{\varnothing \}} defines a π -system generated by f .

{\displaystyle f.} ) If P 1 {\displaystyle P_{1}} and P 2 {\displaystyle P_{2}} are π -systems for Ω Ω 1 {\displaystyle \Omega _{1}} and Ω Ω 2 , {\displaystyle \Omega _{2},} respectively, then { A 1 × × A 2 : A 1 ∈ ∈ P 1 , A 2 ∈ ∈ P 2 } {\displaystyle \{A_{1}\times A_{2}:A_{1}\in P_{1},A_{2}\in P_{2}\}} is a π -system for the Cartesian product Ω Ω 1 × × Ω Ω 2 .

{\displaystyle \Omega _{1}\times \Omega _{2}.} Every 𝜎-algebra is a π -system.

Relationship to 𝜆-systems [ edit ] A 𝜆-system on Ω Ω {\displaystyle \Omega } is a set D {\displaystyle D} of subsets of Ω Ω , {\displaystyle \Omega ,} satisfying Ω Ω ∈ ∈ D , {\displaystyle \Omega \in D,} if A ∈ ∈ D {\displaystyle A\in D} then Ω Ω ∖ ∖ A ∈ ∈ D , {\displaystyle \Omega \setminus A\in D,} if A 1 , A 2 , A 3 , … … {\displaystyle A_{1},A_{2},A_{3},\ldots } is a sequence of (pairwise) disjoint subsets in D {\displaystyle D} then ⋃ ⋃ n = 1 ∞ ∞ A n ∈ ∈ D .

{\displaystyle \textstyle \bigcup \limits _{n=1}^{\infty }A_{n}\in D.} Whilst it is true that any 𝜎-algebra satisfies the properties of being both a π -system and a 𝜆-system, it is not true that any π -system is a 𝜆-system, and moreover it is not true that any π -system is a 𝜎-algebra. However, a useful classification is that any set system which is both a 𝜆-system and a π -system is a 𝜎-algebra. This is used as a step in proving the π -𝜆 theorem.

The π -𝜆 theorem [ edit ] See also: Dynkin system § Sierpiński–Dynkin's π-λ theorem Let D {\displaystyle D} be a 𝜆-system, and let I ⊆ ⊆ D {\displaystyle {\mathcal {I}}\subseteq D} be a π -system contained in D .

{\displaystyle D.} The π -𝜆 theorem [ 1 ] states that the 𝜎-algebra σ σ ( I ) {\displaystyle \sigma ({\mathcal {I}})} generated by I {\displaystyle {\mathcal {I}}} is contained in D : {\displaystyle D~:~} σ σ ( I ) ⊆ ⊆ D .

{\displaystyle \sigma ({\mathcal {I}})\subseteq D.} The π -𝜆 theorem can be used to prove many elementary measure theoretic results. For instance, it is used in proving the uniqueness claim of the Carathéodory extension theorem for 𝜎-finite measures.

[ 2 ] The π -𝜆 theorem is closely related to the monotone class theorem , which provides a similar relationship between monotone classes and algebras, and can be used to derive many of the same results. Since π -systems are simpler classes than algebras, it can be easier to identify the sets that are in them while, on the other hand, checking whether the property under consideration determines a 𝜆-system is often relatively easy. Despite the difference between the two theorems, the π -𝜆 theorem is sometimes referred to as the monotone class theorem.

[ 1 ] Example [ edit ] Let μ μ 1 , μ μ 2 : F → → R {\displaystyle \mu _{1},\mu _{2}:F\to \mathbb {R} } be two measures on the 𝜎-algebra F , {\displaystyle F,} and suppose that F = σ σ ( I ) {\displaystyle F=\sigma (I)} is generated by a π -system I .

{\displaystyle I.} If μ μ 1 ( A ) = μ μ 2 ( A ) {\displaystyle \mu _{1}(A)=\mu _{2}(A)} for all A ∈ ∈ I , {\displaystyle A\in I,} and μ μ 1 ( Ω Ω ) = μ μ 2 ( Ω Ω ) < ∞ ∞ , {\displaystyle \mu _{1}(\Omega )=\mu _{2}(\Omega )<\infty ,} then μ μ 1 = μ μ 2 .

{\displaystyle \mu _{1}=\mu _{2}.} This is the uniqueness statement of the Carathéodory extension theorem for finite measures. If this result does not seem very remarkable, consider the fact that it usually is very difficult or even impossible to fully describe every set in the 𝜎-algebra, and so the problem of equating measures would be completely hopeless without such a tool.

Idea of the proof [ 2 ] Define the collection of sets D = { A ∈ ∈ σ σ ( I ) : : μ μ 1 ( A ) = μ μ 2 ( A ) } .

{\displaystyle D=\left\{A\in \sigma (I)\colon \mu _{1}(A)=\mu _{2}(A)\right\}.} By the first assumption, μ μ 1 {\displaystyle \mu _{1}} and μ μ 2 {\displaystyle \mu _{2}} agree on I {\displaystyle I} and thus I ⊆ ⊆ D .

{\displaystyle I\subseteq D.} By the second assumption, Ω Ω ∈ ∈ D , {\displaystyle \Omega \in D,} and it can further be shown that D {\displaystyle D} is a 𝜆-system. It follows from the π -𝜆 theorem that σ σ ( I ) ⊆ ⊆ D ⊆ ⊆ σ σ ( I ) , {\displaystyle \sigma (I)\subseteq D\subseteq \sigma (I),} and so D = σ σ ( I ) .

{\displaystyle D=\sigma (I).} That is to say, the measures agree on σ σ ( I ) .

{\displaystyle \sigma (I).} π -Systems in probability [ edit ] π -systems are more commonly used in the study of probability theory than in the general field of measure theory. This is primarily due to probabilistic notions such as independence , though it may also be a consequence of the fact that the π -𝜆 theorem was proven by the probabilist Eugene Dynkin . Standard measure theory texts typically prove the same results via monotone classes , rather than π -systems.

Equality in distribution [ edit ] The π -𝜆 theorem motivates the common definition of the probability distribution of a random variable X : ( Ω Ω , F , P ) → → R {\displaystyle X:(\Omega ,{\mathcal {F}},\operatorname {P} )\to \mathbb {R} } in terms of its cumulative distribution function . Recall that the cumulative distribution of a random variable  is defined as F X ( a ) = P ⁡ ⁡ [ X ≤ ≤ a ] , a ∈ ∈ R , {\displaystyle F_{X}(a)=\operatorname {P} [X\leq a],\qquad a\in \mathbb {R} ,} whereas the seemingly more general law of the variable is the probability measure L X ( B ) = P ⁡ ⁡ [ X − − 1 ( B ) ] for all B ∈ ∈ B ( R ) , {\displaystyle {\mathcal {L}}_{X}(B)=\operatorname {P} \left[X^{-1}(B)\right]\quad {\text{ for all }}B\in {\mathcal {B}}(\mathbb {R} ),} where B ( R ) {\displaystyle {\mathcal {B}}(\mathbb {R} )} is the Borel 𝜎-algebra. The random variables X : ( Ω Ω , F , P ) → → R {\displaystyle X:(\Omega ,{\mathcal {F}},\operatorname {P} )\to \mathbb {R} } and Y : ( Ω Ω ~ ~ , F ~ ~ , P ~ ~ ) → → R {\displaystyle Y:({\tilde {\Omega }},{\tilde {\mathcal {F}}},{\tilde {\operatorname {P} }})\to \mathbb {R} } (on two possibly different probability spaces ) are equal in distribution (or law ), denoted by X = D Y , {\displaystyle X\,{\stackrel {\mathcal {D}}{=}}\,Y,} if they have the same cumulative distribution functions; that is, if F X = F Y .

{\displaystyle F_{X}=F_{Y}.} The motivation for the definition stems from the observation that if F X = F Y , {\displaystyle F_{X}=F_{Y},} then that is exactly to say that L X {\displaystyle {\mathcal {L}}_{X}} and L Y {\displaystyle {\mathcal {L}}_{Y}} agree on the π -system { ( − − ∞ ∞ , a ] : a ∈ ∈ R } {\displaystyle \{(-\infty ,a]:a\in \mathbb {R} \}} which generates B ( R ) , {\displaystyle {\mathcal {B}}(\mathbb {R} ),} and so by the example above : L X = L Y .

{\displaystyle {\mathcal {L}}_{X}={\mathcal {L}}_{Y}.} A similar result holds for the joint distribution of a random vector. For example, suppose X {\displaystyle X} and Y {\displaystyle Y} are two random variables defined on the same probability space ( Ω Ω , F , P ) , {\displaystyle (\Omega ,{\mathcal {F}},\operatorname {P} ),} with respectively generated π -systems I X {\displaystyle {\mathcal {I}}_{X}} and I Y .

{\displaystyle {\mathcal {I}}_{Y}.} The joint cumulative distribution function of ( X , Y ) {\displaystyle (X,Y)} is F X , Y ( a , b ) = P ⁡ ⁡ [ X ≤ ≤ a , Y ≤ ≤ b ] = P ⁡ ⁡ [ X − − 1 ( ( − − ∞ ∞ , a ] ) ∩ ∩ Y − − 1 ( ( − − ∞ ∞ , b ] ) ] , for all a , b ∈ ∈ R .

{\displaystyle F_{X,Y}(a,b)=\operatorname {P} [X\leq a,Y\leq b]=\operatorname {P} \left[X^{-1}((-\infty ,a])\cap Y^{-1}((-\infty ,b])\right],\quad {\text{ for all }}a,b\in \mathbb {R} .} However, A = X − − 1 ( ( − − ∞ ∞ , a ] ) ∈ ∈ I X {\displaystyle A=X^{-1}((-\infty ,a])\in {\mathcal {I}}_{X}} and B = Y − − 1 ( ( − − ∞ ∞ , b ] ) ∈ ∈ I Y .

{\displaystyle B=Y^{-1}((-\infty ,b])\in {\mathcal {I}}_{Y}.} Because I X , Y = { A ∩ ∩ B : A ∈ ∈ I X , and B ∈ ∈ I Y } {\displaystyle {\mathcal {I}}_{X,Y}=\left\{A\cap B:A\in {\mathcal {I}}_{X},{\text{ and }}B\in {\mathcal {I}}_{Y}\right\}} is a π -system generated by the random pair ( X , Y ) , {\displaystyle (X,Y),} the π -𝜆 theorem is used to show that the joint cumulative distribution function suffices to determine the joint law of ( X , Y ) .

{\displaystyle (X,Y).} In other words, ( X , Y ) {\displaystyle (X,Y)} and ( W , Z ) {\displaystyle (W,Z)} have the same distribution if and only if they have the same joint cumulative distribution function.

In the theory of stochastic processes , two processes ( X t ) t ∈ ∈ T , ( Y t ) t ∈ ∈ T {\displaystyle (X_{t})_{t\in T},(Y_{t})_{t\in T}} are known to be equal in distribution if and only if they agree on all finite-dimensional distributions; that is, for all t 1 , … … , t n ∈ ∈ T , n ∈ ∈ N , {\displaystyle t_{1},\ldots ,t_{n}\in T,\,n\in \mathbb {N} ,} ( X t 1 , … … , X t n ) = D ( Y t 1 , … … , Y t n ) .

{\displaystyle \left(X_{t_{1}},\ldots ,X_{t_{n}}\right)\,{\stackrel {\mathcal {D}}{=}}\,\left(Y_{t_{1}},\ldots ,Y_{t_{n}}\right).} The proof of this is another application of the π -𝜆 theorem.

[ 3 ] Independent random variables [ edit ] The theory of π -system plays an important role in the probabilistic notion of independence . If X {\displaystyle X} and Y {\displaystyle Y} are two random variables defined on the same probability space ( Ω Ω , F , P ) {\displaystyle (\Omega ,{\mathcal {F}},\operatorname {P} )} then the random variables are independent if and only if their π -systems I X , I Y {\displaystyle {\mathcal {I}}_{X},{\mathcal {I}}_{Y}} satisfy for all A ∈ ∈ I X {\displaystyle A\in {\mathcal {I}}_{X}} and B ∈ ∈ I Y , {\displaystyle B\in {\mathcal {I}}_{Y},} P ⁡ ⁡ [ A ∩ ∩ B ] = P ⁡ ⁡ [ A ] P ⁡ ⁡ [ B ] , {\displaystyle \operatorname {P} [A\cap B]~=~\operatorname {P} [A]\operatorname {P} [B],} which is to say that I X , I Y {\displaystyle {\mathcal {I}}_{X},{\mathcal {I}}_{Y}} are independent. This actually is a special case of the use of π -systems for determining the distribution of ( X , Y ) .

{\displaystyle (X,Y).} Example [ edit ] Let Z = ( Z 1 , Z 2 ) , {\displaystyle Z=\left(Z_{1},Z_{2}\right),} where Z 1 , Z 2 ∼ ∼ N ( 0 , 1 ) {\displaystyle Z_{1},Z_{2}\sim {\mathcal {N}}(0,1)} are iid standard normal random variables. Define the radius and argument (arctan) variables R = Z 1 2 + Z 2 2 , Θ Θ = tan − − 1 ⁡ ⁡ ( Z 2 / Z 1 ) .

{\displaystyle R={\sqrt {Z_{1}^{2}+Z_{2}^{2}}},\qquad \Theta =\tan ^{-1}\left(Z_{2}/Z_{1}\right).} Then R {\displaystyle R} and Θ Θ {\displaystyle \Theta } are independent random variables.

To prove this, it is sufficient to show that the π -systems I R , I Θ Θ {\displaystyle {\mathcal {I}}_{R},{\mathcal {I}}_{\Theta }} are independent: that is, for all ρ ρ ∈ ∈ [ 0 , ∞ ∞ ) {\displaystyle \rho \in [0,\infty )} and θ θ ∈ ∈ [ 0 , 2 π π ] , {\displaystyle \theta \in [0,2\pi ],} P ⁡ ⁡ [ R ≤ ≤ ρ ρ , Θ Θ ≤ ≤ θ θ ] = P ⁡ ⁡ [ R ≤ ≤ ρ ρ ] P ⁡ ⁡ [ Θ Θ ≤ ≤ θ θ ] .

{\displaystyle \operatorname {P} [R\leq \rho ,\Theta \leq \theta ]=\operatorname {P} [R\leq \rho ]\operatorname {P} [\Theta \leq \theta ].} Confirming that this is the case is an exercise in changing variables. Fix ρ ρ ∈ ∈ [ 0 , ∞ ∞ ) {\displaystyle \rho \in [0,\infty )} and θ θ ∈ ∈ [ 0 , 2 π π ] , {\displaystyle \theta \in [0,2\pi ],} then the probability can be expressed as an integral of the probability density function of Z .

{\displaystyle Z.} P ⁡ ⁡ [ R ≤ ≤ ρ ρ , Θ Θ ≤ ≤ θ θ ] = ∫ ∫ R ≤ ≤ ρ ρ , Θ Θ ≤ ≤ θ θ 1 2 π π exp ⁡ ⁡ ( − − 1 2 ( z 1 2 + z 2 2 ) ) d z 1 d z 2 = ∫ ∫ 0 θ θ ∫ ∫ 0 ρ ρ 1 2 π π e − − r 2 2 r d r d θ θ ~ ~ = ( ∫ ∫ 0 θ θ 1 2 π π d θ θ ~ ~ ) ( ∫ ∫ 0 ρ ρ e − − r 2 2 r d r ) = P ⁡ ⁡ [ Θ Θ ≤ ≤ θ θ ] P ⁡ ⁡ [ R ≤ ≤ ρ ρ ] .

{\displaystyle {\begin{aligned}\operatorname {P} [R\leq \rho ,\Theta \leq \theta ]&=\int _{R\leq \rho ,\,\Theta \leq \theta }{\frac {1}{2\pi }}\exp \left({-{\frac {1}{2}}(z_{1}^{2}+z_{2}^{2})}\right)dz_{1}\,dz_{2}\\[5pt]&=\int _{0}^{\theta }\int _{0}^{\rho }{\frac {1}{2\pi }}e^{-{\frac {r^{2}}{2}}}\;r\,dr\,d{\tilde {\theta }}\\[5pt]&=\left(\int _{0}^{\theta }{\frac {1}{2\pi }}\,d{\tilde {\theta }}\right)\;\left(\int _{0}^{\rho }e^{-{\frac {r^{2}}{2}}}\;r\,dr\right)\\[5pt]&=\operatorname {P} [\Theta \leq \theta ]\operatorname {P} [R\leq \rho ].\end{aligned}}} See also [ edit ] Families F {\displaystyle {\mathcal {F}}} of sets over Ω Ω {\displaystyle \Omega } v t e Is necessarily true of F : : {\displaystyle {\mathcal {F}}\colon } or, is F {\displaystyle {\mathcal {F}}} closed under: Directed by ⊇ ⊇ {\displaystyle \,\supseteq } A ∩ ∩ B {\displaystyle A\cap B} A ∪ ∪ B {\displaystyle A\cup B} B ∖ ∖ A {\displaystyle B\setminus A} Ω Ω ∖ ∖ A {\displaystyle \Omega \setminus A} A 1 ∩ ∩ A 2 ∩ ∩ ⋯ ⋯ {\displaystyle A_{1}\cap A_{2}\cap \cdots } A 1 ∪ ∪ A 2 ∪ ∪ ⋯ ⋯ {\displaystyle A_{1}\cup A_{2}\cup \cdots } Ω Ω ∈ ∈ F {\displaystyle \Omega \in {\mathcal {F}}} ∅ ∅ ∈ ∈ F {\displaystyle \varnothing \in {\mathcal {F}}} F.I.P.

π -system Semiring Never Semialgebra (Semifield) Never Monotone class only if A i ↘ ↘ {\displaystyle A_{i}\searrow } only if A i ↗ ↗ {\displaystyle A_{i}\nearrow } 𝜆-system (Dynkin System) only if A ⊆ ⊆ B {\displaystyle A\subseteq B} only if A i ↗ ↗ {\displaystyle A_{i}\nearrow } or they are disjoint Never Ring (Order theory) Ring (Measure theory) Never δ-Ring Never 𝜎-Ring Never Algebra (Field) Never 𝜎-Algebra (𝜎-Field) Never Dual ideal Filter Never Never ∅ ∅ ∉ F {\displaystyle \varnothing \not \in {\mathcal {F}}} Prefilter (Filter base) Never Never ∅ ∅ ∉ F {\displaystyle \varnothing \not \in {\mathcal {F}}} Filter subbase Never Never ∅ ∅ ∉ F {\displaystyle \varnothing \not \in {\mathcal {F}}} Open Topology (even arbitrary ∪ ∪ {\displaystyle \cup } ) Never Closed Topology (even arbitrary ∩ ∩ {\displaystyle \cap } ) Never Is necessarily true of F : : {\displaystyle {\mathcal {F}}\colon } or, is F {\displaystyle {\mathcal {F}}} closed under: directed downward finite intersections finite unions relative complements complements in Ω Ω {\displaystyle \Omega } countable intersections countable unions contains Ω Ω {\displaystyle \Omega } contains ∅ ∅ {\displaystyle \varnothing } Finite Intersection Property Additionally, a semiring is a π -system where every complement B ∖ ∖ A {\displaystyle B\setminus A} is equal to a finite disjoint union of sets in F .

{\displaystyle {\mathcal {F}}.} A semialgebra is a semiring where every complement Ω Ω ∖ ∖ A {\displaystyle \Omega \setminus A} is equal to a finite disjoint union of sets in F .

{\displaystyle {\mathcal {F}}.} A , B , A 1 , A 2 , … … {\displaystyle A,B,A_{1},A_{2},\ldots } are arbitrary elements of F {\displaystyle {\mathcal {F}}} and it is assumed that F ≠ ≠ ∅ ∅ .

{\displaystyle {\mathcal {F}}\neq \varnothing .} δ -ring – Ring closed under countable intersections Field of sets – Algebraic concept in measure theory, also referred to as an algebra of sets Ideal (set theory) – Non-empty family of sets that is closed under finite unions and subsets Independence (probability theory) – When the occurrence of one event does not affect the likelihood of another 𝜆-system (Dynkin system) – Family closed under complements and countable disjoint unions Monotone class theorem – Measure theory and probability theorem Probability distribution – Mathematical function for the probability a given outcome occurs in an experiment Ring of sets – Family closed under unions and relative complements σ-algebra – Algebraic structure of set algebra 𝜎-ideal – Family closed under subsets and countable unions 𝜎-ring – Family of sets closed under countable unions Notes [ edit ] ^ The nullary (0-ary) intersection of subsets of Ω Ω {\displaystyle \Omega } is by convention equal to Ω Ω , {\displaystyle \Omega ,} which is not required to be an element of a π -system.

Citations [ edit ] ^ a b Kallenberg, Foundations Of Modern Probability, p. 2 ^ a b Durrett, Probability Theory and Examples, p. 404 ^ Kallenberg, Foundations Of Modern Probability, p. 48 References [ edit ] Gut, Allan (2005).

Probability: A Graduate Course . Springer Texts in Statistics. New York: Springer.

doi : 10.1007/b138932 .

ISBN 0-387-22833-0 .

Williams, David (1991).

Probability with Martingales . Cambridge University Press.

ISBN 0-521-40605-6 .

Durrett, Richard (2019).

Probability: Theory and Examples (PDF) . Cambridge Series in Statistical and Probabilistic Mathematics. Vol. 49 (5th ed.). Cambridge New York, NY: Cambridge University Press .

ISBN 978-1-108-47368-2 .

OCLC 1100115281 . Retrieved November 5, 2020 .

v t e Measure theory Basic concepts Absolute continuity of measures Lebesgue integration L p spaces Measure Measure space Probability space Measurable space / function Sets Almost everywhere Atom Baire set Borel set equivalence relation Borel space Carathéodory's criterion Cylindrical σ-algebra Cylinder set 𝜆-system Essential range infimum/supremum Locally measurable π -system σ-algebra Non-measurable set Vitali set Null set Support Transverse measure Universally measurable Types of measures Atomic Baire Banach Besov Borel Brown Complex Complete Content ( Logarithmically ) Convex Decomposable Discrete Equivalent Finite Inner ( Quasi- ) Invariant Locally finite Maximising Metric outer Outer Perfect Pre-measure ( Sub- ) Probability Projection-valued Radon Random Regular Borel regular Inner regular Outer regular Saturated Set function σ-finite s-finite Signed Singular Spectral Strictly positive Tight Vector Particular measures Counting Dirac Euler Gaussian Haar Harmonic Hausdorff Intensity Lebesgue Infinite-dimensional Logarithmic Product Projections Pushforward Spherical measure Tangent Trivial Young Maps Measurable function Bochner Strongly Weakly Convergence: almost everywhere of measures in measure of random variables in distribution in probability Cylinder set measure Random: compact set element measure process variable vector Projection-valued measure Main results Carathéodory's extension theorem Convergence theorems Dominated Monotone Vitali Decomposition theorems Hahn Jordan Maharam's Egorov's Fatou's lemma Fubini's Fubini–Tonelli Hölder's inequality Minkowski inequality Radon–Nikodym Riesz–Markov–Kakutani representation theorem Other results Disintegration theorem Lifting theory Lebesgue's density theorem Lebesgue differentiation theorem Sard's theorem Vitali–Hahn–Saks theorem For Lebesgue measure Isoperimetric inequality Brunn–Minkowski theorem Milman's reverse Minkowski–Steiner formula Prékopa–Leindler inequality Vitale's random Brunn–Minkowski inequality Applications & related Convex analysis Descriptive set theory Probability theory Real analysis Spectral theory NewPP limit report
Parsed by mw‐web.codfw.main‐597b4b5bbd‐t88vs
Cached time: 20250814223756
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.642 seconds
Real time usage: 0.998 seconds
Preprocessor visited node count: 5137/1000000
Revision size: 16040/2097152 bytes
Post‐expand include size: 119346/2097152 bytes
Template argument size: 7988/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 29299/5000000 bytes
Lua time usage: 0.254/10.000 seconds
Lua memory usage: 14302919/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  470.293      1 -total
 30.98%  145.715     11 Template:Annotated_link
 17.48%   82.185      1 Template:Families_of_sets
 16.36%   76.956      3 Template:Cite_book
 15.08%   70.901      1 Template:Short_description
  9.27%   43.592      2 Template:Pagetype
  8.22%   38.661      1 Template:Navbar
  6.09%   28.632      2 Template:Navbox
  6.05%   28.470      1 Template:Measure_theory
  5.71%   26.870      1 Template:This Saved in parser cache with key enwiki:pcache:4050532:|#|:idhash:canonical and timestamp 20250814223756 and revision id 1297670823. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Pi-system&oldid=1297670823 " Categories : Measure theory Families of sets Hidden categories: Articles with short description Short description matches Wikidata This page was last edited on 27 June 2025, at 18:44 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Pi-system 6 languages Add topic

