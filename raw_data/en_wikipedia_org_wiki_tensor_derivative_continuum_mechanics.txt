Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Derivatives with respect to vectors and second-order tensors Toggle Derivatives with respect to vectors and second-order tensors subsection 1.1 Derivatives of scalar valued functions of vectors 1.2 Derivatives of vector valued functions of vectors 1.3 Derivatives of scalar valued functions of second-order tensors 1.4 Derivatives of tensor valued functions of second-order tensors 2 Gradient of a tensor field Toggle Gradient of a tensor field subsection 2.1 Cartesian coordinates 2.2 Curvilinear coordinates 2.2.1 Cylindrical polar coordinates 3 Divergence of a tensor field Toggle Divergence of a tensor field subsection 3.1 Cartesian coordinates 3.2 Curvilinear coordinates 3.2.1 Cylindrical polar coordinates 4 Curl of a tensor field Toggle Curl of a tensor field subsection 4.1 Curl of a first-order tensor (vector) field 4.2 Curl of a second-order tensor field 4.3 Identities involving the curl of a tensor field 5 Derivative of the determinant of a second-order tensor 6 Derivatives of the invariants of a second-order tensor 7 Derivative of the second-order identity tensor 8 Derivative of a second-order tensor with respect to itself 9 Derivative of the inverse of a second-order tensor 10 Integration by parts 11 See also 12 References Toggle the table of contents Tensor derivative (continuum mechanics) 1 language Español Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia The derivatives of scalars , vectors , and second-order tensors with respect to second-order tensors are of considerable use in continuum mechanics . These derivatives are used in the theories of nonlinear elasticity and plasticity , particularly in the design of algorithms for numerical simulations .

[ 1 ] The directional derivative provides a systematic way of finding these derivatives.

[ 2 ] Derivatives with respect to vectors and second-order tensors [ edit ] The definitions of directional derivatives for various situations are given below. It is assumed that the functions are sufficiently smooth that derivatives can be taken.

Derivatives of scalar valued functions of vectors [ edit ] Let f ( v ) be a real valued function of the vector v . Then the derivative of f ( v ) with respect to v (or at v ) is the vector defined through its dot product with any vector u being ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = D f ( v ) [ u ] = [ d d α α f ( v + α α u ) ] α α = 0 {\displaystyle {\frac {\partial f}{\partial \mathbf {v} }}\cdot \mathbf {u} =Df(\mathbf {v} )[\mathbf {u} ]=\left[{\frac {d}{d\alpha }}~f(\mathbf {v} +\alpha ~\mathbf {u} )\right]_{\alpha =0}} for all vectors u . The above dot product yields a scalar, and if u is a unit vector gives the directional derivative of f at v , in the u direction.

Properties: If f ( v ) = f 1 ( v ) + f 2 ( v ) {\displaystyle f(\mathbf {v} )=f_{1}(\mathbf {v} )+f_{2}(\mathbf {v} )} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ( ∂ ∂ f 1 ∂ ∂ v + ∂ ∂ f 2 ∂ ∂ v ) ⋅ ⋅ u {\displaystyle {\frac {\partial f}{\partial \mathbf {v} }}\cdot \mathbf {u} =\left({\frac {\partial f_{1}}{\partial \mathbf {v} }}+{\frac {\partial f_{2}}{\partial \mathbf {v} }}\right)\cdot \mathbf {u} } If f ( v ) = f 1 ( v ) f 2 ( v ) {\displaystyle f(\mathbf {v} )=f_{1}(\mathbf {v} )~f_{2}(\mathbf {v} )} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ( ∂ ∂ f 1 ∂ ∂ v ⋅ ⋅ u ) f 2 ( v ) + f 1 ( v ) ( ∂ ∂ f 2 ∂ ∂ v ⋅ ⋅ u ) {\displaystyle {\frac {\partial f}{\partial \mathbf {v} }}\cdot \mathbf {u} =\left({\frac {\partial f_{1}}{\partial \mathbf {v} }}\cdot \mathbf {u} \right)~f_{2}(\mathbf {v} )+f_{1}(\mathbf {v} )~\left({\frac {\partial f_{2}}{\partial \mathbf {v} }}\cdot \mathbf {u} \right)} If f ( v ) = f 1 ( f 2 ( v ) ) {\displaystyle f(\mathbf {v} )=f_{1}(f_{2}(\mathbf {v} ))} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ∂ ∂ f 1 ∂ ∂ f 2 ∂ ∂ f 2 ∂ ∂ v ⋅ ⋅ u {\displaystyle {\frac {\partial f}{\partial \mathbf {v} }}\cdot \mathbf {u} ={\frac {\partial f_{1}}{\partial f_{2}}}~{\frac {\partial f_{2}}{\partial \mathbf {v} }}\cdot \mathbf {u} } Derivatives of vector valued functions of vectors [ edit ] Let f ( v ) be a vector valued function of the vector v . Then the derivative of f ( v ) with respect to v (or at v ) is the second order tensor defined through its dot product with any vector u being ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = D f ( v ) [ u ] = [ d d α α f ( v + α α u ) ] α α = 0 {\displaystyle {\frac {\partial \mathbf {f} }{\partial \mathbf {v} }}\cdot \mathbf {u} =D\mathbf {f} (\mathbf {v} )[\mathbf {u} ]=\left[{\frac {d}{d\alpha }}~\mathbf {f} (\mathbf {v} +\alpha ~\mathbf {u} )\right]_{\alpha =0}} for all vectors u . The above dot product yields a vector, and if u is a unit vector gives the direction derivative of f at v , in the directional u .

Properties: If f ( v ) = f 1 ( v ) + f 2 ( v ) {\displaystyle \mathbf {f} (\mathbf {v} )=\mathbf {f} _{1}(\mathbf {v} )+\mathbf {f} _{2}(\mathbf {v} )} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ( ∂ ∂ f 1 ∂ ∂ v + ∂ ∂ f 2 ∂ ∂ v ) ⋅ ⋅ u {\displaystyle {\frac {\partial \mathbf {f} }{\partial \mathbf {v} }}\cdot \mathbf {u} =\left({\frac {\partial \mathbf {f} _{1}}{\partial \mathbf {v} }}+{\frac {\partial \mathbf {f} _{2}}{\partial \mathbf {v} }}\right)\cdot \mathbf {u} } If f ( v ) = f 1 ( v ) × × f 2 ( v ) {\displaystyle \mathbf {f} (\mathbf {v} )=\mathbf {f} _{1}(\mathbf {v} )\times \mathbf {f} _{2}(\mathbf {v} )} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ( ∂ ∂ f 1 ∂ ∂ v ⋅ ⋅ u ) × × f 2 ( v ) + f 1 ( v ) × × ( ∂ ∂ f 2 ∂ ∂ v ⋅ ⋅ u ) {\displaystyle {\frac {\partial \mathbf {f} }{\partial \mathbf {v} }}\cdot \mathbf {u} =\left({\frac {\partial \mathbf {f} _{1}}{\partial \mathbf {v} }}\cdot \mathbf {u} \right)\times \mathbf {f} _{2}(\mathbf {v} )+\mathbf {f} _{1}(\mathbf {v} )\times \left({\frac {\partial \mathbf {f} _{2}}{\partial \mathbf {v} }}\cdot \mathbf {u} \right)} If f ( v ) = f 1 ( f 2 ( v ) ) {\displaystyle \mathbf {f} (\mathbf {v} )=\mathbf {f} _{1}(\mathbf {f} _{2}(\mathbf {v} ))} then ∂ ∂ f ∂ ∂ v ⋅ ⋅ u = ∂ ∂ f 1 ∂ ∂ f 2 ⋅ ⋅ ( ∂ ∂ f 2 ∂ ∂ v ⋅ ⋅ u ) {\displaystyle {\frac {\partial \mathbf {f} }{\partial \mathbf {v} }}\cdot \mathbf {u} ={\frac {\partial \mathbf {f} _{1}}{\partial \mathbf {f} _{2}}}\cdot \left({\frac {\partial \mathbf {f} _{2}}{\partial \mathbf {v} }}\cdot \mathbf {u} \right)} Derivatives of scalar valued functions of second-order tensors [ edit ] Let f ( S ) {\displaystyle f({\boldsymbol {S}})} be a real valued function of the second order tensor S {\displaystyle {\boldsymbol {S}}} . Then the derivative of f ( S ) {\displaystyle f({\boldsymbol {S}})} with respect to S {\displaystyle {\boldsymbol {S}}} (or at S {\displaystyle {\boldsymbol {S}}} ) in the direction T {\displaystyle {\boldsymbol {T}}} is the second order tensor defined as ∂ ∂ f ∂ ∂ S : T = D f ( S ) [ T ] = [ d d α α f ( S + α α T ) ] α α = 0 {\displaystyle {\frac {\partial f}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=Df({\boldsymbol {S}})[{\boldsymbol {T}}]=\left[{\frac {d}{d\alpha }}~f({\boldsymbol {S}}+\alpha ~{\boldsymbol {T}})\right]_{\alpha =0}} for all second order tensors T {\displaystyle {\boldsymbol {T}}} .

Properties: If f ( S ) = f 1 ( S ) + f 2 ( S ) {\displaystyle f({\boldsymbol {S}})=f_{1}({\boldsymbol {S}})+f_{2}({\boldsymbol {S}})} then ∂ ∂ f ∂ ∂ S : T = ( ∂ ∂ f 1 ∂ ∂ S + ∂ ∂ f 2 ∂ ∂ S ) : T {\displaystyle {\frac {\partial f}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=\left({\frac {\partial f_{1}}{\partial {\boldsymbol {S}}}}+{\frac {\partial f_{2}}{\partial {\boldsymbol {S}}}}\right):{\boldsymbol {T}}} If f ( S ) = f 1 ( S ) f 2 ( S ) {\displaystyle f({\boldsymbol {S}})=f_{1}({\boldsymbol {S}})~f_{2}({\boldsymbol {S}})} then ∂ ∂ f ∂ ∂ S : T = ( ∂ ∂ f 1 ∂ ∂ S : T ) f 2 ( S ) + f 1 ( S ) ( ∂ ∂ f 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial f}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=\left({\frac {\partial f_{1}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)~f_{2}({\boldsymbol {S}})+f_{1}({\boldsymbol {S}})~\left({\frac {\partial f_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} If f ( S ) = f 1 ( f 2 ( S ) ) {\displaystyle f({\boldsymbol {S}})=f_{1}(f_{2}({\boldsymbol {S}}))} then ∂ ∂ f ∂ ∂ S : T = ∂ ∂ f 1 ∂ ∂ f 2 ( ∂ ∂ f 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial f}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}={\frac {\partial f_{1}}{\partial f_{2}}}~\left({\frac {\partial f_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} Derivatives of tensor valued functions of second-order tensors [ edit ] Let F ( S ) {\displaystyle {\boldsymbol {F}}({\boldsymbol {S}})} be a second order tensor valued function of the second order tensor S {\displaystyle {\boldsymbol {S}}} . Then the derivative of F ( S ) {\displaystyle {\boldsymbol {F}}({\boldsymbol {S}})} with respect to S {\displaystyle {\boldsymbol {S}}} (or at S {\displaystyle {\boldsymbol {S}}} ) in the direction T {\displaystyle {\boldsymbol {T}}} is the fourth order tensor defined as ∂ ∂ F ∂ ∂ S : T = D F ( S ) [ T ] = [ d d α α F ( S + α α T ) ] α α = 0 {\displaystyle {\frac {\partial {\boldsymbol {F}}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=D{\boldsymbol {F}}({\boldsymbol {S}})[{\boldsymbol {T}}]=\left[{\frac {d}{d\alpha }}~{\boldsymbol {F}}({\boldsymbol {S}}+\alpha ~{\boldsymbol {T}})\right]_{\alpha =0}} for all second order tensors T {\displaystyle {\boldsymbol {T}}} .

Properties: If F ( S ) = F 1 ( S ) + F 2 ( S ) {\displaystyle {\boldsymbol {F}}({\boldsymbol {S}})={\boldsymbol {F}}_{1}({\boldsymbol {S}})+{\boldsymbol {F}}_{2}({\boldsymbol {S}})} then ∂ ∂ F ∂ ∂ S : T = ( ∂ ∂ F 1 ∂ ∂ S + ∂ ∂ F 2 ∂ ∂ S ) : T {\displaystyle {\frac {\partial {\boldsymbol {F}}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=\left({\frac {\partial {\boldsymbol {F}}_{1}}{\partial {\boldsymbol {S}}}}+{\frac {\partial {\boldsymbol {F}}_{2}}{\partial {\boldsymbol {S}}}}\right):{\boldsymbol {T}}} If F ( S ) = F 1 ( S ) ⋅ ⋅ F 2 ( S ) {\displaystyle {\boldsymbol {F}}({\boldsymbol {S}})={\boldsymbol {F}}_{1}({\boldsymbol {S}})\cdot {\boldsymbol {F}}_{2}({\boldsymbol {S}})} then ∂ ∂ F ∂ ∂ S : T = ( ∂ ∂ F 1 ∂ ∂ S : T ) ⋅ ⋅ F 2 ( S ) + F 1 ( S ) ⋅ ⋅ ( ∂ ∂ F 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial {\boldsymbol {F}}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}=\left({\frac {\partial {\boldsymbol {F}}_{1}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)\cdot {\boldsymbol {F}}_{2}({\boldsymbol {S}})+{\boldsymbol {F}}_{1}({\boldsymbol {S}})\cdot \left({\frac {\partial {\boldsymbol {F}}_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} If F ( S ) = F 1 ( F 2 ( S ) ) {\displaystyle {\boldsymbol {F}}({\boldsymbol {S}})={\boldsymbol {F}}_{1}({\boldsymbol {F}}_{2}({\boldsymbol {S}}))} then ∂ ∂ F ∂ ∂ S : T = ∂ ∂ F 1 ∂ ∂ F 2 : ( ∂ ∂ F 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial {\boldsymbol {F}}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}={\frac {\partial {\boldsymbol {F}}_{1}}{\partial {\boldsymbol {F}}_{2}}}:\left({\frac {\partial {\boldsymbol {F}}_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} If f ( S ) = f 1 ( F 2 ( S ) ) {\displaystyle f({\boldsymbol {S}})=f_{1}({\boldsymbol {F}}_{2}({\boldsymbol {S}}))} then ∂ ∂ f ∂ ∂ S : T = ∂ ∂ f 1 ∂ ∂ F 2 : ( ∂ ∂ F 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial f}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}={\frac {\partial f_{1}}{\partial {\boldsymbol {F}}_{2}}}:\left({\frac {\partial {\boldsymbol {F}}_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} Gradient of a tensor field [ edit ] The gradient , ∇ ∇ T {\displaystyle {\boldsymbol {\nabla }}{\boldsymbol {T}}} , of a tensor field T ( x ) {\displaystyle {\boldsymbol {T}}(\mathbf {x} )} in the direction of an arbitrary constant vector c is defined as: ∇ ∇ T ⋅ ⋅ c = lim α α → → 0 d d α α T ( x + α α c ) {\displaystyle {\boldsymbol {\nabla }}{\boldsymbol {T}}\cdot \mathbf {c} =\lim _{\alpha \rightarrow 0}\quad {\cfrac {d}{d\alpha }}~{\boldsymbol {T}}(\mathbf {x} +\alpha \mathbf {c} )} The gradient of a tensor field of order n is a tensor field of order n +1.

Cartesian coordinates [ edit ] Note: the Einstein summation convention of summing on repeated indices is used below.

If e 1 , e 2 , e 3 {\displaystyle \mathbf {e} _{1},\mathbf {e} _{2},\mathbf {e} _{3}} are the basis vectors in a Cartesian coordinate system, with coordinates of points denoted by ( x 1 , x 2 , x 3 {\displaystyle x_{1},x_{2},x_{3}} ), then the gradient of the tensor field T {\displaystyle {\boldsymbol {T}}} is given by ∇ ∇ T = ∂ ∂ T ∂ ∂ x i ⊗ ⊗ e i {\displaystyle {\boldsymbol {\nabla }}{\boldsymbol {T}}={\cfrac {\partial {\boldsymbol {T}}}{\partial x_{i}}}\otimes \mathbf {e} _{i}} Proof The vectors x and c can be written as x = x i e i {\displaystyle \mathbf {x} =x_{i}~\mathbf {e} _{i}} and c = c i e i {\displaystyle \mathbf {c} =c_{i}~\mathbf {e} _{i}} . Let y := x + α c . In that case the gradient is given by ∇ ∇ T ⋅ ⋅ c = d d α α T ( x 1 + α α c 1 , x 2 + α α c 2 , x 3 + α α c 3 ) | α α = 0 ≡ ≡ d d α α T ( y 1 , y 2 , y 3 ) | α α = 0 = [ ∂ ∂ T ∂ ∂ y 1 ∂ ∂ y 1 ∂ ∂ α α + ∂ ∂ T ∂ ∂ y 2 ∂ ∂ y 2 ∂ ∂ α α + ∂ ∂ T ∂ ∂ y 3 ∂ ∂ y 3 ∂ ∂ α α ] α α = 0 = [ ∂ ∂ T ∂ ∂ y 1 c 1 + ∂ ∂ T ∂ ∂ y 2 c 2 + ∂ ∂ T ∂ ∂ y 3 c 3 ] α α = 0 = ∂ ∂ T ∂ ∂ x 1 c 1 + ∂ ∂ T ∂ ∂ x 2 c 2 + ∂ ∂ T ∂ ∂ x 3 c 3 ≡ ≡ ∂ ∂ T ∂ ∂ x i c i = ∂ ∂ T ∂ ∂ x i ( e i ⋅ ⋅ c ) = [ ∂ ∂ T ∂ ∂ x i ⊗ ⊗ e i ] ⋅ ⋅ c ◻ ◻ {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}{\boldsymbol {T}}\cdot \mathbf {c} &=\left.{\cfrac {d}{d\alpha }}~{\boldsymbol {T}}(x_{1}+\alpha c_{1},x_{2}+\alpha c_{2},x_{3}+\alpha c_{3})\right|_{\alpha =0}\equiv \left.{\cfrac {d}{d\alpha }}~{\boldsymbol {T}}(y_{1},y_{2},y_{3})\right|_{\alpha =0}\\&=\left[{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{1}}}~{\cfrac {\partial y_{1}}{\partial \alpha }}+{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{2}}}~{\cfrac {\partial y_{2}}{\partial \alpha }}+{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{3}}}~{\cfrac {\partial y_{3}}{\partial \alpha }}\right]_{\alpha =0}=\left[{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{1}}}~c_{1}+{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{2}}}~c_{2}+{\cfrac {\partial {\boldsymbol {T}}}{\partial y_{3}}}~c_{3}\right]_{\alpha =0}\\&={\cfrac {\partial {\boldsymbol {T}}}{\partial x_{1}}}~c_{1}+{\cfrac {\partial {\boldsymbol {T}}}{\partial x_{2}}}~c_{2}+{\cfrac {\partial {\boldsymbol {T}}}{\partial x_{3}}}~c_{3}\equiv {\cfrac {\partial {\boldsymbol {T}}}{\partial x_{i}}}~c_{i}={\cfrac {\partial {\boldsymbol {T}}}{\partial x_{i}}}~(\mathbf {e} _{i}\cdot \mathbf {c} )=\left[{\cfrac {\partial {\boldsymbol {T}}}{\partial x_{i}}}\otimes \mathbf {e} _{i}\right]\cdot \mathbf {c} \qquad \square \end{aligned}}} Since the basis vectors do not vary in a Cartesian coordinate system we have the following relations for the gradients of a scalar field ϕ ϕ {\displaystyle \phi } , a vector field v , and a second-order tensor field S {\displaystyle {\boldsymbol {S}}} .

∇ ∇ ϕ ϕ = ∂ ∂ ϕ ϕ ∂ ∂ x i e i = ϕ ϕ , i e i ∇ ∇ v = ∂ ∂ ( v j e j ) ∂ ∂ x i ⊗ ⊗ e i = ∂ ∂ v j ∂ ∂ x i e j ⊗ ⊗ e i = v j , i e j ⊗ ⊗ e i ∇ ∇ S = ∂ ∂ ( S j k e j ⊗ ⊗ e k ) ∂ ∂ x i ⊗ ⊗ e i = ∂ ∂ S j k ∂ ∂ x i e j ⊗ ⊗ e k ⊗ ⊗ e i = S j k , i e j ⊗ ⊗ e k ⊗ ⊗ e i {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\phi &={\cfrac {\partial \phi }{\partial x_{i}}}~\mathbf {e} _{i}=\phi _{,i}~\mathbf {e} _{i}\\{\boldsymbol {\nabla }}\mathbf {v} &={\cfrac {\partial (v_{j}\mathbf {e} _{j})}{\partial x_{i}}}\otimes \mathbf {e} _{i}={\cfrac {\partial v_{j}}{\partial x_{i}}}~\mathbf {e} _{j}\otimes \mathbf {e} _{i}=v_{j,i}~\mathbf {e} _{j}\otimes \mathbf {e} _{i}\\{\boldsymbol {\nabla }}{\boldsymbol {S}}&={\cfrac {\partial (S_{jk}\mathbf {e} _{j}\otimes \mathbf {e} _{k})}{\partial x_{i}}}\otimes \mathbf {e} _{i}={\cfrac {\partial S_{jk}}{\partial x_{i}}}~\mathbf {e} _{j}\otimes \mathbf {e} _{k}\otimes \mathbf {e} _{i}=S_{jk,i}~\mathbf {e} _{j}\otimes \mathbf {e} _{k}\otimes \mathbf {e} _{i}\end{aligned}}} Curvilinear coordinates [ edit ] Main article: Tensors in curvilinear coordinates Note: the Einstein summation convention of summing on repeated indices is used below.

If g 1 , g 2 , g 3 {\displaystyle \mathbf {g} ^{1},\mathbf {g} ^{2},\mathbf {g} ^{3}} are the contravariant basis vectors in a curvilinear coordinate system, with coordinates of points denoted by ( ξ ξ 1 , ξ ξ 2 , ξ ξ 3 {\displaystyle \xi ^{1},\xi ^{2},\xi ^{3}} ), then the gradient of the tensor field T {\displaystyle {\boldsymbol {T}}} is given by [ 3 ] ∇ ∇ T = ∂ ∂ T ∂ ∂ ξ ξ i ⊗ ⊗ g i {\displaystyle {\boldsymbol {\nabla }}{\boldsymbol {T}}={\frac {\partial {\boldsymbol {T}}}{\partial \xi ^{i}}}\otimes \mathbf {g} ^{i}} From this definition we have the following relations for the gradients of a scalar field ϕ ϕ {\displaystyle \phi } , a vector field v , and a second-order tensor field S {\displaystyle {\boldsymbol {S}}} .

∇ ∇ ϕ ϕ = ∂ ∂ ϕ ϕ ∂ ∂ ξ ξ i g i ∇ ∇ v = ∂ ∂ ( v j g j ) ∂ ∂ ξ ξ i ⊗ ⊗ g i = ( ∂ ∂ v j ∂ ∂ ξ ξ i + v k Γ Γ i k j ) g j ⊗ ⊗ g i = ( ∂ ∂ v j ∂ ∂ ξ ξ i − − v k Γ Γ i j k ) g j ⊗ ⊗ g i ∇ ∇ S = ∂ ∂ ( S j k g j ⊗ ⊗ g k ) ∂ ∂ ξ ξ i ⊗ ⊗ g i = ( ∂ ∂ S j k ∂ ∂ ξ ξ i − − S l k Γ Γ i j l − − S j l Γ Γ i k l ) g j ⊗ ⊗ g k ⊗ ⊗ g i {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\phi &={\frac {\partial \phi }{\partial \xi ^{i}}}~\mathbf {g} ^{i}\\[1.2ex]{\boldsymbol {\nabla }}\mathbf {v} &={\frac {\partial \left(v^{j}\mathbf {g} _{j}\right)}{\partial \xi ^{i}}}\otimes \mathbf {g} ^{i}\\&=\left({\frac {\partial v^{j}}{\partial \xi ^{i}}}+v^{k}~\Gamma _{ik}^{j}\right)~\mathbf {g} _{j}\otimes \mathbf {g} ^{i}=\left({\frac {\partial v_{j}}{\partial \xi ^{i}}}-v_{k}~\Gamma _{ij}^{k}\right)~\mathbf {g} ^{j}\otimes \mathbf {g} ^{i}\\[1.2ex]{\boldsymbol {\nabla }}{\boldsymbol {S}}&={\frac {\partial \left(S_{jk}~\mathbf {g} ^{j}\otimes \mathbf {g} ^{k}\right)}{\partial \xi ^{i}}}\otimes \mathbf {g} ^{i}\\&=\left({\frac {\partial S_{jk}}{\partial \xi _{i}}}-S_{lk}~\Gamma _{ij}^{l}-S_{jl}~\Gamma _{ik}^{l}\right)~\mathbf {g} ^{j}\otimes \mathbf {g} ^{k}\otimes \mathbf {g} ^{i}\end{aligned}}} where the Christoffel symbol Γ Γ i j k {\displaystyle \Gamma _{ij}^{k}} is defined using Γ Γ i j k g k = ∂ ∂ g i ∂ ∂ ξ ξ j ⟹ ⟹ Γ Γ i j k = ∂ ∂ g i ∂ ∂ ξ ξ j ⋅ ⋅ g k = − − g i ⋅ ⋅ ∂ ∂ g k ∂ ∂ ξ ξ j {\displaystyle \Gamma _{ij}^{k}~\mathbf {g} _{k}={\frac {\partial \mathbf {g} _{i}}{\partial \xi ^{j}}}\quad \implies \quad \Gamma _{ij}^{k}={\frac {\partial \mathbf {g} _{i}}{\partial \xi ^{j}}}\cdot \mathbf {g} ^{k}=-\mathbf {g} _{i}\cdot {\frac {\partial \mathbf {g} ^{k}}{\partial \xi ^{j}}}} Cylindrical polar coordinates [ edit ] In cylindrical coordinates , the gradient is given by ∇ ∇ ϕ ϕ = ∂ ∂ ϕ ϕ ∂ ∂ r e r + 1 r ∂ ∂ ϕ ϕ ∂ ∂ θ θ e θ θ + ∂ ∂ ϕ ϕ ∂ ∂ z e z {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\phi ={}\quad &{\frac {\partial \phi }{\partial r}}~\mathbf {e} _{r}+{\frac {1}{r}}~{\frac {\partial \phi }{\partial \theta }}~\mathbf {e} _{\theta }+{\frac {\partial \phi }{\partial z}}~\mathbf {e} _{z}\\\end{aligned}}} ∇ ∇ v = ∂ ∂ v r ∂ ∂ r e r ⊗ ⊗ e r + 1 r ( ∂ ∂ v r ∂ ∂ θ θ − − v θ θ ) e r ⊗ ⊗ e θ θ + ∂ ∂ v r ∂ ∂ z e r ⊗ ⊗ e z + ∂ ∂ v θ θ ∂ ∂ r e θ θ ⊗ ⊗ e r + 1 r ( ∂ ∂ v θ θ ∂ ∂ θ θ + v r ) e θ θ ⊗ ⊗ e θ θ + ∂ ∂ v θ θ ∂ ∂ z e θ θ ⊗ ⊗ e z + ∂ ∂ v z ∂ ∂ r e z ⊗ ⊗ e r + 1 r ∂ ∂ v z ∂ ∂ θ θ e z ⊗ ⊗ e θ θ + ∂ ∂ v z ∂ ∂ z e z ⊗ ⊗ e z {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\mathbf {v} ={}\quad &{\frac {\partial v_{r}}{\partial r}}~\mathbf {e} _{r}\otimes \mathbf {e} _{r}+{\frac {1}{r}}\left({\frac {\partial v_{r}}{\partial \theta }}-v_{\theta }\right)~\mathbf {e} _{r}\otimes \mathbf {e} _{\theta }+{\frac {\partial v_{r}}{\partial z}}~\mathbf {e} _{r}\otimes \mathbf {e} _{z}\\{}+{}&{\frac {\partial v_{\theta }}{\partial r}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{r}+{\frac {1}{r}}\left({\frac {\partial v_{\theta }}{\partial \theta }}+v_{r}\right)~\mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }+{\frac {\partial v_{\theta }}{\partial z}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{z}\\{}+{}&{\frac {\partial v_{z}}{\partial r}}~\mathbf {e} _{z}\otimes \mathbf {e} _{r}+{\frac {1}{r}}{\frac {\partial v_{z}}{\partial \theta }}~\mathbf {e} _{z}\otimes \mathbf {e} _{\theta }+{\frac {\partial v_{z}}{\partial z}}~\mathbf {e} _{z}\otimes \mathbf {e} _{z}\\\end{aligned}}} ∇ ∇ S = ∂ ∂ S r r ∂ ∂ r e r ⊗ ⊗ e r ⊗ ⊗ e r + ∂ ∂ S r r ∂ ∂ z e r ⊗ ⊗ e r ⊗ ⊗ e z + 1 r [ ∂ ∂ S r r ∂ ∂ θ θ − − ( S θ θ r + S r θ θ ) ] e r ⊗ ⊗ e r ⊗ ⊗ e θ θ + ∂ ∂ S r θ θ ∂ ∂ r e r ⊗ ⊗ e θ θ ⊗ ⊗ e r + ∂ ∂ S r θ θ ∂ ∂ z e r ⊗ ⊗ e θ θ ⊗ ⊗ e z + 1 r [ ∂ ∂ S r θ θ ∂ ∂ θ θ + ( S r r − − S θ θ θ θ ) ] e r ⊗ ⊗ e θ θ ⊗ ⊗ e θ θ + ∂ ∂ S r z ∂ ∂ r e r ⊗ ⊗ e z ⊗ ⊗ e r + ∂ ∂ S r z ∂ ∂ z e r ⊗ ⊗ e z ⊗ ⊗ e z + 1 r [ ∂ ∂ S r z ∂ ∂ θ θ − − S θ θ z ] e r ⊗ ⊗ e z ⊗ ⊗ e θ θ + ∂ ∂ S θ θ r ∂ ∂ r e θ θ ⊗ ⊗ e r ⊗ ⊗ e r + ∂ ∂ S θ θ r ∂ ∂ z e θ θ ⊗ ⊗ e r ⊗ ⊗ e z + 1 r [ ∂ ∂ S θ θ r ∂ ∂ θ θ + ( S r r − − S θ θ θ θ ) ] e θ θ ⊗ ⊗ e r ⊗ ⊗ e θ θ + ∂ ∂ S θ θ θ θ ∂ ∂ r e θ θ ⊗ ⊗ e θ θ ⊗ ⊗ e r + ∂ ∂ S θ θ θ θ ∂ ∂ z e θ θ ⊗ ⊗ e θ θ ⊗ ⊗ e z + 1 r [ ∂ ∂ S θ θ θ θ ∂ ∂ θ θ + ( S r θ θ + S θ θ r ) ] e θ θ ⊗ ⊗ e θ θ ⊗ ⊗ e θ θ + ∂ ∂ S θ θ z ∂ ∂ r e θ θ ⊗ ⊗ e z ⊗ ⊗ e r + ∂ ∂ S θ θ z ∂ ∂ z e θ θ ⊗ ⊗ e z ⊗ ⊗ e z + 1 r [ ∂ ∂ S θ θ z ∂ ∂ θ θ + S r z ] e θ θ ⊗ ⊗ e z ⊗ ⊗ e θ θ + ∂ ∂ S z r ∂ ∂ r e z ⊗ ⊗ e r ⊗ ⊗ e r + ∂ ∂ S z r ∂ ∂ z e z ⊗ ⊗ e r ⊗ ⊗ e z + 1 r [ ∂ ∂ S z r ∂ ∂ θ θ − − S z θ θ ] e z ⊗ ⊗ e r ⊗ ⊗ e θ θ + ∂ ∂ S z θ θ ∂ ∂ r e z ⊗ ⊗ e θ θ ⊗ ⊗ e r + ∂ ∂ S z θ θ ∂ ∂ z e z ⊗ ⊗ e θ θ ⊗ ⊗ e z + 1 r [ ∂ ∂ S z θ θ ∂ ∂ θ θ + S z r ] e z ⊗ ⊗ e θ θ ⊗ ⊗ e θ θ + ∂ ∂ S z z ∂ ∂ r e z ⊗ ⊗ e z ⊗ ⊗ e r + ∂ ∂ S z z ∂ ∂ z e z ⊗ ⊗ e z ⊗ ⊗ e z + 1 r ∂ ∂ S z z ∂ ∂ θ θ e z ⊗ ⊗ e z ⊗ ⊗ e θ θ {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}{\boldsymbol {S}}={}\quad &{\frac {\partial S_{rr}}{\partial r}}~\mathbf {e} _{r}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{r}+{\frac {\partial S_{rr}}{\partial z}}~\mathbf {e} _{r}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{rr}}{\partial \theta }}-(S_{\theta r}+S_{r\theta })\right]~\mathbf {e} _{r}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{r\theta }}{\partial r}}~\mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{r}+{\frac {\partial S_{r\theta }}{\partial z}}~\mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{r\theta }}{\partial \theta }}+(S_{rr}-S_{\theta \theta })\right]~\mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{rz}}{\partial r}}~\mathbf {e} _{r}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{r}+{\frac {\partial S_{rz}}{\partial z}}~\mathbf {e} _{r}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{rz}}{\partial \theta }}-S_{\theta z}\right]~\mathbf {e} _{r}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{\theta r}}{\partial r}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{r}+{\frac {\partial S_{\theta r}}{\partial z}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{\theta r}}{\partial \theta }}+(S_{rr}-S_{\theta \theta })\right]~\mathbf {e} _{\theta }\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{\theta \theta }}{\partial r}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{r}+{\frac {\partial S_{\theta \theta }}{\partial z}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{\theta \theta }}{\partial \theta }}+(S_{r\theta }+S_{\theta r})\right]~\mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{\theta z}}{\partial r}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{r}+{\frac {\partial S_{\theta z}}{\partial z}}~\mathbf {e} _{\theta }\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{\theta z}}{\partial \theta }}+S_{rz}\right]~\mathbf {e} _{\theta }\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{zr}}{\partial r}}~\mathbf {e} _{z}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{r}+{\frac {\partial S_{zr}}{\partial z}}~\mathbf {e} _{z}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{zr}}{\partial \theta }}-S_{z\theta }\right]~\mathbf {e} _{z}\otimes \mathbf {e} _{r}\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{z\theta }}{\partial r}}~\mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{r}+{\frac {\partial S_{z\theta }}{\partial z}}~\mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{z}+{\frac {1}{r}}\left[{\frac {\partial S_{z\theta }}{\partial \theta }}+S_{zr}\right]~\mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\otimes \mathbf {e} _{\theta }\\{}+{}&{\frac {\partial S_{zz}}{\partial r}}~\mathbf {e} _{z}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{r}+{\frac {\partial S_{zz}}{\partial z}}~\mathbf {e} _{z}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{z}+{\frac {1}{r}}~{\frac {\partial S_{zz}}{\partial \theta }}~\mathbf {e} _{z}\otimes \mathbf {e} _{z}\otimes \mathbf {e} _{\theta }\end{aligned}}} Divergence of a tensor field [ edit ] The divergence of a tensor field T ( x ) {\displaystyle {\boldsymbol {T}}(\mathbf {x} )} is defined using the recursive relation ( ∇ ∇ ⋅ ⋅ T ) ⋅ ⋅ c = ∇ ∇ ⋅ ⋅ ( c ⋅ ⋅ T T ) ; ∇ ∇ ⋅ ⋅ v = tr ( ∇ ∇ v ) {\displaystyle ({\boldsymbol {\nabla }}\cdot {\boldsymbol {T}})\cdot \mathbf {c} ={\boldsymbol {\nabla }}\cdot \left(\mathbf {c} \cdot {\boldsymbol {T}}^{\textsf {T}}\right)~;\qquad {\boldsymbol {\nabla }}\cdot \mathbf {v} ={\text{tr}}({\boldsymbol {\nabla }}\mathbf {v} )} where c is an arbitrary constant vector and v is a vector field. If T {\displaystyle {\boldsymbol {T}}} is a tensor field of order n > 1 then the divergence of the field is a tensor of order n − 1.

Cartesian coordinates [ edit ] Note: the Einstein summation convention of summing on repeated indices is used below.

In a Cartesian coordinate system we have the following relations for a vector field v and a second-order tensor field S {\displaystyle {\boldsymbol {S}}} .

∇ ∇ ⋅ ⋅ v = ∂ ∂ v i ∂ ∂ x i = v i , i ∇ ∇ ⋅ ⋅ S = ∂ ∂ S i k ∂ ∂ x i e k = S i k , i e k {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot \mathbf {v} &={\frac {\partial v_{i}}{\partial x_{i}}}=v_{i,i}\\{\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}&={\frac {\partial S_{ik}}{\partial x_{i}}}~\mathbf {e} _{k}=S_{ik,i}~\mathbf {e} _{k}\end{aligned}}} where tensor index notation for partial derivatives is used in the rightmost expressions. Note that ∇ ∇ ⋅ ⋅ S ≠ ≠ ∇ ∇ ⋅ ⋅ S T .

{\displaystyle {\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}\neq {\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}^{\textsf {T}}.} For a symmetric second-order tensor, the divergence is also often written as [ 4 ] ∇ ∇ ⋅ ⋅ S = ∂ ∂ S k i ∂ ∂ x i e k = S k i , i e k {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}&={\cfrac {\partial S_{ki}}{\partial x_{i}}}~\mathbf {e} _{k}=S_{ki,i}~\mathbf {e} _{k}\end{aligned}}} The above expression is sometimes used as the definition of ∇ ∇ ⋅ ⋅ S {\displaystyle {\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}} in Cartesian component form (often also written as div ⁡ ⁡ S {\displaystyle \operatorname {div} {\boldsymbol {S}}} ).  Note that such a definition is not consistent with the rest of this article (see the section on curvilinear co-ordinates).

The difference stems from whether the differentiation is performed with respect to the rows or columns of S {\displaystyle {\boldsymbol {S}}} , and is conventional. This is demonstrated by an example. In a Cartesian coordinate system the second order tensor (matrix) S {\displaystyle \mathbf {S} } is the gradient of a vector function v {\displaystyle \mathbf {v} } .

∇ ∇ ⋅ ⋅ ( ∇ ∇ v ) = ∇ ∇ ⋅ ⋅ ( v i , j e i ⊗ ⊗ e j ) = v i , j i e i ⋅ ⋅ e i ⊗ ⊗ e j = ( ∇ ∇ ⋅ ⋅ v ) , j e j = ∇ ∇ ( ∇ ∇ ⋅ ⋅ v ) ∇ ∇ ⋅ ⋅ [ ( ∇ ∇ v ) T ] = ∇ ∇ ⋅ ⋅ ( v j , i e i ⊗ ⊗ e j ) = v j , i i e i ⋅ ⋅ e i ⊗ ⊗ e j = ∇ ∇ 2 v j e j = ∇ ∇ 2 v {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot \left({\boldsymbol {\nabla }}\mathbf {v} \right)&={\boldsymbol {\nabla }}\cdot \left(v_{i,j}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\right)=v_{i,ji}~\mathbf {e} _{i}\cdot \mathbf {e} _{i}\otimes \mathbf {e} _{j}=\left({\boldsymbol {\nabla }}\cdot \mathbf {v} \right)_{,j}~\mathbf {e} _{j}={\boldsymbol {\nabla }}\left({\boldsymbol {\nabla }}\cdot \mathbf {v} \right)\\{\boldsymbol {\nabla }}\cdot \left[\left({\boldsymbol {\nabla }}\mathbf {v} \right)^{\textsf {T}}\right]&={\boldsymbol {\nabla }}\cdot \left(v_{j,i}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\right)=v_{j,ii}~\mathbf {e} _{i}\cdot \mathbf {e} _{i}\otimes \mathbf {e} _{j}={\boldsymbol {\nabla }}^{2}v_{j}~\mathbf {e} _{j}={\boldsymbol {\nabla }}^{2}\mathbf {v} \end{aligned}}} The last equation is equivalent to the alternative definition / interpretation [ 4 ] ( ∇ ∇ ⋅ ⋅ ) alt ( ∇ ∇ v ) = ( ∇ ∇ ⋅ ⋅ ) alt ( v i , j e i ⊗ ⊗ e j ) = v i , j j e i ⊗ ⊗ e j ⋅ ⋅ e j = ∇ ∇ 2 v i e i = ∇ ∇ 2 v {\displaystyle {\begin{aligned}\left({\boldsymbol {\nabla }}\cdot \right)_{\text{alt}}\left({\boldsymbol {\nabla }}\mathbf {v} \right)=\left({\boldsymbol {\nabla }}\cdot \right)_{\text{alt}}\left(v_{i,j}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\right)=v_{i,jj}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\cdot \mathbf {e} _{j}={\boldsymbol {\nabla }}^{2}v_{i}~\mathbf {e} _{i}={\boldsymbol {\nabla }}^{2}\mathbf {v} \end{aligned}}} Curvilinear coordinates [ edit ] Main article: Tensors in curvilinear coordinates Note: the Einstein summation convention of summing on repeated indices is used below.

In curvilinear coordinates, the divergences of a vector field v and a second-order tensor field S {\displaystyle {\boldsymbol {S}}} are ∇ ∇ ⋅ ⋅ v = ( ∂ ∂ v i ∂ ∂ ξ ξ i + v k Γ Γ i k i ) ∇ ∇ ⋅ ⋅ S = ( ∂ ∂ S i k ∂ ∂ ξ ξ i − − S l k Γ Γ i i l − − S i l Γ Γ i k l ) g k {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot \mathbf {v} &=\left({\cfrac {\partial v^{i}}{\partial \xi ^{i}}}+v^{k}~\Gamma _{ik}^{i}\right)\\{\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}&=\left({\cfrac {\partial S_{ik}}{\partial \xi _{i}}}-S_{lk}~\Gamma _{ii}^{l}-S_{il}~\Gamma _{ik}^{l}\right)~\mathbf {g} ^{k}\end{aligned}}} More generally, ∇ ∇ ⋅ ⋅ S = [ ∂ ∂ S i j ∂ ∂ q k − − Γ Γ k i l S l j − − Γ Γ k j l S i l ] g i k b j = [ ∂ ∂ S i j ∂ ∂ q i + Γ Γ i l i S l j + Γ Γ i l j S i l ] b j = [ ∂ ∂ S j i ∂ ∂ q i + Γ Γ i l i S j l − − Γ Γ i j l S l i ] b j = [ ∂ ∂ S i j ∂ ∂ q k − − Γ Γ i k l S l j + Γ Γ k l j S i l ] g i k b j {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}&=\left[{\cfrac {\partial S_{ij}}{\partial q^{k}}}-\Gamma _{ki}^{l}~S_{lj}-\Gamma _{kj}^{l}~S_{il}\right]~g^{ik}~\mathbf {b} ^{j}\\[8pt]&=\left[{\cfrac {\partial S^{ij}}{\partial q^{i}}}+\Gamma _{il}^{i}~S^{lj}+\Gamma _{il}^{j}~S^{il}\right]~\mathbf {b} _{j}\\[8pt]&=\left[{\cfrac {\partial S_{~j}^{i}}{\partial q^{i}}}+\Gamma _{il}^{i}~S_{~j}^{l}-\Gamma _{ij}^{l}~S_{~l}^{i}\right]~\mathbf {b} ^{j}\\[8pt]&=\left[{\cfrac {\partial S_{i}^{~j}}{\partial q^{k}}}-\Gamma _{ik}^{l}~S_{l}^{~j}+\Gamma _{kl}^{j}~S_{i}^{~l}\right]~g^{ik}~\mathbf {b} _{j}\end{aligned}}} Cylindrical polar coordinates [ edit ] In cylindrical polar coordinates ∇ ∇ ⋅ ⋅ v = ∂ ∂ v r ∂ ∂ r + 1 r ( ∂ ∂ v θ θ ∂ ∂ θ θ + v r ) + ∂ ∂ v z ∂ ∂ z ∇ ∇ ⋅ ⋅ S = ∂ ∂ S r r ∂ ∂ r e r + ∂ ∂ S r θ θ ∂ ∂ r e θ θ + ∂ ∂ S r z ∂ ∂ r e z + 1 r [ ∂ ∂ S θ θ r ∂ ∂ θ θ + ( S r r − − S θ θ θ θ ) ] e r + 1 r [ ∂ ∂ S θ θ θ θ ∂ ∂ θ θ + ( S r θ θ + S θ θ r ) ] e θ θ + 1 r [ ∂ ∂ S θ θ z ∂ ∂ θ θ + S r z ] e z + ∂ ∂ S z r ∂ ∂ z e r + ∂ ∂ S z θ θ ∂ ∂ z e θ θ + ∂ ∂ S z z ∂ ∂ z e z {\displaystyle {\begin{aligned}{\boldsymbol {\nabla }}\cdot \mathbf {v} =\quad &{\frac {\partial v_{r}}{\partial r}}+{\frac {1}{r}}\left({\frac {\partial v_{\theta }}{\partial \theta }}+v_{r}\right)+{\frac {\partial v_{z}}{\partial z}}\\{\boldsymbol {\nabla }}\cdot {\boldsymbol {S}}=\quad &{\frac {\partial S_{rr}}{\partial r}}~\mathbf {e} _{r}+{\frac {\partial S_{r\theta }}{\partial r}}~\mathbf {e} _{\theta }+{\frac {\partial S_{rz}}{\partial r}}~\mathbf {e} _{z}\\{}+{}&{\frac {1}{r}}\left[{\frac {\partial S_{\theta r}}{\partial \theta }}+(S_{rr}-S_{\theta \theta })\right]~\mathbf {e} _{r}+{\frac {1}{r}}\left[{\frac {\partial S_{\theta \theta }}{\partial \theta }}+(S_{r\theta }+S_{\theta r})\right]~\mathbf {e} _{\theta }+{\frac {1}{r}}\left[{\frac {\partial S_{\theta z}}{\partial \theta }}+S_{rz}\right]~\mathbf {e} _{z}\\{}+{}&{\frac {\partial S_{zr}}{\partial z}}~\mathbf {e} _{r}+{\frac {\partial S_{z\theta }}{\partial z}}~\mathbf {e} _{\theta }+{\frac {\partial S_{zz}}{\partial z}}~\mathbf {e} _{z}\end{aligned}}} Curl of a tensor field [ edit ] The curl of an order- n > 1 tensor field T ( x ) {\displaystyle {\boldsymbol {T}}(\mathbf {x} )} is also defined using the recursive relation ( ∇ ∇ × × T ) ⋅ ⋅ c = ∇ ∇ × × ( c ⋅ ⋅ T ) ; ( ∇ ∇ × × v ) ⋅ ⋅ c = ∇ ∇ ⋅ ⋅ ( v × × c ) {\displaystyle ({\boldsymbol {\nabla }}\times {\boldsymbol {T}})\cdot \mathbf {c} ={\boldsymbol {\nabla }}\times (\mathbf {c} \cdot {\boldsymbol {T}})~;\qquad ({\boldsymbol {\nabla }}\times \mathbf {v} )\cdot \mathbf {c} ={\boldsymbol {\nabla }}\cdot (\mathbf {v} \times \mathbf {c} )} where c is an arbitrary constant vector and v is a vector field.

Curl of a first-order tensor (vector) field [ edit ] Consider a vector field v and an arbitrary constant vector c . In index notation, the cross product is given by v × × c = ε ε i j k v j c k e i {\displaystyle \mathbf {v} \times \mathbf {c} =\varepsilon _{ijk}~v_{j}~c_{k}~\mathbf {e} _{i}} where ε ε i j k {\displaystyle \varepsilon _{ijk}} is the permutation symbol , otherwise known as the Levi-Civita symbol. Then, ∇ ∇ ⋅ ⋅ ( v × × c ) = ε ε i j k v j , i c k = ( ε ε i j k v j , i e k ) ⋅ ⋅ c = ( ∇ ∇ × × v ) ⋅ ⋅ c {\displaystyle {\boldsymbol {\nabla }}\cdot (\mathbf {v} \times \mathbf {c} )=\varepsilon _{ijk}~v_{j,i}~c_{k}=(\varepsilon _{ijk}~v_{j,i}~\mathbf {e} _{k})\cdot \mathbf {c} =({\boldsymbol {\nabla }}\times \mathbf {v} )\cdot \mathbf {c} } Therefore, ∇ ∇ × × v = ε ε i j k v j , i e k {\displaystyle {\boldsymbol {\nabla }}\times \mathbf {v} =\varepsilon _{ijk}~v_{j,i}~\mathbf {e} _{k}} Curl of a second-order tensor field [ edit ] For a second-order tensor S {\displaystyle {\boldsymbol {S}}} c ⋅ ⋅ S = c m S m j e j {\displaystyle \mathbf {c} \cdot {\boldsymbol {S}}=c_{m}~S_{mj}~\mathbf {e} _{j}} Hence, using the definition of the curl of a first-order tensor field, ∇ ∇ × × ( c ⋅ ⋅ S ) = ε ε i j k c m S m j , i e k = ( ε ε i j k S m j , i e k ⊗ ⊗ e m ) ⋅ ⋅ c = ( ∇ ∇ × × S ) ⋅ ⋅ c {\displaystyle {\boldsymbol {\nabla }}\times (\mathbf {c} \cdot {\boldsymbol {S}})=\varepsilon _{ijk}~c_{m}~S_{mj,i}~\mathbf {e} _{k}=(\varepsilon _{ijk}~S_{mj,i}~\mathbf {e} _{k}\otimes \mathbf {e} _{m})\cdot \mathbf {c} =({\boldsymbol {\nabla }}\times {\boldsymbol {S}})\cdot \mathbf {c} } Therefore, we have ∇ ∇ × × S = ε ε i j k S m j , i e k ⊗ ⊗ e m {\displaystyle {\boldsymbol {\nabla }}\times {\boldsymbol {S}}=\varepsilon _{ijk}~S_{mj,i}~\mathbf {e} _{k}\otimes \mathbf {e} _{m}} Identities involving the curl of a tensor field [ edit ] The most commonly used identity involving the curl of a tensor field, T {\displaystyle {\boldsymbol {T}}} , is ∇ ∇ × × ( ∇ ∇ T ) = 0 {\displaystyle {\boldsymbol {\nabla }}\times ({\boldsymbol {\nabla }}{\boldsymbol {T}})={\boldsymbol {0}}} This identity holds for tensor fields of all orders. For the important case of a second-order tensor, S {\displaystyle {\boldsymbol {S}}} , this identity implies that ∇ ∇ × × ( ∇ ∇ S ) = 0 ⟹ ⟹ S m i , j − − S m j , i = 0 {\displaystyle {\boldsymbol {\nabla }}\times ({\boldsymbol {\nabla }}{\boldsymbol {S}})={\boldsymbol {0}}\quad \implies \quad S_{mi,j}-S_{mj,i}=0} Derivative of the determinant of a second-order tensor [ edit ] The derivative of the determinant of a second order tensor A {\displaystyle {\boldsymbol {A}}} is given by ∂ ∂ ∂ ∂ A det ( A ) = det ( A ) [ A − − 1 ] T .

{\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\det({\boldsymbol {A}})=\det({\boldsymbol {A}})~\left[{\boldsymbol {A}}^{-1}\right]^{\textsf {T}}~.} In an orthonormal basis, the components of A {\displaystyle {\boldsymbol {A}}} can be written as a matrix A . In that case, the right hand side corresponds the cofactors of the matrix.

Proof Let A {\displaystyle {\boldsymbol {A}}} be a second order tensor and let f ( A ) = det ( A ) {\displaystyle f({\boldsymbol {A}})=\det({\boldsymbol {A}})} . Then, from the definition of the derivative of a scalar valued function of a tensor, we have ∂ ∂ f ∂ ∂ A : T = d d α α det ( A + α α T ) | α α = 0 = d d α α det [ α α A ( 1 α α I + A − − 1 ⋅ ⋅ T ) ] | α α = 0 = d d α α [ α α 3 det ( A ) det ( 1 α α I + A − − 1 ⋅ ⋅ T ) ] | α α = 0 .

{\displaystyle {\begin{aligned}{\frac {\partial f}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}&=\left.{\cfrac {d}{d\alpha }}\det({\boldsymbol {A}}+\alpha ~{\boldsymbol {T}})\right|_{\alpha =0}\\&=\left.{\cfrac {d}{d\alpha }}\det \left[\alpha ~{\boldsymbol {A}}\left({\cfrac {1}{\alpha }}~{\boldsymbol {\mathit {I}}}+{\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)\right]\right|_{\alpha =0}\\&=\left.{\cfrac {d}{d\alpha }}\left[\alpha ^{3}~\det({\boldsymbol {A}})~\det \left({\cfrac {1}{\alpha }}~{\boldsymbol {\mathit {I}}}+{\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)\right]\right|_{\alpha =0}.\end{aligned}}} The determinant of a tensor can be expressed in the form of a characteristic equation in terms of the invariants I 1 , I 2 , I 3 {\displaystyle I_{1},I_{2},I_{3}} using det ( λ λ I + A ) = λ λ 3 + I 1 ( A ) λ λ 2 + I 2 ( A ) λ λ + I 3 ( A ) .

{\displaystyle \det(\lambda ~{\boldsymbol {\mathit {I}}}+{\boldsymbol {A}})=\lambda ^{3}+I_{1}({\boldsymbol {A}})~\lambda ^{2}+I_{2}({\boldsymbol {A}})~\lambda +I_{3}({\boldsymbol {A}}).} Using this expansion we can write ∂ ∂ f ∂ ∂ A : T = d d α α [ α α 3 det ( A ) ( 1 α α 3 + I 1 ( A − − 1 ⋅ ⋅ T ) 1 α α 2 + I 2 ( A − − 1 ⋅ ⋅ T ) 1 α α + I 3 ( A − − 1 ⋅ ⋅ T ) ) ] | α α = 0 = det ( A ) d d α α [ 1 + I 1 ( A − − 1 ⋅ ⋅ T ) α α + I 2 ( A − − 1 ⋅ ⋅ T ) α α 2 + I 3 ( A − − 1 ⋅ ⋅ T ) α α 3 ] | α α = 0 = det ( A ) [ I 1 ( A − − 1 ⋅ ⋅ T ) + 2 I 2 ( A − − 1 ⋅ ⋅ T ) α α + 3 I 3 ( A − − 1 ⋅ ⋅ T ) α α 2 ] | α α = 0 = det ( A ) I 1 ( A − − 1 ⋅ ⋅ T ) .

{\displaystyle {\begin{aligned}{\frac {\partial f}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}&=\left.{\cfrac {d}{d\alpha }}\left[\alpha ^{3}~\det({\boldsymbol {A}})~\left({\cfrac {1}{\alpha ^{3}}}+I_{1}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~{\cfrac {1}{\alpha ^{2}}}+I_{2}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~{\cfrac {1}{\alpha }}+I_{3}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)\right)\right]\right|_{\alpha =0}\\&=\left.\det({\boldsymbol {A}})~{\cfrac {d}{d\alpha }}\left[1+I_{1}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~\alpha +I_{2}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~\alpha ^{2}+I_{3}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~\alpha ^{3}\right]\right|_{\alpha =0}\\&=\left.\det({\boldsymbol {A}})~\left[I_{1}({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}})+2~I_{2}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~\alpha +3~I_{3}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~\alpha ^{2}\right]\right|_{\alpha =0}\\&=\det({\boldsymbol {A}})~I_{1}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)~.\end{aligned}}} Recall that the invariant I 1 {\displaystyle I_{1}} is given by I 1 ( A ) = tr A .

{\displaystyle I_{1}({\boldsymbol {A}})={\text{tr}}{\boldsymbol {A}}.} Hence, ∂ ∂ f ∂ ∂ A : T = det ( A ) tr ( A − − 1 ⋅ ⋅ T ) = det ( A ) [ A − − 1 ] T : T .

{\displaystyle {\frac {\partial f}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}=\det({\boldsymbol {A}})~{\text{tr}}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\right)=\det({\boldsymbol {A}})~\left[{\boldsymbol {A}}^{-1}\right]^{\textsf {T}}:{\boldsymbol {T}}.} Invoking the arbitrariness of T {\displaystyle {\boldsymbol {T}}} we then have ∂ ∂ f ∂ ∂ A = det ( A ) [ A − − 1 ] T .

{\displaystyle {\frac {\partial f}{\partial {\boldsymbol {A}}}}=\det({\boldsymbol {A}})~\left[{\boldsymbol {A}}^{-1}\right]^{\textsf {T}}~.} Derivatives of the invariants of a second-order tensor [ edit ] The principal invariants of a second order tensor are I 1 ( A ) = tr A I 2 ( A ) = 1 2 [ ( tr A ) 2 − − tr A 2 ] I 3 ( A ) = det ( A ) {\displaystyle {\begin{aligned}I_{1}({\boldsymbol {A}})&={\text{tr}}{\boldsymbol {A}}\\I_{2}({\boldsymbol {A}})&={\tfrac {1}{2}}\left[({\text{tr}}{\boldsymbol {A}})^{2}-{\text{tr}}{{\boldsymbol {A}}^{2}}\right]\\I_{3}({\boldsymbol {A}})&=\det({\boldsymbol {A}})\end{aligned}}} The derivatives of these three invariants with respect to A {\displaystyle {\boldsymbol {A}}} are ∂ ∂ I 1 ∂ ∂ A = 1 ∂ ∂ I 2 ∂ ∂ A = I 1 1 − − A T ∂ ∂ I 3 ∂ ∂ A = det ( A ) [ A − − 1 ] T = I 2 1 − − A T ( I 1 1 − − A T ) = ( A 2 − − I 1 A + I 2 1 ) T {\displaystyle {\begin{aligned}{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}&={\boldsymbol {\mathit {1}}}\\[3pt]{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}&=I_{1}\,{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\\[3pt]{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}&=\det({\boldsymbol {A}})~\left[{\boldsymbol {A}}^{-1}\right]^{\textsf {T}}\\&=I_{2}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}~\left(I_{1}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\right)=\left({\boldsymbol {A}}^{2}-I_{1}~{\boldsymbol {A}}+I_{2}~{\boldsymbol {\mathit {1}}}\right)^{\textsf {T}}\end{aligned}}} Proof From the derivative of the determinant we know that ∂ ∂ I 3 ∂ ∂ A = det ( A ) [ A − − 1 ] T .

{\displaystyle {\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}=\det({\boldsymbol {A}})~\left[{\boldsymbol {A}}^{-1}\right]^{\textsf {T}}~.} For the derivatives of the other two invariants, let us go back to the characteristic equation det ( λ λ 1 + A ) = λ λ 3 + I 1 ( A ) λ λ 2 + I 2 ( A ) λ λ + I 3 ( A ) .

{\displaystyle \det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})=\lambda ^{3}+I_{1}({\boldsymbol {A}})~\lambda ^{2}+I_{2}({\boldsymbol {A}})~\lambda +I_{3}({\boldsymbol {A}})~.} Using the same approach as for the determinant of a tensor, we can show that ∂ ∂ ∂ ∂ A det ( λ λ 1 + A ) = det ( λ λ 1 + A ) [ ( λ λ 1 + A ) − − 1 ] T .

{\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})=\det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})~\left[(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})^{-1}\right]^{\textsf {T}}~.} Now the left hand side can be expanded as ∂ ∂ ∂ ∂ A det ( λ λ 1 + A ) = ∂ ∂ ∂ ∂ A [ λ λ 3 + I 1 ( A ) λ λ 2 + I 2 ( A ) λ λ + I 3 ( A ) ] = ∂ ∂ I 1 ∂ ∂ A λ λ 2 + ∂ ∂ I 2 ∂ ∂ A λ λ + ∂ ∂ I 3 ∂ ∂ A .

{\displaystyle {\begin{aligned}{\frac {\partial }{\partial {\boldsymbol {A}}}}\det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})&={\frac {\partial }{\partial {\boldsymbol {A}}}}\left[\lambda ^{3}+I_{1}({\boldsymbol {A}})~\lambda ^{2}+I_{2}({\boldsymbol {A}})~\lambda +I_{3}({\boldsymbol {A}})\right]\\&={\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}~.\end{aligned}}} Hence ∂ ∂ I 1 ∂ ∂ A λ λ 2 + ∂ ∂ I 2 ∂ ∂ A λ λ + ∂ ∂ I 3 ∂ ∂ A = det ( λ λ 1 + A ) [ ( λ λ 1 + A ) − − 1 ] T {\displaystyle {\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}=\det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})~\left[(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})^{-1}\right]^{\textsf {T}}} or, ( λ λ 1 + A ) T ⋅ ⋅ [ ∂ ∂ I 1 ∂ ∂ A λ λ 2 + ∂ ∂ I 2 ∂ ∂ A λ λ + ∂ ∂ I 3 ∂ ∂ A ] = det ( λ λ 1 + A ) 1 .

{\displaystyle (\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})^{\textsf {T}}\cdot \left[{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}\right]=\det(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}})~{\boldsymbol {\mathit {1}}}~.} Expanding the right hand side and separating terms on the left hand side gives ( λ λ 1 + A T ) ⋅ ⋅ [ ∂ ∂ I 1 ∂ ∂ A λ λ 2 + ∂ ∂ I 2 ∂ ∂ A λ λ + ∂ ∂ I 3 ∂ ∂ A ] = [ λ λ 3 + I 1 λ λ 2 + I 2 λ λ + I 3 ] 1 {\displaystyle \left(\lambda ~{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}}^{\textsf {T}}\right)\cdot \left[{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}\right]=\left[\lambda ^{3}+I_{1}~\lambda ^{2}+I_{2}~\lambda +I_{3}\right]{\boldsymbol {\mathit {1}}}} or, [ ∂ ∂ I 1 ∂ ∂ A λ λ 3 + ∂ ∂ I 2 ∂ ∂ A λ λ 2 + ∂ ∂ I 3 ∂ ∂ A λ λ ] 1 + A T ⋅ ⋅ ∂ ∂ I 1 ∂ ∂ A λ λ 2 + A T ⋅ ⋅ ∂ ∂ I 2 ∂ ∂ A λ λ + A T ⋅ ⋅ ∂ ∂ I 3 ∂ ∂ A = [ λ λ 3 + I 1 λ λ 2 + I 2 λ λ + I 3 ] 1 .

{\displaystyle {\begin{aligned}\left[{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{3}\right.&\left.+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}~\lambda \right]{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}\\&=\left[\lambda ^{3}+I_{1}~\lambda ^{2}+I_{2}~\lambda +I_{3}\right]{\boldsymbol {\mathit {1}}}~.\end{aligned}}} If we define I 0 := 1 {\displaystyle I_{0}:=1} and I 4 := 0 {\displaystyle I_{4}:=0} , we can write the above as [ ∂ ∂ I 1 ∂ ∂ A λ λ 3 + ∂ ∂ I 2 ∂ ∂ A λ λ 2 + ∂ ∂ I 3 ∂ ∂ A λ λ + ∂ ∂ I 4 ∂ ∂ A ] 1 + A T ⋅ ⋅ ∂ ∂ I 0 ∂ ∂ A λ λ 3 + A T ⋅ ⋅ ∂ ∂ I 1 ∂ ∂ A λ λ 2 + A T ⋅ ⋅ ∂ ∂ I 2 ∂ ∂ A λ λ + A T ⋅ ⋅ ∂ ∂ I 3 ∂ ∂ A = [ I 0 λ λ 3 + I 1 λ λ 2 + I 2 λ λ + I 3 ] 1 .

{\displaystyle {\begin{aligned}\left[{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{3}\right.&\left.+{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}~\lambda +{\frac {\partial I_{4}}{\partial {\boldsymbol {A}}}}\right]{\boldsymbol {\mathit {1}}}+{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{0}}{\partial {\boldsymbol {A}}}}~\lambda ^{3}+{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~\lambda ^{2}+{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~\lambda +{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}\\&=\left[I_{0}~\lambda ^{3}+I_{1}~\lambda ^{2}+I_{2}~\lambda +I_{3}\right]{\boldsymbol {\mathit {1}}}~.\end{aligned}}} Collecting terms containing various powers of λ, we get λ λ 3 ( I 0 1 − − ∂ ∂ I 1 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 0 ∂ ∂ A ) + λ λ 2 ( I 1 1 − − ∂ ∂ I 2 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 1 ∂ ∂ A ) + λ λ ( I 2 1 − − ∂ ∂ I 3 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 2 ∂ ∂ A ) + ( I 3 1 − − ∂ ∂ I 4 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 3 ∂ ∂ A ) = 0 .

{\displaystyle {\begin{aligned}\lambda ^{3}&\left(I_{0}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{0}}{\partial {\boldsymbol {A}}}}\right)+\lambda ^{2}\left(I_{1}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}\right)+\\&\qquad \qquad \lambda \left(I_{2}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}\right)+\left(I_{3}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{4}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}\right)=0~.\end{aligned}}} Then, invoking the arbitrariness of λ, we have I 0 1 − − ∂ ∂ I 1 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 0 ∂ ∂ A = 0 I 1 1 − − ∂ ∂ I 2 ∂ ∂ A 1 − − I 2 1 − − ∂ ∂ I 3 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 2 ∂ ∂ A = 0 I 3 1 − − ∂ ∂ I 4 ∂ ∂ A 1 − − A T ⋅ ⋅ ∂ ∂ I 3 ∂ ∂ A = 0 .

{\displaystyle {\begin{aligned}I_{0}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{0}}{\partial {\boldsymbol {A}}}}&=0\\I_{1}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-I_{2}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}&=0\\I_{3}~{\boldsymbol {\mathit {1}}}-{\frac {\partial I_{4}}{\partial {\boldsymbol {A}}}}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\cdot {\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}&=0~.\end{aligned}}} This implies that ∂ ∂ I 1 ∂ ∂ A = 1 ∂ ∂ I 2 ∂ ∂ A = I 1 1 − − A T ∂ ∂ I 3 ∂ ∂ A = I 2 1 − − A T ( I 1 1 − − A T ) = ( A 2 − − I 1 A + I 2 1 ) T {\displaystyle {\begin{aligned}{\frac {\partial I_{1}}{\partial {\boldsymbol {A}}}}&={\boldsymbol {\mathit {1}}}\\{\frac {\partial I_{2}}{\partial {\boldsymbol {A}}}}&=I_{1}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\\{\frac {\partial I_{3}}{\partial {\boldsymbol {A}}}}&=I_{2}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}~\left(I_{1}~{\boldsymbol {\mathit {1}}}-{\boldsymbol {A}}^{\textsf {T}}\right)=\left({\boldsymbol {A}}^{2}-I_{1}~{\boldsymbol {A}}+I_{2}~{\boldsymbol {\mathit {1}}}\right)^{\textsf {T}}\end{aligned}}} Derivative of the second-order identity tensor [ edit ] Let 1 {\displaystyle {\boldsymbol {\mathit {1}}}} be the second order identity tensor. Then the derivative of this tensor with respect to a second order tensor A {\displaystyle {\boldsymbol {A}}} is given by ∂ ∂ 1 ∂ ∂ A : T = 0 : T = 0 {\displaystyle {\frac {\partial {\boldsymbol {\mathit {1}}}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}={\boldsymbol {\mathsf {0}}}:{\boldsymbol {T}}={\boldsymbol {\mathit {0}}}} This is because 1 {\displaystyle {\boldsymbol {\mathit {1}}}} is independent of A {\displaystyle {\boldsymbol {A}}} .

Derivative of a second-order tensor with respect to itself [ edit ] Let A {\displaystyle {\boldsymbol {A}}} be a second order tensor. Then ∂ ∂ A ∂ ∂ A : T = [ ∂ ∂ ∂ ∂ α α ( A + α α T ) ] α α = 0 = T = I : T {\displaystyle {\frac {\partial {\boldsymbol {A}}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}=\left[{\frac {\partial }{\partial \alpha }}({\boldsymbol {A}}+\alpha ~{\boldsymbol {T}})\right]_{\alpha =0}={\boldsymbol {T}}={\boldsymbol {\mathsf {I}}}:{\boldsymbol {T}}} Therefore, ∂ ∂ A ∂ ∂ A = I {\displaystyle {\frac {\partial {\boldsymbol {A}}}{\partial {\boldsymbol {A}}}}={\boldsymbol {\mathsf {I}}}} Here I {\displaystyle {\boldsymbol {\mathsf {I}}}} is the fourth order identity tensor. In index notation with respect to an orthonormal basis I = δ δ i k δ δ j l e i ⊗ ⊗ e j ⊗ ⊗ e k ⊗ ⊗ e l {\displaystyle {\boldsymbol {\mathsf {I}}}=\delta _{ik}~\delta _{jl}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\otimes \mathbf {e} _{k}\otimes \mathbf {e} _{l}} This result implies that ∂ ∂ A T ∂ ∂ A : T = I T : T = T T {\displaystyle {\frac {\partial {\boldsymbol {A}}^{\textsf {T}}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}={\boldsymbol {\mathsf {I}}}^{\textsf {T}}:{\boldsymbol {T}}={\boldsymbol {T}}^{\textsf {T}}} where I T = δ δ j k δ δ i l e i ⊗ ⊗ e j ⊗ ⊗ e k ⊗ ⊗ e l {\displaystyle {\boldsymbol {\mathsf {I}}}^{\textsf {T}}=\delta _{jk}~\delta _{il}~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\otimes \mathbf {e} _{k}\otimes \mathbf {e} _{l}} Therefore, if the tensor A {\displaystyle {\boldsymbol {A}}} is symmetric, then the derivative is also symmetric and we get ∂ ∂ A ∂ ∂ A = I ( s ) = 1 2 ( I + I T ) {\displaystyle {\frac {\partial {\boldsymbol {A}}}{\partial {\boldsymbol {A}}}}={\boldsymbol {\mathsf {I}}}^{(s)}={\frac {1}{2}}~\left({\boldsymbol {\mathsf {I}}}+{\boldsymbol {\mathsf {I}}}^{\textsf {T}}\right)} where the symmetric fourth order identity tensor is I ( s ) = 1 2 ( δ δ i k δ δ j l + δ δ i l δ δ j k ) e i ⊗ ⊗ e j ⊗ ⊗ e k ⊗ ⊗ e l {\displaystyle {\boldsymbol {\mathsf {I}}}^{(s)}={\frac {1}{2}}~(\delta _{ik}~\delta _{jl}+\delta _{il}~\delta _{jk})~\mathbf {e} _{i}\otimes \mathbf {e} _{j}\otimes \mathbf {e} _{k}\otimes \mathbf {e} _{l}} Derivative of the inverse of a second-order tensor [ edit ] Let A {\displaystyle {\boldsymbol {A}}} and T {\displaystyle {\boldsymbol {T}}} be two second order tensors, then ∂ ∂ ∂ ∂ A ( A − − 1 ) : T = − − A − − 1 ⋅ ⋅ T ⋅ ⋅ A − − 1 {\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\left({\boldsymbol {A}}^{-1}\right):{\boldsymbol {T}}=-{\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\cdot {\boldsymbol {A}}^{-1}} In index notation with respect to an orthonormal basis ∂ ∂ A i j − − 1 ∂ ∂ A k l T k l = − − A i k − − 1 T k l A l j − − 1 ⟹ ⟹ ∂ ∂ A i j − − 1 ∂ ∂ A k l = − − A i k − − 1 A l j − − 1 {\displaystyle {\frac {\partial A_{ij}^{-1}}{\partial A_{kl}}}~T_{kl}=-A_{ik}^{-1}~T_{kl}~A_{lj}^{-1}\implies {\frac {\partial A_{ij}^{-1}}{\partial A_{kl}}}=-A_{ik}^{-1}~A_{lj}^{-1}} We also have ∂ ∂ ∂ ∂ A ( A − − T ) : T = − − A − − T ⋅ ⋅ T T ⋅ ⋅ A − − T {\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\left({\boldsymbol {A}}^{-{\textsf {T}}}\right):{\boldsymbol {T}}=-{\boldsymbol {A}}^{-{\textsf {T}}}\cdot {\boldsymbol {T}}^{\textsf {T}}\cdot {\boldsymbol {A}}^{-{\textsf {T}}}} In index notation ∂ ∂ A j i − − 1 ∂ ∂ A k l T k l = − − A j k − − 1 T l k A l i − − 1 ⟹ ⟹ ∂ ∂ A j i − − 1 ∂ ∂ A k l = − − A l i − − 1 A j k − − 1 {\displaystyle {\frac {\partial A_{ji}^{-1}}{\partial A_{kl}}}~T_{kl}=-A_{jk}^{-1}~T_{lk}~A_{li}^{-1}\implies {\frac {\partial A_{ji}^{-1}}{\partial A_{kl}}}=-A_{li}^{-1}~A_{jk}^{-1}} If the tensor A {\displaystyle {\boldsymbol {A}}} is symmetric then ∂ ∂ A i j − − 1 ∂ ∂ A k l = − − 1 2 ( A i k − − 1 A j l − − 1 + A i l − − 1 A j k − − 1 ) {\displaystyle {\frac {\partial A_{ij}^{-1}}{\partial A_{kl}}}=-{\cfrac {1}{2}}\left(A_{ik}^{-1}~A_{jl}^{-1}+A_{il}^{-1}~A_{jk}^{-1}\right)} Proof Recall that ∂ ∂ 1 ∂ ∂ A : T = 0 {\displaystyle {\frac {\partial {\boldsymbol {\mathit {1}}}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}={\boldsymbol {\mathit {0}}}} Since A − − 1 ⋅ ⋅ A = 1 {\displaystyle {\boldsymbol {A}}^{-1}\cdot {\boldsymbol {A}}={\boldsymbol {\mathit {1}}}} , we can write ∂ ∂ ∂ ∂ A ( A − − 1 ⋅ ⋅ A ) : T = 0 {\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\left({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {A}}\right):{\boldsymbol {T}}={\boldsymbol {\mathit {0}}}} Using the product rule for second order tensors ∂ ∂ ∂ ∂ S [ F 1 ( S ) ⋅ ⋅ F 2 ( S ) ] : T = ( ∂ ∂ F 1 ∂ ∂ S : T ) ⋅ ⋅ F 2 + F 1 ⋅ ⋅ ( ∂ ∂ F 2 ∂ ∂ S : T ) {\displaystyle {\frac {\partial }{\partial {\boldsymbol {S}}}}[{\boldsymbol {F}}_{1}({\boldsymbol {S}})\cdot {\boldsymbol {F}}_{2}({\boldsymbol {S}})]:{\boldsymbol {T}}=\left({\frac {\partial {\boldsymbol {F}}_{1}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)\cdot {\boldsymbol {F}}_{2}+{\boldsymbol {F}}_{1}\cdot \left({\frac {\partial {\boldsymbol {F}}_{2}}{\partial {\boldsymbol {S}}}}:{\boldsymbol {T}}\right)} we get ∂ ∂ ∂ ∂ A ( A − − 1 ⋅ ⋅ A ) : T = ( ∂ ∂ A − − 1 ∂ ∂ A : T ) ⋅ ⋅ A + A − − 1 ⋅ ⋅ ( ∂ ∂ A ∂ ∂ A : T ) = 0 {\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}({\boldsymbol {A}}^{-1}\cdot {\boldsymbol {A}}):{\boldsymbol {T}}=\left({\frac {\partial {\boldsymbol {A}}^{-1}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}\right)\cdot {\boldsymbol {A}}+{\boldsymbol {A}}^{-1}\cdot \left({\frac {\partial {\boldsymbol {A}}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}\right)={\boldsymbol {\mathit {0}}}} or, ( ∂ ∂ A − − 1 ∂ ∂ A : T ) ⋅ ⋅ A = − − A − − 1 ⋅ ⋅ T {\displaystyle \left({\frac {\partial {\boldsymbol {A}}^{-1}}{\partial {\boldsymbol {A}}}}:{\boldsymbol {T}}\right)\cdot {\boldsymbol {A}}=-{\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}} Therefore, ∂ ∂ ∂ ∂ A ( A − − 1 ) : T = − − A − − 1 ⋅ ⋅ T ⋅ ⋅ A − − 1 {\displaystyle {\frac {\partial }{\partial {\boldsymbol {A}}}}\left({\boldsymbol {A}}^{-1}\right):{\boldsymbol {T}}=-{\boldsymbol {A}}^{-1}\cdot {\boldsymbol {T}}\cdot {\boldsymbol {A}}^{-1}} Integration by parts [ edit ] Domain Ω Ω {\displaystyle \Omega } , its boundary Γ Γ {\displaystyle \Gamma } and the outward unit normal n {\displaystyle \mathbf {n} } Another important operation related to tensor derivatives in continuum mechanics is integration by parts. The formula for integration by parts can be written as ∫ ∫ Ω Ω F ⊗ ⊗ ∇ ∇ G d Ω Ω = ∫ ∫ Γ Γ n ⊗ ⊗ ( F ⊗ ⊗ G ) d Γ Γ − − ∫ ∫ Ω Ω G ⊗ ⊗ ∇ ∇ F d Ω Ω {\displaystyle \int _{\Omega }{\boldsymbol {F}}\otimes {\boldsymbol {\nabla }}{\boldsymbol {G}}\,d\Omega =\int _{\Gamma }\mathbf {n} \otimes ({\boldsymbol {F}}\otimes {\boldsymbol {G}})\,d\Gamma -\int _{\Omega }{\boldsymbol {G}}\otimes {\boldsymbol {\nabla }}{\boldsymbol {F}}\,d\Omega } where F {\displaystyle {\boldsymbol {F}}} and G {\displaystyle {\boldsymbol {G}}} are differentiable tensor fields of arbitrary order, n {\displaystyle \mathbf {n} } is the unit outward normal to the domain over which the tensor fields are defined, ⊗ ⊗ {\displaystyle \otimes } represents a generalized tensor product operator, and ∇ ∇ {\displaystyle {\boldsymbol {\nabla }}} is a generalized gradient operator. When F {\displaystyle {\boldsymbol {F}}} is equal to the identity tensor, we get the divergence theorem ∫ ∫ Ω Ω ∇ ∇ G d Ω Ω = ∫ ∫ Γ Γ n ⊗ ⊗ G d Γ Γ .

{\displaystyle \int _{\Omega }{\boldsymbol {\nabla }}{\boldsymbol {G}}\,d\Omega =\int _{\Gamma }\mathbf {n} \otimes {\boldsymbol {G}}\,d\Gamma \,.} We can express the formula for integration by parts in Cartesian index notation as ∫ ∫ Ω Ω F i j k .

.

.

.

G l m n .

.

.

, p d Ω Ω = ∫ ∫ Γ Γ n p F i j k .

.

.

G l m n .

.

.

d Γ Γ − − ∫ ∫ Ω Ω G l m n .

.

.

F i j k .

.

.

, p d Ω Ω .

{\displaystyle \int _{\Omega }F_{ijk....}\,G_{lmn...,p}\,d\Omega =\int _{\Gamma }n_{p}\,F_{ijk...}\,G_{lmn...}\,d\Gamma -\int _{\Omega }G_{lmn...}\,F_{ijk...,p}\,d\Omega \,.} For the special case where the tensor product operation is a contraction of one index and the gradient operation is a divergence, and both F {\displaystyle {\boldsymbol {F}}} and G {\displaystyle {\boldsymbol {G}}} are second order tensors, we have ∫ ∫ Ω Ω F ⋅ ⋅ ( ∇ ∇ ⋅ ⋅ G ) d Ω Ω = ∫ ∫ Γ Γ n ⋅ ⋅ ( G ⋅ ⋅ F T ) d Γ Γ − − ∫ ∫ Ω Ω ( ∇ ∇ F ) : G T d Ω Ω .

{\displaystyle \int _{\Omega }{\boldsymbol {F}}\cdot ({\boldsymbol {\nabla }}\cdot {\boldsymbol {G}})\,d\Omega =\int _{\Gamma }\mathbf {n} \cdot \left({\boldsymbol {G}}\cdot {\boldsymbol {F}}^{\textsf {T}}\right)\,d\Gamma -\int _{\Omega }({\boldsymbol {\nabla }}{\boldsymbol {F}}):{\boldsymbol {G}}^{\textsf {T}}\,d\Omega \,.} <a>evelina</a> In index notation, ∫ ∫ Ω Ω F i j G p j , p d Ω Ω = ∫ ∫ Γ Γ n p F i j G p j d Γ Γ − − ∫ ∫ Ω Ω G p j F i j , p d Ω Ω .

{\displaystyle \int _{\Omega }F_{ij}\,G_{pj,p}\,d\Omega =\int _{\Gamma }n_{p}\,F_{ij}\,G_{pj}\,d\Gamma -\int _{\Omega }G_{pj}\,F_{ij,p}\,d\Omega \,.} See also [ edit ] Covariant derivative Ricci calculus References [ edit ] ^ Simo, J. C.; Hughes, T. J. R. (1998).

Computational Inelasticity . Springer.

doi : 10.1007/b98904 .

ISBN 978-0-387-97520-7 .

^ Marsden, Jerrold E.; Hughes, Thomas J. R. (2000).

Mathematical Foundations of Elasticity . Dover.

ISBN 978-0-486-678658 .

^ Ogden, R. W. (2000).

Nonlinear Elastic Deformations . Dover.

ISBN 978-0-486-696485 .

^ a b Hjelmstad, Keith (2004).

Fundamentals of Structural Mechanics . Springer Science & Business Media. p. 45.

ISBN 978-0-387-233307 .

NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐d4jn7
Cached time: 20250812013509
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.419 seconds
Real time usage: 0.626 seconds
Preprocessor visited node count: 1430/1000000
Revision size: 46219/2097152 bytes
Post‐expand include size: 13638/2097152 bytes
Template argument size: 4909/2097152 bytes
Highest expansion depth: 9/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 24545/5000000 bytes
Lua time usage: 0.182/10.000 seconds
Lua memory usage: 4261202/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  281.202      1 -total
 49.49%  139.165      1 Template:Short_description
 37.97%  106.776      2 Template:Pagetype
 37.48%  105.392      1 Template:Reflist
 32.84%   92.343      4 Template:Cite_book
  7.49%   21.075      3 Template:Main_other
  6.80%   19.132      1 Template:SDcat
  4.49%   12.620      4 Template:Einstein_summation_convention
  3.90%   10.960      1 Template:Hatnote
  3.89%   10.945      2 Template:Main Saved in parser cache with key enwiki:pcache:18637421:|#|:idhash:canonical and timestamp 20250812013509 and revision id 1291393655. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Tensor_derivative_(continuum_mechanics)&oldid=1291393655 " Categories : Solid mechanics Mechanics Hidden categories: Articles with short description Short description with empty Wikidata description This page was last edited on 20 May 2025, at 23:20 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Tensor derivative (continuum mechanics) 1 language Add topic

