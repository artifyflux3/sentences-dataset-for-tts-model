Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Properties Toggle Properties subsection 1.1 Alternative parametrization 1.2 Summation 1.3 Entropy 1.4 Characteristic Function 2 Related distributions Toggle Related distributions subsection 2.1 Special cases 2.2 Conjugate prior for Gaussian 2.3 Sichel distribution 3 Notes 4 References 5 See also Toggle the table of contents Generalized inverse Gaussian distribution 4 languages Català فارسی Français 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Family of continuous probability distributions Generalized inverse Gaussian Probability density function Parameters a > 0, b > 0, p real Support x > 0 PDF f ( x ) = ( a / b ) p / 2 2 K p ( a b ) x ( p − − 1 ) e − − ( a x + b / x ) / 2 {\displaystyle f(x)={\frac {(a/b)^{p/2}}{2K_{p}({\sqrt {ab}})}}x^{(p-1)}e^{-(ax+b/x)/2}} Mean E ⁡ ⁡ [ x ] = b K p + 1 ( a b ) a K p ( a b ) {\displaystyle \operatorname {E} [x]={\frac {{\sqrt {b}}\ K_{p+1}({\sqrt {ab}})}{{\sqrt {a}}\ K_{p}({\sqrt {ab}})}}} E ⁡ ⁡ [ x − − 1 ] = a K p + 1 ( a b ) b K p ( a b ) − − 2 p b {\displaystyle \operatorname {E} [x^{-1}]={\frac {{\sqrt {a}}\ K_{p+1}({\sqrt {ab}})}{{\sqrt {b}}\ K_{p}({\sqrt {ab}})}}-{\frac {2p}{b}}} E ⁡ ⁡ [ ln ⁡ ⁡ x ] = ln ⁡ ⁡ b a + ∂ ∂ ∂ ∂ p ln ⁡ ⁡ K p ( a b ) {\displaystyle \operatorname {E} [\ln x]=\ln {\frac {\sqrt {b}}{\sqrt {a}}}+{\frac {\partial }{\partial p}}\ln K_{p}({\sqrt {ab}})} Mode ( p − − 1 ) + ( p − − 1 ) 2 + a b a {\displaystyle {\frac {(p-1)+{\sqrt {(p-1)^{2}+ab}}}{a}}} Variance ( b a ) [ K p + 2 ( a b ) K p ( a b ) − − ( K p + 1 ( a b ) K p ( a b ) ) 2 ] {\displaystyle \left({\frac {b}{a}}\right)\left[{\frac {K_{p+2}({\sqrt {ab}})}{K_{p}({\sqrt {ab}})}}-\left({\frac {K_{p+1}({\sqrt {ab}})}{K_{p}({\sqrt {ab}})}}\right)^{2}\right]} MGF ( a a − − 2 t ) p 2 K p ( b ( a − − 2 t ) ) K p ( a b ) {\displaystyle \left({\frac {a}{a-2t}}\right)^{\frac {p}{2}}{\frac {K_{p}({\sqrt {b(a-2t)}})}{K_{p}({\sqrt {ab}})}}} CF ( a a − − 2 i t ) p 2 K p ( b ( a − − 2 i t ) ) K p ( a b ) {\displaystyle \left({\frac {a}{a-2it}}\right)^{\frac {p}{2}}{\frac {K_{p}({\sqrt {b(a-2it)}})}{K_{p}({\sqrt {ab}})}}} In probability theory and statistics , the generalized inverse Gaussian distribution ( GIG )  is a three-parameter family of continuous probability distributions with probability density function f ( x ) = ( a / b ) p / 2 2 K p ( a b ) x ( p − − 1 ) e − − ( a x + b / x ) / 2 , x > 0 , {\displaystyle f(x)={\frac {(a/b)^{p/2}}{2K_{p}({\sqrt {ab}})}}x^{(p-1)}e^{-(ax+b/x)/2},\qquad x>0,} where K p is a modified Bessel function of the second kind, a > 0, b > 0 and p a real parameter. It is used extensively in geostatistics , statistical linguistics, finance, etc. This distribution was first proposed by Étienne Halphen .

[ 1 ] [ 2 ] [ 3 ] It was rediscovered and popularised by Ole Barndorff-Nielsen , who called it the generalized inverse Gaussian distribution.  Its statistical properties are discussed in Bent Jørgensen's lecture notes.

[ 4 ] Properties [ edit ] Alternative parametrization [ edit ] By setting θ θ = a b {\displaystyle \theta ={\sqrt {ab}}} and η η = b / a {\displaystyle \eta ={\sqrt {b/a}}} , we can alternatively express the GIG distribution as f ( x ) = 1 2 η η K p ( θ θ ) ( x η η ) p − − 1 e − − θ θ ( x / η η + η η / x ) / 2 , {\displaystyle f(x)={\frac {1}{2\eta K_{p}(\theta )}}\left({\frac {x}{\eta }}\right)^{p-1}e^{-\theta (x/\eta +\eta /x)/2},} where θ θ {\displaystyle \theta } is the concentration parameter while η η {\displaystyle \eta } is the scaling parameter.

Summation [ edit ] Barndorff-Nielsen and Halgreen proved that the GIG distribution is infinitely divisible .

[ 5 ] Entropy [ edit ] The entropy of the generalized inverse Gaussian distribution  is given as [ citation needed ] H = 1 2 log ⁡ ⁡ ( b a ) + log ⁡ ⁡ ( 2 K p ( a b ) ) − − ( p − − 1 ) [ d d ν ν K ν ν ( a b ) ] ν ν = p K p ( a b ) + a b 2 K p ( a b ) ( K p + 1 ( a b ) + K p − − 1 ( a b ) ) {\displaystyle {\begin{aligned}H={\frac {1}{2}}\log \left({\frac {b}{a}}\right)&{}+\log \left(2K_{p}\left({\sqrt {ab}}\right)\right)-(p-1){\frac {\left[{\frac {d}{d\nu }}K_{\nu }\left({\sqrt {ab}}\right)\right]_{\nu =p}}{K_{p}\left({\sqrt {ab}}\right)}}\\&{}+{\frac {\sqrt {ab}}{2K_{p}\left({\sqrt {ab}}\right)}}\left(K_{p+1}\left({\sqrt {ab}}\right)+K_{p-1}\left({\sqrt {ab}}\right)\right)\end{aligned}}} where [ d d ν ν K ν ν ( a b ) ] ν ν = p {\displaystyle \left[{\frac {d}{d\nu }}K_{\nu }\left({\sqrt {ab}}\right)\right]_{\nu =p}} is a derivative of the modified Bessel function of the second kind with respect to the order ν ν {\displaystyle \nu } evaluated at ν ν = p {\displaystyle \nu =p} Characteristic Function [ edit ] The characteristic of a random variable X ∼ ∼ G I G ( p , a , b ) {\displaystyle X\sim GIG(p,a,b)} is given as (for a derivation of the characteristic function, see supplementary materials of [ 6 ] ) E ( e i t X ) = ( a a − − 2 i t ) p 2 K p ( ( a − − 2 i t ) b ) K p ( a b ) {\displaystyle E(e^{itX})=\left({\frac {a}{a-2it}}\right)^{\frac {p}{2}}{\frac {K_{p}\left({\sqrt {(a-2it)b}}\right)}{K_{p}\left({\sqrt {ab}}\right)}}} for t ∈ ∈ R {\displaystyle t\in \mathbb {R} } where i {\displaystyle i} denotes the imaginary number .

Related distributions [ edit ] Special cases [ edit ] The inverse Gaussian and gamma distributions are special cases of the generalized inverse Gaussian distribution for p = −1/2 and b = 0, respectively.

[ 7 ] Specifically, an inverse Gaussian distribution of the form f ( x ; μ μ , λ λ ) = [ λ λ 2 π π x 3 ] 1 / 2 exp ⁡ ⁡ ( − − λ λ ( x − − μ μ ) 2 2 μ μ 2 x ) {\displaystyle f(x;\mu ,\lambda )=\left[{\frac {\lambda }{2\pi x^{3}}}\right]^{1/2}\exp {\left({\frac {-\lambda (x-\mu )^{2}}{2\mu ^{2}x}}\right)}} is a GIG with a = λ λ / μ μ 2 {\displaystyle a=\lambda /\mu ^{2}} , b = λ λ {\displaystyle b=\lambda } , and p = − − 1 / 2 {\displaystyle p=-1/2} .  A Gamma distribution of the form g ( x ; α α , β β ) = β β α α 1 Γ Γ ( α α ) x α α − − 1 e − − β β x {\displaystyle g(x;\alpha ,\beta )=\beta ^{\alpha }{\frac {1}{\Gamma (\alpha )}}x^{\alpha -1}e^{-\beta x}} is a GIG with a = 2 β β {\displaystyle a=2\beta } , b = 0 {\displaystyle b=0} , and p = α α {\displaystyle p=\alpha } .

Other special cases include the inverse-gamma distribution , for a = 0.

[ 7 ] Conjugate prior for Gaussian [ edit ] The GIG distribution is conjugate to the normal distribution when serving as the mixing distribution in a normal variance-mean mixture .

[ 8 ] [ 9 ] Let the prior distribution for some hidden variable, say z {\displaystyle z} , be GIG: P ( z ∣ ∣ a , b , p ) = GIG ⁡ ⁡ ( z ∣ ∣ a , b , p ) {\displaystyle P(z\mid a,b,p)=\operatorname {GIG} (z\mid a,b,p)} and let there be T {\displaystyle T} observed data points, X = x 1 , … … , x T {\displaystyle X=x_{1},\ldots ,x_{T}} , with normal likelihood function, conditioned on z : {\displaystyle z:} P ( X ∣ ∣ z , α α , β β ) = ∏ ∏ i = 1 T N ( x i ∣ ∣ α α + β β z , z ) {\displaystyle P(X\mid z,\alpha ,\beta )=\prod _{i=1}^{T}N(x_{i}\mid \alpha +\beta z,z)} where N ( x ∣ ∣ μ μ , v ) {\displaystyle N(x\mid \mu ,v)} is the normal distribution, with mean μ μ {\displaystyle \mu } and variance v {\displaystyle v} . Then the posterior for z {\displaystyle z} , given the data is also GIG: P ( z ∣ ∣ X , a , b , p , α α , β β ) = GIG ( z ∣ ∣ a + T β β 2 , b + S , p − − T 2 ) {\displaystyle P(z\mid X,a,b,p,\alpha ,\beta )={\text{GIG}}\left(z\mid a+T\beta ^{2},b+S,p-{\frac {T}{2}}\right)} where S = ∑ ∑ i = 1 T ( x i − − α α ) 2 {\displaystyle \textstyle S=\sum _{i=1}^{T}(x_{i}-\alpha )^{2}} .

[ note 1 ] Sichel distribution [ edit ] The Sichel distribution results when the GIG is used as the mixing distribution for the Poisson parameter λ λ {\displaystyle \lambda } .

[ 10 ] [ 11 ] Notes [ edit ] ^ Due to the conjugacy, these details can be derived without solving integrals, by noting that P ( z ∣ ∣ X , a , b , p , α α , β β ) ∝ ∝ P ( z ∣ ∣ a , b , p ) P ( X ∣ ∣ z , α α , β β ) {\displaystyle P(z\mid X,a,b,p,\alpha ,\beta )\propto P(z\mid a,b,p)P(X\mid z,\alpha ,\beta )} .

Omitting all factors independent of z {\displaystyle z} , the right-hand-side can be simplified to give an un-normalized GIG distribution, from which the posterior parameters can be identified.

References [ edit ] ^ Seshadri, V. (1997). "Halphen's laws". In Kotz, S.; Read, C. B.; Banks, D. L. (eds.).

Encyclopedia of Statistical Sciences, Update Volume 1 . New York: Wiley. pp.

302– 306.

^ Perreault, L.; Bobée, B.; Rasmussen, P. F. (1999). "Halphen Distribution System. I: Mathematical and Statistical Properties".

Journal of Hydrologic Engineering .

4 (3): 189.

doi : 10.1061/(ASCE)1084-0699(1999)4:3(189) .

^ Étienne Halphen was the grandson of the mathematician Georges Henri Halphen .

^ Jørgensen, Bent (1982).

Statistical Properties of the Generalized Inverse Gaussian Distribution . Lecture Notes in Statistics. Vol. 9. New York–Berlin: Springer-Verlag.

ISBN 0-387-90665-7 .

MR 0648107 .

^ Barndorff-Nielsen, O.; Halgreen, Christian (1977). "Infinite Divisibility of the Hyperbolic and Generalized Inverse Gaussian Distributions".

Zeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete .

38 : 309– 311.

doi : 10.1007/BF00533162 .

^ Pal, Subhadip; Gaskins, Jeremy (23 May 2022).

"Modified Pólya-Gamma data augmentation for Bayesian analysis of directional data" .

Journal of Statistical Computation and Simulation .

92 (16): 3430– 3451.

doi : 10.1080/00949655.2022.2067853 .

ISSN 0094-9655 .

S2CID 249022546 .

^ a b Johnson, Norman L.; Kotz, Samuel; Balakrishnan, N. (1994), Continuous univariate distributions. Vol. 1 , Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics (2nd ed.), New York: John Wiley & Sons , pp.

284– 285, ISBN 978-0-471-58495-7 , MR 1299979 ^ Karlis, Dimitris (2002). "An EM type algorithm for maximum likelihood estimation of the normal–inverse Gaussian distribution".

Statistics & Probability Letters .

57 (1): 43– 52.

doi : 10.1016/S0167-7152(02)00040-8 .

^ Barndorf-Nielsen, O. E. (1997). "Normal Inverse Gaussian Distributions and stochastic volatility modelling".

Scand. J. Statist .

24 (1): 1– 13.

doi : 10.1111/1467-9469.00045 .

^ Sichel, Herbert S. (1975). "On a distribution law for word frequencies".

Journal of the American Statistical Association .

70 (351a): 542– 547.

doi : 10.1080/01621459.1975.10482469 .

^ Stein, Gillian Z.; Zucchini, Walter; Juritz, June M. (1987). "Parameter estimation for the Sichel distribution and its multivariate extension".

Journal of the American Statistical Association .

82 (399): 938– 944.

doi : 10.1080/01621459.1987.10478520 .

See also [ edit ] Inverse Gaussian distribution Gamma distribution v t e Probability distributions ( list ) Discrete univariate with finite support Benford Bernoulli Beta-binomial Binomial Categorical Hypergeometric Negative Poisson binomial Rademacher Soliton Discrete uniform Zipf Zipf–Mandelbrot with infinite support Beta negative binomial Borel Conway–Maxwell–Poisson Discrete phase-type Delaporte Extended negative binomial Flory–Schulz Gauss–Kuzmin Geometric Logarithmic Mixed Poisson Negative binomial Panjer Parabolic fractal Poisson Skellam Yule–Simon Zeta Continuous univariate supported on a bounded interval Arcsine ARGUS Balding–Nichols Bates Beta Generalized Beta rectangular Continuous Bernoulli Irwin–Hall Kumaraswamy Logit-normal Noncentral beta PERT Raised cosine Reciprocal Triangular U-quadratic Uniform Wigner semicircle supported on a semi-infinite interval Benini Benktander 1st kind Benktander 2nd kind Beta prime Burr Chi Chi-squared Noncentral Inverse Scaled Dagum Davis Erlang Hyper Exponential Hyperexponential Hypoexponential Logarithmic F Noncentral Folded normal Fréchet Gamma Generalized Inverse gamma/Gompertz Gompertz Shifted Half-logistic Half-normal Hotelling's T -squared Hartman–Watson Inverse Gaussian Generalized Kolmogorov Lévy Log-Cauchy Log-Laplace Log-logistic Log-normal Log-t Lomax Matrix-exponential Maxwell–Boltzmann Maxwell–Jüttner Mittag-Leffler Nakagami Pareto Phase-type Poly-Weibull Rayleigh Relativistic Breit–Wigner Rice Truncated normal type-2 Gumbel Weibull Discrete Wilks's lambda supported on the whole real line Cauchy Exponential power Fisher's z Kaniadakis κ-Gaussian Gaussian q Generalized hyperbolic Generalized logistic (logistic-beta) Generalized normal Geometric stable Gumbel Holtsmark Hyperbolic secant Johnson's S U Landau Laplace Asymmetric Logistic Noncentral t Normal (Gaussian) Normal-inverse Gaussian Skew normal Slash Stable Student's t Tracy–Widom Variance-gamma Voigt with support whose type varies Generalized chi-squared Generalized extreme value Generalized Pareto Marchenko–Pastur Kaniadakis κ -exponential Kaniadakis κ -Gamma Kaniadakis κ -Weibull Kaniadakis κ -Logistic Kaniadakis κ -Erlang q -exponential q -Gaussian q -Weibull Shifted log-logistic Tukey lambda Mixed univariate continuous- discrete Rectified Gaussian Multivariate (joint) Discrete: Ewens Multinomial Dirichlet Negative Continuous: Dirichlet Generalized Multivariate Laplace Multivariate normal Multivariate stable Multivariate t Normal-gamma Inverse Matrix-valued: LKJ Matrix beta Matrix normal Matrix t Matrix gamma Inverse Wishart Normal Inverse Normal-inverse Complex Uniform distribution on a Stiefel manifold Directional Univariate (circular) directional Circular uniform Univariate von Mises Wrapped normal Wrapped Cauchy Wrapped exponential Wrapped asymmetric Laplace Wrapped Lévy Bivariate (spherical) Kent Bivariate (toroidal) Bivariate von Mises Multivariate von Mises–Fisher Bingham Degenerate and singular Degenerate Dirac delta function Singular Cantor Families Circular Compound Poisson Elliptical Exponential Natural exponential Location–scale Maximum entropy Mixture Pearson Tweedie Wrapped Category Commons NewPP limit report
Parsed by mw‐web.codfw.main‐7c956d68b4‐8fjwk
Cached time: 20250817092335
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.423 seconds
Real time usage: 0.572 seconds
Preprocessor visited node count: 1971/1000000
Revision size: 10309/2097152 bytes
Post‐expand include size: 93324/2097152 bytes
Template argument size: 2632/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 52544/5000000 bytes
Lua time usage: 0.209/10.000 seconds
Lua memory usage: 6020094/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  352.405      1 -total
 36.45%  128.456      2 Template:Reflist
 25.00%   88.100      4 Template:Navbox
 24.28%   85.553      1 Template:ProbDistributions
 19.87%   70.022      2 Template:Cite_book
 19.43%   68.460      1 Template:Short_description
 10.39%   36.618      2 Template:Pagetype
  9.65%   34.005      7 Template:Cite_journal
  9.58%   33.757      1 Template:Probability_distribution
  8.41%   29.632      1 Template:Citation_needed Saved in parser cache with key enwiki:pcache:2682998:|#|:idhash:canonical and timestamp 20250817092335 and revision id 1287195024. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Generalized_inverse_Gaussian_distribution&oldid=1287195024 " Categories : Continuous distributions Exponential family distributions Hidden categories: Articles with short description Short description is different from Wikidata All articles with unsourced statements Articles with unsourced statements from February 2012 This page was last edited on 24 April 2025, at 16:33 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Generalized inverse Gaussian distribution 4 languages Add topic

