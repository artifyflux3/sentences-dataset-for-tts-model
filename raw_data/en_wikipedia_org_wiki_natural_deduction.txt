Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 History Toggle History subsection 1.1 History of notation styles 2 Notation Toggle Notation subsection 2.1 Gentzen's tree notation 2.2 Suppes–Lemmon notation 3 Propositional language syntax Toggle Propositional language syntax subsection 3.1 Common definition styles 3.2 Gentzen-style definition 4 Gentzen-style propositional logic Toggle Gentzen-style propositional logic subsection 4.1 Gentzen-style inference rules 4.2 Gentzen-style example proofs 5 Fitch-style propositional logic 6 Suppes–Lemmon-style propositional logic Toggle Suppes–Lemmon-style propositional logic subsection 6.1 Suppes–Lemmon-style inference rules 6.2 Suppes–Lemmon-style examples proof 6.2.1 Example 2 6.2.2 Example 3 7 Consistency, completeness, and normal forms 8 First and higher-order extensions 9 Proofs and type theory Toggle Proofs and type theory subsection 9.1 Substitution theorem 9.2 Example: Dependent Type Theory 10 Classical and modal logics Toggle Classical and modal logics subsection 10.1 Modal substitution theorem 11 Comparison with sequent calculus Toggle Comparison with sequent calculus subsection 11.1 Cut (substitution) 12 See also 13 Notes 14 References Toggle References subsection 14.1 General references 15 External links Toggle the table of contents Natural deduction 17 languages Deutsch Español فارسی Français 한국어 Italiano Nederlands 日本語 Norsk bokmål Polski Português Русский Simple English Suomi Svenska 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Kind of proof calculus In logic and proof theory , natural deduction is a kind of proof calculus in which logical reasoning is expressed by inference rules closely related to the "natural" way of reasoning.

[ 1 ] This contrasts with Hilbert-style systems , which instead use axioms as much as possible to express the logical laws of deductive reasoning .

History [ edit ] Natural deduction grew out of a context of dissatisfaction with the axiomatizations of deductive reasoning common to the systems of Hilbert , Frege , and Russell (see, e.g., Hilbert system ). Such axiomatizations were most famously used by Russell and Whitehead in their mathematical treatise Principia Mathematica . Spurred on by a series of seminars in Poland in 1926 by Łukasiewicz that advocated a more natural treatment of logic, Jaśkowski made the earliest attempts at defining a more natural deduction, first in 1929 using a diagrammatic notation, and later updating his proposal in a sequence of papers in 1934 and 1935.

[ 2 ] His proposals led to different notations such as Fitch notation or Suppes ' method, for which Lemmon gave a variant now known as Suppes–Lemmon notation .

Natural deduction in its modern form was independently proposed by the German mathematician Gerhard Gentzen in 1933, in a dissertation delivered to the faculty of mathematical sciences of the University of Göttingen .

[ 3 ] The term natural deduction (or rather, its German equivalent natürliches Schließen ) was coined in that paper: Ich wollte nun zunächst einmal einen Formalismus aufstellen, der dem wirklichen Schließen möglichst nahe kommt. So ergab sich ein "Kalkül des natürlichen Schließens".

[ 4 ] First I wished to construct a formalism that comes as close as possible to actual reasoning. Thus arose a "calculus of natural deduction".

Gentzen was motivated by a desire to establish the consistency of number theory . He was unable to prove the main result required for the consistency result, the cut elimination theorem —the Hauptsatz—directly for natural deduction. For this reason he introduced his alternative system, the sequent calculus , for which he proved the Hauptsatz both for classical and intuitionistic logic . In a series of seminars in 1961 and 1962 Prawitz gave a comprehensive summary of natural deduction calculi, and transported much of Gentzen's work with sequent calculi into the natural deduction framework. His 1965 monograph Natural deduction: a proof-theoretical study [ 5 ] was to become a reference work on natural deduction, and included applications for modal and second-order logic .

In natural deduction, a proposition is deduced from a collection of premises by applying inference rules repeatedly. The system presented in this article is a minor variation of Gentzen's or Prawitz's formulation, but with a closer adherence to Martin-Löf 's description of logical judgments and connectives.

[ 6 ] History of notation styles [ edit ] Natural deduction has had a large variety of notation styles, [ 7 ] which can make it difficult to recognize a proof if you're not familiar with one of them. To help with this situation, this article has a § Notation section explaining how to read all the notation that it will actually use. This section just explains the historical evolution of notation styles, most of which cannot be shown because there are no illustrations available under a public copyright license – the reader is pointed to the SEP and IEP for pictures.

Gentzen invented natural deduction using tree-shaped proofs – see § Gentzen's tree notation for details.

Jaśkowski changed this to a notation that used various nested boxes.

[ 7 ] Fitch changed Jaśkowski method of drawing the boxes, creating Fitch notation .

[ 7 ] 1940: In a textbook, Quine [ 8 ] indicated antecedent dependencies by line numbers in square brackets, anticipating Suppes' 1957 line-number notation.

1950: In a textbook, Quine (1982 , pp. 241–255) demonstrated a method of using one or more asterisks to the left of each line of proof to indicate dependencies. This is equivalent to Kleene's vertical bars. (It is not totally clear if Quine's asterisk notation appeared in the original 1950 edition or was added in a later edition.) 1957: An introduction to practical logic theorem proving in a textbook by Suppes (1999 , pp. 25–150). This indicated dependencies (i.e. antecedent propositions) by line numbers at the left of each line.

1963: Stoll (1979 , pp. 183–190, 215–219) uses sets of line numbers to indicate antecedent dependencies of the lines of sequential logical arguments based on natural deduction inference rules.

1965: The entire textbook by Lemmon (1978) is an introduction to logic proofs using a method based on that of Suppes , what is now known as Suppes–Lemmon notation .

1967: In a textbook, Kleene (2002 , pp. 50–58, 128–130) briefly demonstrated two kinds of practical logic proofs, one system using explicit quotations of antecedent propositions on the left of each line, the other system using vertical bar-lines on the left to indicate dependencies.

[ 9 ] Notation [ edit ] Here is a table with the most common notational variants for logical connectives .

Notational variants of the connectives [ 10 ] [ 11 ] Connective Symbol AND A ∧ ∧ B {\displaystyle A\land B} , A ⋅ ⋅ B {\displaystyle A\cdot B} , A B {\displaystyle AB} , A & & B {\displaystyle A\&B} , A & & & & B {\displaystyle A\&\&B} equivalent A ≡ ≡ B {\displaystyle A\equiv B} , A ⇔ ⇔ B {\displaystyle A\Leftrightarrow B} , A ⇋ ⇋ B {\displaystyle A\leftrightharpoons B} implies A ⇒ ⇒ B {\displaystyle A\Rightarrow B} , A ⊃ ⊃ B {\displaystyle A\supset B} , A → → B {\displaystyle A\rightarrow B} NAND A ∧ ∧ ¯ ¯ B {\displaystyle A{\overline {\land }}B} , A ∣ ∣ B {\displaystyle A\mid B} , A ⋅ ⋅ B ¯ ¯ {\displaystyle {\overline {A\cdot B}}} nonequivalent A ≢ B {\displaystyle A\not \equiv B} , A ⇎ B {\displaystyle A\not \Leftrightarrow B} , A ↮ ↮ B {\displaystyle A\nleftrightarrow B} NOR A ∨ ∨ ¯ ¯ B {\displaystyle A{\overline {\lor }}B} , A ↓ ↓ B {\displaystyle A\downarrow B} , A + B ¯ ¯ {\displaystyle {\overline {A+B}}} NOT ¬ ¬ A {\displaystyle \neg A} , − − A {\displaystyle -A} , A ¯ ¯ {\displaystyle {\overline {A}}} , ∼ ∼ A {\displaystyle \sim A} OR A ∨ ∨ B {\displaystyle A\lor B} , A + B {\displaystyle A+B} , A ∣ ∣ B {\displaystyle A\mid B} , A ∥ ∥ B {\displaystyle A\parallel B} XNOR A {\displaystyle A} XNOR B {\displaystyle B} XOR A ∨ ∨ _ _ B {\displaystyle A{\underline {\lor }}B} , A ⊕ ⊕ B {\displaystyle A\oplus B} Gentzen's tree notation [ edit ] Gentzen , who invented natural deduction, had his own notation style for arguments. This will be exemplified by a simple argument below. Let's say we have a simple example argument in propositional logic , such as, "if it's raining then it's cloudly; it is raining; therefore it's cloudy". (This is in modus ponens .) Representing this as a list of propositions, as is common, we would have: 1 ) P → → Q {\displaystyle 1)~P\to Q} 2 ) P {\displaystyle 2)~P} ∴ ∴ Q {\displaystyle \therefore ~Q} In Gentzen's notation, [ 7 ] this would be written like this: P → → Q , P Q {\displaystyle {\frac {P\to Q,P}{Q}}} The premises are shown above a line, called the inference line , [ 12 ] [ 13 ] separated by a comma , which indicates combination of premises.

[ 14 ] The conclusion is written below the inference line.

[ 12 ] The inference line represents syntactic consequence , [ 12 ] sometimes called deductive consequence , [ 15 ] [ 16 ] which is also symbolized with ⊢.

[ 16 ] So the above can also be written in one line as P → → Q , P ⊢ ⊢ Q {\displaystyle P\to Q,P\vdash Q} . (The turnstile, for syntactic consequence, is of lower precedence than the comma, which represents premise combination, which in turn is of lower precedence than the arrow, used for material implication; so no parentheses are needed to interpret this formula.) [ 14 ] Syntactic consequence is contrasted with semantic consequence , [ 17 ] which is symbolized with ⊧.

[ 18 ] [ 16 ] In this case, the conclusion follows syntactically because natural deduction is a syntactic proof system , which assumes inference rules as primitives .

Gentzen's style will be used in much of this article. Gentzen's discharging annotations used to internalise hypothetical judgments can be avoided by representing proofs as a tree of sequents Γ ⊢A instead of a tree of judgments that A (is true).

Suppes–Lemmon notation [ edit ] Many textbooks use Suppes–Lemmon notation , [ 7 ] so this article will also give that – although as of now, this is only included for propositional logic , and the rest of the coverage is given only in Gentzen style. A proof , laid out in accordance with the Suppes–Lemmon notation style, is a sequence of lines containing sentences, [ 19 ] where each sentence is either an assumption, or the result of applying a rule of proof to earlier sentences in the sequence.

[ 19 ] Each line of proof is made up of a sentence of proof , together with its annotation , its assumption set , and the current line number .

[ 19 ] The assumption set lists the assumptions on which the given sentence of proof depends, which are referenced by the line numbers.

[ 19 ] The annotation specifies which rule of proof was applied, and to which earlier lines, to yield the current sentence.

[ 19 ] Here's an example proof: P → → Q , ¬ ¬ Q ⊢ ⊢ ¬ ¬ P {\displaystyle P\to Q,\neg Q\vdash \neg P} Suppes–Lemmon style proof (first example) Assumption set Line number Formula ( wff ) Annotation 1 1 P → → Q {\displaystyle P\to Q} A 2 2 ¬ ¬ Q {\displaystyle \neg Q} A 3 3 P {\displaystyle P} A 1, 3 4 Q {\displaystyle Q} 1, 3 →E 1, 2 5 ¬ ¬ P {\displaystyle \neg P} 2, 4 RAA Q.E.D This proof will become clearer when the inference rules and their appropriate annotations are specified – see § Propositional inference rules (Suppes–Lemmon style) .

Propositional language syntax [ edit ] Main article: Propositional calculus § Syntax This section defines the formal syntax for a propositional logic language , contrasting the common ways of doing so with a Gentzen-style way of doing so.

Common definition styles [ edit ] In classical propositional calculus the formal language L {\displaystyle {\mathcal {L}}} is usually defined (here: by recursion ) as follows: [ 20 ] Each propositional variable is a formula .

" ⊥ ⊥ {\displaystyle \bot } " is a formula.

If φ φ {\displaystyle \varphi } and ψ ψ {\displaystyle \psi } are formulae, so are ( φ φ ∧ ∧ ψ ψ ) {\displaystyle (\varphi \land \psi )} , ( φ φ ∨ ∨ ψ ψ ) {\displaystyle (\varphi \lor \psi )} , ( φ φ → → ψ ψ ) {\displaystyle (\varphi \to \psi )} , ( φ φ ↔ ↔ ψ ψ ) {\displaystyle (\varphi \leftrightarrow \psi )} .

Nothing else is a formula.

Negation ( ¬ ¬ {\displaystyle \neg } ) is defined as implication to falsity ¬ ¬ ϕ ϕ = def ϕ ϕ → → ⊥ ⊥ {\displaystyle \neg \phi \;{\overset {\text{def}}{=}}\;\phi \to \bot } , where ⊥ ⊥ {\displaystyle \bot } (falsum) represents a contradiction or absolute falsehood.

[ 21 ] [ 22 ] [ 23 ] [ 24 ] [ 25 ] Older publications, and publications that do not focus on logical systems like minimal , intuitionistic or Hilbert systems , take negation as a primitive logical connective , meaning it is assumed as a basic operation and not defined in terms of other connectives.

[ 26 ] [ 27 ] Some authors, such as Bostock , use ⊥ ⊥ {\displaystyle \bot } and ⊤ ⊤ {\displaystyle \top } , and also define ¬ ¬ {\displaystyle \neg } as primitives.

[ 28 ] [ 29 ] Gentzen-style definition [ edit ] A syntax definition can also be given using § Gentzen's tree notation , by writing well-formed formulas below the inference line and any schematic variables used by those formulas above it.

[ 26 ] For instance, the equivalent of rules 3 and 4, from Bostock's definition above, is written as follows: φ φ ( ¬ ¬ φ φ ) φ φ ψ ψ ( φ φ ∨ ∨ ψ ψ ) φ φ ψ ψ ( φ φ ∧ ∧ ψ ψ ) φ φ ψ ψ ( φ φ → → ψ ψ ) φ φ ψ ψ ( φ φ ↔ ↔ ψ ψ ) {\displaystyle {\frac {\varphi }{(\neg \varphi )}}\quad {\frac {\varphi \quad \psi }{(\varphi \lor \psi )}}\quad {\frac {\varphi \quad \psi }{(\varphi \land \psi )}}\quad {\frac {\varphi \quad \psi }{(\varphi \rightarrow \psi )}}\quad {\frac {\varphi \quad \psi }{(\varphi \leftrightarrow \psi )}}} .

A different notational convention sees the language's syntax as a categorial grammar with the single category "formula", denoted by the symbol F {\displaystyle {\mathcal {F}}} . So any elements of the syntax are introduced by categorizations, for which the notation is φ φ : F {\displaystyle \varphi :{\mathcal {F}}} , meaning " φ φ {\displaystyle \varphi } is an expression for an object in the category F {\displaystyle {\mathcal {F}}} ." [ 30 ] The sentence-letters, then, are introduced by categorizations such as P : F {\displaystyle P:{\mathcal {F}}} , Q : F {\displaystyle Q:{\mathcal {F}}} , R : F {\displaystyle R:{\mathcal {F}}} , and so on; [ 30 ] the connectives, in turn, are defined by statements similar to the above, but using categorization notation, as seen below: Connectives defined through a categorial grammar [ 30 ] Conjunction (&) Disjunction (∨) Implication (→) Negation (¬) A : F B : F & & ( A ) ( B ) : F {\displaystyle {\frac {A:{\mathcal {F}}\quad B:{\mathcal {F}}}{\&(A)(B):{\mathcal {F}}}}} A : F B : F ∨ ∨ ( A ) ( B ) : F {\displaystyle {\frac {A:{\mathcal {F}}\quad B:{\mathcal {F}}}{\vee (A)(B):{\mathcal {F}}}}} A : F B : F ⊃ ⊃ ( A ) ( B ) : F {\displaystyle {\frac {A:{\mathcal {F}}\quad B:{\mathcal {F}}}{\supset (A)(B):{\mathcal {F}}}}} A : F ¬ ¬ ( A ) : F {\displaystyle {\frac {A:{\mathcal {F}}}{\neg (A):{\mathcal {F}}}}} In the rest of this article, the φ φ : F {\displaystyle \varphi :{\mathcal {F}}} categorization notation will be used for any Gentzen-notation statements defining the language's grammar; any other statements in Gentzen notation will be inferences, asserting that a sequent follows rather than that an expression is a well-formed formula.

Gentzen-style propositional logic [ edit ] Gentzen-style inference rules [ edit ] Let the propositional language L {\displaystyle {\mathcal {L}}} be inductively defined as Φ Φ ::= p 1 , p 2 , ⋯ ⋯ ∣ ∣ ⊥ ⊥ ∣ ∣ ( Φ Φ → → Φ Φ ) ∣ ∣ ( Φ Φ ∧ ∧ Φ Φ ) ∣ ∣ ( Φ Φ ∨ ∨ Φ Φ ) {\displaystyle \Phi ::=p_{1},p_{2},\dots \mid \bot \mid (\Phi \to \Phi )\mid (\Phi \land \Phi )\mid (\Phi \lor \Phi )} .

Define negation as ¬ ¬ Φ Φ = def ( Φ Φ → → ⊥ ⊥ ) {\displaystyle \neg \Phi \,{\overset {\text{def}}{=}}\,(\Phi \to \bot )} .

The following is a list of primitive inference rules for natural deduction in propositional logic: [ 31 ] [ 26 ] Rules for propositional logic Introduction rules Elimination rules φ φ ψ ψ φ φ ∧ ∧ ψ ψ ( ∧ ∧ I ) {\displaystyle {\begin{array}{c}\varphi \qquad \psi \\\hline \varphi \land \psi \end{array}}(\land _{I})} φ φ ∧ ∧ ψ ψ φ φ ( ∧ ∧ E ) {\displaystyle {\begin{array}{c}\varphi \land \psi \\\hline \varphi \end{array}}(\land _{E})} φ φ φ φ ∨ ∨ ψ ψ ( ∨ ∨ I ) {\displaystyle {\begin{array}{c}\varphi \\\hline \varphi \lor \psi \end{array}}(\lor _{I})} φ φ ∨ ∨ ψ ψ [ φ φ ] u ⋮ ⋮ χ χ [ ψ ψ ] v ⋮ ⋮ χ χ χ χ ∨ ∨ E u , v {\displaystyle {\cfrac {\varphi \lor \psi \quad {\begin{matrix}[\varphi ]^{u}\\\vdots \\\chi \end{matrix}}\quad {\begin{matrix}[\psi ]^{v}\\\vdots \\\chi \end{matrix}}}{\chi }}\ \lor _{E^{u,v}}} [ φ φ ] u ⋮ ⋮ ψ ψ φ φ → → ψ ψ ( → → I ) u {\displaystyle {\begin{array}{c}[\varphi ]^{u}\\\vdots \\\psi \\\hline \varphi \to \psi \end{array}}(\to _{I})\ u} φ φ φ φ → → ψ ψ ψ ψ ( → → E ) {\displaystyle {\begin{array}{c}\varphi \qquad \varphi \to \psi \\\hline \psi \end{array}}(\to _{E})} ⊥ ⊥ φ φ ( ⊥ ⊥ E ) {\displaystyle {\begin{array}{c}\bot \\\hline \varphi \end{array}}(\bot _{E})} [ 32 ] ( φ φ → → ⊥ ⊥ ) → → ⊥ ⊥ φ φ ( ¬ ¬ ¬ ¬ E ) {\displaystyle {\begin{array}{c}(\varphi \to \bot )\to \bot \\\hline \varphi \end{array}}(\neg \neg _{E})} In this table the Greek letters φ φ , ψ ψ , χ χ {\displaystyle \varphi ,\psi ,\chi } are schemata , which range over formulas rather than only over atomic propositions. The name of a rule is given to the right of its formula tree. For instance, the first introduction rule is named ∧ ∧ I {\displaystyle \land _{I}} , which is short for "conjunction introduction".

Minimal logic : the natural deduction rules are N D M P C = { ∧ ∧ I , ∧ ∧ E , ∨ ∨ I , ∨ ∨ E , → → I , → → E } {\displaystyle ND_{MPC}=\{\land _{I},\land _{E},\lor _{I},\lor _{E},\to _{I},\to _{E}\}} .

Without the rules ⊥ ⊥ E {\displaystyle \bot _{E}} and ¬ ¬ ¬ ¬ E {\displaystyle \neg \neg _{E}} the system defines minimal logic (as discussed by Johansson ).

[ 33 ] Intuitionistic logic : the natural deduction rules are N D I P C = N D M P C ∪ ∪ { ⊥ ⊥ E } {\displaystyle ND_{IPC}=ND_{MPC}\cup \{\bot _{E}\}} .

When the rule ⊥ ⊥ E {\displaystyle \bot _{E}} ( principle of explosion ) is added to the rules for minimal logic, the system defines intuitionistic logic.

The statement P → → ¬ ¬ ¬ ¬ P {\displaystyle P\to \neg \neg P} is valid (already in minimal logic, see example 1 below), unlike the reverse implication which would entail the law of excluded middle .

Classical logic : the natural deduction rules are N D C P C = N D I P C ∪ ∪ { ¬ ¬ ¬ ¬ E } {\displaystyle ND_{CPC}=ND_{IPC}\cup \{\neg \neg _{E}\}} .

[ 32 ] When all listed natural deduction rules are admitted, the system defines classical logic.

[ 34 ] [ 35 ] [ 36 ] Gentzen-style example proofs [ edit ] Example 1 : [ 24 ] Proof, within minimal logic, of P → → ¬ ¬ ¬ ¬ P {\displaystyle P\to \neg \neg P} .

Goal: P → → ( ( P → → ⊥ ⊥ ) → → ⊥ ⊥ ) {\displaystyle P\to ((P\to \bot )\to \bot )} Proof: [ P ] v [ P → → ⊥ ⊥ ] u ⊥ ⊥ → → E ( ( P → → ⊥ ⊥ ) → → ⊥ ⊥ ) P → → ( ( P → → ⊥ ⊥ ) → → ⊥ ⊥ ) → → I v → → I u {\displaystyle {\cfrac {{\cfrac {[P]^{v}\qquad [P\to \bot ]^{u}}{\bot }}\to _{E}}{{\cfrac {((P\to \bot )\to \bot )}{P\to ((P\to \bot )\to \bot )}}\to _{I^{v}}}}\to _{I^{u}}} Example 2 : Proof, within minimal logic, of A → → ( B → → ( A ∧ ∧ B ) ) {\displaystyle A\to \left(B\to \left(A\land B\right)\right)} : [ A ] u [ B ] w A ∧ ∧ B ∧ ∧ I B → → ( A ∧ ∧ B ) A → → ( B → → ( A ∧ ∧ B ) ) → → I u → → I w {\displaystyle {\cfrac {{\cfrac {[A]^{u}\quad [B]^{w}}{A\land B}}\ \land _{I}}{{\cfrac {B\to \left(A\land B\right)}{A\to \left(B\to \left(A\land B\right)\right)}}\ \to _{I^{u}}}}\ \to _{I^{w}}} Fitch-style propositional logic [ edit ] Main article: Fitch notation Fitch developed a system of natural deduction which is characterized by linear presentation of the proof, instead of presentation as a tree; subordinate proofs , where assumptions could be opened within a subderivation and discharged later.

Later logicians and educators such as Patrick Suppes [ 37 ] and E. J. Lemmon [ 38 ] rebranded Fitch's system. While they introduced graphical changes—such as replacing indentation with vertical bars—the underlying structure of Fitch-style natural deduction remained intact. These variations are often referred to as the Suppes–Lemmon format, though they are fundamentally based on Fitch's original notation.

Suppes–Lemmon-style propositional logic [ edit ] Main article: Suppes–Lemmon notation Suppes–Lemmon-style inference rules [ edit ] The linear presentation used in Fitch- and Suppes–Lemmon-style proofs — with line numbers and vertical alignment/assumption sets — makes subproofs clearly visible. Fitch (sparingly and cautiously) used derived rules . Suppes–Lemmon went further and added derived rules to the toolbox of natural deduction rules.

Suppes introduced natural deduction using Gentzen-style rules.

[ 37 ] He defined negation in terms of contradiction: ¬ ¬ P ≡ ≡ ( P → → ⊥ ⊥ ) {\displaystyle \neg P\equiv (P\to \bot )} .

He discussed derived rules explicitly, though not always distinguishing them clearly from primitive ones in layout.

His system is close to minimal, but allows derived steps for brevity.

Lemmon formalized more derived rules.

[ 38 ] He as well defined negation as implication to falsity: ¬ ¬ P ≡ ≡ P → → ⊥ ⊥ {\displaystyle \neg P\equiv P\to \bot } . This is not stated as a formal definition in Beginning Logic , but it is implicitly assumed throughout the system. Here's how we know: Use of RAA (Reductio ad Absurdum): Lemmon regularly used RAA in the form: Assume P {\displaystyle P} , derive ⊥ ⊥ {\displaystyle \bot } , then conclude ¬ ¬ P {\displaystyle \neg P} .

This only works if ¬ ¬ P {\displaystyle \neg P} is understood as P → → ⊥ ⊥ {\displaystyle P\to \bot } .

Proofs involving contradiction: Lemmon used the fact that from ¬ ¬ P ∧ ∧ P {\displaystyle \neg P\land P} one can derive ⊥ ⊥ {\displaystyle \bot } .

This requires treating ¬ ¬ P {\displaystyle \neg P} as P → → ⊥ ⊥ {\displaystyle P\to \bot } , so that modus ponens yields contradiction.

Absence of a primitive “¬” rule: Lemmon did not include a standalone rule for introducing or eliminating ¬. Instead, he derived negation using implication and contradiction.

In the table below, based on Lemmon (1978) [ 39 ] and Allen & Hand (2022), [ 19 ] Lemmon's derived rules are highlighted. They can be derived from the (non-highlighted) Gentzen rules.

There are nine primitive rules of proof, which are the rule assumption , plus four pairs of introduction and elimination rules for the binary connectives, and the rules of double negation and reductio ad absurdum , of which only one is needed.

[ 32 ] [ 19 ] Disjunctive Syllogism can be used as an easier alternative to the proper ∨-elimination, [ 19 ] and MTT is a commonly given rule, [ 39 ] although it is not primitive.

[ 19 ] List of Inference Rules Rule Name Alternative names Annotation Assumption set Statement Rule of Assumptions Assumption A The current line number.

At any stage of the argument, introduce a proposition as an assumption of the argument.

Conjunction introduction Ampersand introduction, conjunction (CONJ) [ 40 ] m, n &I The union of the assumption sets at lines m and n .

From φ φ {\displaystyle \varphi } and ψ ψ {\displaystyle \psi } at lines m and n , infer φ φ ∧ ∧ ψ ψ {\displaystyle \varphi \land \psi } .

Conjunction elimination Simplification (S), ampersand elimination m &E The same as at line m .

From φ φ ∧ ∧ ψ ψ {\displaystyle \varphi \land \psi } at line m , infer φ φ {\displaystyle \varphi } and ψ ψ {\displaystyle \psi } .

Disjunction introduction Addition (ADD) m ∨I The same as at line m .

From φ φ {\displaystyle \varphi } at line m , infer φ φ ∨ ∨ ψ ψ {\displaystyle \varphi \lor \psi } , whatever ψ ψ {\displaystyle \psi } may be.

Disjunction elimination Wedge elimination, dilemma (DL) [ 40 ] j,k,l,m,n ∨E The lines j,k,l,m,n .

From φ φ ∨ ∨ ψ ψ {\displaystyle \varphi \lor \psi } at line j , and an assumption of φ φ {\displaystyle \varphi } at line k , and a derivation of χ χ {\displaystyle \chi } from φ φ {\displaystyle \varphi } at line l , and an assumption of ψ ψ {\displaystyle \psi } at line m , and a derivation of χ χ {\displaystyle \chi } from ψ ψ {\displaystyle \psi } at line n , infer χ χ {\displaystyle \chi } .

Arrow introduction Conditional proof (CP), [ 40 ] conditional introduction n, →I (m) Everything in the assumption set at line n , excepting m , the line where the antecedent was assumed.

From ψ ψ {\displaystyle \psi } at line n , following from the assumption of φ φ {\displaystyle \varphi } at line m , infer φ φ → → ψ ψ {\displaystyle \varphi \to \psi } .

Arrow elimination Modus ponendo ponens (MPP), modus ponens (MP), [ 40 ] conditional elimination m, n →E The union of the assumption sets at lines m and n .

From φ φ → → ψ ψ {\displaystyle \varphi \to \psi } at line m , and φ φ {\displaystyle \varphi } at line n , infer ψ ψ {\displaystyle \psi } .

Double negation [ 40 ] Double negation elimination m DN The same as at line m .

From ¬ ¬ ¬ ¬ φ φ {\displaystyle \neg \neg \varphi } at line m , infer φ φ {\displaystyle \varphi } .

Reductio ad absurdum Indirect Proof (IP), negation introduction (¬I), negation elimination (¬E) m, n RAA (k) The union of the assumption sets at lines m and n , excluding k (the denied assumption).

To simplify the statement of the rule, the word "denial" here is used in this way: the denial of a formula φ φ {\displaystyle \varphi } that is not a negation is ¬ ¬ φ φ {\displaystyle \neg \varphi } , whereas a negation , ¬ ¬ φ φ {\displaystyle \neg \varphi } , has two denials , viz., φ φ {\displaystyle \varphi } and ¬ ¬ ¬ ¬ φ φ {\displaystyle \neg \neg \varphi } . at lines m and n , infer the denial of any assumption appearing in the proof (at line k ).

Disjunctive Syllogism Wedge elimination (∨E), modus tollendo ponens (MTP) m,n DS The union of the assumption sets at lines m and n .

From φ φ ∨ ∨ ψ ψ {\displaystyle \varphi \lor \psi } at line m and ¬ ¬ φ φ {\displaystyle \neg \varphi } at line n , infer ψ ψ {\displaystyle \psi } From φ φ ∨ ∨ ψ ψ {\displaystyle \varphi \lor \psi } at line m and ¬ ¬ ψ ψ {\displaystyle \neg \psi } at line n , infer φ φ {\displaystyle \varphi } .

Double arrow introduction Biconditional definition ( Df ↔ ↔ {\displaystyle \leftrightarrow } ), biconditional introduction m, n ↔ ↔ {\displaystyle \leftrightarrow } I The union of the assumption sets at lines m and n .

From φ φ → → ψ ψ {\displaystyle \varphi \to \psi } and ψ ψ → → φ φ {\displaystyle \psi \to \varphi } at lines m and n , infer φ φ ↔ ↔ ψ ψ {\displaystyle \varphi \leftrightarrow \psi } .

Double arrow elimination Biconditional definition ( Df ↔ ↔ {\displaystyle \leftrightarrow } ), biconditional elimination m ↔ ↔ {\displaystyle \leftrightarrow } E The same as at line m .

From φ φ ↔ ↔ ψ ψ {\displaystyle \varphi \leftrightarrow \psi } at line m , infer either φ φ → → ψ ψ {\displaystyle \varphi \to \psi } or ψ ψ → → φ φ {\displaystyle \psi \to \varphi } .

Modus tollendo tollens Modus tollens (MT) m, n MTT The union of the assumption sets at lines m and n .

From φ φ → → ψ ψ {\displaystyle \varphi \to \psi } at line m , and ¬ ¬ ψ ψ {\displaystyle \neg \psi } at line n , infer ¬ ¬ φ φ {\displaystyle \neg \varphi } .

Suppes–Lemmon-style examples proof [ edit ] Recall that an example proof was already given when introducing § Suppes–Lemmon notation . This is a second example.

Example 2 [ edit ] P ∨ ∨ Q , ¬ ¬ P , ¬ ¬ P → → ¬ ¬ Q ⊢ ⊢ ⊥ ⊥ {\displaystyle P\lor Q,\neg P,\neg P\to \neg Q\vdash \bot } contradiction Suppes–Lemmon style proof (second example) Assumption set Line number Formula Annotation 1 1 P ∨ ∨ Q {\displaystyle P\lor Q} A 2 2 ¬ ¬ P {\displaystyle \neg P} A 3 3 ¬ ¬ P → → ¬ ¬ Q {\displaystyle \neg P\to \neg Q} A 2,3 4 ¬ ¬ Q {\displaystyle \neg Q} 2, 3 →E 1,2,3 5 P {\displaystyle P} A (subproof) 1,2,3,5 6 ⊥ ⊥ {\displaystyle \bot } 2, 5 RAA [ 41 ] 1,2,3 7 Q {\displaystyle Q} A (subproof) 1,2,3,7 8 ⊥ ⊥ {\displaystyle \bot } 4, 7 RAA [ 41 ] 1,2,3 9 ⊥ ⊥ {\displaystyle \bot } 1, 5–6, 7–8 vE Q.E.D.

Example 3 [ edit ] The next derivation proves two theorems: lines 1 - 8 prove within minimal logic : ⊢ ⊢ M P C ¬ ¬ ¬ ¬ ( P ∨ ∨ ¬ ¬ P ) {\displaystyle \vdash _{MPC}\neg \neg (P\lor \neg P)} .

lines 1 - 9 prove within classical logic : ⊢ ⊢ C P C P ∨ ∨ ¬ ¬ P {\displaystyle \vdash _{CPC}P\lor \neg P} .

Goals: lines 1 - 8: ⊢ ⊢ M P C ( ( P ∨ ∨ ( P → → ⊥ ⊥ ) ) → → ⊥ ⊥ ) → → ⊥ ⊥ {\displaystyle \vdash _{MPC}((P\lor (P\to \bot ))\to \bot )\to \bot } .

lines 1 - 9: ⊢ ⊢ C P C P ∨ ∨ ( P → → ⊥ ⊥ ) {\displaystyle \vdash _{CPC}P\lor (P\to \bot )} .

⊢ ⊢ P ∨ ∨ ¬ ¬ P {\displaystyle \vdash P\lor \neg P} Suppes–Lemmon style proof (third example) Assumption set Line number Formula Annotation 1 1 ( P ∨ ∨ ( P → → ⊥ ⊥ ) ) → → ⊥ ⊥ {\displaystyle (P\lor (P\to \bot ))\to \bot } A 1, 2 2 P {\displaystyle P} A 1, 2 3 P ∨ ∨ ( P → → ⊥ ⊥ ) {\displaystyle P\lor (P\to \bot )} 2, ∨I 1, 2 4 ⊥ ⊥ {\displaystyle \bot } 1, 3, →E 1 5 P → → ⊥ ⊥ {\displaystyle P\to \bot } 2, 4, →I (discharging 2) 1 6 P ∨ ∨ ( P → → ⊥ ⊥ ) {\displaystyle P\lor (P\to \bot )} 5, ∨I 1 7 ⊥ ⊥ {\displaystyle \bot } 1, 6, →E ∅ 8 ( ( P ∨ ∨ ( P → → ⊥ ⊥ ) ) → → ⊥ ⊥ ) → → ⊥ ⊥ {\displaystyle ((P\lor (P\to \bot ))\to \bot )\to \bot } 1, 7, →I (discharging 1) ∅ 9 P ∨ ∨ ( P → → ⊥ ⊥ ) {\displaystyle P\lor (P\to \bot )} 8, DN Q.E.D Remark : Valery Glivenko proved the following theorem: If φ φ {\displaystyle \varphi } is a propositional formula , then φ φ {\displaystyle \varphi } is a classical tautology if and only if ¬ ¬ ¬ ¬ φ φ {\displaystyle \neg \neg \varphi } is an intuitionistic tautology.

This implies that all classical propositional theorems φ φ {\displaystyle \varphi } can be proved like in this example: Prove ¬ ¬ ¬ ¬ φ φ {\displaystyle \neg \neg \varphi } within intuitionistic logic (i.e. without ¬ ¬ ¬ ¬ E {\displaystyle \neg \neg _{E}} ).

Apply ¬ ¬ ¬ ¬ E {\displaystyle \neg \neg _{E}} to get φ φ {\displaystyle \varphi } from ¬ ¬ ¬ ¬ φ φ {\displaystyle \neg \neg \varphi } .

Consistency, completeness, and normal forms [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) A theory is said to be consistent if falsehood is not provable (from no assumptions) and is complete if every theorem or its negation is provable using the inference rules of the logic. These are statements about the entire logic, and are usually tied to some notion of a model . However, there are local notions of consistency and completeness that are purely syntactic checks on the inference rules, and require no appeals to models. The first of these is local consistency, also known as local reducibility, which says that any derivation containing an introduction of a connective followed immediately by its elimination can be turned into an equivalent derivation without this detour. It is a check on the strength of elimination rules: they must not be so strong that they include knowledge not already contained in their premises. As an example, consider conjunctions.

A u B w A ∧ ∧ B ∧ ∧ I A ∧ ∧ E 1 ⇒ ⇒ A u {\displaystyle {\begin{aligned}{\cfrac {{\cfrac {{\cfrac {}{A\ }}u\qquad {\cfrac {}{B\ }}w}{A\wedge B\ }}\wedge _{I}}{A\ }}\wedge _{E1}\end{aligned}}\quad \Rightarrow \quad {\cfrac {}{A\ }}u} Dually, local completeness says that the elimination rules are strong enough to decompose a connective into the forms suitable for its introduction rule. Again for conjunctions: A ∧ ∧ B u ⇒ ⇒ A ∧ ∧ B u A ∧ ∧ E 1 A ∧ ∧ B u B ∧ ∧ E 2 A ∧ ∧ B ∧ ∧ I {\displaystyle {\cfrac {}{A\wedge B\ }}u\quad \Rightarrow \quad {\begin{aligned}{\cfrac {{\cfrac {{\cfrac {}{A\wedge B\ }}u}{A\ }}\wedge _{E1}\qquad {\cfrac {{\cfrac {}{A\wedge B\ }}u}{B\ }}\wedge _{E2}}{A\wedge B\ }}\wedge _{I}\end{aligned}}} These notions correspond exactly to β-reduction (beta reduction) and η-conversion (eta conversion) in the lambda calculus , using the Curry–Howard isomorphism . By local completeness, we see that every derivation can be converted to an equivalent derivation where the principal connective is introduced. In fact, if the entire derivation obeys this ordering of eliminations followed by introductions, then it is said to be normal . In a normal derivation all eliminations happen above introductions. In most logics, every derivation has an equivalent normal derivation, called a normal form . The existence of normal forms is generally hard to prove using natural deduction alone, though such accounts do exist in the literature, most notably by Dag Prawitz in 1961.

[ 42 ] It is much easier to show this indirectly by means of a cut-free sequent calculus presentation.

First and higher-order extensions [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) Summary of first-order system The logic of the earlier section is an example of a single-sorted logic, i.e.

, a logic with a single kind of object: propositions. Many extensions of this simple framework have been proposed; in this section we will extend it with a second sort of individuals or terms . More precisely, we will add a new category, "term", denoted T {\displaystyle {\mathcal {T}}} . We shall fix a countable set V {\displaystyle V} of variables , another countable set F {\displaystyle F} of function symbols , and construct terms with the following formation rules: v ∈ ∈ V v : T var F {\displaystyle {\frac {v\in V}{v:{\mathcal {T}}}}{\hbox{ var}}_{F}} and f ∈ ∈ F t 1 : T t 2 : T ⋯ ⋯ t n : T f ( t 1 , t 2 , ⋯ ⋯ , t n ) : T app F {\displaystyle {\frac {f\in F\qquad t_{1}:{\mathcal {T}}\qquad t_{2}:{\mathcal {T}}\qquad \cdots \qquad t_{n}:{\mathcal {T}}}{f(t_{1},t_{2},\cdots ,t_{n}):{\mathcal {T}}}}{\hbox{ app}}_{F}} For propositions, we consider a third countable set P of predicates , and define atomic predicates over terms with the following formation rule: ϕ ϕ ∈ ∈ P t 1 : T t 2 : T ⋯ ⋯ t n : T ϕ ϕ ( t 1 , t 2 , ⋯ ⋯ , t n ) : F pred F {\displaystyle {\frac {\phi \in P\qquad t_{1}:{\mathcal {T}}\qquad t_{2}:{\mathcal {T}}\qquad \cdots \qquad t_{n}:{\mathcal {T}}}{\phi (t_{1},t_{2},\cdots ,t_{n}):{\mathcal {F}}}}{\hbox{ pred}}_{F}} The first two rules of formation provide a definition of a term that is effectively the same as that defined in term algebra and model theory , although the focus of those fields of study is quite different from natural deduction. The third rule of formation effectively defines an atomic formula , as in first-order logic , and again in model theory.

To these are added a pair of formation rules, defining the notation for quantified propositions; one for universal (∀) and existential (∃) quantification: x ∈ ∈ V A : F ∀ ∀ x .

A : F ∀ ∀ F x ∈ ∈ V A : F ∃ ∃ x .

A : F ∃ ∃ F {\displaystyle {\frac {x\in V\qquad A:{\mathcal {F}}}{\forall x.A:{\mathcal {F}}}}\;\forall _{F}\qquad \qquad {\frac {x\in V\qquad A:{\mathcal {F}}}{\exists x.A:{\mathcal {F}}}}\;\exists _{F}} The universal quantifier has the introduction and elimination rules: a : T u ⋮ ⋮ [ a / x ] A ∀ ∀ x .

A ∀ ∀ I u , a ∀ ∀ x .

A t : T [ t / x ] A ∀ ∀ E {\displaystyle {\cfrac {\begin{array}{c}{\cfrac {}{a:{\mathcal {T}}}}{\text{ u}}\\\vdots \\{}[a/x]A\end{array}}{\forall x.A}}\;\forall _{I^{u,a}}\qquad \qquad {\frac {\forall x.A\qquad t:{\mathcal {T}}}{[t/x]A}}\;\forall _{E}} The existential quantifier has the introduction and elimination rules: [ t / x ] A ∃ ∃ x .

A ∃ ∃ I a : T u [ a / x ] A v ⏟ ⏟ ⋮ ⋮ ∃ ∃ x .

A C C ∃ ∃ E a , u , v {\displaystyle {\frac {[t/x]A}{\exists x.A}}\;\exists _{I}\qquad \qquad {\cfrac {\begin{array}{cc}&\underbrace {\,{\cfrac {}{a:{\mathcal {T}}}}{\hbox{ u}}\quad {\cfrac {}{[a/x]A}}{\hbox{ v}}\,} \\&\vdots \\\exists x.A\quad &C\\\end{array}}{C}}\exists _{E^{a,u,v}}} In these rules, the notation [ t / x ] A stands for the substitution of t for every (visible) instance of x in A , avoiding capture.

[ 43 ] As before the superscripts on the name stand for the components that are discharged: the term a cannot occur in the conclusion of ∀I (such terms are known as eigenvariables or parameters ), and the hypotheses named u and v in ∃E are localised to the second premise in a hypothetical derivation. Although the propositional logic of earlier sections was decidable , adding the quantifiers makes the logic undecidable.

So far, the quantified extensions are first-order : they distinguish propositions from the kinds of objects quantified over.

Higher-order logic takes a different approach and has only a single sort of propositions. The quantifiers have as the domain of quantification the very same sort of propositions, as reflected in the formation rules: p : F u ⋮ ⋮ A : F ∀ ∀ p .

A : F ∀ ∀ F u p : F u ⋮ ⋮ A : F ∃ ∃ p .

A : F ∃ ∃ F u {\displaystyle {\cfrac {\begin{matrix}{\cfrac {}{p:{\mathcal {F}}}}{\hbox{ u}}\\\vdots \\A:{\mathcal {F}}\\\end{matrix}}{\forall p.A:{\mathcal {F}}}}\;\forall _{F^{u}}\qquad \qquad {\cfrac {\begin{matrix}{\cfrac {}{p:{\mathcal {F}}}}{\hbox{ u}}\\\vdots \\A:{\mathcal {F}}\\\end{matrix}}{\exists p.A:{\mathcal {F}}}}\;\exists _{F^{u}}} A discussion of the introduction and elimination forms for higher-order logic is beyond the scope of this article. It is possible to be in-between first-order and higher-order logics. For example, second-order logic has two kinds of propositions, one kind quantifying over terms, and the second kind quantifying over propositions of the first kind.

Proofs and type theory [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) The presentation of natural deduction so far has concentrated on the nature of propositions without giving a formal definition of a proof . To formalise the notion of proof, we alter the presentation of hypothetical derivations slightly. We label the antecedents with proof variables (from some countable set V of variables), and decorate the succedent with the actual proof. The antecedents or hypotheses are separated from the succedent by means of a turnstile (⊢). This modification sometimes goes under the name of localised hypotheses . The following diagram summarises the change.

──── u 1 ──── u 2 ... ──── u n J 1 J 2 J n ⋮
              J ⇒ u 1 :J 1 , u 2 :J 2 , ..., u n :J n ⊢ J The collection of hypotheses will be written as Γ when their exact composition is not relevant.
To make proofs explicit, we move from the proof-less judgment " A " to a judgment: "π is a proof of (A) ", which is written symbolically as "π : A ". Following the standard approach, proofs are specified with their own formation rules for the judgment "π proof ". The simplest possible proof is the use of a labelled hypothesis; in this case the evidence is the label itself.

u ∈ V
─────── proof-F
u proof ───────────────────── hyp
u:A ⊢ u : A Let us re-examine some of the connectives with explicit proofs. For conjunction, we look at the introduction rule ∧I to discover the form of proofs of conjunction: they must be a pair of proofs of the two conjuncts. Thus: π 1 proof    π 2 proof
──────────────────── pair-F
(π 1 , π 2 ) proof Γ ⊢ π 1 : A    Γ ⊢ π 2 : B
───────────────────────── ∧I
Γ ⊢ (π 1 , π 2 ) : A ∧ B The elimination rules ∧E 1 and ∧E 2 select either the left or the right conjunct; thus the proofs are a pair of projections—first ( fst ) and second ( snd ).

π proof
─────────── fst -F fst π proof Γ ⊢ π : A ∧ B
───────────── ∧E 1 Γ ⊢ fst π : A π proof
─────────── snd -F snd π proof Γ ⊢ π : A ∧ B
───────────── ∧E 2 Γ ⊢ snd π : B For implication, the introduction form localises or binds the hypothesis, written using a λ; this corresponds to the discharged label. In the rule, "Γ, u : A " stands for the collection of hypotheses Γ, together with the additional hypothesis u .

π proof
──────────── λ-F
λu. π proof Γ, u:A ⊢ π : B
───────────────── ⊃I
Γ ⊢ λu. π : A ⊃ B π 1 proof   π 2 proof
─────────────────── app-F
π 1 π 2 proof Γ ⊢ π 1 : A ⊃ B    Γ ⊢ π 2 : A
──────────────────────────── ⊃E
Γ ⊢ π 1 π 2 : B With proofs available explicitly, one can manipulate and reason about proofs. The key operation on proofs is the substitution of one proof for an assumption used in another proof. This is commonly known as a substitution theorem , and can be proved by induction on the depth (or structure) of the second judgment.

Substitution theorem [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) If Γ ⊢ π 1 : A and Γ, u : A ⊢ π 2 : B , then Γ ⊢ [π 1 / u ] π 2 : B.

So far the judgment "Γ ⊢ π : A " has had a purely logical interpretation. In type theory , the logical view is exchanged for a more computational view of objects. Propositions in the logical interpretation are now viewed as types , and proofs as programs in the lambda calculus . Thus the interpretation of "π : A " is " the program π has type A ". The logical connectives are also given a different reading: conjunction is viewed as product (×), implication as the function arrow (→), etc. The differences are only cosmetic, however. Type theory has a natural deduction presentation in terms of formation, introduction and elimination rules; in fact, the reader can easily reconstruct what is known as simple type theory from the previous sections.

The difference between logic and type theory is primarily a shift of focus from the types (propositions) to the programs (proofs). Type theory is chiefly interested in the convertibility or reducibility of programs. For every type, there are canonical programs of that type which are irreducible; these are known as canonical forms or values . If every program can be reduced to a canonical form, then the type theory is said to be normalising (or weakly normalising ). If the canonical form is unique, then the theory is said to be strongly normalising . Normalisability is a rare feature of most non-trivial type theories, which is a big departure from the logical world. (Recall that almost every logical derivation has an equivalent normal derivation.) To sketch the reason: in type theories that admit recursive definitions, it is possible to write programs that never reduce to a value; such looping programs can generally be given any type. In particular, the looping program has type ⊥, although there is no logical proof of "⊥". For this reason, the propositions as types; proofs as programs paradigm only works in one direction, if at all: interpreting a type theory as a logic generally gives an inconsistent logic.

Example: Dependent Type Theory [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) Like logic, type theory has many extensions and variants, including first-order and higher-order versions. One branch, known as dependent type theory , is used in a number of computer-assisted proof systems.  Dependent type theory allows quantifiers to range over programs themselves. These quantified types are written as Π and Σ instead of ∀ and ∃, and have the following formation rules: Γ ⊢ A type    Γ, x:A ⊢ B type
───────────────────────────── Π-F
Γ ⊢ Πx:A. B type Γ ⊢ A type  Γ, x:A ⊢ B type
──────────────────────────── Σ-F
Γ ⊢ Σx:A. B type These types are generalisations of the arrow and product types, respectively, as witnessed by their introduction and elimination rules.

Γ, x:A ⊢ π : B
──────────────────── ΠI
Γ ⊢ λx. π : Πx:A. B Γ ⊢ π 1 : Πx:A. B   Γ ⊢ π 2 : A
───────────────────────────── ΠE
Γ ⊢ π 1 π 2 : [π 2 /x] B Γ ⊢ π 1 : A    Γ, x:A ⊢ π 2 : B
───────────────────────────── ΣI
Γ ⊢ (π 1 , π 2 ) : Σx:A. B Γ ⊢ π : Σx:A. B
──────────────── ΣE 1 Γ ⊢ fst π : A Γ ⊢ π : Σx:A. B
──────────────────────── ΣE 2 Γ ⊢ snd π : [ fst π/x] B Dependent type theory in full generality is very powerful: it is able to express almost any conceivable property of programs directly in the types of the program. This generality comes at a steep price — either typechecking is undecidable ( extensional type theory ), or extensional reasoning is more difficult ( intensional type theory ). For this reason, some dependent type theories do not allow quantification over arbitrary programs, but rather restrict to programs of a given decidable index domain , for example integers, strings, or linear programs.

Since dependent type theories allow types to depend on programs, a natural question to ask is whether it is possible for programs to depend on types, or any other combination. There are many kinds of answers to such questions. A popular approach in type theory is to allow programs to be quantified over types, also known as parametric polymorphism ; of this there are two main kinds: if types and programs are kept separate, then one obtains a somewhat more well-behaved system called predicative polymorphism ; if the distinction between program and type is blurred, one obtains the type-theoretic analogue of higher-order logic, also known as impredicative polymorphism . Various combinations of dependency and polymorphism have been considered in the literature, the most famous being the lambda cube of Henk Barendregt .

The intersection of logic and type theory is a vast and active research area. New logics are usually formalised in a general type theoretic setting, known as a logical framework . Popular modern logical frameworks such as the calculus of constructions and LF are based on higher-order dependent type theory, with various trade-offs in terms of decidability and expressive power. These logical frameworks are themselves always specified as natural deduction systems, which is a testament to the versatility of the natural deduction approach.

Classical and modal logics [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) For simplicity, the logics presented so far have been intuitionistic .

Classical logic extends intuitionistic logic with an additional axiom or principle of excluded middle : For any proposition p, the proposition p ∨ ¬p is true.

This statement is not obviously either an introduction or an elimination; indeed, it involves two distinct connectives. Gentzen's original treatment of excluded middle prescribed one of the following three (equivalent) formulations, which were already present in analogous forms in the systems of Hilbert and Heyting : ────────────── XM 1 A ∨ ¬A ¬¬A
────────── XM 2 A ──────── u ¬A
⋮ p ────── XM 3 u, p A (XM 3 is merely XM 2 expressed in terms of E.) This treatment of excluded middle, in addition to being objectionable from a purist's standpoint, introduces additional complications in the definition of normal forms.

A comparatively more satisfactory treatment of classical natural deduction in terms of introduction and elimination rules alone was first proposed by Parigot in 1992 in the form of a classical lambda calculus called λμ . The key insight of his approach was to replace a truth-centric judgment A with a more classical notion, reminiscent of the sequent calculus : in localised form, instead of Γ ⊢ A , he used Γ ⊢ Δ, with Δ a collection of propositions similar to Γ. Γ was treated as a conjunction, and Δ as a disjunction. This structure is essentially lifted directly from classical sequent calculi , but the innovation in λμ was to give a computational meaning to classical natural deduction proofs in terms of a callcc or a throw/catch mechanism seen in LISP and its descendants. (See also: first class control .) Another important extension was for modal and other logics that need more than just the basic judgment of truth. These were first described, for the alethic modal logics S4 and S5 , in a natural deduction style by Prawitz in 1965, [ 5 ] and have since accumulated a large body of related work. To give a simple example, the modal logic S4 requires one new judgment, " A valid ", that is categorical with respect to truth: If "A" (is true) under no assumption that "B" (is true), then "A valid".

This categorical judgment is internalised as a unary connective ◻ A (read " necessarily A ") with the following introduction and elimination rules: A valid
──────── ◻I
◻ A ◻ A
──────── ◻E
A Note that the premise " A valid " has no defining rules; instead, the categorical definition of validity is used in its place. This mode becomes clearer in the localised form when the hypotheses are explicit. We write "Ω;Γ ⊢ A " where Γ contains the true hypotheses as before, and Ω contains valid hypotheses. On the right there is just a single judgment " A "; validity is not needed here since "Ω ⊢ A valid " is by definition the same as "Ω;⋅ ⊢ A ". The introduction and elimination forms are then: Ω;⋅ ⊢ π : A
──────────────────── ◻I
Ω;⋅ ⊢ box π : ◻ A Ω;Γ ⊢ π : ◻ A
────────────────────── ◻E
Ω;Γ ⊢ unbox π : A The modal hypotheses have their own version of the hypothesis rule and substitution theorem.

─────────────────────────────── valid-hyp
Ω, u: (A valid) ; Γ ⊢ u : A Modal substitution theorem [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) If Ω;⋅ ⊢ π 1 : A and Ω, u : ( A valid ) ; Γ ⊢ π 2 : C , then Ω;Γ ⊢ [π 1 / u ] π 2 : C .

This framework of separating judgments into distinct collections of hypotheses, also known as multi-zoned or polyadic contexts, is very powerful and extensible; it has been applied for many different modal logics, and also for linear and other substructural logics , to give a few examples. However, relatively few systems of modal logic can be formalised directly in natural deduction. To give proof-theoretic characterisations of these systems, extensions such as labelling or systems of deep inference.

The addition of labels to formulae permits much finer control of the conditions under which rules apply, allowing the more flexible techniques of analytic tableaux to be applied, as has been done in the case of labelled deduction . Labels also allow the naming of worlds in Kripke semantics; Simpson (1994) presents an influential technique for converting frame conditions of modal logics in Kripke semantics into inference rules in a natural deduction formalisation of hybrid logic .

Stouppa (2004) surveys the application of many proof theories, such as Avron and Pottinger's hypersequents and Belnap's display logic to such modal logics as S5 and B.

Comparison with sequent calculus [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) Main article: Sequent calculus The sequent calculus is the chief alternative to natural deduction as a foundation of mathematical logic . In natural deduction the flow of information is bi-directional: elimination rules flow information downwards by deconstruction, and introduction rules flow information upwards by assembly. Thus, a natural deduction proof does not have a purely bottom-up or top-down reading, making it unsuitable for automation in proof search. To address this fact, Gentzen in 1935 proposed his sequent calculus , though he initially intended it as a technical device for clarifying the consistency of predicate logic .

Kleene , in his seminal 1952 book Introduction to Metamathematics , gave the first formulation of the sequent calculus in the modern style.

[ 44 ] In the sequent calculus all inference rules have a purely bottom-up reading. Inference rules can apply to elements on both sides of the turnstile . (To differentiate from natural deduction, this article uses a double arrow ⇒ instead of the right tack ⊢ for sequents.) The introduction rules of natural deduction are viewed as right rules in the sequent calculus, and are structurally very similar. The elimination rules on the other hand turn into left rules in the sequent calculus. To give an example, consider disjunction; the right rules are familiar: Γ ⇒ A
───────── ∨R 1 Γ ⇒ A ∨ B Γ ⇒ B
───────── ∨R 2 Γ ⇒ A ∨ B On the left: Γ, u:A ⇒ C       Γ, v:B ⇒ C
─────────────────────────── ∨L
Γ, w: (A ∨ B) ⇒ C Recall the ∨E rule of natural deduction in localised form: Γ ⊢ A ∨ B    Γ, u:A ⊢ C    Γ, v:B ⊢ C
─────────────────────────────────────── ∨E
Γ ⊢ C The proposition A ∨ B , which is the succedent of a premise in ∨E, turns into a hypothesis of the conclusion in the left rule ∨L. Thus, left rules can be seen as a sort of inverted elimination rule. This observation can be illustrated as follows: natural deduction sequent calculus ────── hyp
 |
 | elim. rules
 |
 ↓
 ────────────────────── ↑↓ meet
 ↑
 |
 | intro. rules
 |
 conclusion ⇒ ─────────────────────────── init
 ↑            ↑
 |            |
 | left rules | right rules
 |            |
 conclusion In the sequent calculus, the left and right rules are performed in lock-step until one reaches the initial sequent , which corresponds to the meeting point of elimination and introduction rules in natural deduction. These initial rules are superficially similar to the hypothesis rule of natural deduction, but in the sequent calculus they describe a transposition or a handshake of a left and a right proposition: ────────── init
Γ, u:A ⇒ A The correspondence between the sequent calculus and natural deduction is a pair of soundness and completeness theorems, which are both provable by means of an inductive argument.

Soundness of ⇒ wrt. ⊢ If Γ ⇒ A , then Γ ⊢ A .

Completeness of ⇒ wrt. ⊢ If Γ ⊢ A , then Γ ⇒ A .

It is clear by these theorems that the sequent calculus does not change the notion of truth, because the same collection of propositions remain true. Thus, one can use the same proof objects as before in sequent calculus derivations. As an example, consider the conjunctions. The right rule is virtually identical to the introduction rule sequent calculus natural deduction Γ ⇒ π 1 : A     Γ ⇒ π 2 : B
─────────────────────────── ∧R
Γ ⇒ (π 1 , π 2 ) : A ∧ B Γ ⊢ π 1 : A      Γ ⊢ π 2 : B
───────────────────────── ∧I
Γ ⊢ (π 1 , π 2 ) : A ∧ B The left rule, however, performs some additional substitutions that are not performed in the corresponding elimination rules.

sequent calculus natural deduction Γ, u:A ⇒ π : C
──────────────────────────────── ∧L 1 Γ, v: (A ∧ B) ⇒ [ fst v/u] π : C Γ ⊢ π : A ∧ B
───────────── ∧E 1 Γ ⊢ fst π : A Γ, u:B ⇒ π : C
──────────────────────────────── ∧L 2 Γ, v: (A ∧ B) ⇒ [ snd v/u] π : C Γ ⊢ π : A ∧ B
───────────── ∧E 2 Γ ⊢ snd π : B The kinds of proofs generated in the sequent calculus are therefore rather different from those of natural deduction. The sequent calculus produces proofs in what is known as the β-normal η-long form, which corresponds to a canonical representation of the normal form of the natural deduction proof. If one attempts to describe these proofs using natural deduction itself, one obtains what is called the intercalation calculus (first described by John Byrnes), which can be used to formally define the notion of a normal form for natural deduction.

The substitution theorem of natural deduction takes the form of a structural rule or structural theorem known as cut in the sequent calculus.

Cut (substitution) [ edit ] This section does not cite any sources .

Please help improve this section by adding citations to reliable sources . Unsourced material may be challenged and removed .

( May 2024 ) ( Learn how and when to remove this message ) If Γ ⇒ π 1 : A and Γ, u : A ⇒ π 2 : C , then Γ ⇒ [π 1 /u] π 2 : C .

In most well behaved logics, cut is unnecessary as an inference rule, though it remains provable as a meta-theorem ; the superfluousness of the cut rule is usually presented as a computational process, known as cut elimination . This has an interesting application for natural deduction; usually it is extremely tedious to prove certain properties directly in natural deduction because of an unbounded number of cases. For example, consider showing that a given proposition is not provable in natural deduction. A simple inductive argument fails because of rules like ∨E or E which can introduce arbitrary propositions. However, we know that the sequent calculus is complete with respect to natural deduction, so it is enough to show this unprovability in the sequent calculus. Now, if cut is not available as an inference rule, then all sequent rules either introduce a connective on the right or the left, so the depth of a sequent derivation is fully bounded by the connectives in the final conclusion. Thus, showing unprovability is much easier, because there are only a finite number of cases to consider, and each case is composed entirely of sub-propositions of the conclusion. A simple instance of this is the global consistency theorem: "⋅ ⊢ ⊥" is not provable. In the sequent calculus version, this is manifestly true because there is no rule that can have "⋅ ⇒ ⊥" as a conclusion! Proof theorists often prefer to work on cut-free sequent calculus formulations because of such properties.

See also [ edit ] Philosophy portal Mathematical logic Sequent calculus Gerhard Gentzen System L (tabular natural deduction) Argument map , the general term for tree-like logic notation Notes [ edit ] ^ Indrzejczak .

^ Jaśkowski 1934 .

^ Gentzen 1935a , Gentzen 1935b .

^ Gentzen 1935a , p. 176.

^ a b Prawitz 1965 harvnb error: no target: CITEREFPrawitz1965 ( help ) , Prawitz 2006 harvnb error: no target: CITEREFPrawitz2006 ( help ) .

^ Martin-Löf 1996 .

^ a b c d e Pelletier & Hazen 2024 .

^ Quine (1981) . See particularly pages 91–93 for Quine's line-number notation for antecedent dependencies.

^ A particular advantage of Kleene's tabular natural deduction systems is that he proves the validity of the inference rules for both propositional calculus and predicate calculus. See Kleene 2002 , pp. 44–45, 118–119.

^ von Plato 2013 , p. 9.

^ Weisstein .

^ a b c von Plato 2013 , pp. 9, 32, 121.

^ Sutcliffe .

^ a b Restall 2018 .

^ Magnus et al. 2023 , p. 142, CHAPTER 20, Proof-theoretic concepts.

^ a b c Paseau & Leek .

^ Paseau & Pregel 2023 .

^ Magnus et al. 2023 , p. 82, 12.5 The double turnstile.

^ a b c d e f g h i Allen & Hand 2022 .

^ Allen & Hand 2022 , p. 12.

^ Kleene 2002 .

^ Prawitz 1965 .

sfn error: no target: CITEREFPrawitz1965 ( help ) ^ von Plato 2013 , p. 18.

^ a b Van Dalen 2013 .

^ Hansson & Hendricks 2018 , p. 179.

^ a b c Ayala-Rincón & de Moura 2017 , pp. 2, 20.

^ Hansson & Hendricks 2018 , p. 38.

^ Bostock 1997 , p. 21.

^ This is required in paraconsistent logics that do not treat ¬ ¬ {\displaystyle \neg } and ( ϕ ϕ → → ⊥ ⊥ ) {\displaystyle (\phi \to \bot )} as equivalents.

^ a b c von Plato 2013 , pp. 12–13.

^ Prawitz 1965 , p. 20.

sfn error: no target: CITEREFPrawitz1965 ( help ) ^ a b c Instead of ¬ ¬ ¬ ¬ {\displaystyle \neg \neg } E one can add reductio ad absurdum as a rule to obtain classical logic: [ 34 ] [ 35 ] [ φ φ → → ⊥ ⊥ ] ⋮ ⋮ ⊥ ⊥ φ φ {\displaystyle {\frac {\begin{array}{c}[\varphi \to \bot ]\\\vdots \\\bot \end{array}}{\varphi }}} (RAA) ^ Johansson 1937 .

^ a b Prawitz 1965 , p. 21.

sfn error: no target: CITEREFPrawitz1965 ( help ) ^ a b Ayala-Rincón & de Moura 2017 , pp. 17–24.

^ Tennant 1990 , p. 48.

^ a b Suppes 1999 .

^ a b Lemmon 1978 .

^ a b Lemmon 1978 , pp. passim, especially 39-40.

^ a b c d e Arthur 2017 .

^ a b This is not conform the RAA rule. The rule which is implicitly applied is →E on φ φ , φ φ → → ⊥ ⊥ {\displaystyle \varphi ,\varphi \to \bot } . As negation is not defined as an implication, this modus ponens is undocumented.

^ See also his book Prawitz 1965 harvnb error: no target: CITEREFPrawitz1965 ( help ) , Prawitz 2006 harvnb error: no target: CITEREFPrawitz2006 ( help ) .

^ See the article on lambda calculus for more detail about the concept of substitution.

^ Kleene 2009 , pp. 440–516. See also Kleene 1980 .

References [ edit ] General references [ edit ] Allen, Colin; Hand, Michael (2022).

Logic Primer (3rd ed.). Cambridge, Massachusetts: The MIT Press.

ISBN 978-0-262-54364-4 .

Arthur, Richard T. W. (2017).

An Introduction to Logic: Using Natural Deduction, Real Arguments, a Little History, and Some Humour (2nd ed.). Peterborough, Ontario: Broadview Press.

ISBN 978-1-55481-332-2 .

OCLC 962129086 .

Ayala-Rincón, Mauricio; de Moura, Flávio L. C. (2017).

Applied Logic for Computer Scientists . Undergraduate Topics in Computer Science. Springer.

doi : 10.1007/978-3-319-51653-0 .

ISBN 978-3-319-51651-6 .

Barker-Plummer, Dave; Barwise, Jon ; Etchemendy, John (2011).

Language Proof and Logic (2nd ed.). CSLI Publications.

ISBN 978-1575866321 .

Bostock, David (1997).

Intermediate Logic . Oxford ; New York: Clarendon Press ; Oxford University Press.

ISBN 978-0-19-875141-0 .

Gallier, Jean (2005).

"Constructive Logics. Part I: A Tutorial on Proof Systems and Typed λ-Calculi" . Archived from the original on 5 July 2017 . Retrieved 12 June 2014 .

Gentzen, Gerhard Karl Erich (1935a).

"Untersuchungen über das logische Schließen. I" .

Mathematische Zeitschrift .

39 (2): 176– 210.

doi : 10.1007/bf01201353 .

S2CID 121546341 .

Archived from the original on 24 December 2015.

— (1964) [1935]. "Investigations into logical deduction".

American Philosophical Quarterly .

1 (4): 249– 287.

Gentzen, Gerhard Karl Erich (1935b).

"Untersuchungen über das logische Schließen. II" .

Mathematische Zeitschrift .

39 (3): 405– 431.

doi : 10.1007/bf01201363 .

S2CID 186239837 .

Archived from the original on 9 July 2012.

— (1965) [1935]. "Investigations into logical deduction".

American Philosophical Quarterly .

2 (3): 204– 218.

Girard, Jean-Yves (1990).

Proofs and Types . Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, Cambridge, England. Archived from the original on 4 July 2016 . Retrieved 20 April 2006 .

Translated and with appendices by Paul Taylor and Yves Lafont.

Hansson, Sven Ove; Hendricks, Vincent F. (2018).

Introduction to Formal Philosophy . Springer Undergraduate Texts in Philosophy. Cham: Springer.

ISBN 978-3-030-08454-7 .

Jaśkowski, Stanisław (1934).

On the rules of suppositions in formal logic .

Reprinted in Polish logic 1920–39 , ed. Storrs McCall.

Johansson, Ingebrigt (1937).

"Der Minimalkalkül, ein reduzierter intuitionistischer Formalismus" .

Compositio Mathematica (in German).

4 : 119– 136.

Kleene, Stephen Cole (1980) [1952].

Introduction to metamathematics (Eleventh ed.). North-Holland.

ISBN 978-0-7204-2103-3 .

Kleene, Stephen Cole (2009) [1952].

Introduction to metamathematics . Ishi Press International.

ISBN 978-0-923891-57-2 .

Kleene, Stephen Cole (2002) [1967].

Mathematical logic . Mineola, New York: Dover Publications.

ISBN 978-0-486-42533-7 .

Lemmon, Edward John (1978) [1965].

Beginning Logic (Fifth printing, 1985 ed.). Boca Raton, FL: Hackett Publishing Company .

ISBN 0915144-50-6 .

Magnus, P.D.; Button, Tim; Trueman, Robert; Zach, Richard (2023).

forall x: An Introduction to Formal Logic (Fall 2023 ed.). Open Logic Project . Retrieved 4 May 2025 .

Martin-Löf, Per (1996).

"On the meanings of the logical constants and the justifications of the logical laws" (PDF) .

Nordic Journal of Philosophical Logic .

1 (1): 11– 60. Archived from the original (PDF) on 8 December 2023 . Retrieved 2 July 2010 .

Lecture notes to a short course at Università degli Studi di Siena, April 1983.

Paseau, A. C.; Leek, Robert.

"The Compactness Theorem" . Internet Encyclopedia of Philosophy . Retrieved 22 March 2024 .

Paseau, Alexander; Pregel, Fabian (2023), "Deductivism in the Philosophy of Mathematics" , in Zalta, Edward N.; Nodelman, Uri (eds.), The Stanford Encyclopedia of Philosophy (Fall 2023 ed.), Metaphysics Research Lab, Stanford University , retrieved 22 March 2024 Pelletier, Francis Jeffry; Hazen, Allen (2024), "Natural Deduction Systems in Logic" , in Zalta, Edward N.; Nodelman, Uri (eds.), The Stanford Encyclopedia of Philosophy (Spring 2024 ed.), Metaphysics Research Lab, Stanford University , retrieved 22 March 2024 Pfenning, Frank; Davies, Rowan (2001).

"A judgmental reconstruction of modal logic" (PDF) .

Mathematical Structures in Computer Science .

11 (4): 511– 540.

CiteSeerX 10.1.1.43.1611 .

doi : 10.1017/S0960129501003322 .

S2CID 16467268 .

Prawitz, Dag (1965).

Natural Deduction: A Proof-Theoretic Study . Acta Universitatis Stockholmiensis; Stockholm Studies in Philosophy, 3 . Stockholm, Göteborg, Uppsala: Almqvist & Wiksell .

OCLC 912927896 .

Prawitz, Dag (2006).

Natural Deduction: A Proof-Theoretic Study . Mineola, New York: Dover Publications.

ISBN 9780486446554 .

OCLC 61296001 .

Quine, Willard Van Orman (1981) [1940].

Mathematical logic (Revised ed.). Cambridge, Massachusetts: Harvard University Press.

ISBN 978-0-674-55451-1 .

Quine, Willard Van Orman (1982) [1950].

Methods of logic (Fourth ed.). Cambridge, Massachusetts: Harvard University Press.

ISBN 978-0-674-57176-1 .

Restall, Greg (2018), "Substructural Logics" , in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy (Spring 2018 ed.), Metaphysics Research Lab, Stanford University , retrieved 22 March 2024 Simpson, Alex K. (1994).

The Proof Theory and Semantics of Intuitionistic Modal Logic (PDF) (Thesis).

Edinburgh Research Archive (ERA) .

hdl : 1842/407 .

Stoll, Robert Roth (1979) [1963].

Set Theory and Logic . Mineola, New York: Dover Publications.

ISBN 978-0-486-63829-4 .

Stouppa, Phiniki (2004).

The Design of Modal Proof Theories: The Case of S5 . University of Dresden.

CiteSeerX 10.1.1.140.1858 .

MSc thesis.

Suppes, Patrick Colonel (1999) [1957].

Introduction to logic . Mineola, New York: Dover Publications.

ISBN 978-0-486-40687-9 .

Sutcliffe, Geoff.

"Propositional Logic" .

www.cs.miami.edu . University of Miami . Retrieved 4 May 2025 .

Tennant, Neil (1990) [1978].

Natural Logic (1st, repr. with corrections ed.).

Edinburgh University Press .

ISBN 0852245793 .

Van Dalen, Dirk (2013) [1980].

Logic and Structure . Universitext (5 ed.). London, Heidelberg, New York, Dordrecht: Springer .

doi : 10.1007/978-1-4471-4558-5 .

ISBN 978-1-4471-4558-5 .

von Plato, Jan (2013).

Elements of Logical Reasoning (1. publ ed.). Cambridge: Cambridge University Press .

ISBN 978-1-107-03659-8 .

Weisstein, Eric W.

"Connective" .

mathworld.wolfram.com . Retrieved 22 March 2024 .

External links [ edit ] Indrzejczak, Andrzej.

"Natural Deduction" .

Internet Encyclopedia of Philosophy . Retrieved 4 May 2025 .

Laboreo, Daniel Clemente (August 2004).

"Introduction to natural deduction" (PDF) .

"Domino On Acid" . Retrieved 10 December 2023 .

Natural deduction visualized as a game of dominoes Pelletier, Francis Jeffry.

"A History of Natural Deduction and Elementary Logic Textbooks" (PDF) .

"Natural Deduction Systems in Logic" entry  by Pelletier, Francis Jeffry; Hazen, Allen in the Stanford Encyclopedia of Philosophy , 29 October 2021 Levy, Michel.

"A Propositional Prover" .

v t e Mathematical logic General Axiom list Cardinality First-order logic Formal proof Formal semantics Foundations of mathematics Information theory Lemma Logical consequence Model Theorem Theory Type theory Theorems ( list ) and paradoxes Gödel's completeness and incompleteness theorems Tarski's undefinability Banach–Tarski paradox Cantor's theorem, paradox and diagonal argument Compactness Halting problem Lindström's Löwenheim–Skolem Russell's paradox Logics Traditional Classical logic Logical truth Tautology Proposition Inference Logical equivalence Consistency Equiconsistency Argument Soundness Validity Syllogism Square of opposition Venn diagram Propositional Boolean algebra Boolean functions Logical connectives Propositional calculus Propositional formula Truth tables Many-valued logic 3 finite ∞ Predicate First-order list Second-order Monadic Higher-order Fixed-point Free Quantifiers Predicate Monadic predicate calculus Set theory Set hereditary Class ( Ur- ) Element Ordinal number Extensionality Forcing Relation equivalence partition Set operations: intersection union complement Cartesian product power set identities Types of sets Countable Uncountable Empty Inhabited Singleton Finite Infinite Transitive Ultrafilter Recursive Fuzzy Universal Universe constructible Grothendieck Von Neumann Maps and cardinality Function / Map domain codomain image In / Sur / Bi -jection Schröder–Bernstein theorem Isomorphism Gödel numbering Enumeration Large cardinal inaccessible Aleph number Operation binary Set theories Zermelo–Fraenkel axiom of choice continuum hypothesis General Kripke–Platek Morse–Kelley Naive New Foundations Tarski–Grothendieck Von Neumann–Bernays–Gödel Ackermann Constructive Formal systems ( list ), language and syntax Alphabet Arity Automata Axiom schema Expression ground Extension by definition conservative Relation Formation rule Grammar Formula atomic closed ground open Free/bound variable Language Metalanguage Logical connective ¬ ∨ ∧ → ↔ = Predicate functional variable propositional variable Proof Quantifier ∃ !

∀ rank Sentence atomic spectrum Signature String Substitution Symbol function logical/constant non-logical variable Term Theory list Example axiomatic systems ( list ) of arithmetic : Peano second-order elementary function primitive recursive Robinson Skolem of the real numbers Tarski's axiomatization of Boolean algebras canonical minimal axioms of geometry : Euclidean : Elements Hilbert's Tarski's non-Euclidean Principia Mathematica Proof theory Formal proof Natural deduction Logical consequence Rule of inference Sequent calculus Theorem Systems axiomatic deductive Hilbert list Complete theory Independence ( from ZFC ) Proof of impossibility Ordinal analysis Reverse mathematics Self-verifying theories Model theory Interpretation function of models Model equivalence finite saturated spectrum submodel Non-standard model of arithmetic Diagram elementary Categorical theory Model complete theory Satisfiability Semantics of logic Strength Theories of truth semantic Tarski's Kripke's T-schema Transfer principle Truth predicate Truth value Type Ultraproduct Validity Computability theory Church encoding Church–Turing thesis Computably enumerable Computable function Computable set Decision problem decidable undecidable P NP P versus NP problem Kolmogorov complexity Lambda calculus Primitive recursive function Recursion Recursive set Turing machine Type theory Related Abstract logic Algebraic logic Automated theorem proving Category theory Concrete / Abstract category Category of sets History of logic History of mathematical logic timeline Logicism Mathematical object Philosophy of mathematics Supertask Mathematics portal v t e Major topics in Foundations of Mathematics Mathematical logic Peano axioms Mathematical induction Formal system Axiomatic system Hilbert system Natural deduction Mathematical proof Model theory Mathematical constructivism Modal logic List of mathematical logic topics Set theory Set Naive set theory Axiomatic set theory Zermelo set theory Zermelo–Fraenkel set theory Constructive set theory Descriptive set theory Determinacy Russell's paradox List of set theory topics Type theory Axiom of reducibility Simple type theory Dependent type theory Intuitionistic type theory Homotopy type theory Univalent foundations Girard's paradox Category theory Category Topos theory Category of sets Higher category theory ∞-groupoid ∞-topos theory Mathematical structuralism Glossary of category theory List of category theory topics NewPP limit report
Parsed by mw‐api‐ext.codfw.main‐77f755c49c‐2svk7
Cached time: 20250818002250
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.243 seconds
Real time usage: 1.627 seconds
Preprocessor visited node count: 9663/1000000
Revision size: 77117/2097152 bytes
Post‐expand include size: 231297/2097152 bytes
Template argument size: 8719/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 170091/5000000 bytes
Lua time usage: 0.605/10.000 seconds
Lua memory usage: 8662044/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  901.642      1 -total
 22.79%  205.491     23 Template:Cite_book
 19.80%  178.537     65 Template:Sfn
 13.90%  125.311      5 Template:Navbox
 11.86%  106.933      1 Template:Mathematical_logic
  8.25%   74.423      1 Template:Short_description
  7.79%   70.273      9 Template:Unreferenced_section
  6.98%   62.905      9 Template:Unreferenced
  6.26%   56.478      2 Template:Pagetype
  6.08%   54.817      9 Template:Ambox Saved in parser cache with key enwiki:pcache:51072:|#|:idhash:canonical and timestamp 20250818002250 and revision id 1306485576. Rendering was triggered because: unknown Retrieved from " https://en.wikipedia.org/w/index.php?title=Natural_deduction&oldid=1306485576 " Categories : Logical calculi Deductive reasoning Proof theory Methods of proof Hidden categories: Harv and Sfn no-target errors Articles with short description Short description matches Wikidata Use dmy dates from March 2025 Articles needing additional references from May 2024 All articles needing additional references CS1 German-language sources (de) Articles with Stanford Encyclopedia of Philosophy links Pages that use a deprecated format of the math tags This page was last edited on 18 August 2025, at 00:22 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Natural deduction 17 languages Add topic

