Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Lattice random walk Toggle Lattice random walk subsection 1.1 One-dimensional random walk 1.1.1 As a Markov chain 1.1.2 Heterogeneous generalization 1.2 Higher dimensions 1.3 Relation to Wiener process 2 Gaussian random walk Toggle Gaussian random walk subsection 2.1 Number of distinct sites 2.2 Information rate 3 Applications 4 Variants Toggle Variants subsection 4.1 On graphs 4.2 Self-interacting random walks 4.3 Biased random walks on graphs 4.4 Maximal entropy random walk 4.5 Correlated random walks 5 See also 6 References 7 Bibliography 8 External links Toggle the table of contents Random walk 30 languages العربية Български Català Čeština Dansk Deutsch Español Esperanto فارسی Français Galego 한국어 Bahasa Indonesia Italiano עברית Magyar Nederlands 日本語 پښتو Polski Português Русский Simple English Српски / srpski Suomi Türkçe Українська اردو 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Process forming a path from many random steps For the novel, see Random Walk .

Part of a series on statistics Probability theory Probability Axioms Determinism System Indeterminism Randomness Probability space Sample space Event Collectively exhaustive events Elementary event Mutual exclusivity Outcome Singleton Experiment Bernoulli trial Probability distribution Bernoulli distribution Binomial distribution Exponential distribution Normal distribution Pareto distribution Poisson distribution Probability measure Random variable Bernoulli process Continuous or discrete Expected value Variance Markov chain Observed value Random walk Stochastic process Complementary event Joint probability Marginal probability Conditional probability Independence Conditional independence Law of total probability Law of large numbers Bayes' theorem Boole's inequality Venn diagram Tree diagram v t e Five eight-step random walks from a central point. Some paths appear shorter than eight steps where the route has doubled back on itself. ( animated version ) In mathematics , a random walk , sometimes known as a drunkard's walk , is a stochastic process that describes a path that consists of a succession of random steps on some mathematical space .

An elementary example of a random walk is the random walk on the integer number line Z {\displaystyle \mathbb {Z} } which starts at 0, and at each step moves +1 or −1 with equal probability . Other examples include the path traced by a molecule as it travels in a liquid or a gas (see Brownian motion ), the search path of a foraging animal, or the price of a fluctuating stock and the financial status of a gambler . Random walks have applications to engineering and many scientific fields including ecology , psychology , computer science , physics , chemistry , biology , economics , and sociology . The term random walk was first introduced by Karl Pearson in 1905.

[ 1 ] Realizations of random walks can be obtained by Monte Carlo simulation .

[ 2 ] Lattice random walk [ edit ] A popular random walk model is that of a random walk on a regular lattice, where at each step the location jumps to another site according to some probability distribution. In a simple random walk , the location can only jump to neighboring sites of the lattice, forming a lattice path . In a simple symmetric random walk on a locally finite lattice, the probabilities of the location jumping to each one of its immediate neighbors are the same. The best-studied example is the random walk on the d -dimensional integer lattice (sometimes called the hypercubic lattice) Z d {\displaystyle \mathbb {Z} ^{d}} .

[ 3 ] If the state space is limited to finite dimensions, the random walk model is called a simple bordered symmetric random walk , and the transition probabilities depend on the location of the state because on margin and corner states the movement is limited.

[ 4 ] One-dimensional random walk [ edit ] An elementary example of a random walk is the random walk on the integer number line, Z {\displaystyle \mathbb {Z} } , which starts at 0 and at each step moves +1 or −1 with equal probability.

This walk can be illustrated as follows. A marker is placed at zero on the number line, and a fair coin is flipped. If it lands on heads, the marker is moved one unit to the right. If it lands on tails, the marker is moved one unit to the left. After five flips, the marker could now be on -5, -3, -1, 1, 3, 5. With five flips, three heads and two tails, in any order, it will land on 1. There are 10 ways of landing on 1 (by flipping three heads and two tails), 10 ways of landing on −1 (by flipping three tails and two heads), 5 ways of landing on 3 (by flipping four heads and one tail), 5 ways of landing on −3 (by flipping four tails and one head), 1 way of landing on 5 (by flipping five heads), and 1 way of landing on −5 (by flipping five tails). See the figure below for an illustration of the possible outcomes of 5 flips.

All possible random walk outcomes after 5 flips of a fair coin Random walk in two dimensions ( animated version ) Random walk in two dimensions with 25 thousand steps ( animated version ) Random walk in two dimensions with two million even smaller steps. This image was generated in such a way that points that are more frequently traversed are darker. In the limit, for very small steps, one obtains Brownian motion .

To define this walk formally, take independent random variables Z 1 , Z 2 , … … {\displaystyle Z_{1},Z_{2},\dots } , where each variable is either 1 or −1, with a 50% probability for either value, and set S 0 = 0 {\displaystyle S_{0}=0} and S n = ∑ ∑ j = 1 n Z j .

{\textstyle S_{n}=\sum _{j=1}^{n}Z_{j}.} The series { S n } {\displaystyle \{S_{n}\}} is called the simple random walk on Z {\displaystyle \mathbb {Z} } .  This series (the sum of the sequence of −1s and 1s) gives the net distance walked, if each part of the walk is of length one.
The expectation E ( S n ) {\displaystyle E(S_{n})} of S n {\displaystyle S_{n}} is zero. That is, the mean of all coin flips approaches zero as the number of flips increases. This follows by the finite additivity property of expectation: E ( S n ) = ∑ ∑ j = 1 n E ( Z j ) = 0.

{\displaystyle E(S_{n})=\sum _{j=1}^{n}E(Z_{j})=0.} A similar calculation, using the independence of the random variables and the fact that E ( Z n 2 ) = 1 {\displaystyle E(Z_{n}^{2})=1} , shows that: E ( S n 2 ) = ∑ ∑ i = 1 n E ( Z i 2 ) + 2 ∑ ∑ 1 ≤ ≤ i < j ≤ ≤ n E ( Z i Z j ) = n .

{\displaystyle E(S_{n}^{2})=\sum _{i=1}^{n}E(Z_{i}^{2})+2\sum _{1\leq i<j\leq n}E(Z_{i}Z_{j})=n.} This hints that E ( | S n | ) {\displaystyle E(|S_{n}|)\,\!} , the expected translation distance after n steps, should be of the order of n {\displaystyle {\sqrt {n}}} .

In fact, [ 5 ] lim n → → ∞ ∞ E ( | S n | ) n = 2 π π .

{\displaystyle \lim _{n\to \infty }{\frac {E(|S_{n}|)}{\sqrt {n}}}={\sqrt {\frac {2}{\pi }}}.} To answer the question of how many times will a random walk cross a boundary line if permitted to continue walking forever, a simple random walk on Z {\displaystyle \mathbb {Z} } will cross every point an infinite number of times. This result has many names: the level-crossing phenomenon , recurrence or the gambler's ruin . The reason for the last name is as follows: a gambler with a finite amount of money will eventually lose when playing a fair game against a bank with an infinite amount of money. The gambler's money will perform a random walk, and it will reach zero at some point, and the game will be over.

If a and b are positive integers, then the expected number of steps until a one-dimensional simple random walk starting at 0 first hits b or − a is ab .  The probability that this walk will hit b before − a is a / ( a + b ) {\displaystyle a/(a+b)} , which can be derived from the fact that simple random walk is a martingale . And these expectations and hitting probabilities can be computed in O ( a + b ) {\displaystyle O(a+b)} in the general one-dimensional random walk Markov chain.

Some of the results mentioned above can be derived from properties of Pascal's triangle . The number of different walks of n steps where each step is +1 or −1 is 2 n . For the simple random walk, each of these walks is equally likely. 
In order for S n to be equal to a number k it is necessary and sufficient that the number of +1 in the walk exceeds those of −1 by k . It follows +1 must appear ( n + k )/2 times among n steps of a walk, hence the number of walks which satisfy S n = k {\displaystyle S_{n}=k} equals the number of ways of choosing ( n + k )/2 elements from an n element set, [ 6 ] denoted ( n ( n + k ) / 2 ) {\textstyle n \choose (n+k)/2} . For this to have meaning, it is necessary that n + k be an even number, which implies n and k are either both even or both odd. Therefore, the probability that S n = k {\displaystyle S_{n}=k} is equal to 2 − − n ( n ( n + k ) / 2 ) {\textstyle 2^{-n}{n \choose (n+k)/2}} . By representing entries of Pascal's triangle in terms of factorials and using Stirling's formula , one can obtain good estimates for these probabilities for large values of n {\displaystyle n} .

If space is confined to Z {\displaystyle \mathbb {Z} } + for brevity, the number of ways in which a random walk will land on any given number having five flips can be shown as {0,5,0,4,0,1}.

This relation with Pascal's triangle is demonstrated for small values of n . At zero turns, the only possibility will be to remain at zero. However, at one turn, there is one chance of landing on −1 or one chance of landing on 1. At two turns, a marker at 1 could move to 2 or back to zero. A marker at −1, could move to −2 or back to zero. Therefore, there is one chance of landing on −2, two chances of landing on zero, and one chance of landing on 2.

k −5 −4 −3 −2 −1 0 1 2 3 4 5 P [ S 0 = k ] {\displaystyle P[S_{0}=k]} 1 2 P [ S 1 = k ] {\displaystyle 2P[S_{1}=k]} 1 1 2 2 P [ S 2 = k ] {\displaystyle 2^{2}P[S_{2}=k]} 1 2 1 2 3 P [ S 3 = k ] {\displaystyle 2^{3}P[S_{3}=k]} 1 3 3 1 2 4 P [ S 4 = k ] {\displaystyle 2^{4}P[S_{4}=k]} 1 4 6 4 1 2 5 P [ S 5 = k ] {\displaystyle 2^{5}P[S_{5}=k]} 1 5 10 10 5 1 The central limit theorem and the law of the iterated logarithm describe important aspects of the behavior of simple random walks on Z {\displaystyle \mathbb {Z} } . In particular, the former entails that as n increases, the probabilities (proportional to the numbers in each row) approach a normal distribution .

To be precise, knowing that P ( X n = k ) = 2 − − n ( n ( n + k ) / 2 ) {\textstyle \mathbb {P} (X_{n}=k)=2^{-n}{\binom {n}{(n+k)/2}}} ,
and using Stirling's formula one has log ⁡ ⁡ P ( X n = k ) = n [ ( 1 + k n + 1 2 n ) log ⁡ ⁡ ( 1 + k n ) + ( 1 − − k n + 1 2 n ) log ⁡ ⁡ ( 1 − − k n ) ] + log ⁡ ⁡ 2 π π + o ( 1 ) .

{\displaystyle {\log \mathbb {P} (X_{n}=k)}=n\left[\left({1+{\frac {k}{n}}+{\frac {1}{2n}}}\right)\log \left(1+{\frac {k}{n}}\right)+\left({1-{\frac {k}{n}}+{\frac {1}{2n}}}\right)\log \left(1-{\frac {k}{n}}\right)\right]+\log {\frac {\sqrt {2}}{\sqrt {\pi }}}+o(1).} Fixing the scaling k = ⌊ ⌊ n x ⌋ ⌋ {\textstyle k=\lfloor {\sqrt {n}}x\rfloor } ,  for x {\textstyle x} fixed, and using the expansion log ⁡ ⁡ ( 1 + k / n ) = k / n − − k 2 / 2 n 2 + … … {\textstyle \log(1+{k}/{n})=k/n-k^{2}/2n^{2}+\dots } when k / n {\textstyle k/n} vanishes, it follows P ( X n n = ⌊ ⌊ n x ⌋ ⌋ n ) = 1 n 1 2 π π e − − x 2 ( 1 + o ( 1 ) ) .

{\displaystyle {\mathbb {P} \left({\frac {X_{n}}{n}}={\frac {\lfloor {\sqrt {n}}x\rfloor }{\sqrt {n}}}\right)}={\frac {1}{\sqrt {n}}}{\frac {1}{2{\sqrt {\pi }}}}e^{-{x^{2}}}(1+o(1)).} taking the limit (and observing that 1 / n {\textstyle {1}/{\sqrt {n}}} corresponds to the spacing of the scaling grid) one finds the gaussian density f ( x ) = 1 2 π π e − − x 2 {\textstyle f(x)={\frac {1}{2{\sqrt {\pi }}}}e^{-{x^{2}}}} . Indeed, for a absolutely continuous random variable X {\textstyle X} with density f X {\textstyle f_{X}} it holds P ( X ∈ ∈ [ x , x + d x ) ) = f X ( x ) d x {\textstyle \mathbb {P} \left(X\in [x,x+dx)\right)=f_{X}(x)dx} , with d x {\textstyle dx} corresponding to an infinitesimal spacing.

As a direct generalization, one can consider random walks on crystal lattices (infinite-fold abelian covering graphs over finite graphs). Actually it is possible to establish the central limit theorem and large deviation theorem in this setting.

[ 7 ] [ 8 ] As a Markov chain [ edit ] A one-dimensional random walk can also be looked at as a Markov chain whose state space is given by the integers i = 0 , ± ± 1 , ± ± 2 , … … .

{\displaystyle i=0,\pm 1,\pm 2,\dots .} For some number p satisfying 0 < p < 1 {\displaystyle \,0<p<1} , the transition probabilities (the probability P i,j of moving from state i to state j ) are given by P i , i + 1 = p = 1 − − P i , i − − 1 .

{\displaystyle \,P_{i,i+1}=p=1-P_{i,i-1}.} Heterogeneous generalization [ edit ] Main article: Heterogeneous random walk in one dimension The heterogeneous random walk draws in each time step a random number that determines the local jumping probabilities and then a random number that determines the actual jump direction. The main question is the probability of staying in each of the various sites after t {\displaystyle t} jumps, and in the limit of this probability when t {\displaystyle t} is very large.

Higher dimensions [ edit ] Three random walks in three dimensions In higher dimensions, the set of randomly walked points has interesting geometric properties. In fact, one gets a discrete fractal , that is, a set which exhibits stochastic self-similarity on large scales. On small scales, one can observe "jaggedness" resulting from the grid on which the walk is performed.  The trajectory of a random walk is the collection of points visited, considered as a set with disregard to when the walk arrived at the point. In one dimension, the trajectory is simply all points between the minimum height and the maximum height the walk achieved (both are, on average, on the order of n {\displaystyle {\sqrt {n}}} ).

To visualize the two-dimensional case, one can imagine a person walking randomly around a city. The city is effectively infinite and arranged in a square grid of sidewalks. At every intersection, the person randomly chooses one of the four possible routes (including the one originally travelled from). Formally, this is a random walk on the set of all points in the plane with integer coordinates .

To answer the question of the person ever getting back to the original starting point of the walk, this is the 2-dimensional equivalent of the level-crossing problem discussed above. In 1921 George Pólya proved that the person almost surely would in a 2-dimensional random walk, but for 3 dimensions or higher, the probability of returning to the origin decreases as the number of dimensions increases. In 3 dimensions, the probability decreases to roughly 34%.

[ 9 ] The mathematician Shizuo Kakutani was known to refer to this result with the following quote: "A drunk man will find his way home, but a drunk bird may get lost forever".

[ 10 ] The probability of recurrence is in general p = 1 − − ( 1 π π d ∫ ∫ [ − − π π , π π ] d ∏ ∏ i = 1 d d θ θ i 1 − − 1 d ∑ ∑ i = 1 d cos ⁡ ⁡ θ θ i ) − − 1 {\displaystyle p=1-\left({\frac {1}{\pi ^{d}}}\int _{[-\pi ,\pi ]^{d}}{\frac {\prod _{i=1}^{d}d\theta _{i}}{1-{\frac {1}{d}}\sum _{i=1}^{d}\cos \theta _{i}}}\right)^{-1}} , which can be derived by generating functions [ 11 ] or Poisson process.

[ 12 ] Another variation of this question which was also asked by Pólya is: "if two people leave the same starting point, then will they ever meet again?" [ 13 ] It can be shown that the difference between their locations (two independent random walks) is also a simple random walk, so they almost surely meet again in a 2-dimensional walk, but for 3 dimensions and higher the probability decreases with the number of the dimensions.

Paul Erdős and Samuel James Taylor also showed in 1960 that for dimensions less or equal than 4, two independent random walks starting from any two given points have infinitely many intersections almost surely, but for dimensions higher than 5, they almost surely intersect only finitely often.

[ 14 ] The asymptotic function for a two-dimensional random walk as the number of steps increases is given by a Rayleigh distribution . The probability distribution is a function of the radius from the origin and the step length is constant for each step. Here, the step length is assumed to be 1, N is the total number of steps and r is the radius from the origin.

[ 15 ] P ( r ) = 2 r N e − − r 2 / N {\displaystyle P(r)={\frac {2r}{N}}e^{-r^{2}/N}} Relation to Wiener process [ edit ] Simulated steps approximating a Wiener process in two dimensions A Wiener process is a stochastic process with similar behavior to Brownian motion , the physical phenomenon of a minute particle diffusing in a fluid. (Sometimes the Wiener process is called "Brownian motion", although this is strictly speaking a confusion of a model with the phenomenon being modeled.) A Wiener process is the scaling limit of random walk in dimension 1. This means that if there is a random walk with very small steps, there is an approximation to a Wiener process (and, less accurately, to Brownian motion). To be more precise, if the step size is ε, one needs to take a walk of length L /ε 2 to approximate a Wiener length of L . As the step size tends to 0 (and the number of steps increases proportionally), random walk converges to a Wiener process in an appropriate sense. Formally, if B is the space of all paths of length L with the maximum topology, and if M is the space of measure over B with the norm topology, then the convergence is in the space M . Similarly, a Wiener process in several dimensions is the scaling limit of random walk in the same number of dimensions.

A random walk is a discrete fractal (a function with integer dimensions; 1, 2, ...), but a Wiener process trajectory is a true fractal, and there is a connection between the two. For example, take a random walk until it hits a circle of radius r times the step length. The average number of steps it performs is r 2 .

[ citation needed ] This fact is the discrete version of the fact that a Wiener process walk is a fractal of Hausdorff dimension 2.

[ citation needed ] In two dimensions, the average number of points the same random walk has on the boundary of its trajectory is r 4/3 . This corresponds to the fact that the boundary of the trajectory of a Wiener process is a fractal of dimension 4/3, a fact predicted by Mandelbrot using simulations but proved only in 2000
by Lawler , Schramm and Werner .

[ 16 ] A Wiener process enjoys many symmetries a random walk does not. For example, a Wiener process walk is invariant to rotations, but the random walk is not, since the underlying grid is not (random walk is invariant to rotations by 90 degrees, but Wiener processes are invariant to rotations by, for example, 17 degrees too). This means that in many cases, problems on a random walk are easier to solve by translating them to a Wiener process, solving the problem there, and then translating back. On the other hand, some problems are easier to solve with random walks due to its discrete nature.

Random walk and Wiener process can be coupled , namely manifested on the same probability space in a dependent way that forces them to be quite close. The simplest such coupling is the Skorokhod embedding , but there exist more precise couplings, such as Komlós–Major–Tusnády approximation theorem.

The convergence of a random walk toward the Wiener process is controlled by the central limit theorem , and by Donsker's theorem .  For a particle in a known fixed position at t = 0, the central limit theorem tells us that after a large number of independent steps in the random walk, the walker's position is distributed according to a normal distribution of total variance : σ σ 2 = t δ δ t ε ε 2 , {\displaystyle \sigma ^{2}={\frac {t}{\delta t}}\,\varepsilon ^{2},} where t is the time elapsed since the start of the random walk, ε ε {\displaystyle \varepsilon } is the size of a step of the random walk, and δ δ t {\displaystyle \delta t} is the time elapsed between two successive steps.

This corresponds to the Green's function of the diffusion equation that controls the Wiener process, which suggests that, after a large number of steps, the random walk converges toward a Wiener process.

In 3D, the variance corresponding to the Green's function of the diffusion equation is: σ σ 2 = 6 D t .

{\displaystyle \sigma ^{2}=6\,D\,t.} By equalizing this quantity with the variance associated to the position of the random walker, one obtains the equivalent diffusion coefficient to be considered for the asymptotic Wiener process toward which the random walk converges after a large number of steps: D = ε ε 2 6 δ δ t {\displaystyle D={\frac {\varepsilon ^{2}}{6\delta t}}} (valid only in 3D).

The two expressions of the variance above correspond to the distribution associated to the vector R → → {\displaystyle {\vec {R}}} that links the two ends of the random walk, in 3D. The variance associated to each component R x {\displaystyle R_{x}} , R y {\displaystyle R_{y}} or R z {\displaystyle R_{z}} is only one third of this value (still in 3D).

For 2D: [ 17 ] D = ε ε 2 4 δ δ t .

{\displaystyle D={\frac {\varepsilon ^{2}}{4\delta t}}.} For 1D: [ 18 ] D = ε ε 2 2 δ δ t .

{\displaystyle D={\frac {\varepsilon ^{2}}{2\delta t}}.} Gaussian random walk [ edit ] A random walk having a step size that varies according to a normal distribution is used as a model for real-world time series data such as financial markets.

Here, the step size is the inverse cumulative normal distribution Φ Φ − − 1 ( z , μ μ , σ σ ) {\displaystyle \Phi ^{-1}(z,\mu ,\sigma )} where 0 ≤ z ≤ 1 is a uniformly distributed random number, and μ and σ are the mean and standard deviations of the normal distribution, respectively.

If μ is nonzero, the random walk will vary about a linear trend. If v s is the starting value of the random walk, the expected value after n steps will be v s + n μ.

For the special case where μ is equal to zero, after n steps, the translation distance's probability distribution is given by N (0, n σ 2 ), where N () is the notation for the normal distribution, n is the number of steps, and σ is from the inverse cumulative normal distribution as given above.

Proof: The Gaussian random walk can be thought of as the sum of a sequence of independent and identically distributed random variables, X i from the inverse cumulative normal distribution with mean equal zero and σ of the original inverse cumulative normal distribution: Z = ∑ ∑ i = 0 n X i , {\displaystyle Z=\sum _{i=0}^{n}{X_{i}},} but we have the distribution for the sum of two independent normally distributed random variables, Z = X + Y , is given by N ( μ μ X + μ μ Y , σ σ X 2 + σ σ Y 2 ) {\displaystyle {\mathcal {N}}(\mu _{X}+\mu _{Y},\sigma _{X}^{2}+\sigma _{Y}^{2})} (see here) .

In our case, μ X = μ Y = 0 and σ 2 X = σ 2 Y = σ 2 yield N ( 0 , 2 σ σ 2 ) {\displaystyle {\mathcal {N}}(0,2\sigma ^{2})} By induction, for n steps we have Z ∼ ∼ N ( 0 , n σ σ 2 ) .

{\displaystyle Z\sim {\mathcal {N}}(0,n\sigma ^{2}).} For steps distributed according to any distribution with zero mean and a finite variance (not necessarily just a normal distribution), the root mean square translation distance after n steps is (see Bienaymé's identity ) V a r ( S n ) = E [ S n 2 ] = σ σ n .

{\displaystyle {\sqrt {Var(S_{n})}}={\sqrt {E[S_{n}^{2}]}}=\sigma {\sqrt {n}}.} But for the Gaussian random walk, this is just the standard deviation of the translation distance's distribution after n steps. Hence, if μ is equal to zero, and since the root mean square(RMS) translation distance is one standard deviation, there is 68.27% probability that the RMS translation distance after n steps will fall between ± ± σ σ n {\displaystyle \pm \sigma {\sqrt {n}}} . Likewise, there is 50% probability that the translation distance after n steps will fall between ± ± 0.6745 σ σ n {\displaystyle \pm 0.6745\sigma {\sqrt {n}}} .

Number of distinct sites [ edit ] The number of distinct sites visited by a single random walker S ( t ) {\displaystyle S(t)} has been studied extensively for square and cubic lattices and for fractals.

[ 19 ] [ 20 ] This quantity is useful for the analysis of problems of trapping and kinetic reactions. It is also related to the vibrational density of states, [ 21 ] [ 22 ] diffusion reactions processes [ 23 ] and spread of populations in ecology.

[ 24 ] [ 25 ] Information rate [ edit ] The information rate of a Gaussian random walk with respect to the squared error distance, i.e. its quadratic rate distortion function , is given parametrically by [ 26 ] R ( D θ θ ) = 1 2 ∫ ∫ 0 1 max { 0 , log 2 ⁡ ⁡ ( S ( φ φ ) / θ θ ) } d φ φ , {\displaystyle R(D_{\theta })={\frac {1}{2}}\int _{0}^{1}\max\{0,\log _{2}\left(S(\varphi )/\theta \right)\}\,d\varphi ,} D θ θ = ∫ ∫ 0 1 min { S ( φ φ ) , θ θ } d φ φ , {\displaystyle D_{\theta }=\int _{0}^{1}\min\{S(\varphi ),\theta \}\,d\varphi ,} where S ( φ φ ) = ( 2 sin ⁡ ⁡ ( π π φ φ / 2 ) ) − − 2 {\displaystyle S(\varphi )=\left(2\sin(\pi \varphi /2)\right)^{-2}} . Therefore, it is impossible to encode { Z n } n = 1 N {\displaystyle {\{Z_{n}\}_{n=1}^{N}}} using a binary code of less than N R ( D θ θ ) {\displaystyle NR(D_{\theta })} bits and recover it with expected mean squared error less than D θ θ {\displaystyle D_{\theta }} . On the other hand, for any ε ε > 0 {\displaystyle \varepsilon >0} , there exists an N ∈ ∈ N {\displaystyle N\in \mathbb {N} } large enough and a binary code of no more than 2 N R ( D θ θ ) {\displaystyle 2^{NR(D_{\theta })}} distinct elements such that the expected mean squared error in recovering { Z n } n = 1 N {\displaystyle {\{Z_{n}\}_{n=1}^{N}}} from this code is at most D θ θ − − ε ε {\displaystyle D_{\theta }-\varepsilon } .

Applications [ edit ] This section needs additional citations for verification .

Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.

( February 2013 ) ( Learn how and when to remove this message ) Antony Gormley 's Quantum Cloud sculpture in London was designed by a computer using a random walk algorithm As mentioned, the range of natural phenomena which have been subject to attempts at description by some flavour of random walks is considerable. This is  particularly the case in the fields of physics, [ 27 ] [ 28 ] chemistry, [ 29 ] materials science , [ 30 ] [ 31 ] and biology.

[ 32 ] [ 33 ] [ 34 ] The following are some specific applications of random walks: In financial economics , the random walk hypothesis is used to model shares prices and other factors.

[ 35 ] Empirical studies found some deviations from this theoretical model, especially in short term and long term correlations. See share prices .

In population genetics , random walk describes the statistical properties of genetic drift or long-term randomly fluctuating selection.

[ 36 ] In physics , random walks are used as simplified models of physical Brownian motion and diffusion such as the random movement of molecules in liquids and gases. See for example diffusion-limited aggregation. Also in physics, random walks and some of the self interacting walks play a role in quantum field theory .

In semiconductor manufacturing , random walks are used to analyze the effects of thermal treatment at smaller nodes. It is applied to understand the diffusion of dopants , defects , impurities etc., during critical fabrication steps. Random walk treatments are also used to study the diffusion of reactants, products and plasma during chemical vapor deposition processes. Continuum diffusion has been used to study the flow of gases, at macroscopic scales, in CVD reactors. However, smaller dimensions and increased complexity has forced us to treat them with random walk. This allows for accurate analysis of stochastic processes, at molecular level and smaller, in semiconductor manufacturing.

In mathematical ecology , random walks are used to describe individual animal movements, to empirically support processes of biodiffusion , and occasionally to model population dynamics .

In polymer physics , random walk describes an ideal chain . It is the simplest model to study polymers .

[ 37 ] In other fields of mathematics, random walk is used to calculate solutions to Laplace's equation , to estimate the harmonic measure , and for various constructions in analysis and combinatorics .

In computer science , random walks are used to estimate the size of the Web .

[ 38 ] In image segmentation , random walks are used to determine the labels (i.e., "object" or "background") to associate with each pixel.

[ 39 ] This algorithm is typically referred to as the random walker segmentation algorithm.

In brain research , random walks and reinforced random walks are used to model cascades of neuron firing in the brain.

In vision science , ocular drift tends to behave like a random walk.

[ 40 ] According to some authors, fixational eye movements in general are also well described by a random walk.

[ 41 ] In psychology , random walks explain accurately the relation between the time needed to make a decision and the probability that a certain decision will be made.

[ 42 ] Random walks can be used to sample from a state space which is unknown or very large, for example to pick a random page off the internet.

[ citation needed ] In computer science , this method is known as Markov Chain Monte Carlo (MCMC).

In wireless networking , a random walk is used to model node movement.

[ citation needed ] Motile bacteria engage in biased random walks .

[ 43 ] In physics, random walks underlie the method of Fermi estimation .

[ citation needed ] On the web, the Twitter website uses random walks to make suggestions of whom to follow [ 44 ] Dave Bayer and Persi Diaconis have proven that 7 riffle shuffles are sufficient to mix a deck of cards (see more details under shuffle ). This result translates to a statement about random walk on the symmetric group which is what they prove, with a crucial use of the group structure via Fourier analysis.

Variants [ edit ] A number of types of stochastic processes have been considered that are similar to the pure random walks but where the simple structure is allowed to be more generalized. The pure structure can be characterized by the steps being defined by independent and identically distributed random variables . Random walks can take place on a variety of spaces, such as graphs , the integers, the real line, the plane or higher-dimensional vector spaces, on curved surfaces or higher-dimensional Riemannian manifolds , and on groups . It is also possible to define random walks which take their steps at random times, and in that case, the position X t has to be defined for all times t ∈ [0, +∞) . Specific cases or limits of random walks include the Lévy flight and diffusion models such as Brownian motion .

On graphs [ edit ] A random walk of length k on a possibly infinite graph G with a root 0 is a stochastic process with random variables X 1 , X 2 , … … , X k {\displaystyle X_{1},X_{2},\dots ,X_{k}} such that X 1 = 0 {\displaystyle X_{1}=0} and X i + 1 {\displaystyle {X_{i+1}}} is a vertex chosen uniformly at random from the neighbors of X i {\displaystyle X_{i}} .
Then the number p v , w , k ( G ) {\displaystyle p_{v,w,k}(G)} is the probability that a random walk of length k starting at v ends at w .
In particular, if G is a graph with root 0 , p 0 , 0 , 2 k {\displaystyle p_{0,0,2k}} is the probability that a 2 k {\displaystyle 2k} -step random walk returns to 0 .

Building on the analogy from the earlier section on higher dimensions, assume now that our city is no longer a perfect square grid. When our person reaches a certain junction, he picks between the variously available roads with equal probability. Thus, if the junction has seven exits the person will go to each one with probability one-seventh. This is a random walk on a graph. Will our person reach his home? It turns out that under rather mild conditions, the answer is still yes, [ 45 ] but depending on the graph, the answer to the variant question 'Will two persons meet again?' may not be that they meet infinitely often almost surely.

[ 46 ] An example of a case where the person will reach his home almost surely is when the lengths of all the blocks are between a and b (where a and b are any two finite positive numbers). Notice that we do not assume that the graph is planar , i.e. the city may contain tunnels and bridges. One way to prove this result is using the connection to electrical networks . Take a map of the city and place a one ohm resistor on every block. Now measure the "resistance between a point and infinity". In other words, choose some number R and take all the points in the electrical network with distance bigger than R from our point and wire them together. This is now a finite electrical network, and we may measure the resistance from our point to the wired points. Take R to infinity. The limit is called the resistance between a point and infinity . It turns out that the following is true (an elementary proof can be found in the book by Doyle and Snell): Theorem : a graph is transient if and only if the resistance between a point and infinity is finite. It is not important which point is chosen if the graph is connected.

In other words, in a transient system, one only needs to overcome a finite resistance to get to infinity from any point.  In a recurrent system, the resistance from any point to infinity is infinite.

This characterization of transience and recurrence is very useful, and specifically it allows us to analyze the case of a city drawn in the plane with the distances bounded.

A random walk on a graph is a very special case of a Markov chain . Unlike a general Markov chain, random walk on a graph enjoys a property called time symmetry or reversibility . Roughly speaking, this property, also called the principle of detailed balance , means that the probabilities to traverse a given path in one direction or the other have a very simple connection between them (if the graph is regular , they are just equal). This property has important consequences.

Starting in the 1980s, much research has gone into connecting properties of the graph to random walks. In addition to the electrical network connection described above, there are important connections to isoperimetric inequalities , see more here , functional inequalities such as Sobolev and Poincaré inequalities and properties of solutions of Laplace's equation . A significant portion of this research was focused on Cayley graphs of finitely generated groups . In many cases these discrete results carry over to, or are derived from manifolds and Lie groups .

In the context of random graphs , particularly that of the Erdős–Rényi model , analytical results to some properties of random walkers have been obtained. These include the distribution of first [ 47 ] and last hitting times [ 48 ] of the walker, where the first hitting time is given by the first time the walker steps into a previously visited site of the graph, and the last hitting time corresponds the first time the walker cannot perform an additional move without revisiting a previously visited site.

A good reference for random walk on graphs is the online book by Aldous and Fill . For groups see the book of Woess.
If the transition kernel p ( x , y ) {\displaystyle p(x,y)} is itself random (based on an environment ω ω {\displaystyle \omega } ) then the random walk is called a "random walk in random environment". When the law of the random walk includes the randomness of ω ω {\displaystyle \omega } , the law is called the annealed law; on the other hand, if ω ω {\displaystyle \omega } is seen as fixed, the law is called a quenched law. See the book of Hughes, the book of Revesz, or the lecture notes of Zeitouni.

We can think about choosing every possible edge with the same probability as maximizing uncertainty (entropy) locally. We could also do it globally – in maximal entropy random walk (MERW) we want all paths to be equally probable, or in other words: for every two vertexes, each path of given length is equally probable.

[ 49 ] This random walk has much stronger localization properties.

Self-interacting random walks [ edit ] There are a number of interesting models of random paths in which each step depends on the past in a complicated manner. All are more complex for solving analytically than the usual random walk; still, the behavior of any model of a random walker is obtainable using computers. Examples include: The self-avoiding walk .

[ 50 ] The self-avoiding walk of length n on Z d {\displaystyle \mathbb {Z} ^{d}} is the random n -step path which starts at the origin, makes transitions only between adjacent sites in Z d {\displaystyle \mathbb {Z} ^{d}} , never revisit a site, and is chosen uniformly among all such paths. In two dimensions, due to self-trapping, a typical self-avoiding walk is very short, [ 51 ] while in higher dimension it grows beyond all bounds.
This model has often been used in polymer physics (since the 1960s).

The loop-erased random walk .

[ 52 ] [ 53 ] The reinforced random walk .

[ 54 ] The exploration process .

[ citation needed ] The multiagent random walk .

[ 55 ] Biased random walks on graphs [ edit ] Main article: Biased random walk on a graph Maximal entropy random walk [ edit ] Main article: Maximal entropy random walk Random walk chosen to maximize entropy rate , has much stronger localization properties.

Correlated random walks [ edit ] Random walks where the direction of movement at one time is correlated with the direction of movement at the next time. It is used to model animal movements.

[ 56 ] [ 57 ] See also [ edit ] Branching random walk – Stochastic process Brownian motion – Random motion of particles suspended in a fluid Law of the iterated logarithm – Mathematical theorem Lévy flight – Random walk with heavy-tailed step lengths Lévy flight foraging hypothesis Loop-erased random walk – Model for a random simple path Maximal entropy random walk Self-avoiding walk – Sequence of moves on a lattice Unit root – Feature of some stochastic processes References [ edit ] ^ Pearson, Karl (1905). "The Problem of the Random Walk".

Nature .

72 (1865): 294.

Bibcode : 1905Natur..72..294P .

doi : 10.1038/072294b0 .

S2CID 4010776 .

^ Theory and Applications of Monte Carlo Simulations. (2013). Kroatien: IntechOpen. Page 229, https://books.google.com/books?id=3HWfDwAAQBAJ&pg=PA229 ^ Pal, Révész (1990) Random walk in random and nonrandom environments , World Scientific ^ Kohls, Moritz; Hernandez, Tanja (2016). "Expected Coverage of Random Walk Mobility Algorithm".

arXiv : 1611.02861 [ stat.AP ].

^ "Random Walk-1-Dimensional – from Wolfram MathWorld" . Mathworld.wolfram.com. 26 April 2000 . Retrieved 2 November 2016 .

^ Edward A. Codling et al., Random walk models in biology, Journal of the Royal Society Interface, 2008 ^ Kotani, M.; Sunada, T.

(2003).

Spectral geometry of crystal lattices . Contemporary Mathematics. Vol. 338. pp.

271– 305.

doi : 10.1090/conm/338/06077 .

ISBN 978-0-8218-3383-4 .

^ Kotani, M.; Sunada, T.

(2006). "Large deviation and the tangent cone at infinity of a crystal lattice".

Math. Z .

254 (4): 837– 870.

doi : 10.1007/s00209-006-0951-9 .

S2CID 122531716 .

^ "Pólya's Random Walk Constants" . Mathworld.wolfram.com . Retrieved 2 November 2016 .

^ Durrett, Rick (2010).

Probability: Theory and Examples . Cambridge University Press. pp.

191 .

ISBN 978-1-139-49113-6 .

^ Novak, Jonathan (2014).

"Pólya's Random Walk Theorem" .

The American Mathematical Monthly .

121 (8): 711– 716.

arXiv : 1301.3916 .

doi : 10.4169/amer.math.monthly.121.08.711 .

ISSN 0002-9890 .

JSTOR 10.4169/amer.math.monthly.121.08.711 .

^ Lange, Kenneth (2015).

"Polya′s Random Walk Theorem Revisited" .

The American Mathematical Monthly .

122 (10): 1005– 1007.

doi : 10.4169/amer.math.monthly.122.10.1005 .

ISSN 0002-9890 .

JSTOR 10.4169/amer.math.monthly.122.10.1005 .

^ Pólya, George (1984).

Probability; Combinatorics; Teaching and learning in mathematics . Rota, Gian-Carlo, 1932-1999., Reynolds, M. C., Shortt, Rae Michael. Cambridge, Mass.: MIT Press. pp.

582 –585.

ISBN 0-262-16097-8 .

OCLC 10208449 .

^ Erdős, P.; Taylor, S. J. (1960). "Some intersection properties of random walk paths".

Acta Mathematica Academiae Scientiarum Hungaricae .

11 ( 3– 4): 231– 248.

CiteSeerX 10.1.1.210.6357 .

doi : 10.1007/BF02020942 .

ISSN 0001-5954 .

S2CID 14143214 .

^ H. Rycroft, Chris; Z. Bazant, Martin.

"Lecture 1: Introduction to Random Walks and Diffusion" (PDF) .

MIT OpenCourseWare . Department of Mathematics, MIT.

^ MacKenzie, D. (2000). "MATHEMATICS: Taking the Measure of the Wildest Dance on Earth".

Science .

290 (5498): 1883– 4.

doi : 10.1126/science.290.5498.1883 .

PMID 17742050 .

S2CID 12829171 .

(Erratum: doi : 10.1126/science.291.5504.597 ) ^ Chapter 2 DIFFUSION . dartmouth.edu.

^ Diffusion equation for the random walk Archived 21 April 2015 at the Wayback Machine . physics.uakron.edu.

^ Weiss, George H.; Rubin, Robert J. (1982). "Random Walks: Theory and Selected Applications".

Advances in Chemical Physics . Vol. 52. pp.

363– 505.

doi : 10.1002/9780470142769.ch5 .

ISBN 978-0-470-14276-9 .

^ Blumen, A.; Klafter, J.; Zumofen, G. (1986). "Models for Reaction Dynamics in Glasses".

Optical Spectroscopy of Glasses . Physic and Chemistry of Materials with Low-Dimensional Structures. Vol. 1. pp.

199– 265.

Bibcode : 1986PCMLD...1..199B .

doi : 10.1007/978-94-009-4650-7_5 .

ISBN 978-94-010-8566-3 .

^ Alexander, S.; Orbach, R. (1982).

"Density of states on fractals: " fractons " " (PDF) .

Journal de Physique Lettres .

43 (17): 625– 631.

doi : 10.1051/jphyslet:019820043017062500 .

S2CID 67757791 .

^ Rammal, R.; Toulouse, G. (1983).

"Random walks on fractal structures and percolation clusters" .

Journal de Physique Lettres .

44 (1): 13– 22.

doi : 10.1051/jphyslet:0198300440101300 .

^ Smoluchowski, M.V. (1917). "Versuch einer mathematischen Theorie der Koagulationskinetik kolloider Lösungen".

Z. Phys. Chem.

(29): 129– 168.

, Rice, S.A. (1 March 1985).

Diffusion-Limited Reactions . Comprehensive Chemical Kinetics. Vol. 25. Elsevier.

ISBN 978-0-444-42354-2 . Retrieved 13 August 2013 .

^ Skellam, J. G. (1951). "Random Dispersal in Theoretical Populations".

Biometrika .

38 (1/2): 196– 218.

doi : 10.2307/2332328 .

JSTOR 2332328 .

PMID 14848123 .

^ Skellam, J. G. (1952). "Studies in Statistical Ecology: I. Spatial Pattern".

Biometrika .

39 (3/4): 346– 362.

doi : 10.2307/2334030 .

JSTOR 2334030 .

^ Berger, T. (1970). "Information rates of Wiener processes".

IEEE Transactions on Information Theory .

16 (2): 134– 139.

doi : 10.1109/TIT.1970.1054423 .

^ Risken H. (1984) The Fokker–Planck Equation . Springer, Berlin.

^ De Gennes P. G. (1979) Scaling Concepts in Polymer Physics . Cornell University Press, Ithaca and London.

^ Van Kampen N. G. (1992) Stochastic Processes in Physics and Chemistry , revised and enlarged edition. North-Holland, Amsterdam.

^ Weiss, George H.

(1994).

Aspects and Applications of the Random Walk . Random Materials and Processes. North-Holland Publishing Co., Amsterdam.

ISBN 978-0-444-81606-1 .

MR 1280031 .

^ Doi M. and Edwards S. F. (1986) The Theory of Polymer Dynamics . Clarendon Press, Oxford ^ Goel N. W. and Richter-Dyn N.

(1974) Stochastic Models in Biology . Academic Press, New York.

^ Redner S. (2001) A Guide to First-Passage Process . Cambridge University Press, Cambridge, UK.

^ Cox D. R. (1962) Renewal Theory . Methuen, London.

^ David A. Kodde and Hein Schreuder (1984), Forecasting Corporate Revenue and Profit: Time-Series Models versus Management and Analysts, Journal of Business Finance and Accounting, vol. 11, no 3, Autumn 1984 ^ Hansen, Thomas F.; Martins, Emília P. (August 1996).

"Translating Between Microevolutionary Process and Macroevolutionary Patterns: The Correlation Structure of Interspecific Data" .

Evolution .

50 (4): 1404– 1417.

doi : 10.1111/j.1558-5646.1996.tb03914.x .

ISSN 0014-3820 .

PMID 28565714 .

^ Jones, R.A.L. (2004).

Soft condensed matter (Reprint. ed.). Oxford [u.a.]: Oxford Univ. Pr. pp.

77 –78.

ISBN 978-0-19-850589-1 .

^ Bar-Yossef, Ziv; Gurevich, Maxim (2008). "Random sampling from a search engine's index".

Journal of the ACM .

55 (5). Association for Computing Machinery (ACM): 1– 74.

doi : 10.1145/1411509.1411514 .

ISSN 0004-5411 .

^ Grady, L (2006).

"Random walks for image segmentation" (PDF) .

IEEE Transactions on Pattern Analysis and Machine Intelligence .

28 (11): 1768– 83.

CiteSeerX 10.1.1.375.3389 .

doi : 10.1109/TPAMI.2006.233 .

PMID 17063682 .

S2CID 489789 . Archived from the original (PDF) on 5 July 2017 . Retrieved 2 November 2016 .

^ Rucci, M; Victor, J. D. (2015).

"The unsteady eye: An information-processing stage, not a bug" .

Trends in Neurosciences .

38 (4): 195– 206.

doi : 10.1016/j.tins.2015.01.005 .

PMC 4385455 .

PMID 25698649 .

^ Engbert, R.; Mergenthaler, K.; Sinn, P.; Pikovsky, A. (2011).

"An integrated model of fixational eye movements and microsaccades" .

Proceedings of the National Academy of Sciences .

108 (39): E765-70.

Bibcode : 2011PNAS..108E.765E .

doi : 10.1073/pnas.1102730108 .

PMC 3182695 .

PMID 21873243 .

^ Nosofsky, R. M.; Palmeri, T. J. (1997).

"An exemplar-based random walk model of speeded classification" (PDF) .

Psychological Review .

104 (2): 266– 300.

doi : 10.1037/0033-295x.104.2.266 .

PMID 9127583 . Archived from the original (PDF) on 10 December 2004.

^ Codling, E. A; Plank, M. J; Benhamou, S. (6 August 2008).

"Random walk models in biology" .

Journal of the Royal Society Interface .

5 (25): 813– 834.

doi : 10.1098/rsif.2008.0014 .

PMC 2504494 .

PMID 18426776 .

^ Gupta, Pankaj et al.

WTF: The who-to-follow system at Twitter , Proceedings of the 22nd international conference on World Wide Web ^ It is interesting to remark that in a general graph the meeting of two independent random walkers does not always reduces to the problem of a single random walk returning to its starting point.

^ Krishnapur, Manjunath; Peres, Yuval (2004).

"Recurrent Graphs where Two Independent Random Walks Collide Finitely Often" .

Electronic Communications in Probability .

9 : 72– 81.

arXiv : math/0406487 .

Bibcode : 2004math......6487K .

doi : 10.1214/ECP.v9-1111 .

ISSN 1083-589X .

S2CID 16584737 .

^ Tishby, Ido; Biham, Ofer; Katzav, Eytan (2017). "The distribution of first hitting times of randomwalks on Erdős–Rényi networks".

Journal of Physics A: Mathematical and Theoretical .

50 (11): 115001.

arXiv : 1606.01560 .

Bibcode : 2017JPhA...50k5001T .

doi : 10.1088/1751-8121/aa5af3 .

S2CID 118850609 .

^ Tishby, Ido; Biham, Ofer; Katzav, Eytan (2016). "The distribution of path lengths of self avoiding walks on Erdős–Rényi networks".

Journal of Physics A: Mathematical and Theoretical .

49 (28): 285002.

arXiv : 1603.06613 .

Bibcode : 2016JPhA...49B5002T .

doi : 10.1088/1751-8113/49/28/285002 .

S2CID 119182848 .

^ Burda, Z.; Duda, J.; Luck, J. M.; Waclaw, B. (2009). "Localization of the Maximal Entropy Random Walk".

Physical Review Letters .

102 (16): 160602.

arXiv : 0810.4113 .

Bibcode : 2009PhRvL.102p0602B .

doi : 10.1103/PhysRevLett.102.160602 .

PMID 19518691 .

S2CID 32134048 .

^ Madras, Neal and Slade, Gordon (1996) The Self-Avoiding Walk , Birkhäuser Boston.

ISBN 0-8176-3891-1 .

^ Hemmer, S.; Hemmer, P. C. (1984).

"An average self-avoiding random walk on the square lattice lasts 71 steps" .

J. Chem. Phys .

81 (1): 584– 585.

Bibcode : 1984JChPh..81..584H .

doi : 10.1063/1.447349 .

^ Lawler, Gregory (1996).

Intersection of random walks , Birkhäuser Boston.

ISBN 0-8176-3892-X .

^ Lawler, Gregory Conformally Invariant Processes in the Plane , book.ps .

^ Pemantle, Robin (2007).

"A survey of random processes with reinforcement" (PDF) .

Probability Surveys .

4 : 1– 79.

arXiv : math/0610076 .

doi : 10.1214/07-PS094 .

S2CID 11964062 .

^ Alamgir, M. and von Luxburg, U.

(2010).

"Multi-agent random walks for local clustering on graphs" Archived 15 April 2012 at the Wayback Machine , IEEE 10th International Conference on Data Mining (ICDM) , pp. 18–27.

^ Bovet, Pierre; Benhamou, Simon (1988). "Spatial analysis of animals' movements using a correlated random walk model".

Journal of Theoretical Biology .

131 (4): 419– 433.

Bibcode : 1988JThBi.131..419B .

doi : 10.1016/S0022-5193(88)80038-9 .

^ Kareiva, P.M.; Shigesada, N. (1983). "Analyzing insect movement as a correlated random walk".

Oecologia .

56 ( 2– 3): 234– 238.

Bibcode : 1983Oecol..56..234K .

doi : 10.1007/BF00379695 .

PMID 28310199 .

S2CID 20329045 .

Bibliography [ edit ] Aldous, David ; Fill, James Allen (2002).

Reversible Markov Chains and Random Walks on Graphs .

Archived from the original on 27 February 2019.

Doyle, Peter G.; Snell, J. Laurie (1984).

Random Walks and Electric Networks . Carus Mathematical Monographs. Vol. 22.

Mathematical Association of America .

arXiv : math.PR/0001057 .

ISBN 978-0-88385-024-4 .

MR 0920811 .

Feller, William (1968), An Introduction to Probability Theory and its Applications (Volume 1).

ISBN 0-471-25708-7 Hughes, Barry D. (1996), Random Walks and Random Environments , Oxford University Press.

ISBN 0-19-853789-1 Norris, James (1998), Markov Chains , Cambridge University Press.

ISBN 0-521-63396-6 Pólya G.(1921), "Über eine Aufgabe der Wahrscheinlichkeitsrechnung betreffend die Irrfahrt im Strassennetz" Archived 4 March 2016 at the Wayback Machine , Mathematische Annalen , 84(1–2):149–160, March 1921.

Révész, Pal (2013), Random Walk in Random and Non-random Environments (Third Edition) , World Scientific Pub Co.

ISBN 978-981-4447-50-8 Sunada, Toshikazu (2012).

Topological Crystallography: With a View Towards Discrete Geometric Analysis . Surveys and Tutorials in the Applied Mathematical Sciences. Vol. 6. Springer.

ISBN 978-4-431-54177-6 .

Weiss G.

Aspects and Applications of the Random Walk , North-Holland, 1994.

Woess, Wolfgang (2000), Random Walks on Infinite Graphs and Groups , Cambridge tracts in mathematics 138, Cambridge University Press.

ISBN 0-521-55292-3 External links [ edit ] Pólya's Random Walk Constants Random walk in Java Applet Archived 31 August 2007 at the Wayback Machine Quantum random walk Gaussian random walk estimator Electron Conductance Models Using Maximal Entropy Random Walks Wolfram Demonstrations Project v t e Stochastic processes Discrete time Bernoulli process Branching process Chinese restaurant process Galton–Watson process Independent and identically distributed random variables Markov chain Moran process Random walk Loop-erased Self-avoiding Biased Maximal entropy Continuous time Additive process Airy process Bessel process Birth–death process pure birth Brownian motion Bridge Dyson Excursion Fractional Geometric Meander Cauchy process Contact process Continuous-time random walk Cox process Diffusion process Empirical process Feller process Fleming–Viot process Gamma process Geometric process Hawkes process Hunt process Interacting particle systems Itô diffusion Itô process Jump diffusion Jump process Lévy process Local time Markov additive process McKean–Vlasov process Ornstein–Uhlenbeck process Poisson process Compound Non-homogeneous Quasimartingale Schramm–Loewner evolution Semimartingale Sigma-martingale Stable process Superprocess Telegraph process Variance gamma process Wiener process Wiener sausage Both Branching process Gaussian process Hidden Markov model (HMM) Markov process Martingale Differences Local Sub- Super- Random dynamical system Regenerative process Renewal process Stochastic chains with memory of variable length White noise Fields and other Dirichlet process Gaussian random field Gibbs measure Hopfield model Ising model Potts model Boolean network Markov random field Percolation Pitman–Yor process Point process Cox Determinantal Poisson Random field Random graph Time series models Autoregressive conditional heteroskedasticity (ARCH) model Autoregressive integrated moving average (ARIMA) model Autoregressive (AR) model Autoregressive–moving-average (ARMA) model Generalized autoregressive conditional heteroskedasticity (GARCH) model Moving-average (MA) model Financial models Binomial options pricing model Black–Derman–Toy Black–Karasinski Black–Scholes Chan–Karolyi–Longstaff–Sanders (CKLS) Chen Constant elasticity of variance (CEV) Cox–Ingersoll–Ross (CIR) Garman–Kohlhagen Heath–Jarrow–Morton (HJM) Heston Ho–Lee Hull–White Korn-Kreer-Lenssen LIBOR market Rendleman–Bartter SABR volatility Vašíček Wilkie Actuarial models Bühlmann Cramér–Lundberg Risk process Sparre–Anderson Queueing models Bulk Fluid Generalized queueing network M/G/1 M/M/1 M/M/c Properties Càdlàg paths Continuous Continuous paths Ergodic Exchangeable Feller-continuous Gauss–Markov Markov Mixing Piecewise-deterministic Predictable Progressively measurable Self-similar Stationary Time-reversible Limit theorems Central limit theorem Donsker's theorem Doob's martingale convergence theorems Ergodic theorem Fisher–Tippett–Gnedenko theorem Large deviation principle Law of large numbers (weak/strong) Law of the iterated logarithm Maximal ergodic theorem Sanov's theorem Zero–one laws ( Blumenthal , Borel–Cantelli , Engelbert–Schmidt , Hewitt–Savage , Kolmogorov , Lévy ) Inequalities Burkholder–Davis–Gundy Doob's martingale Doob's upcrossing Kunita–Watanabe Marcinkiewicz–Zygmund Tools Cameron–Martin formula Convergence of random variables Doléans-Dade exponential Doob decomposition theorem Doob–Meyer decomposition theorem Doob's optional stopping theorem Dynkin's formula Feynman–Kac formula Filtration Girsanov theorem Infinitesimal generator Itô integral Itô's lemma Karhunen–Loève theorem Kolmogorov continuity theorem Kolmogorov extension theorem Lévy–Prokhorov metric Malliavin calculus Martingale representation theorem Optional stopping theorem Prokhorov's theorem Quadratic variation Reflection principle Skorokhod integral Skorokhod's representation theorem Skorokhod space Snell envelope Stochastic differential equation Tanaka Stopping time Stratonovich integral Uniform integrability Usual hypotheses Wiener space Classical Abstract Disciplines Actuarial mathematics Control theory Econometrics Ergodic theory Extreme value theory (EVT) Large deviations theory Mathematical finance Mathematical statistics Probability theory Queueing theory Renewal theory Ruin theory Signal processing Statistics Stochastic analysis Time series analysis Machine learning List of topics Category Authority control databases National United States France BnF data Japan Israel Other Yale LUX NewPP limit report
Parsed by mw‐web.codfw.main‐597b4b5bbd‐5r7fr
Cached time: 20250814215147
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.986 seconds
Real time usage: 1.228 seconds
Preprocessor visited node count: 6833/1000000
Revision size: 57152/2097152 bytes
Post‐expand include size: 175621/2097152 bytes
Template argument size: 6071/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 213996/5000000 bytes
Lua time usage: 0.586/10.000 seconds
Lua memory usage: 20739421/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  878.478      1 -total
 41.41%  363.780      1 Template:Reflist
 27.16%  238.625     27 Template:Cite_journal
 16.03%  140.822      9 Template:Annotated_link
  7.74%   68.015      1 Template:Probability_fundamentals
  7.59%   66.713      1 Template:Sidebar
  7.18%   63.088     11 Template:Cite_book
  6.69%   58.754      1 Template:Short_description
  5.99%   52.595      6 Template:Citation_needed
  5.08%   44.623      6 Template:Fix Saved in parser cache with key enwiki:pcache:235451:|#|:idhash:canonical and timestamp 20250814215147 and revision id 1304455507. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Random_walk&oldid=1304455507 " Categories : Stochastic processes Variants of random walks Hidden categories: Articles intentionally citing publications with errata Webarchive template wayback links Articles with short description Short description is different from Wikidata Use dmy dates from March 2020 All articles with unsourced statements Articles with unsourced statements from April 2012 Articles needing additional references from February 2013 All articles needing additional references This page was last edited on 6 August 2025, at 04:35 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Random walk 30 languages Add topic

