Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 References 2 Further reading Toggle the table of contents Truncated Newton method 1 language 日本語 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia The truncated Newton method , originated in a paper by Ron Dembo and Trond Steihaug, [ 1 ] also known as Hessian-free optimization , [ 2 ] are a family of optimization algorithms designed for optimizing non-linear functions with large numbers of independent variables . A truncated Newton method consists of repeated application of an iterative optimization algorithm to approximately solve Newton's equations , to determine an update to the function's parameters. The inner solver is truncated , i.e., run for only a limited number of iterations. It follows that, for truncated Newton methods to work, the inner solver needs to produce a good approximation in a finite number of iterations; [ 3 ] conjugate gradient has been suggested and evaluated as a candidate inner loop.

[ 2 ] Another prerequisite is good preconditioning for the inner algorithm.

[ 4 ] References [ edit ] ^ Dembo, Ron S.; Steihaug, Trond (1983). "Truncated-Newton algorithms for large-scale unconstrained optimization".

Mathematical Programming .

26 (2). Springer: 190– 212.

doi : 10.1007/BF02592055 .

S2CID 40537623 .

. Convergence results for this algorithm can be found in Dembo, Ron S.; Eisenstat, Stanley C.; Steihaug, Trond (1982). "Inexact newton methods".

SIAM Journal on Numerical Analysis .

19 (2): 400– 408.

Bibcode : 1982SJNA...19..400D .

doi : 10.1137/0719025 .

JSTOR 2156954 .

.

^ a b Martens, James (2010).

Deep learning via Hessian-free optimization (PDF) . Proc.

International Conference on Machine Learning .

^ Nash, Stephen G. (2000).

"A survey of truncated-Newton methods" .

Journal of Computational and Applied Mathematics .

124 ( 1– 2): 45– 59.

Bibcode : 2000JCoAM.124...45N .

doi : 10.1016/S0377-0427(00)00426-X .

^ Nash, Stephen G. (1985).

"Preconditioning of truncated-Newton methods" (PDF) .

SIAM J. Sci. Stat. Comput .

6 (3): 599– 616.

doi : 10.1137/0906042 .

Further reading [ edit ] Grippo, L.; Lampariello, F.; Lucidi, S. (1989). "A Truncated Newton Method with Nonmonotone Line Search for Unconstrained Optimization".

J. Optimization Theory and Applications .

60 (3): 401– 419.

CiteSeerX 10.1.1.455.7495 .

doi : 10.1007/BF00940345 .

S2CID 18990650 .

Nash, Stephen G.; Nocedal, Jorge (1991). "A numerical study of the limited memory BFGS method and the truncated-Newton method for large scale optimization".

SIAM J. Optim .

1 (3): 358– 372.

CiteSeerX 10.1.1.474.3400 .

doi : 10.1137/0801023 .

v t e Optimization : Algorithms , methods , and heuristics Unconstrained nonlinear Functions Golden-section search Powell's method Line search Nelder–Mead method Successive parabolic interpolation Gradients Convergence Trust region Wolfe conditions Quasi–Newton Berndt–Hall–Hall–Hausman Broyden–Fletcher–Goldfarb–Shanno and L-BFGS Davidon–Fletcher–Powell Symmetric rank-one (SR1) Other methods Conjugate gradient Gauss–Newton Gradient Mirror Levenberg–Marquardt Powell's dog leg method Truncated Newton Hessians Newton's method Optimization computes maxima and minima.

Constrained nonlinear General Barrier methods Penalty methods Differentiable Augmented Lagrangian methods Sequential quadratic programming Successive linear programming Convex optimization Convex minimization Cutting-plane method Reduced gradient (Frank–Wolfe) Subgradient method Linear and quadratic Interior point Affine scaling Ellipsoid algorithm of Khachiyan Projective algorithm of Karmarkar Basis- exchange Simplex algorithm of Dantzig Revised simplex algorithm Criss-cross algorithm Principal pivoting algorithm of Lemke Active-set method Combinatorial Paradigms Approximation algorithm Dynamic programming Greedy algorithm Integer programming Branch and bound / cut Graph algorithms Minimum spanning tree Borůvka Prim Kruskal Shortest path Bellman–Ford SPFA Dijkstra Floyd–Warshall Network flows Dinic Edmonds–Karp Ford–Fulkerson Push–relabel maximum flow Metaheuristics Evolutionary algorithm Hill climbing Local search Parallel metaheuristics Simulated annealing Spiral optimization algorithm Tabu search Software v t e Sir Isaac Newton Publications Fluxions (1671) De Motu (1684) Principia (1687) Opticks (1704) Queries (1704) Arithmetica (1707) De Analysi (1711) Other writings Quaestiones (1661–1665) " standing on the shoulders of giants " (1675) Notes on the Jewish Temple (c. 1680) " General Scholium " (1713; " hypotheses non fingo " ) Ancient Kingdoms Amended (1728) Corruptions of Scripture (1754) Contributions Calculus fluxion Impact depth Inertia Newton disc Newton polygon Newton–Okounkov body Newton's reflector Newtonian telescope Newton scale Newton's metal Spectrum Structural coloration Newtonianism Bucket argument Newton's inequalities Newton's law of cooling Newton's law of universal gravitation post-Newtonian expansion parameterized gravitational constant Newton–Cartan theory Schrödinger–Newton equation Newton's laws of motion Kepler's laws Newtonian dynamics Newton's method in optimization Apollonius's problem truncated Newton method Gauss–Newton algorithm Newton's rings Newton's theorem about ovals Newton–Pepys problem Newtonian potential Newtonian fluid Classical mechanics Corpuscular theory of light Leibniz–Newton calculus controversy Newton's notation Rotating spheres Newton's cannonball Newton–Cotes formulas Newton's method generalized Gauss–Newton method Newton fractal Newton's identities Newton polynomial Newton's theorem of revolving orbits Newton–Euler equations Newton number kissing number problem Newton's quotient Parallelogram of force Newton–Puiseux theorem Absolute space and time Luminiferous aether Newtonian series table Personal life Woolsthorpe Manor (birthplace) Cranbury Park (home) Early life Later life Apple tree Religious views Occult studies Scientific Revolution Copernican Revolution Relations Catherine Barton (niece) John Conduitt (nephew-in-law) Isaac Barrow (professor) William Clarke (mentor) Benjamin Pulleyn (tutor) Roger Cotes (student) William Whiston (student) John Keill (disciple) William Stukeley (friend) William Jones (friend) Abraham de Moivre (friend) Depictions Newton by Blake (monotype) Newton by Paolozzi (sculpture) Isaac Newton Gargoyle Astronomers Monument Namesake Newton (unit) Newton's cradle Isaac Newton Institute Isaac Newton Medal Isaac Newton Telescope Isaac Newton Group of Telescopes XMM-Newton Sir Isaac Newton Sixth Form Statal Institute of Higher Education Isaac Newton Newton International Fellowship Categories Isaac Newton This applied mathematics –related article is a stub . You can help Wikipedia by expanding it .

v t e NewPP limit report
Parsed by mw‐web.codfw.main‐7c956d68b4‐m2w55
Cached time: 20250818055901
Cache expiry: 21600
Reduced expiry: true
Complications: [vary‐revision‐sha1]
CPU time usage: 0.281 seconds
Real time usage: 0.332 seconds
Preprocessor visited node count: 1121/1000000
Revision size: 3388/2097152 bytes
Post‐expand include size: 95970/2097152 bytes
Template argument size: 227/2097152 bytes
Highest expansion depth: 11/100
Expensive parser function count: 1/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 45605/5000000 bytes
Lua time usage: 0.171/10.000 seconds
Lua memory usage: 4253804/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  269.744      1 -total
 39.65%  106.965      1 Template:Reflist
 35.84%   96.675      6 Template:Cite_journal
 34.42%   92.844      1 Template:Optimization_algorithms
 33.55%   90.502      1 Template:Navbox_with_collapsible_groups
 10.41%   28.084      9 Template:Navbox
  9.23%   24.905      1 Template:R
  7.27%   19.613      1 Template:R/ref
  5.66%   15.269      1 Template:Applied-math-stub
  5.61%   15.145      1 Template:R/superscript Saved in parser cache with key enwiki:pcache:47372547:|#|:idhash:canonical and timestamp 20250818055901 and revision id 1168931097. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Truncated_Newton_method&oldid=1168931097 " Categories : Optimization algorithms and methods Applied mathematics stubs Hidden category: All stub articles This page was last edited on 6 August 2023, at 00:12 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Truncated Newton method 1 language Add topic

