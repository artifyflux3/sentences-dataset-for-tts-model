Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Units Toggle Units subsection 1.1 One-sided vs. two-sided 2 Definition Toggle Definition subsection 2.1 Energy spectral density 2.2 Power spectral density 2.2.1 Properties of the power spectral density 2.3 Cross power spectral density 3 Estimation 4 Related concepts 5 Applications Toggle Applications subsection 5.1 Electrical engineering 5.2 Cosmology 6 See also 7 Notes 8 References 9 External links Toggle the table of contents Spectral density 19 languages Boarisch Català Deutsch Eesti Español Esperanto فارسی Français Italiano 日本語 Polski Português Русский Simple English Svenska Türkçe Українська Tiếng Việt 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Frequency spectrum ) Relative importance of certain frequencies in a composite signal This article is about signal processing and relation of spectra to time-series. For further applications in the physical sciences, see Spectrum (physical sciences) .

"Spectral power density" redirects here; not to be confused with Spectral power .

The spectral density of a fluorescent light as a function of optical wavelength shows peaks at atomic transitions, indicated by the numbered arrows.

The voice waveform over time (left) has a broad audio power spectrum (right).

This article may be too technical for most readers to understand .

Please help improve it to make it understandable to non-experts , without removing the technical details.

( June 2024 ) ( Learn how and when to remove this message ) In signal processing , the power spectrum S x x ( f ) {\displaystyle S_{xx}(f)} of a continuous time signal x ( t ) {\displaystyle x(t)} describes the distribution of power into frequency components f {\displaystyle f} composing that signal.

[ 1 ] Fourier analysis shows that any physical signal can be decomposed into a distribution of frequencies over a continuous range, where some of the power may be concentrated at discrete frequencies. The statistical average of the energy or power of any type of signal (including noise ) as analyzed in terms of its frequency content, is called its spectral density .

When the energy of the signal is concentrated around a finite time interval, especially if its total energy is finite, one may compute the energy spectral density . More commonly used is the power spectral density (PSD, or simply power spectrum ), which applies to signals existing over all time, or over a time period large enough (especially in relation to the duration of a measurement) that it could as well have been over an infinite time interval. The PSD then refers to the spectral power distribution that would be found, since the total energy of such a signal over all time would generally be infinite.

Summation or integration of the spectral components yields the total power (for a physical process) or variance (in a statistical process), identical to what would be obtained by integrating x 2 ( t ) {\displaystyle x^{2}(t)} over the time domain, as dictated by Parseval's theorem .

[ 1 ] The spectrum of a physical process x ( t ) {\displaystyle x(t)} often contains essential information about the nature of x {\displaystyle x} . For instance, the pitch and timbre of a musical instrument can be determined from a spectral analysis. The color of a light source is determined by the spectrum of the electromagnetic wave's electric field E ( t ) {\displaystyle E(t)} as it oscillates at an extremely high frequency. Obtaining a spectrum from time series data such as these involves the Fourier transform , and generalizations based on Fourier analysis. In many cases the time domain is not directly captured in practice, such as when a dispersive prism is used to obtain a spectrum of light in a spectrograph , or when a sound is perceived through its effect on the auditory receptors of the inner ear, each of which is sensitive to a particular frequency.

However this article concentrates on situations in which the time series is known (at least in a statistical sense) or directly measured (such as by a microphone sampled by a computer). The power spectrum is important in statistical signal processing and in the statistical study of stochastic processes , as well as in many other branches of physics and engineering . Typically the process is a function of time, but one can similarly discuss data in the spatial domain being decomposed in terms of spatial frequency .

[ 1 ] Units [ edit ] See also: Fourier transform § Units In physics , the signal might be a wave, such as an electromagnetic wave , an acoustic wave , or the vibration of a mechanism. The power spectral density (PSD) of the signal describes the power density of the signal as a function of frequency. Power spectral density is commonly expressed in the SI unit watt per hertz (W/Hz).

[ 2 ] When a signal is defined in terms of only a voltage varying in time, for instance, there is no specific power associated with a given voltage. In this case "power" is simply reckoned in terms of the square of the signal, as this would always be proportional to the actual power delivered by that signal into a given impedance . So one might use the unit V 2 ⋅Hz −1 for the PSD.

Energy spectral density (ESD) would have the unit V 2 ⋅s⋅Hz −1 , since energy is power multiplied by time (e.g., watt-hour ).

[ 3 ] In the general case, the unit of PSD will be the ratio of unit of variance per unit of frequency; so, for example, a series of displacement values (in meters) over time (in seconds) will have PSD with the unit m 2 /Hz.
In the analysis of random vibrations , the unit g 0 2 ⋅Hz −1 may be used for the PSD of acceleration , where g 0 denotes standard gravity .

[ 4 ] Mathematically, it is not necessary to assign physical dimensions to the signal or to the independent variable. In the following discussion the meaning of x ( t ) will remain unspecified, but the independent variable will be assumed to be that of time.

One-sided vs. two-sided [ edit ] A PSD can be either a one-sided function of only positive frequencies or a two-sided function of both positive and negative frequencies but with only half the amplitude. Noise PSDs are generally one-sided in engineering and two-sided in physics.

[ 5 ] Definition [ edit ] Energy spectral density [ edit ] "Energy spectral density" redirects here; not to be confused with Energy spectrum .

In signal processing , the energy of a signal x ( t ) {\displaystyle x(t)} is given by E ≜ ≜ ∫ ∫ − − ∞ ∞ ∞ ∞ | x ( t ) | 2 d t .

{\displaystyle E\triangleq \int _{-\infty }^{\infty }\left|x(t)\right|^{2}\ dt.} Assuming the total energy is finite (i.e.

x ( t ) {\displaystyle x(t)} is a square-integrable function ) allows applying Parseval's theorem (or Plancherel's theorem ).

[ 6 ] That is, ∫ ∫ − − ∞ ∞ ∞ ∞ | x ( t ) | 2 d t = ∫ ∫ − − ∞ ∞ ∞ ∞ | x ^ ^ ( f ) | 2 d f , {\displaystyle \int _{-\infty }^{\infty }|x(t)|^{2}\,dt=\int _{-\infty }^{\infty }\left|{\hat {x}}(f)\right|^{2}\,df,} where x ^ ^ ( f ) = ∫ ∫ − − ∞ ∞ ∞ ∞ e − − i 2 π π f t x ( t ) d t , {\displaystyle {\hat {x}}(f)=\int _{-\infty }^{\infty }e^{-i2\pi ft}x(t)\ dt,} is the Fourier transform of x ( t ) {\displaystyle x(t)} at frequency f {\displaystyle f} (in Hz ).

[ 7 ] The theorem also holds true in the discrete-time cases. Since the integral on the left-hand side is the energy of the signal, the value of | x ^ ^ ( f ) | 2 d f {\displaystyle \left|{\hat {x}}(f)\right|^{2}df} can be interpreted as a density function multiplied by an infinitesimally small frequency interval, describing the energy contained in the signal at frequency f {\displaystyle f} in the frequency interval f + d f {\displaystyle f+df} .

Therefore, the energy spectral density of x ( t ) {\displaystyle x(t)} is defined as [ 8 ] S ¯ ¯ x x ( f ) ≜ ≜ | x ^ ^ ( f ) | 2 {\displaystyle {\bar {S}}_{xx}(f)\triangleq \left|{\hat {x}}(f)\right|^{2}} Eq.1 The function S ¯ ¯ x x ( f ) {\displaystyle {\bar {S}}_{xx}(f)} and the autocorrelation of x ( t ) {\displaystyle x(t)} form a Fourier transform pair, a result also known as the Wiener–Khinchin theorem (see also Periodogram ).

As a physical example of how one might measure the energy spectral density of a signal, suppose V ( t ) {\displaystyle V(t)} represents the potential (in volts ) of an electrical pulse propagating along a transmission line of impedance Z {\displaystyle Z} , and suppose the line is terminated with a matched resistor (so that all of the pulse energy is delivered to the resistor and none is reflected back). By Ohm's law , the power delivered to the resistor at time t {\displaystyle t} is equal to V ( t ) 2 / Z {\displaystyle V(t)^{2}/Z} , so the total energy is found by integrating V ( t ) 2 / Z {\displaystyle V(t)^{2}/Z} with respect to time over the duration of the pulse. To find the value of the energy spectral density S ¯ ¯ x x ( f ) {\displaystyle {\bar {S}}_{xx}(f)} at frequency f {\displaystyle f} , one could insert between the transmission line and the resistor a bandpass filter which passes only a narrow range of frequencies ( Δ Δ f {\displaystyle \Delta f} , say) near the frequency of interest and then measure the total energy E ( f ) {\displaystyle E(f)} dissipated across the resistor. The value of the energy spectral density at f {\displaystyle f} is then estimated to be E ( f ) / Δ Δ f {\displaystyle E(f)/\Delta f} . In this example, since the power V ( t ) 2 / Z {\displaystyle V(t)^{2}/Z} has the unit V 2 ⋅Ω −1 , the energy E ( f ) {\displaystyle E(f)} has the unit V 2 ⋅s⋅Ω −1 = J , and hence the estimate E ( f ) / Δ Δ f {\displaystyle E(f)/\Delta f} of the energy spectral density has the unit J⋅Hz −1 . In many situations, it is common to omit the step of dividing by Z {\displaystyle Z} so that the energy spectral density instead has the unit V 2 ⋅Hz −1 .

This definition generalizes in a straightforward manner to a discrete signal with a countably infinite number of values x n {\displaystyle x_{n}} such as a signal sampled at discrete times t n = t 0 + ( n Δ Δ t ) {\displaystyle t_{n}=t_{0}+(n\,\Delta t)} : S ¯ ¯ x x ( f ) = lim N → → ∞ ∞ ( Δ Δ t ) 2 | ∑ ∑ n = − − N N x n e − − i 2 π π f n Δ Δ t | 2 ⏟ ⏟ | x ^ ^ d ( f ) | 2 , {\displaystyle {\bar {S}}_{xx}(f)=\lim _{N\to \infty }(\Delta t)^{2}\underbrace {\left|\sum _{n=-N}^{N}x_{n}e^{-i2\pi fn\,\Delta t}\right|^{2}} _{\left|{\hat {x}}_{d}(f)\right|^{2}},} where x ^ ^ d ( f ) {\displaystyle {\hat {x}}_{d}(f)} is the discrete-time Fourier transform of x n .

{\displaystyle x_{n}.} The sampling interval Δ Δ t {\displaystyle \Delta t} is needed to keep the correct physical unit and to ensure that we recover the continuous case in the limit Δ Δ t → → 0 {\displaystyle \Delta t\to 0} . But in the mathematical sciences the interval is often set to 1, which simplifies the results at the expense of generality. (Also see Normalized frequency (unit) ) Power spectral density [ edit ] Not to be confused with spectral power distribution .

The power spectrum of the measured cosmic microwave background radiation temperature anisotropy in terms of the angular scale. The solid line is a theoretical model, for comparison.

The above definition of energy spectral density is suitable for transients (pulse-like signals) whose energy is concentrated around one time window; then the Fourier transforms of the signals generally exist. For continuous signals over all time, one must rather define the power spectral density (PSD) which exists for stationary processes ; this describes how the power of a signal or time series is distributed over frequency, as in the simple example given previously.  Here, power can be the actual physical power, or more often, for convenience with abstract signals, is simply identified with the squared value of the signal. For example, statisticians study the variance of a function over time x ( t ) {\displaystyle x(t)} (or over another independent variable), and using an analogy with electrical signals (among other physical processes), it is customary to refer to it as the power spectrum even when there is no physical power involved. If one were to create a physical voltage source which followed x ( t ) {\displaystyle x(t)} and applied it to the terminals of a one ohm resistor , then indeed the instantaneous power dissipated in that resistor would be given by x 2 ( t ) {\displaystyle x^{2}(t)} watts .

The average power P {\displaystyle P} of a signal x ( t ) {\displaystyle x(t)} over all time is therefore given by the following time average, where the period T {\displaystyle T} is centered about some arbitrary time t = t 0 {\displaystyle t=t_{0}} : P = lim T → → ∞ ∞ 1 T ∫ ∫ t 0 − − T / 2 t 0 + T / 2 | x ( t ) | 2 d t {\displaystyle P=\lim _{T\to \infty }{\frac {1}{T}}\int _{t_{0}-T/2}^{t_{0}+T/2}\left|x(t)\right|^{2}\,dt} Whenever it is more convenient to deal with time limits in the signal itself rather than time limits in the bounds of the integral, the average power can also be written as P = lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ | x T ( t ) | 2 d t , {\displaystyle P=\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }\left|x_{T}(t)\right|^{2}\,dt,} where x T ( t ) = x ( t ) w T ( t ) {\displaystyle x_{T}(t)=x(t)w_{T}(t)} and w T ( t ) {\displaystyle w_{T}(t)} is unity within the arbitrary period and zero elsewhere.

When P {\displaystyle P} is non-zero, the integral must grow to infinity at least as fast as T {\displaystyle T} does. That is the reason why we cannot use the energy of the signal, which is that diverging integral.

In analyzing the frequency content of the signal x ( t ) {\displaystyle x(t)} , one might like to compute the ordinary Fourier transform x ^ ^ ( f ) {\displaystyle {\hat {x}}(f)} ; however, for many signals of interest the ordinary Fourier transform does not formally exist.

[ nb 1 ] However, under suitable conditions, certain generalizations of the Fourier transform (e.g. the Fourier–Stieltjes transform ) still adhere to Parseval's theorem . As such, P = lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ | x ^ ^ T ( f ) | 2 d f , {\displaystyle P=\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }|{\hat {x}}_{T}(f)|^{2}\,df,} where the integrand defines the power spectral density : [ 9 ] [ 10 ] S x x ( f ) = lim T → → ∞ ∞ 1 T | x ^ ^ T ( f ) | 2 {\displaystyle S_{xx}(f)=\lim _{T\to \infty }{\frac {1}{T}}|{\hat {x}}_{T}(f)|^{2}\,} Eq.2 The convolution theorem then allows regarding | x ^ ^ T ( f ) | 2 {\displaystyle |{\hat {x}}_{T}(f)|^{2}} as the Fourier transform of the time convolution of x T ∗ ∗ ( − − t ) {\displaystyle x_{T}^{*}(-t)} and x T ( t ) {\displaystyle x_{T}(t)} , where * represents the complex conjugate.

In order to deduce Eq.2, we will find an expression for [ x ^ ^ T ( f ) ] ∗ ∗ {\displaystyle [{\hat {x}}_{T}(f)]^{*}} that will be useful for the purpose. In fact, we will demonstrate that [ x ^ ^ T ( f ) ] ∗ ∗ = F { x T ∗ ∗ ( − − t ) } {\displaystyle [{\hat {x}}_{T}(f)]^{*}={\mathcal {F}}\left\{x_{T}^{*}(-t)\right\}} . Start by noting that F { x T ∗ ∗ ( − − t ) } = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( − − t ) e − − i 2 π π f t d t {\displaystyle {\begin{aligned}{\mathcal {F}}\left\{x_{T}^{*}(-t)\right\}&=\int _{-\infty }^{\infty }x_{T}^{*}(-t)e^{-i2\pi ft}dt\end{aligned}}} and let z = − − t {\displaystyle z=-t} , so that z → → − − ∞ ∞ {\displaystyle z\rightarrow -\infty } when t → → ∞ ∞ {\displaystyle t\rightarrow \infty } and vice versa. So ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( − − t ) e − − i 2 π π f t d t = ∫ ∫ ∞ ∞ − − ∞ ∞ x T ∗ ∗ ( z ) e i 2 π π f z ( − − d z ) = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( z ) e i 2 π π f z d z = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t ) e i 2 π π f t d t {\displaystyle {\begin{aligned}\int _{-\infty }^{\infty }x_{T}^{*}(-t)e^{-i2\pi ft}dt&=\int _{\infty }^{-\infty }x_{T}^{*}(z)e^{i2\pi fz}\left(-dz\right)\\&=\int _{-\infty }^{\infty }x_{T}^{*}(z)e^{i2\pi fz}dz\\&=\int _{-\infty }^{\infty }x_{T}^{*}(t)e^{i2\pi ft}dt\end{aligned}}} where, in the last line, use has been made of z {\displaystyle z} and t {\displaystyle t} being dummy variables.
So, we have F { x T ∗ ∗ ( − − t ) } = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( − − t ) e − − i 2 π π f t d t = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t ) e i 2 π π f t d t = ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t ) [ e − − i 2 π π f t ] ∗ ∗ d t = [ ∫ ∫ − − ∞ ∞ ∞ ∞ x T ( t ) e − − i 2 π π f t d t ] ∗ ∗ = [ F { x T ( t ) } ] ∗ ∗ = [ x ^ ^ T ( f ) ] ∗ ∗ {\displaystyle {\begin{aligned}{\mathcal {F}}\left\{x_{T}^{*}(-t)\right\}&=\int _{-\infty }^{\infty }x_{T}^{*}(-t)e^{-i2\pi ft}dt\\&=\int _{-\infty }^{\infty }x_{T}^{*}(t)e^{i2\pi ft}dt\\&=\int _{-\infty }^{\infty }x_{T}^{*}(t)[e^{-i2\pi ft}]^{*}dt\\&=\left[\int _{-\infty }^{\infty }x_{T}(t)e^{-i2\pi ft}dt\right]^{*}\\&=\left[{\mathcal {F}}\left\{x_{T}(t)\right\}\right]^{*}\\&=\left[{\hat {x}}_{T}(f)\right]^{*}\end{aligned}}} q.e.d.

Now, let's demonstrate eq.2 by using the demonstrated identity. In addition, we will make the substitution u ( t ) = x T ∗ ∗ ( − − t ) {\displaystyle u(t)=x_{T}^{*}(-t)} . In this way, we have: | x ^ ^ T ( f ) | 2 = [ x ^ ^ T ( f ) ] ∗ ∗ ⋅ ⋅ x ^ ^ T ( f ) = F { x T ∗ ∗ ( − − t ) } ⋅ ⋅ F { x T ( t ) } = F { u ( t ) } ⋅ ⋅ F { x T ( t ) } = F { u ( t ) ∗ ∗ x T ( t ) } = ∫ ∫ − − ∞ ∞ ∞ ∞ [ ∫ ∫ − − ∞ ∞ ∞ ∞ u ( τ τ − − t ) x T ( t ) d t ] e − − i 2 π π f τ τ d τ τ = ∫ ∫ − − ∞ ∞ ∞ ∞ [ ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t − − τ τ ) x T ( t ) d t ] e − − i 2 π π f τ τ d τ τ , {\displaystyle {\begin{aligned}\left|{\hat {x}}_{T}(f)\right|^{2}&=[{\hat {x}}_{T}(f)]^{*}\cdot {\hat {x}}_{T}(f)\\&={\mathcal {F}}\left\{x_{T}^{*}(-t)\right\}\cdot {\mathcal {F}}\left\{x_{T}(t)\right\}\\&={\mathcal {F}}\left\{u(t)\right\}\cdot {\mathcal {F}}\left\{x_{T}(t)\right\}\\&={\mathcal {F}}\left\{u(t)\mathbin {\mathbf {*} } x_{T}(t)\right\}\\&=\int _{-\infty }^{\infty }\left[\int _{-\infty }^{\infty }u(\tau -t)x_{T}(t)dt\right]e^{-i2\pi f\tau }d\tau \\&=\int _{-\infty }^{\infty }\left[\int _{-\infty }^{\infty }x_{T}^{*}(t-\tau )x_{T}(t)dt\right]e^{-i2\pi f\tau }\ d\tau ,\end{aligned}}} where the convolution theorem has been used when passing from the 3rd to the 4th line.

Now, if we divide the time convolution above by the period T {\displaystyle T} and take the limit as T → → ∞ ∞ {\displaystyle T\rightarrow \infty } , it becomes the autocorrelation function of the non-windowed signal x ( t ) {\displaystyle x(t)} , which is denoted as R x x ( τ τ ) {\displaystyle R_{xx}(\tau )} , provided that x ( t ) {\displaystyle x(t)} is ergodic , which is true in most, but not all, practical cases.

[ nb 2 ] lim T → → ∞ ∞ 1 T | x ^ ^ T ( f ) | 2 = ∫ ∫ − − ∞ ∞ ∞ ∞ [ lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t − − τ τ ) x T ( t ) d t ] e − − i 2 π π f τ τ d τ τ = ∫ ∫ − − ∞ ∞ ∞ ∞ R x x ( τ τ ) e − − i 2 π π f τ τ d τ τ {\displaystyle \lim _{T\to \infty }{\frac {1}{T}}\left|{\hat {x}}_{T}(f)\right|^{2}=\int _{-\infty }^{\infty }\left[\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }x_{T}^{*}(t-\tau )x_{T}(t)dt\right]e^{-i2\pi f\tau }\ d\tau =\int _{-\infty }^{\infty }R_{xx}(\tau )e^{-i2\pi f\tau }d\tau } Assuming the ergodicity of x ( t ) {\displaystyle x(t)} , the power spectral density can be found once more as the Fourier transform of the autocorrelation function R x x {\displaystyle R_{xx}} , a property known as the Wiener–Khinchin theorem .

[ 11 ] S x x ( f ) = ∫ ∫ − − ∞ ∞ ∞ ∞ R x x ( τ τ ) e − − i 2 π π f τ τ d τ τ = R ^ ^ x x ( f ) {\displaystyle S_{xx}(f)=\int _{-\infty }^{\infty }R_{xx}(\tau )e^{-i2\pi f\tau }\,d\tau ={\hat {R}}_{xx}(f)} Eq.3 Many authors use this relationship to define the power spectral density in terms of the autocorrelation function instead of the Fourier transform of the signal as we have done.

[ 12 ] The power of the signal in a given frequency band [ f 1 , f 2 ] {\displaystyle [f_{1},f_{2}]} , where 0 < f 1 < f 2 {\displaystyle 0<f_{1}<f_{2}} , can be calculated by integrating over frequency. Since S x x ( − − f ) = S x x ( f ) {\displaystyle S_{xx}(-f)=S_{xx}(f)} , an equal amount of power can be attributed to positive and negative frequency bands, which accounts for the factor of 2 in the following form (such trivial factors depend on the conventions used): P band-limited = 2 ∫ ∫ f 1 f 2 S x x ( f ) d f {\displaystyle P_{\textsf {band-limited}}=2\int _{f_{1}}^{f_{2}}S_{xx}(f)\,df} More generally, similar techniques may be used to estimate a time-varying spectral density. In this case the time interval T {\displaystyle T} is finite rather than approaching infinity. This results in decreased spectral coverage and resolution since frequencies of less than 1 / T {\displaystyle 1/T} are not sampled, and results at frequencies which are not an integer multiple of 1 / T {\displaystyle 1/T} are not independent. Just using a single such time series, the estimated power spectrum will be very "noisy"; however this can be alleviated if it is possible to evaluate the expected value (in the above equation) using a large (or infinite) number of short-term spectra corresponding to statistical ensembles of realizations of x ( t ) {\displaystyle x(t)} evaluated over the specified time window.

Just as with the energy spectral density, the definition of the power spectral density can be generalized to discrete time variables x n {\displaystyle x_{n}} . As before, we can consider a window of − − N ≤ ≤ n ≤ ≤ N {\displaystyle -N\leq n\leq N} with the signal sampled at discrete times t n = t 0 + ( n Δ Δ t ) {\displaystyle t_{n}=t_{0}+(n\,\Delta t)} for a total measurement period T = ( 2 N + 1 ) Δ Δ t {\displaystyle T=(2N+1)\,\Delta t} .

S x x ( f ) = lim N → → ∞ ∞ ( Δ Δ t ) 2 T | ∑ ∑ n = − − N N x n e − − i 2 π π f n Δ Δ t | 2 {\displaystyle S_{xx}(f)=\lim _{N\to \infty }{\frac {(\Delta t)^{2}}{T}}\left|\sum _{n=-N}^{N}x_{n}e^{-i2\pi fn\,\Delta t}\right|^{2}} Note that a single estimate of the PSD can be obtained through a finite number of samplings.  As before, the actual PSD is achieved when N {\displaystyle N} (and thus T {\displaystyle T} ) approaches infinity and the expected value is formally applied. In a real-world application, one would typically average a finite-measurement PSD over many trials to obtain a more accurate estimate of the theoretical PSD of the physical process underlying the individual measurements.  This computed PSD is sometimes called a periodogram . This periodogram converges to the true PSD as the number of estimates as well as the averaging time interval T {\displaystyle T} approach infinity.

[ 13 ] If two signals both possess power spectral densities, then the cross-spectral density can similarly be calculated; as the PSD is related to the autocorrelation, so is the cross-spectral density related to the cross-correlation .

Properties of the power spectral density [ edit ] Some properties of the PSD include: [ 14 ] The power spectrum is always real and non-negative, and the spectrum of a real valued process is also an even function of frequency: S x x ( − − f ) = S x x ( f ) {\displaystyle S_{xx}(-f)=S_{xx}(f)} .

For a continuous stochastic process x(t), the autocorrelation function R xx ( t ) can be reconstructed from its power spectrum S xx (f) by using the inverse Fourier transform Using Parseval's theorem , one can compute the variance (average power) of a process by integrating the power spectrum over all frequency: P = Var ⁡ ⁡ ( x ) = ∫ ∫ − − ∞ ∞ ∞ ∞ S x x ( f ) d f {\displaystyle P=\operatorname {Var} (x)=\int _{-\infty }^{\infty }\!S_{xx}(f)\,df} For a real process x ( t ) with power spectral density S x x ( f ) {\displaystyle S_{xx}(f)} , one can compute the integrated spectrum or power spectral distribution F ( f ) {\displaystyle F(f)} , which specifies the average bandlimited power contained in frequencies from DC to f using: [ 15 ] F ( f ) = 2 ∫ ∫ 0 f S x x ( f ′ ) d f ′ .

{\displaystyle F(f)=2\int _{0}^{f}S_{xx}(f')\,df'.} Note that the previous expression for total power (signal variance) is a special case where f → ∞ .

Cross power spectral density [ edit ] See also: Coherence (signal processing) Given two signals x ( t ) {\displaystyle x(t)} and y ( t ) {\displaystyle y(t)} , each of which possess power spectral densities S x x ( f ) {\displaystyle S_{xx}(f)} and S y y ( f ) {\displaystyle S_{yy}(f)} , it is possible to define a cross power spectral density ( CPSD ) or cross spectral density ( CSD ).  To begin, let us consider the average power of such a combined signal.

P = lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ [ x T ( t ) + y T ( t ) ] ∗ ∗ [ x T ( t ) + y T ( t ) ] d t = lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ | x T ( t ) | 2 + x T ∗ ∗ ( t ) y T ( t ) + y T ∗ ∗ ( t ) x T ( t ) + | y T ( t ) | 2 d t {\displaystyle {\begin{aligned}P&=\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }\left[x_{T}(t)+y_{T}(t)\right]^{*}\left[x_{T}(t)+y_{T}(t)\right]dt\\&=\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }|x_{T}(t)|^{2}+x_{T}^{*}(t)y_{T}(t)+y_{T}^{*}(t)x_{T}(t)+|y_{T}(t)|^{2}dt\\\end{aligned}}} Using the same notation and methods as used for the power spectral density derivation, we exploit Parseval's theorem and obtain S x y ( f ) = lim T → → ∞ ∞ 1 T [ x ^ ^ T ∗ ∗ ( f ) y ^ ^ T ( f ) ] S y x ( f ) = lim T → → ∞ ∞ 1 T [ y ^ ^ T ∗ ∗ ( f ) x ^ ^ T ( f ) ] {\displaystyle {\begin{aligned}S_{xy}(f)&=\lim _{T\to \infty }{\frac {1}{T}}\left[{\hat {x}}_{T}^{*}(f){\hat {y}}_{T}(f)\right]&S_{yx}(f)&=\lim _{T\to \infty }{\frac {1}{T}}\left[{\hat {y}}_{T}^{*}(f){\hat {x}}_{T}(f)\right]\end{aligned}}} where, again, the contributions of S x x ( f ) {\displaystyle S_{xx}(f)} and S y y ( f ) {\displaystyle S_{yy}(f)} are already understood.  Note that S x y ∗ ∗ ( f ) = S y x ( f ) {\displaystyle S_{xy}^{*}(f)=S_{yx}(f)} , so the full contribution to the cross power is, generally, from twice the real part of either individual CPSD . Just as before, from here we recast these products as the Fourier transform of a time convolution, which when divided by the period and taken to the limit T → → ∞ ∞ {\displaystyle T\to \infty } becomes the Fourier transform of a cross-correlation function.

[ 16 ] S x y ( f ) = ∫ ∫ − − ∞ ∞ ∞ ∞ [ lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ x T ∗ ∗ ( t − − τ τ ) y T ( t ) d t ] e − − i 2 π π f τ τ d τ τ = ∫ ∫ − − ∞ ∞ ∞ ∞ R x y ( τ τ ) e − − i 2 π π f τ τ d τ τ S y x ( f ) = ∫ ∫ − − ∞ ∞ ∞ ∞ [ lim T → → ∞ ∞ 1 T ∫ ∫ − − ∞ ∞ ∞ ∞ y T ∗ ∗ ( t − − τ τ ) x T ( t ) d t ] e − − i 2 π π f τ τ d τ τ = ∫ ∫ − − ∞ ∞ ∞ ∞ R y x ( τ τ ) e − − i 2 π π f τ τ d τ τ , {\displaystyle {\begin{aligned}S_{xy}(f)&=\int _{-\infty }^{\infty }\left[\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }x_{T}^{*}(t-\tau )y_{T}(t)dt\right]e^{-i2\pi f\tau }d\tau =\int _{-\infty }^{\infty }R_{xy}(\tau )e^{-i2\pi f\tau }d\tau \\S_{yx}(f)&=\int _{-\infty }^{\infty }\left[\lim _{T\to \infty }{\frac {1}{T}}\int _{-\infty }^{\infty }y_{T}^{*}(t-\tau )x_{T}(t)dt\right]e^{-i2\pi f\tau }d\tau =\int _{-\infty }^{\infty }R_{yx}(\tau )e^{-i2\pi f\tau }d\tau ,\end{aligned}}} where R x y ( τ τ ) {\displaystyle R_{xy}(\tau )} is the cross-correlation of x ( t ) {\displaystyle x(t)} with y ( t ) {\displaystyle y(t)} and R y x ( τ τ ) {\displaystyle R_{yx}(\tau )} is the cross-correlation of y ( t ) {\displaystyle y(t)} with x ( t ) {\displaystyle x(t)} .  In light of this, the PSD is seen to be a special case of the CSD for x ( t ) = y ( t ) {\displaystyle x(t)=y(t)} .  If x ( t ) {\displaystyle x(t)} and y ( t ) {\displaystyle y(t)} are real signals (e.g. voltage or current), their Fourier transforms x ^ ^ ( f ) {\displaystyle {\hat {x}}(f)} and y ^ ^ ( f ) {\displaystyle {\hat {y}}(f)} are usually restricted to positive frequencies by convention.  Therefore, in typical signal processing, the full CPSD is just one of the CPSD s scaled by a factor of two.

CPSD Full = 2 S x y ( f ) = 2 S y x ( f ) {\displaystyle \operatorname {CPSD} _{\text{Full}}=2S_{xy}(f)=2S_{yx}(f)} For discrete signals x n and y n , the relationship between the cross-spectral density and the cross-covariance is S x y ( f ) = ∑ ∑ n = − − ∞ ∞ ∞ ∞ R x y ( τ τ n ) e − − i 2 π π f τ τ n Δ Δ τ τ {\displaystyle S_{xy}(f)=\sum _{n=-\infty }^{\infty }R_{xy}(\tau _{n})e^{-i2\pi f\tau _{n}}\,\Delta \tau } Estimation [ edit ] Main article: Spectral density estimation The goal of spectral density estimation is to estimate the spectral density of a random signal from a sequence of time samples. Depending on what is known about the signal, estimation techniques can involve parametric or non-parametric approaches, and may be based on time-domain or frequency-domain analysis. For example, a common parametric technique involves fitting the observations to an autoregressive model . A common non-parametric technique is the periodogram .

The spectral density is usually estimated using Fourier transform methods (such as the Welch method ), but other techniques such as the maximum entropy method can also be used.

Related concepts [ edit ] Not to be confused with spectral density (physical science) .

The spectral centroid of a signal is the midpoint of its spectral density function, i.e. the frequency that divides the distribution into two equal parts.

The spectral edge frequency ( SEF ), usually expressed as "SEF x ", represents the frequency below which x percent of the total power of a given signal are located; typically, x is in the range 75 to 95. It is more particularly a popular measure used in EEG monitoring, in which case SEF has variously been used to estimate the depth of anesthesia and stages of sleep .

[ 17 ] [ 18 ] A spectral envelope is the envelope curve of the spectrum density. It describes one point in time (one window, to be precise). For example, in remote sensing using a spectrometer , the spectral envelope of a feature is the boundary of its spectral properties, as defined by the range of brightness levels in each of the spectral bands of interest.

The spectral density is a function of frequency, not a function of time. However, the spectral density of a small window of a longer signal may be calculated, and plotted versus time associated with the window. Such a graph is called a spectrogram . This is the basis of a number of spectral analysis techniques such as the short-time Fourier transform and wavelets .

A "spectrum" generally means the power spectral density, as discussed above, which depicts the distribution of signal content over frequency. For transfer functions (e.g., Bode plot , chirp ) the complete frequency response may be graphed in two parts: power versus frequency and phase versus frequency—the phase spectral density , phase spectrum , or spectral phase . Less commonly, the two parts may be the real and imaginary parts of the transfer function. This is not to be confused with the frequency response of a transfer function, which also includes a phase (or equivalently, a real and imaginary part) as a function of frequency. The time-domain impulse response h ( t ) {\displaystyle h(t)} cannot generally be uniquely recovered from the power spectral density alone without the phase part. Although these are also Fourier transform pairs, there is no symmetry (as there is for the autocorrelation ) forcing the Fourier transform to be real-valued. See Ultrashort pulse#Spectral phase , phase noise , group delay .

Sometimes one encounters an amplitude spectral density ( ASD ), which is the square root of the PSD; the ASD of a voltage signal has the unit V⋅Hz −1/2 .

[ 19 ] This is useful when the shape of the spectrum is rather constant, since variations in the ASD will then be proportional to variations in the signal's voltage level itself. But it is mathematically preferred to use the PSD, since only in that case is the area under the curve meaningful in terms of actual power over all frequency or over a specified bandwidth.

Applications [ edit ] Further information: Spectrum Any signal that can be represented as a variable that varies in time has a corresponding frequency spectrum. This includes familiar entities such as visible light (perceived as color ), musical notes (perceived as pitch ), radio/TV (specified by their frequency, or sometimes wavelength ) and even the regular rotation of the earth. When these signals are viewed in the form of a frequency spectrum, certain aspects of the received signals or the underlying processes producing them are revealed. In some cases the frequency spectrum may include a distinct peak corresponding to a sine wave component. And additionally there may be peaks corresponding to harmonics of a fundamental peak, indicating a periodic signal which is not simply sinusoidal. Or a continuous spectrum may show narrow frequency intervals which are strongly enhanced corresponding to resonances, or frequency intervals containing almost zero power as would be produced by a notch filter .

Electrical engineering [ edit ] Spectrogram of an FM radio signal with frequency on the horizontal axis and time increasing upwards on the vertical axis.

The concept and use of the power spectrum of a signal is fundamental in electrical engineering , especially in electronic communication systems , including radio communications , radars , and related systems, plus passive remote sensing technology. Electronic instruments called spectrum analyzers are used to observe and measure the power spectra of signals.

The spectrum analyzer measures the magnitude of the short-time Fourier transform (STFT) of an input signal. If the signal being analyzed can be considered a stationary process, the STFT is a good smoothed estimate of its power spectral density.

Cosmology [ edit ] Primordial fluctuations , density variations in the early universe, are quantified by a power spectrum which gives the power of the variations as a function of spatial scale.

See also [ edit ] Bispectrum Brightness temperature Colors of noise Least-squares spectral analysis Noise spectral density Spectral density estimation Spectral efficiency Spectral leakage Spectral power distribution Whittle likelihood Window function Notes [ edit ] ^ Some authors, e.g., ( Risken & Frank 1996 , p. 30) still use the non-normalized Fourier transform in a formal way to formulate a definition of the power spectral density ⟨ ⟨ x ^ ^ ( ω ω ) x ^ ^ ∗ ∗ ( ω ω ′ ) ⟩ ⟩ = 2 π π f ( ω ω ) δ δ ( ω ω − − ω ω ′ ) , {\displaystyle \langle {\hat {x}}(\omega ){\hat {x}}^{\ast }(\omega ')\rangle =2\pi f(\omega )\delta (\omega -\omega '),} where δ δ ( ω ω − − ω ω ′ ) {\displaystyle \delta (\omega -\omega ')} is the Dirac delta function . Such formal statements may sometimes be useful to guide the intuition, but should always be used with utmost care.

^ The Wiener–Khinchin theorem makes sense of this formula for any wide-sense stationary process under weaker hypotheses: R x x {\displaystyle R_{xx}} does not need to be absolutely integrable, it only needs to exist.  But the integral can no longer be interpreted as usual.  The formula also makes sense if interpreted as involving distributions (in the sense of Laurent Schwartz , not in the sense of a statistical Cumulative distribution function ) instead of functions.  If R x x {\displaystyle R_{xx}} is continuous, Bochner's theorem can be used to prove that its Fourier transform exists as a positive measure , whose distribution function is F (but not necessarily as a function and not necessarily possessing a probability density).

^ a b c P Stoica & R Moses (2005).

"Spectral Analysis of Signals" (PDF) .

^ Maral 2004 .

^ Norton & Karczub 2003 .

^ Birolini 2007 , p. 83.

^ Paschotta, Rüdiger (5 April 2005).

"Power Spectral Density" .

rp-photonics.com . Archived from the original on 2024-04-15 . Retrieved 2024-06-26 .

^ Oppenheim & Verghese 2016 , p. 60.

^ Stein 2000 , pp. 108, 115.

^ Oppenheim & Verghese 2016 , p. 14.

^ Oppenheim & Verghese 2016 , pp. 422–423.

^ Miller & Childers 2012 , pp. 429–431.

^ Miller & Childers 2012 , p. 433.

^ Dennis Ward Ricker (2003).

Echo Signal Processing . Springer.

ISBN 978-1-4020-7395-3 .

^ Brown & Hwang 1997 .

^ Miller & Childers 2012 , p. 431.

^ Davenport & Root 1987 .

^ William D Penny (2009).

"Signal Processing Course, chapter 7" .

^ Iranmanesh & Rodriguez-Villegas 2017 .

^ Imtiaz & Rodriguez-Villegas 2014 .

^ Michael Cerna & Audrey F. Harvey (2000).

"The Fundamentals of FFT-Based Signal Analysis and Measurement" (PDF) . Archived from the original on September 15, 2012.

References [ edit ] Birolini, Alessandro (2007).

Reliability Engineering . Berlin ; New York: Springer Science & Business Media.

ISBN 978-3-540-49388-4 .

Brown, Robert Grover; Hwang, Patrick Y. C. (1997).

Introduction to Random Signals and Applied Kalman Filtering with Matlab Exercises and Solutions . New York: Wiley-Liss.

ISBN 978-0-471-12839-7 .

Davenport, Wilbur B. (Jr); Root, William L. (1987).

An Introduction to the Theory of Random Signals and Noise . New York: Wiley-IEEE Press.

ISBN 978-0-87942-235-6 .

Imtiaz, Syed Anas; Rodriguez-Villegas, Esther (2014).

"A Low Computational Cost Algorithm for REM Sleep Detection Using Single Channel EEG" .

Annals of Biomedical Engineering .

42 (11): 2344– 59.

doi : 10.1007/s10439-014-1085-6 .

PMC 4204008 .

PMID 25113231 .

Iranmanesh, Saam; Rodriguez-Villegas, Esther (2017). "An Ultralow-Power Sleep Spindle Detection System on Chip".

IEEE Transactions on Biomedical Circuits and Systems .

11 (4): 858– 866.

Bibcode : 2017ITBC...11..858I .

doi : 10.1109/TBCAS.2017.2690908 .

hdl : 10044/1/46059 .

PMID 28541914 .

S2CID 206608057 .

Maral, Gerard (2004).

VSAT Networks . West Sussex, England ; Hoboken, NJ: Wiley.

ISBN 978-0-470-86684-9 .

Miller, Scott; Childers, Donald (2012).

Probability and Random Processes . Boston, MA: Academic Press.

ISBN 978-0-12-386981-4 .

OCLC 696092052 .

Norton, M. P.; Karczub, D. G. (2003).

Fundamentals of Noise and Vibration Analysis for Engineers . Cambridge: Cambridge University Press.

ISBN 978-0-521-49913-2 .

Oppenheim, Alan V.; Verghese, George C. (2016).

Signals, Systems & Inference . Boston: Pearson.

ISBN 978-0-13-394328-3 .

Risken, Hannes; Frank, Till (1996).

The Fokker-Planck Equation . New York: Springer Science & Business Media.

ISBN 978-3-540-61530-9 .

Stein, Jonathan Y. (2000).

Digital Signal Processing . New York Weinheim: Wiley-Interscience.

ISBN 978-0-471-29546-4 .

External links [ edit ] Power Spectral Density Matlab scripts v t e Decibel suffixes (dB) dBm (or dBmW) dBW dBV dBm/Hz PSD dBA dBZ (radar) dBsm dBc dBi dBFS dBrn dB-Hz See also logarithmic unit link budget signal noise telecommunications NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐9hx7v
Cached time: 20250812013828
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.669 seconds
Real time usage: 0.861 seconds
Preprocessor visited node count: 3386/1000000
Revision size: 37876/2097152 bytes
Post‐expand include size: 52204/2097152 bytes
Template argument size: 4025/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 14/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 77855/5000000 bytes
Lua time usage: 0.353/10.000 seconds
Lua memory usage: 7982063/52428800 bytes
Number of Wikibase entities loaded: 0/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  581.368      1 -total
 21.26%  123.590      2 Template:Reflist
 16.38%   95.229      4 Template:Cite_web
 13.91%   80.874      1 Template:Short_description
 11.92%   69.318      1 Template:Decibel
 11.63%   67.589      1 Template:Navbox
 11.18%   64.991     14 Template:Sfn
  9.90%   57.548     10 Template:Cite_book
  9.35%   54.332      2 Template:Pagetype
  7.48%   43.476      3 Template:Equation_box_1 Saved in parser cache with key enwiki:pcache:202672:|#|:idhash:canonical and timestamp 20250812013828 and revision id 1304261642. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Spectral_density&oldid=1304261642#Explanation " Categories : Frequency-domain analysis Signal processing Waves Spectroscopy Scattering Fourier analysis Radio spectrum Spectrum (physical sciences) Hidden categories: CS1: unfit URL Articles with short description Short description matches Wikidata Use American English from March 2019 All Wikipedia articles written in American English Wikipedia articles that are too technical from June 2024 All articles that are too technical This page was last edited on 5 August 2025, at 00:17 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Spectral density 19 languages Add topic

