Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 History Toggle History subsection 1.1 'Common' and 'special' sources of variation 1.2 Application to non-manufacturing processes 2 Variation in manufacturing 3 Application Toggle Application subsection 3.1 Control charts 3.1.1 Stable process 3.1.2 Excessive variations 3.1.3 Process stability metrics 4 Mathematics of control charts 5 See also 6 References 7 Bibliography 8 External links Toggle the table of contents Statistical process control 26 languages العربية Català Deutsch Eesti Español فارسی Français हिन्दी Interlingua Italiano ಕನ್ನಡ Nederlands 日本語 Norsk bokmål Polski Português Română Русский Simple English Српски / srpski Sunda Suomi Svenska தமிழ் Українська 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Method of quality control "SQc" redirects here. For other uses, see SQC (disambiguation) .

This section needs additional citations for verification .

Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.

( March 2022 ) ( Learn how and when to remove this message ) Simple example of a process control chart, tracking the etch (removal) rate of Silicon in an ICP Plasma Etcher at a microelectronics waferfab .

[ 1 ] Time-series data shows the mean value and ±5% bars. A more sophisticated SPC chart may include "control limit" & "spec limit" % lines to indicate whether/what action should be taken.

Statistical process control ( SPC ) or statistical quality control ( SQC ) is the application of statistical methods to monitor and control the quality of a production process. This helps to ensure that the process operates efficiently, producing more specification-conforming products with less waste scrap. SPC can be applied to any process where the "conforming product" (product meeting specifications) output can be measured. Key tools used in SPC include run charts , control charts , a focus on continuous improvement , and the design of experiments . An example of a process where SPC is applied is manufacturing lines.

SPC must be practiced in two phases: the first phase is the initial establishment of the process, and the second phase is the regular production use of the process. In the second phase, a decision of the period to be examined must be made, depending upon the change in 5M&E conditions (Man, Machine, Material, Method, Movement, Environment) and wear rate of parts used in the manufacturing process (machine parts, jigs, and fixtures).

An advantage of SPC over other methods of quality control, such as " inspection ," is that it emphasizes early detection and prevention of problems, rather than the correction of problems after they have occurred.

In addition to reducing waste, SPC can lead to a reduction in the time required to produce the product. SPC makes it less likely the finished product will need to be reworked or scrapped.

History [ edit ] Statistical process control was pioneered by Walter A. Shewhart at Bell Laboratories in the early 1920s. Shewhart developed the control chart in 1924 and the concept of a state of statistical control. Statistical control is equivalent to the concept of exchangeability [ 2 ] [ 3 ] developed by logician William Ernest Johnson also in 1924 in his book Logic, Part III: The Logical Foundations of Science .

[ 4 ] Along with a team at AT&T that included Harold Dodge and Harry Romig he worked to put sampling inspection on a rational statistical basis as well. Shewhart consulted with Colonel Leslie E. Simon in the application of control charts to munitions manufacture at the Army's Picatinny Arsenal in 1934. That successful application helped convince Army Ordnance to engage AT&T's George D. Edwards to consult on the use of statistical quality control among its divisions and contractors at the outbreak of World War II.

W. Edwards Deming invited Shewhart to speak at the Graduate School of the U.S. Department of Agriculture and served as the editor of Shewhart's book Statistical Method from the Viewpoint of Quality Control (1939), which was the result of that lecture. Deming was an important architect of the quality control short courses that trained American industry in the new techniques during WWII. The graduates of these wartime courses formed a new professional society in 1945, the American Society for Quality Control , which elected Edwards as its first president. Deming travelled to Japan during the Allied Occupation and met with the Union of Japanese Scientists and Engineers (JUSE) in an effort to introduce SPC methods to Japanese industry.

[ 5 ] [ 6 ] 'Common' and 'special' sources of variation [ edit ] Main article: Common cause and special cause (statistics) Shewhart read the new statistical theories coming out of Britain, especially the work of William Sealy Gosset , Karl Pearson , and Ronald Fisher . However, he understood that data from physical processes seldom produced a normal distribution curve (that is, a Gaussian distribution or ' bell curve '). He discovered that data from measurements of variation in manufacturing did not always behave the same way as data from measurements of natural phenomena (for example, Brownian motion of particles). Shewhart concluded that while every process displays variation, some processes display variation that is natural to the process (" common " sources of variation); these processes he described as being in (statistical) control . Other processes additionally display variation that is not present in the causal system of the process at all times (" special " sources of variation), which Shewhart described as not in control .

[ 7 ] Application to non-manufacturing processes [ edit ] Statistical process control is appropriate to support any repetitive process, and has been implemented in many settings where for example ISO 9000 quality management systems are used, including financial auditing and accounting, IT operations, health care processes, and clerical processes such as loan arrangement and administration, customer billing etc. Despite criticism of its use in design and development, it is well-placed to manage semi-automated data governance of high-volume data processing operations, for example in an enterprise data warehouse, or an enterprise data quality management system.

[ 8 ] In the 1988 Capability Maturity Model (CMM) the Software Engineering Institute suggested that SPC could be applied to software engineering processes. The Level 4 and Level 5 practices of the Capability Maturity Model Integration ( CMMI ) use this concept.

The application of SPC to non-repetitive, knowledge-intensive processes, such as research and development or systems engineering, has encountered skepticism and remains controversial.

[ 9 ] [ 10 ] [ 11 ] In No Silver Bullet , Fred Brooks points out that the complexity, conformance requirements, changeability, and invisibility of software [ 12 ] [ 13 ] results in inherent and essential variation that cannot be removed. This implies that SPC is less effective in the software development than in, e.g., manufacturing.

Variation in manufacturing [ edit ] In manufacturing, quality is defined as conformance to specification. However, no two products or characteristics are ever exactly the same, because any process contains many sources of variability. In mass-manufacturing, traditionally, the quality of a finished article is ensured by post-manufacturing inspection of the product. Each article (or a sample of articles from a production lot) may be accepted or rejected according to how well it meets its design specifications , SPC uses statistical tools to observe the performance of the production process in order to detect significant variations before they result in the production of a sub-standard article.
Any source of variation at any point of time in a process will fall into one of two classes.

(1) Common causes 'Common' causes are sometimes referred to as 'non-assignable', or 'normal' sources of variation. It refers to any source of variation that consistently acts on process, of which there are typically many. This type of causes collectively produce a statistically stable and repeatable distribution over time.

(2) Special causes 'Special' causes are sometimes referred to as 'assignable' sources of variation. The term refers to any factor causing variation that affects only some of the process output. They are often intermittent and unpredictable.

Most processes have many sources of variation; most of them are minor and may be ignored. If the dominant assignable sources of variation are detected, potentially they can be identified and removed. When they are removed, the process is said to be 'stable'. When a process is stable, its variation should remain within a known set of limits. That is, at least, until another assignable source of variation occurs.

For example, a breakfast cereal packaging line may be designed to fill each cereal box with 500 grams of cereal. Some boxes will have slightly more than 500 grams, and some will have slightly less. When the package weights are measured, the data will demonstrate a distribution of net weights.

If the production process, its inputs, or its environment (for example, the machine on the line) change, the distribution of the data will change. For example, as the cams and pulleys of the machinery wear, the cereal filling machine may put more than the specified amount of cereal into each box. Although this might benefit the customer, from the manufacturer's point of view it is wasteful, and increases the cost of production. If the manufacturer finds the change and its source in a timely manner, the change can be corrected (for example, the cams and pulleys replaced).

From an SPC perspective, if the weight of each cereal box varies randomly, some higher and some lower, always within an acceptable range, then the process is considered stable. If the cams and pulleys of the machinery start to wear out, the weights of the cereal box might not be random. The degraded functionality of the cams and pulleys may lead to a non-random linear pattern of increasing cereal box weights. We call this common cause variation. If, however, all the cereal boxes suddenly weighed much more than average because of an unexpected malfunction of the cams and pulleys, this would be considered a special cause variation.

Application [ edit ] The application of SPC involves three main phases of activity: Understanding the process and the specification limits.

Eliminating assignable (special) sources of variation, so that the process is stable.

Monitoring the ongoing production process, assisted by the use of control charts, to detect significant changes of mean or variation.

The proper implementation of SPC has been limited, in part due to a lack of statistical expertise at many organizations.

[ 14 ] Control charts [ edit ] The data from measurements of variations at points on the process map is monitored using control charts . Control charts attempt to differentiate "assignable" ("special") sources of variation from "common" sources. "Common" sources, because they are an expected part of the process, are of much less concern to the manufacturer than "assignable" sources. Using control charts is a continuous activity, ongoing over time.

Stable process [ edit ] When the process does not trigger any of the control chart "detection rules" for the control chart, it is said to be "stable". A process capability analysis may be performed on a stable process to predict the ability of the process to produce "conforming product" in the future.

A stable process can be demonstrated by a process signature that is free of variances outside of the capability index. A process signature is the plotted points compared with the capability index.

Excessive variations [ edit ] When the process triggers any of the control chart "detection rules", (or alternatively, the process capability is low), other activities may be performed to identify the source of the excessive variation.
The tools used in these extra activities include: Ishikawa diagram , designed experiments , and Pareto charts . Designed experiments are a means of objectively quantifying the relative importance (strength) of sources of variation. Once the sources of (special cause) variation are identified, they can be minimized or eliminated.  Steps to eliminating a source of variation might include: development of standards, staff training, error-proofing, and changes to the process itself or its inputs.

Process stability metrics [ edit ] When monitoring many processes with control charts, it is sometimes useful to calculate quantitative measures of the stability of the processes. These metrics can then be used to identify/prioritize the processes that are most in need of corrective actions. These metrics can also be viewed as supplementing the traditional process capability metrics. Several metrics have been proposed, as described in Ramirez and Runger.

[ 15 ] They are (1) a Stability Ratio which compares the long-term variability to the short-term variability, (2) an ANOVA Test which compares the within-subgroup variation to the between-subgroup variation, and (3) an Instability Ratio which compares the number of subgroups that have one or more violations of the Western Electric rules to the total number of subgroups.

Mathematics of control charts [ edit ] Digital control charts use logic-based rules that determine "derived values" which signal the need for correction. For example, derived value = last value + average absolute difference between the last N numbers.

See also [ edit ] ANOVA Gauge R&R Distribution-free control chart Electronic design automation Industrial engineering Process Window Index Process capability index Quality assurance Reliability engineering Six sigma Stochastic control Total quality management References [ edit ] ^ Dutra, Noah; John, Demis.

"Process Group - Process Control Data - UCSB Nanofab Wiki" .

UCSB NanoFab Wiki . Retrieved 2024-11-08 .

^ Barlow & Irony 1992 ^ Bergman 2009 ^ Zabell 1992 ^ Deming, W. Edwards (1952).

Lectures on statistical control of quality (Rev. 2nd ed.). Nippon Kagaku Gijutsu Remmei.

OCLC 2518026 .

^ Deming, W. Edwards and Dowd S. John (translator) Lecture to Japanese Management, Deming Electronic Network Web Site, 1950 (from a Japanese transcript of a lecture by Deming to "80% of Japanese top management" given at the Hotel de Yama at Mr. Hakone in August 1950) ^ Why SPC?

. SPC Press. 1992.

ISBN 978-0-945320-17-3 .

^ English, Larry (1999).

Improving Data Warehouse and Business Information Quality: Methods for Reducing Costs and Increasing Profits . Wiley.

ISBN 978-0-471-25383-9 .

^ Raczynski, Bob; Curtis, Bill (May–June 2008). "Point/Counterpoint: Counterpoint Argument: Software Data Violate SPC's Underlying Assumptions".

IEEE Software .

25 (3): 49– 51.

doi : 10.1109/MS.2008.68 .

^ Binder, Robert V. (September–October 1997). "Can a Manufacturing Quality Model Work for Software?".

IEEE Software .

14 (5): 101– 5.

doi : 10.1109/52.605937 .

S2CID 40550515 .

^ Raczynski, Bob (February 20, 2009).

"Is Statistical Process Control Applicable to Software Development Processes?" .

StickyMinds .

^ Brooks, Jr., F. P.

(1987).

"No Silver Bullet—Essence and Accidents of Software Engineering" (PDF) .

Computer .

20 (4): 10– 19.

CiteSeerX 10.1.1.117.315 .

doi : 10.1109/MC.1987.1663532 .

^ Brooks, Fred P. (1986). "No Silver Bullet — Essence and Accident in Software Engineering".

Information processing 86: proceedings of the IFIP 10th World Computer Congress . North-Holland. pp.

1069– 76.

ISBN 978-0-444-70077-3 .

^ Zwetsloot, Inez M.; Jones-Farmer, L. Allison; Woodall, William H. (2 July 2024).

"Monitoring univariate processes using control charts: Some practical issues and advice" .

Quality Engineering .

36 (3): 487– 499.

doi : 10.1080/08982112.2023.2238049 .

There are few areas of statistical application with a wider gap between methodological development and application than is seen in SPC (statistical process control). Many organizations in dire need of SPC are not using it at all, while most of the remainder are using methods essentially exactly as Shewhart proposed them early this century. The reasons for this are varied. One that cannot be overlooked is Deming's observation that any procedure which requires regular intervention by an expert statistician to work properly will not be implemented.

^ Ramirez, B.; Runger, G. (2006). "Quantitative Techniques to Evaluate Process Stability".

Quality Engineering .

18 (1): 53– 68.

doi : 10.1080/08982110500403581 .

S2CID 109601393 .

Bibliography [ edit ] Barlow, R.E.; Irony, T.Z. (1992).

"Foundations of statistical quality control" . In Ghosh, M.; Pathak, P.K. (eds.).

Current Issues in Statistical Inference: Essays in Honor of D. Basu . Hayward, CA: Institute of Mathematical Statistics. pp.

99– 112.

ISBN 978-0-940600-24-9 .

Bergman, B. (2009). "Conceptualistic Pragmatism: A framework for Bayesian analysis?".

IIE Transactions .

41 : 86– 93.

doi : 10.1080/07408170802322713 .

S2CID 119485220 .

Deming, W. E.

(1975). "On probability as a basis for action".

The American Statistician .

29 (4): 146– 152.

doi : 10.1080/00031305.1975.10477402 .

PMID 1078437 .

S2CID 21043630 .

— (1982).

Out of the Crisis: Quality, Productivity and Competitive Position .

ISBN 0-521-30553-5 .

Grant, E.L. (1946).

Statistical quality control . McGraw-Hill.

ISBN 0-07-100447-5 .

{{ cite book }} : ISBN / Date incompatibility ( help ) Oakland, J. (2002).

Statistical Process Control .

ISBN 0-7506-5766-9 .

Salacinski, T. (2015).

SPC — Statistical Process Control . The Warsaw University of Technology Publishing House.

ISBN 978-83-7814-319-2 .

Shewhart, W.A. (1931).

Economic Control of Quality of Manufactured Product . American Society for Quality Control.

ISBN 0-87389-076-0 .

{{ cite book }} : ISBN / Date incompatibility ( help ) — (1939).

Statistical Method from the Viewpoint of Quality Control . Courier Corporation.

ISBN 0-486-65232-7 .

{{ cite book }} : ISBN / Date incompatibility ( help ) Statistical Process Control (SPC) Reference Manual (2 ed.). Automotive Industry Action Group (AIAG). 2005.

Wheeler, D.J. (2000).

Normality and the Process-Behaviour Chart . SPC Press.

ISBN 0-945320-56-6 .

Wheeler, D.J.; Chambers, D.S. (1992).

Understanding Statistical Process Control . SPC Press.

ISBN 0-945320-13-2 .

Wheeler, Donald J. (1999).

Understanding Variation: The Key to Managing Chaos (2nd ed.). SPC Press.

ISBN 0-945320-53-1 .

Wise, Stephen A.; Fair, Douglas C. (1998).

Innovative Control Charting: Practical SPC Solutions for Today's Manufacturing Environment . ASQ Quality Press.

ISBN 0-87389-385-9 .

Zabell, S.L. (1992). "Predicting the unpredictable".

Synthese .

90 (2): 205.

doi : 10.1007/bf00485351 .

S2CID 9416747 .

External links [ edit ] MIT Course - Control of Manufacturing Processes Guthrie, William F. (2012).

"NIST/SEMATECH e-Handbook of Statistical Methods" . National Institute of Standards and Technology.

doi : 10.18434/M32189 .

Statistical process control at Wikipedia's sister projects : Media from Commons Data from Wikidata v t e Statistics Outline Index Descriptive statistics Continuous data Center Mean Arithmetic Arithmetic-Geometric Contraharmonic Cubic Generalized/power Geometric Harmonic Heronian Heinz Lehmer Median Mode Dispersion Average absolute deviation Coefficient of variation Interquartile range Percentile Range Standard deviation Variance Shape Central limit theorem Moments Kurtosis L-moments Skewness Count data Index of dispersion Summary tables Contingency table Frequency distribution Grouped data Dependence Partial correlation Pearson product-moment correlation Rank correlation Kendall's τ Spearman's ρ Scatter plot Graphics Bar chart Biplot Box plot Control chart Correlogram Fan chart Forest plot Histogram Pie chart Q–Q plot Radar chart Run chart Scatter plot Stem-and-leaf display Violin plot Data collection Study design Effect size Missing data Optimal design Population Replication Sample size determination Statistic Statistical power Survey methodology Sampling Cluster Stratified Opinion poll Questionnaire Standard error Controlled experiments Blocking Factorial experiment Interaction Random assignment Randomized controlled trial Randomized experiment Scientific control Adaptive designs Adaptive clinical trial Stochastic approximation Up-and-down designs Observational studies Cohort study Cross-sectional study Natural experiment Quasi-experiment Statistical inference Statistical theory Population Statistic Probability distribution Sampling distribution Order statistic Empirical distribution Density estimation Statistical model Model specification L p space Parameter location scale shape Parametric family Likelihood (monotone) Location–scale family Exponential family Completeness Sufficiency Statistical functional Bootstrap U V Optimal decision loss function Efficiency Statistical distance divergence Asymptotics Robustness Frequentist inference Point estimation Estimating equations Maximum likelihood Method of moments M-estimator Minimum distance Unbiased estimators Mean-unbiased minimum-variance Rao–Blackwellization Lehmann–Scheffé theorem Median unbiased Plug-in Interval estimation Confidence interval Pivot Likelihood interval Prediction interval Tolerance interval Resampling Bootstrap Jackknife Testing hypotheses 1- & 2-tails Power Uniformly most powerful test Permutation test Randomization test Multiple comparisons Parametric tests Likelihood-ratio Score/Lagrange multiplier Wald Specific tests Z -test (normal) Student's t -test F -test Goodness of fit Chi-squared G -test Kolmogorov–Smirnov Anderson–Darling Lilliefors Jarque–Bera Normality (Shapiro–Wilk) Likelihood-ratio test Model selection Cross validation AIC BIC Rank statistics Sign Sample median Signed rank (Wilcoxon) Hodges–Lehmann estimator Rank sum (Mann–Whitney) Nonparametric anova 1-way (Kruskal–Wallis) 2-way (Friedman) Ordered alternative (Jonckheere–Terpstra) Van der Waerden test Bayesian inference Bayesian probability prior posterior Credible interval Bayes factor Bayesian estimator Maximum posterior estimator Correlation Regression analysis Correlation Pearson product-moment Partial correlation Confounding variable Coefficient of determination Regression analysis Errors and residuals Regression validation Mixed effects models Simultaneous equations models Multivariate adaptive regression splines (MARS) Linear regression Simple linear regression Ordinary least squares General linear model Bayesian regression Non-standard predictors Nonlinear regression Nonparametric Semiparametric Isotonic Robust Homoscedasticity and Heteroscedasticity Generalized linear model Exponential families Logistic (Bernoulli) / Binomial / Poisson regressions Partition of variance Analysis of variance (ANOVA, anova) Analysis of covariance Multivariate ANOVA Degrees of freedom Categorical / multivariate / time-series / survival analysis Categorical Cohen's kappa Contingency table Graphical model Log-linear model McNemar's test Cochran–Mantel–Haenszel statistics Multivariate Regression Manova Principal components Canonical correlation Discriminant analysis Cluster analysis Classification Structural equation model Factor analysis Multivariate distributions Elliptical distributions Normal Time-series General Decomposition Trend Stationarity Seasonal adjustment Exponential smoothing Cointegration Structural break Granger causality Specific tests Dickey–Fuller Johansen Q-statistic (Ljung–Box) Durbin–Watson Breusch–Godfrey Time domain Autocorrelation (ACF) partial (PACF) Cross-correlation (XCF) ARMA model ARIMA model (Box–Jenkins) Autoregressive conditional heteroskedasticity (ARCH) Vector autoregression (VAR) Frequency domain Spectral density estimation Fourier analysis Least-squares spectral analysis Wavelet Whittle likelihood Survival Survival function Kaplan–Meier estimator (product limit) Proportional hazards models Accelerated failure time (AFT) model First hitting time Hazard function Nelson–Aalen estimator Test Log-rank test Applications Biostatistics Bioinformatics Clinical trials / studies Epidemiology Medical statistics Engineering statistics Chemometrics Methods engineering Probabilistic design Process / quality control Reliability System identification Social statistics Actuarial science Census Crime statistics Demography Econometrics Jurimetrics National accounts Official statistics Population statistics Psychometrics Spatial statistics Cartography Environmental statistics Geographic information system Geostatistics Kriging Category Mathematics portal Commons WikiProject v t e Six Sigma tools Define phase Project charter Voice of the customer Value-stream mapping SIPOC Measure phase Business process mapping Process capability Pareto chart Analyse phase Root cause analysis Failure mode and effects analysis Multi-vari chart Improve phase Design of experiments Kaizen Control phase Control plan Statistical process control 5S Poka-yoke DMAIC Authority control databases National Germany Czech Republic Other Yale LUX NewPP limit report
Parsed by mw‐web.codfw.main‐6cc77c66b8‐x52l2
Cached time: 20250812014034
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.664 seconds
Real time usage: 0.813 seconds
Preprocessor visited node count: 2882/1000000
Revision size: 21791/2097152 bytes
Post‐expand include size: 214427/2097152 bytes
Template argument size: 2081/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 6/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 105818/5000000 bytes
Lua time usage: 0.436/10.000 seconds
Lua memory usage: 8063386/52428800 bytes
Number of Wikibase entities loaded: 1/500 Transclusion expansion time report (%,ms,calls,template)
100.00%  673.661      1 -total
 28.26%  190.354      1 Template:Reflist
 22.55%  151.910      1 Template:Statistics
 22.17%  149.383      1 Template:Navbox_with_collapsible_groups
 13.13%   88.432     15 Template:Cite_book
 12.55%   84.534      3 Template:Cite_web
  8.76%   59.020      1 Template:Short_description
  8.60%   57.957     12 Template:Navbox
  8.04%   54.141      8 Template:Cite_journal
  7.00%   47.190      1 Template:Subject_bar Saved in parser cache with key enwiki:pcache:593680:|#|:idhash:canonical and timestamp 20250812014034 and revision id 1297088470. Rendering was triggered because: page-view Retrieved from " https://en.wikipedia.org/w/index.php?title=Statistical_process_control&oldid=1297088470 " Category : Statistical process control Hidden categories: Articles with short description Short description is different from Wikidata Articles needing additional references from March 2022 All articles needing additional references CS1 errors: ISBN date This page was last edited on 24 June 2025, at 02:45 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Statistical process control 26 languages Add topic

