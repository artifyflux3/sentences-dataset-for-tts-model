Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Contribute Help Learn to edit Community portal Recent changes Upload file Special pages Search Search Appearance Donate Create account Log in Personal tools Donate Create account Log in Pages for logged out editors learn more Contributions Talk CentralNotice Contents move to sidebar hide (Top) 1 Concept 2 Standard deviation and standard error 3 Maximum margin of error at different confidence levels 4 Specific margins of error 5 Comparing percentages 6 Effect of finite population size 7 See also 8 References 9 Sources 10 External links Toggle the table of contents Margin of error 23 languages العربية বাংলা Català Ελληνικά Español Euskara Français Galego 한국어 Bahasa Indonesia Íslenska Jawa Norsk bokmål Português Русский Simple English Српски / srpski Sunda Suomi Türkçe Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Permanent link Page information Cite this page Get shortened URL Download QR code Print/export Download as PDF Printable version In other projects Wikidata item Appearance move to sidebar hide From Wikipedia, the free encyclopedia Statistic expressing the amount of random sampling error in a survey's results This article is about the statistical precision of estimates from sample surveys. For observational errors, see Observational error . For safety margins in engineering, see Factor of safety . For tolerance in engineering, see Engineering tolerance . For the eponymous movie, see Margin for error (film) .

This article includes a list of general references , but it lacks sufficient corresponding inline citations .

Please help to improve this article by introducing more precise citations.

( November 2021 ) ( Learn how and when to remove this message ) Probability densities of polls of different sizes, each color-coded to its 95% confidence interval (below), margin of error (left), and sample size (right). Each interval reflects the range within which one may have 95% confidence that the true percentage may be found, given a reported percentage of 50%. The margin of error is half the confidence interval (also, the radius of the interval). The larger the sample, the smaller the margin of error. Also, the further from 50% the reported percentage, the smaller the margin of error.

The margin of error is a statistic expressing the amount of random sampling error in the results of a survey . The larger the margin of error, the less confidence one should have that a poll result would reflect the result of a simultaneous census of the entire population . The margin of error will be positive whenever a population is incompletely sampled and the outcome measure has positive variance , which is to say, whenever the measure varies .

The term margin of error is often used in non-survey contexts to indicate observational error in reporting measured quantities.

Concept [ edit ] Consider a simple yes/no poll P {\displaystyle P} as a sample of n {\displaystyle n} respondents drawn from a population N , ( n ≪ ≪ N ) {\displaystyle N{\text{, }}(n\ll N)} reporting the percentage p {\displaystyle p} of yes responses. We would like to know how close p {\displaystyle p} is to the true result of a survey of the entire population N {\displaystyle N} , without having to conduct one. If, hypothetically, we were to conduct a poll P {\displaystyle P} over subsequent samples of n {\displaystyle n} respondents (newly drawn from N {\displaystyle N} ), we would expect those subsequent results p 1 , p 2 , … … {\displaystyle p_{1},p_{2},\ldots } to be normally distributed about p ¯ ¯ {\displaystyle {\overline {p}}} , the true but unknown percentage of the population. The margin of error describes the distance within which a specified percentage of these results is expected to vary from p ¯ ¯ {\displaystyle {\overline {p}}} .

Going by the Central limit theorem , the margin of error helps to explain how the distribution of sample means (or percentage of yes, in this case) will approximate a normal distribution as sample size increases. If this applies, it would speak about the sampling being unbiased, but not about the inherent distribution of the data.

[ 1 ] According to the 68-95-99.7 rule , we would expect that 95% of the results p 1 , p 2 , … … {\displaystyle p_{1},p_{2},\ldots } will fall within about two standard deviations ( ± ± 2 σ σ P {\displaystyle \pm 2\sigma _{P}} ) either side of the true mean p ¯ ¯ {\displaystyle {\overline {p}}} .  This interval is called the confidence interval , and the radius (half the interval) is called the margin of error , corresponding to a 95% confidence level .

Generally, at a confidence level γ γ {\displaystyle \gamma } , a sample sized n {\displaystyle n} of a population having expected standard deviation σ σ {\displaystyle \sigma } has a margin of error M O E γ γ = z γ γ × × σ σ 2 n {\displaystyle MOE_{\gamma }=z_{\gamma }\times {\sqrt {\frac {\sigma ^{2}}{n}}}} where z γ γ {\displaystyle z_{\gamma }} denotes the quantile (also, commonly, a z-score ), and σ σ 2 n {\displaystyle {\sqrt {\frac {\sigma ^{2}}{n}}}} is the standard error .

Standard deviation and standard error [ edit ] We would expect the average of normally distributed values p 1 , p 2 , … … {\displaystyle p_{1},p_{2},\ldots } to have a standard deviation which somehow varies with n {\displaystyle n} . The smaller n {\displaystyle n} , the wider the margin. This is called the standard error σ σ p ¯ ¯ {\displaystyle \sigma _{\overline {p}}} .

For the single result from our survey, we assume that p = p ¯ ¯ {\displaystyle p={\overline {p}}} , and that all subsequent results p 1 , p 2 , … … {\displaystyle p_{1},p_{2},\ldots } together would have a variance σ σ P 2 = P ( 1 − − P ) {\displaystyle \sigma _{P}^{2}=P(1-P)} .

Standard error = σ σ p ¯ ¯ ≈ ≈ σ σ P 2 n ≈ ≈ p ( 1 − − p ) n {\displaystyle {\text{Standard error}}=\sigma _{\overline {p}}\approx {\sqrt {\frac {\sigma _{P}^{2}}{n}}}\approx {\sqrt {\frac {p(1-p)}{n}}}} Note that p ( 1 − − p ) {\displaystyle p(1-p)} corresponds to the variance of a Bernoulli distribution .

Maximum margin of error at different confidence levels [ edit ] For a confidence level γ γ {\displaystyle \gamma } , there is a corresponding confidence interval about the mean μ μ ± ± z γ γ σ σ {\displaystyle \mu \pm z_{\gamma }\sigma } , that is, the interval [ μ μ − − z γ γ σ σ , μ μ + z γ γ σ σ ] {\displaystyle [\mu -z_{\gamma }\sigma ,\mu +z_{\gamma }\sigma ]} within which values of P {\displaystyle P} should fall with probability γ γ {\displaystyle \gamma } . Precise values of z γ γ {\displaystyle z_{\gamma }} are given by the quantile function of the normal distribution (which the 68–95–99.7 rule approximates).

Note that z γ γ {\displaystyle z_{\gamma }} is undefined for | γ γ | ≥ ≥ 1 {\displaystyle |\gamma |\geq 1} , that is, z 1.00 {\displaystyle z_{1.00}} is undefined, as is z 1.10 {\displaystyle z_{1.10}} .

γ γ {\displaystyle \gamma } z γ γ {\displaystyle z_{\gamma }} γ γ {\displaystyle \gamma } z γ γ {\displaystyle z_{\gamma }} 0.84 0.994 457 883 210 0.9995 3.290 526 731 492 0.95 1.644 853 626 951 0.99995 3.890 591 886 413 0.975 1.959963984540 0.999995 4.417 173 413 469 0.99 2.326 347 874 041 0.9999995 4.891 638 475 699 0.995 2.575 829 303 549 0.99999995 5.326 723 886 384 0.9975 2.807 033 768 344 0.999999995 5.730 728 868 236 0.9985 2.967 737 925 342 0.9999999995 6.109 410 204 869 Log-log graphs of M O E γ γ ( 0.5 ) {\displaystyle MOE_{\gamma }(0.5)} vs sample size n and confidence level γ . The arrows show that the maximum margin error for a sample size of 1000 is ±3.1% at 95% confidence level, and ±4.1% at 99%.

The inset parabola σ σ p 2 = p − − p 2 {\displaystyle \sigma _{p}^{2}=p-p^{2}} illustrates the relationship between σ σ p 2 {\displaystyle \sigma _{p}^{2}} at p = 0.71 {\displaystyle p=0.71} and σ σ m a x 2 {\displaystyle \sigma _{max}^{2}} at p = 0.5 {\displaystyle p=0.5} . In the example, MOE 95 (0.71) ≈ 0.9 × ±3.1% ≈ ±2.8%.

Since max σ σ P 2 = max P ( 1 − − P ) = 0.25 {\displaystyle \max \sigma _{P}^{2}=\max P(1-P)=0.25} at p = 0.5 {\displaystyle p=0.5} , we can arbitrarily set p = p ¯ ¯ = 0.5 {\displaystyle p={\overline {p}}=0.5} , calculate σ σ P {\displaystyle \sigma _{P}} , σ σ p ¯ ¯ {\displaystyle \sigma _{\overline {p}}} , and z γ γ σ σ p ¯ ¯ {\displaystyle z_{\gamma }\sigma _{\overline {p}}} to obtain the maximum margin of error for P {\displaystyle P} at a given confidence level γ γ {\displaystyle \gamma } and sample size n {\displaystyle n} , even before having actual results.  With p = 0.5 , n = 1013 {\displaystyle p=0.5,n=1013} M O E 95 ( 0.5 ) = z 0.95 σ σ p ¯ ¯ ≈ ≈ z 0.95 σ σ P 2 n = 1.96 .25 n = 0.98 / n = ± ± 3.1 % % {\displaystyle MOE_{95}(0.5)=z_{0.95}\sigma _{\overline {p}}\approx z_{0.95}{\sqrt {\frac {\sigma _{P}^{2}}{n}}}=1.96{\sqrt {\frac {.25}{n}}}=0.98/{\sqrt {n}}=\pm 3.1\%} M O E 99 ( 0.5 ) = z 0.99 σ σ p ¯ ¯ ≈ ≈ z 0.99 σ σ P 2 n = 2.58 .25 n = 1.29 / n = ± ± 4.1 % % {\displaystyle MOE_{99}(0.5)=z_{0.99}\sigma _{\overline {p}}\approx z_{0.99}{\sqrt {\frac {\sigma _{P}^{2}}{n}}}=2.58{\sqrt {\frac {.25}{n}}}=1.29/{\sqrt {n}}=\pm 4.1\%} Also, usefully, for any reported M O E 95 {\displaystyle MOE_{95}} M O E 99 = z 0.99 z 0.95 M O E 95 ≈ ≈ 1.3 × × M O E 95 {\displaystyle MOE_{99}={\frac {z_{0.99}}{z_{0.95}}}MOE_{95}\approx 1.3\times MOE_{95}} Specific margins of error [ edit ] If a poll has multiple percentage results (for example, a poll measuring a single multiple-choice preference), the result closest to 50% will have the highest margin of error. Typically, it is this number that is reported as the margin of error for the entire poll. Imagine poll P {\displaystyle P} reports p a , p b , p c {\displaystyle p_{a},p_{b},p_{c}} as 71 % % , 27 % % , 2 % % , n = 1013 {\displaystyle 71\%,27\%,2\%,n=1013} M O E 95 ( P a ) = z 0.95 σ σ p a ¯ ¯ ≈ ≈ 1.96 p a ( 1 − − p a ) n = 0.89 / n = ± ± 2.8 % % {\displaystyle MOE_{95}(P_{a})=z_{0.95}\sigma _{\overline {p_{a}}}\approx 1.96{\sqrt {\frac {p_{a}(1-p_{a})}{n}}}=0.89/{\sqrt {n}}=\pm 2.8\%} (as in the figure above) M O E 95 ( P b ) = z 0.95 σ σ p b ¯ ¯ ≈ ≈ 1.96 p b ( 1 − − p b ) n = 0.87 / n = ± ± 2.7 % % {\displaystyle MOE_{95}(P_{b})=z_{0.95}\sigma _{\overline {p_{b}}}\approx 1.96{\sqrt {\frac {p_{b}(1-p_{b})}{n}}}=0.87/{\sqrt {n}}=\pm 2.7\%} M O E 95 ( P c ) = z 0.95 σ σ p c ¯ ¯ ≈ ≈ 1.96 p c ( 1 − − p c ) n = 0.27 / n = ± ± 0.8 % % {\displaystyle MOE_{95}(P_{c})=z_{0.95}\sigma _{\overline {p_{c}}}\approx 1.96{\sqrt {\frac {p_{c}(1-p_{c})}{n}}}=0.27/{\sqrt {n}}=\pm 0.8\%} As a given percentage approaches the extremes of 0% or 100%, its margin of error approaches ±0%.

Comparing percentages [ edit ] Imagine multiple-choice poll P {\displaystyle P} reports p a , p b , p c {\displaystyle p_{a},p_{b},p_{c}} as 46 % % , 42 % % , 12 % % , n = 1013 {\displaystyle 46\%,42\%,12\%,n=1013} . As described above, the margin of error reported for the poll would typically be M O E 95 ( P a ) {\displaystyle MOE_{95}(P_{a})} , as p a {\displaystyle p_{a}} is closest to 50%. The popular notion of statistical tie or statistical dead heat, however, concerns itself not with the accuracy of the individual results, but with that of the ranking of the results. Which is in first?

If, hypothetically, we were to conduct a poll P {\displaystyle P} over subsequent samples of n {\displaystyle n} respondents (newly drawn from N {\displaystyle N} ), and report the result p w = p a − − p b {\displaystyle p_{w}=p_{a}-p_{b}} , we could use the standard error of difference to understand how p w 1 , p w 2 , p w 3 , … … {\displaystyle p_{w_{1}},p_{w_{2}},p_{w_{3}},\ldots } is expected to fall about p w ¯ ¯ {\displaystyle {\overline {p_{w}}}} .  For this, we need to apply the sum of variances to obtain a new variance, σ σ P w 2 {\displaystyle \sigma _{P_{w}}^{2}} , σ σ P w 2 = σ σ P a − − P b 2 = σ σ P a 2 + σ σ P b 2 − − 2 σ σ P a , P b = p a ( 1 − − p a ) + p b ( 1 − − p b ) + 2 p a p b {\displaystyle \sigma _{P_{w}}^{2}=\sigma _{P_{a}-P_{b}}^{2}=\sigma _{P_{a}}^{2}+\sigma _{P_{b}}^{2}-2\sigma _{P_{a},P_{b}}=p_{a}(1-p_{a})+p_{b}(1-p_{b})+2p_{a}p_{b}} where σ σ P a , P b = − − P a P b {\displaystyle \sigma _{P_{a},P_{b}}=-P_{a}P_{b}} is the covariance of P a {\displaystyle P_{a}} and P b {\displaystyle P_{b}} .

Thus (after simplifying), Standard error of difference = σ σ w ¯ ¯ ≈ ≈ σ σ P w 2 n = p a + p b − − ( p a − − p b ) 2 n = 0.029 , P w = P a − − P b {\displaystyle {\text{Standard error of difference}}=\sigma _{\overline {w}}\approx {\sqrt {\frac {\sigma _{P_{w}}^{2}}{n}}}={\sqrt {\frac {p_{a}+p_{b}-(p_{a}-p_{b})^{2}}{n}}}=0.029,P_{w}=P_{a}-P_{b}} M O E 95 ( P a ) = z 0.95 σ σ p a ¯ ¯ ≈ ≈ ± ± 3.1 % % {\displaystyle MOE_{95}(P_{a})=z_{0.95}\sigma _{\overline {p_{a}}}\approx \pm {3.1\%}} M O E 95 ( P w ) = z 0.95 σ σ w ¯ ¯ ≈ ≈ ± ± 5.8 % % {\displaystyle MOE_{95}(P_{w})=z_{0.95}\sigma _{\overline {w}}\approx \pm {5.8\%}} Note that this assumes that P c {\displaystyle P_{c}} is close to constant, that is, respondents choosing either A or B would almost never choose C (making P a {\displaystyle P_{a}} and P b {\displaystyle P_{b}} close to perfectly negatively correlated ). With three or more choices in closer contention, choosing a correct formula for σ σ P w 2 {\displaystyle \sigma _{P_{w}}^{2}} becomes more complicated.

Effect of finite population size [ edit ] The formulae above for the margin of error assume that there is an infinitely large population and thus do not depend on the size of population N {\displaystyle N} , but only on the sample size n {\displaystyle n} . According to sampling theory , this assumption is reasonable when the sampling fraction is small. The margin of error for a particular sampling method is essentially the same regardless of whether the population of interest is the size of a school, city, state, or country, as long as the sampling fraction is small.

In cases where the sampling fraction is larger (in practice, greater than 5%), analysts might adjust the margin of error using a finite population correction to account for the added precision gained by sampling a much larger percentage of the population. FPC can be calculated using the formula [ 2 ] FPC = N − − n N − − 1 {\displaystyle \operatorname {FPC} ={\sqrt {\frac {N-n}{N-1}}}} ...and so, if poll P {\displaystyle P} were conducted over 24% of, say, an electorate of 300,000 voters, M O E 95 ( 0.5 ) = z 0.95 σ σ p ¯ ¯ ≈ ≈ 0.98 72 , 000 = ± ± 0.4 % % {\displaystyle MOE_{95}(0.5)=z_{0.95}\sigma _{\overline {p}}\approx {\frac {0.98}{\sqrt {72,000}}}=\pm 0.4\%} M O E 95 F P C ( 0.5 ) = z 0.95 σ σ p ¯ ¯ N − − n N − − 1 ≈ ≈ 0.98 72 , 000 300 , 000 − − 72 , 000 300 , 000 − − 1 = ± ± 0.3 % % {\displaystyle MOE_{95_{FPC}}(0.5)=z_{0.95}\sigma _{\overline {p}}{\sqrt {\frac {N-n}{N-1}}}\approx {\frac {0.98}{\sqrt {72,000}}}{\sqrt {\frac {300,000-72,000}{300,000-1}}}=\pm 0.3\%} Intuitively, for appropriately large N {\displaystyle N} , lim n → → 0 N − − n N − − 1 ≈ ≈ 1 {\displaystyle \lim _{n\to 0}{\sqrt {\frac {N-n}{N-1}}}\approx 1} lim n → → N N − − n N − − 1 = 0 {\displaystyle \lim _{n\to N}{\sqrt {\frac {N-n}{N-1}}}=0} In the former case, n {\displaystyle n} is so small as to require no correction. In the latter case, the poll effectively becomes a census and sampling error becomes moot.

See also [ edit ] Engineering tolerance Key relevance Measurement uncertainty Random error References [ edit ] ^ Siegfried, Tom (2014-07-03).

"Scientists' grasp of confidence intervals doesn't inspire confidence | Science News" .

Science News . Retrieved 2024-08-06 .

^ Isserlis, L. (1918).

"On the value of a mean as calculated from a sample" .

Journal of the Royal Statistical Society .

81 (1). Blackwell Publishing: 75– 81.

doi : 10.2307/2340569 .

JSTOR 2340569 .

(Equation 1) Sources [ edit ] Sudman, Seymour and Bradburn, Norman (1982).

Asking Questions: A Practical Guide to Questionnaire Design . San Francisco: Jossey Bass.

ISBN 0-87589-546-8 Wonnacott, T.H.; R.J. Wonnacott (1990).

Introductory Statistics (5th ed.). Wiley.

ISBN 0-471-61518-8 .

External links [ edit ] Wikibooks has more on the topic of: Margin of error "Errors, theory of" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] Weisstein, Eric W.

"Margin of Error" .

MathWorld .

Retrieved from " https://en.wikipedia.org/w/index.php?title=Margin_of_error&oldid=1291130091 " Categories : Error Measurement Sampling (statistics) Statistical deviation and dispersion Statistical intervals Hidden categories: Articles with short description Short description matches Wikidata Articles lacking in-text citations from November 2021 All articles lacking in-text citations This page was last edited on 19 May 2025, at 07:51 (UTC) .

Text is available under the Creative Commons Attribution-ShareAlike 4.0 License ;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy . Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Search Search Toggle the table of contents Margin of error 23 languages Add topic

